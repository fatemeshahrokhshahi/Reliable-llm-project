{
  "metadata": {
    "total_records": 1701,
    "sources": {
      "springer": 100,
      "ieee": 601,
      "arxiv": 1000
    },
    "creation_date": "2025-01-03 22:14:13",
    "fields": [
      "source",
      "identifier",
      "title",
      "abstract",
      "subjects"
    ]
  },
  "data": [
    {
      "source": "Springer",
      "identifier": "10.1007/s11930-024-00397-y",
      "title": "The Impact of Artificial Intelligence on Human Sexuality: A Five-Year Literature Review 2020–2024",
      "abstract": "Purpose of Review Millions of people now use generative artificial intelligence (GenAI) tools in their daily lives for a variety of purposes, including sexual ones. This narrative literature review provides the first scoping overview of current research on generative AI use in the context of sexual health and behaviors. Recent Findings The review includes 88 peer-reviewed English language publications from 2020 to 2024 that report on 106 studies and address four main areas of AI use in sexual health and behaviors among the general population: (1) People use AI tools such as ChatGPT to obtain sexual information and education. We identified k  = 14 publications that evaluated the quality of AI-generated sexual health information. They found high accuracy and completeness. (2) People use AI tools such as ChatGPT and dedicated counseling/therapy chatbots to solve their sexual and relationship problems. We identified k  = 16 publications providing empirical results on therapists’ and clients’ perspectives and AI tools’ therapeutic capabilities with mixed but overall promising results. (3) People use AI tools such as companion and adult chatbots (e.g., Replika) to experience sexual and romantic intimacy. We identified k  = 22 publications in this area that confirm sexual and romantic gratifications of AI conversational agents, but also point to risks such as emotional dependence. (4) People use image- and video-generating AI tools to produce pornography with different sexual and non-sexual motivations. We found k  = 36 studies on AI pornography that primarily address the production, uses, and consequences of – as well as the countermeasures against – non-consensual deepfake pornography. This sort of content predominantly victimizes women and girls whose faces are swapped into pornographic material and circulated without their consent. Research on ethical AI pornography is largely missing. Summary Generative AI tools present new risks and opportunities for human sexuality and sexual health. More research is needed to better understand the intersection of GenAI and sexuality in order to a) help people navigate their sexual GenAI experiences, b) guide sex educators, counselors, and therapists on how to address and incorporate AI tools into their professional work, c) advise AI developers on how to design tools that avoid harm, d) enlighten policymakers on how to regulate AI for the sake of sexual health, and e) inform journalists and knowledge workers on how to report about AI and sexuality in an evidence-based manner.",
      "subjects": [
        "Medicine & Public Health",
        "Urology",
        "Endocrinology",
        "Urology",
        "Endocrinology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s13280-024-02086-5",
      "title": "Reaping what we sow: Centering values in food systems transformations research",
      "abstract": "In many transdisciplinary research settings, a lack of attention to the values underpinning project aims can inhibit stakeholder engagement and ultimately slow or undermine project outcomes. As a research collective (The Careoperative), we have developed a set of four shared values through a facilitated visioning process, as central to the way we work together: care, reflexivity, inclusivity, and collectivity. In this paper, we explore the implications of a values-centered approach to collaboration in food system transformation research. The paper presents two cases that illustrate how researchers might approach centering values in practice. Where much research on food system transformation focuses on values of food system stakeholders, we contribute insights into the values of researchers in such transdisciplinary endeavors. Specifically, we argue that researchers working on sustainability transformations need to be better prepared to engage in such reflections and aspire to embody values aligned with the transformations they seek to research.",
      "subjects": [
        "Environment",
        "Environment, general",
        "Ecology",
        "Atmospheric Sciences",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology",
        "Environmental Sciences",
        "Ecology",
        "Atmospheric Science",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s12083-024-01826-4",
      "title": "A multi-cycle recursive clustering algorithm for the analysis of social media data streams",
      "abstract": "Events are usually embedded in latent topics and the extraction of these latent topics are enabled by event detection algorithms. Unsupervised algorithms like Clustering algorithms are very useful for detecting events but with requirements which may not be relevant or easy to determine when using unstructured textual social media data. For instance, some algorithms are required to be used on specific data shapes, but determining the shape of an unstructured data may not be practical aside from the high level of noise in the data. Many of the existing algorithms work well with structured data, however, some of these algorithms can be adapted to unstructured data with the caveat that cluster formations may not contain consistent contextual information. We propose a novel Multi-Cycle Recursive Clustering Algorithm (MCRCA), able to sequentially eliminate noise, resulting in high homogeneous cluster formations. MCRCA does not require the initial specification of clusters numbers as the estimated number of clusters can be deduced at convergence. Our algorithm out-performs the classical LDA and K-Means algorithms in forming highly homogeneous clusters, context-wise.",
      "subjects": [
        "Engineering",
        "Communications Engineering, Networks",
        "Information Systems and Communication Service",
        "Computer Communication Networks",
        "Signal,Image and Speech Processing",
        "Communications Engineering, Networks",
        "Computer Engineering and Networks",
        "Computer Communication Networks",
        "Signal, Speech and Image Processing"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s13280-024-02083-8",
      "title": "Geodesign to advance boundary work in urban planning: A study in Stockholm focused on nature-based solutions",
      "abstract": "Geodesign supports collaborative urban planning by managing ‘boundaries’ between diverse knowledge holders. However, there is a paucity of empirical evidence of its contribution to ‘boundary work’. This paper aims to evaluate how a geodesign process facilitates knowledge co-production through boundary work and to assess the scientific credibility, political saliency, and procedural legitimacy of its outputs in urban planning. We propose a replicable geodesign framework to assess boundary work, and test it in a case study on urban transformations with nature-based solutions in the Skarpnäck district of Stockholm, Sweden. Findings indicate that all geodesign steps facilitated communication by promoting collective reasoning. Participants acknowledged contributions to knowledge co-production and decision-making by mediating between different perspectives. However, data quality and modeling simplicity were identified as critical factors affecting the outputs’ perceived credibility. Future applications should include co-designing the geodesign process, improving capacity and skills, and facilitating more integrated planning.",
      "subjects": [
        "Environment",
        "Environment, general",
        "Ecology",
        "Atmospheric Sciences",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology",
        "Environmental Sciences",
        "Ecology",
        "Atmospheric Science",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s10695-024-01418-2",
      "title": "Evaluation of carp sperm respiration: fluorometry with optochemical oxygen sensor versus polarography",
      "abstract": "The primary function of spermatozoa is to fertilize the oocyte, which depends on their motility and is directly associated with their metabolic state. The oxygen consumption rate (OCR) of spermatozoa reflects the respiratory capacity of sperm mitochondria under various physiological conditions and is an essential marker of sperm quality. We determined the OCR of common carp ( Cyprinus carpio ) sperm using two respirometry methods: the conventionally used polarographic method with a Clark-type electrode and fluorometric assay with an Oxo Dish optochemical oxygen sensor. The latter was used for the first time to evaluate spermatozoa oxygen consumption in various metabolic states (under different treatments) at different dilution rates. These two methods were compared using Bland–Altman analysis, and the applicability of the optochemical oxygen sensor for evaluating carp sperm oxygen consumption was discussed. Sperm motility and progressive velocity parameters were also assessed to evaluate the effect of sperm respiration under different metabolic states and dilution rates and preincubation period on the physiological status of spermatozoa. The comparison of these respirometry methods clearly shows that while the polarographic method allows immediate measurement of oxygen levels after adding a sperm sample, the optochemical oxygen sensor has a priority in the amount of data obtained due to simultaneous measurements of several samples (e.g., different males, different fish species, repetitions of the same sample or various experimental conditions), even at a later time after adding sperm to the measuring chamber. However, the compared methods are complementary, and the proposed methodology can be applied to other fish species.",
      "subjects": [
        "Life Sciences",
        "Freshwater & Marine Ecology",
        "Animal Physiology",
        "Animal Anatomy / Morphology / Histology",
        "Animal Biochemistry",
        "Zoology",
        "Freshwater and Marine Ecology",
        "Animal Physiology",
        "Animal Anatomy",
        "Chemical Biology",
        "Zoology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s13280-024-02091-8",
      "title": "A conceptual framework of indicators for the suitability of forests for outdoor recreation",
      "abstract": "Forests’ ability to provide opportunities for recreation is an important ecosystem service. This has prompted attempts to create indicators to assess forests' suitability for recreation, although hitherto with limited success. This study introduces a novel framework for indicators of potential and realised recreational values of forests, with a primary focus on Sweden and Fennoscandia. We divided forest attributes into intrinsic qualities (i.e. the structure and composition of the forest), extrinsic qualities (i.e. the location of the forest in relation to other components of the landscape), and facilitation qualities (i.e. the presence of recreational infrastructure). Using Fennoscandia as a case study, we performed a literature review to find specific indicators of recreational values, as well as evaluate the current availability of spatial data suitable to map the forest qualities on a national scale. The most important intrinsic quality we identified was tree size/age, whereas for extrinsic quality it was proximity to water. Systematic monitoring of recreational use is essential to estimate realised recreational values. The conceptual framework proved to be a valuable tool for identifying potential indicators, and applying it in other regions is likely to yield useful outcomes.",
      "subjects": [
        "Environment",
        "Environment, general",
        "Ecology",
        "Atmospheric Sciences",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology",
        "Environmental Sciences",
        "Ecology",
        "Atmospheric Science",
        "Physical Geography",
        "Environmental Management",
        "Environmental Engineering/Biotechnology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s13346-024-01679-7",
      "title": "3D printed microneedles: revamping transdermal drug delivery systems",
      "abstract": "One of the advancements of the transdermal drug delivery system (TDDS) is the development of microneedles (MNs). These micron-sized needles are used for delivering various types of drugs to address the disadvantage of other transdermal techniques as well as oral drug delivery systems. MNs have high patient acceptance due to self-administration with minimally invasive and pain compared to the parenteral drug delivery. Over the years, various methods have been adopted to evolve the MNs and make them more cost-effective, accurate, and suitable for multiple applications. One such method is the 3D printing of MNs. The development of MN platforms using 3D printing has been made possible by improved features like precision, printing resolution, and the feasibility of using low-cost raw materials. In this review, we have tried to explain various types of MNs, fabrication methods, materials used in the formulation of MNs, and the recent applications that utilize 3D-printed MNs.",
      "subjects": [
        "Biomedicine",
        "Pharmaceutical Sciences/Technology",
        "Pharmaceutics"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/s11071-024-10333-3",
      "title": "Exploring iterative and non-iterative Fourier series-based methods of control optimization in application to a discontinuous capsule drive model",
      "abstract": "The paper explains iterative and non-iterative approaches to control optimization with use of the Fourier series-based method. Both variants of the presented algorithm are used to numerically approximate optimal control of a discontinuous pendulum capsule drive. Firstly, the general algorithm and its two realizations (iterative and non-iterative) are presented. It is shown that the iterative variant assures non-decreasing quality of solutions in subsequent repetitions of the procedure and the background of such guarantees is explained. A numerical example follows: control of a self-propelled capsule drive is optimized using both approaches. Results are compared and discussed. It is expected that the presented methods can be useful in optimal control estimation for complex systems, particularly discontinuous ones.",
      "subjects": [
        "Physics",
        "Applications of Nonlinear Dynamics and Chaos Theory",
        "Statistical Physics and Dynamical Systems",
        "Classical Mechanics",
        "Vibration, Dynamical Systems, Control",
        "Multibody Systems and Mechanical Vibrations",
        "Classical Mechanics",
        "Mechanical Engineering",
        "Applied and Technical Physics"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1038/s41586-024-08168-4",
      "title": "Offline ensemble co-reactivation links memories across days",
      "abstract": "Memories are encoded in neural ensembles during learning^ 1 – 6 and are stabilized by post-learning reactivation^ 7 – 17 . Integrating recent experiences into existing memories ensures that memories contain the most recently available information, but how the brain accomplishes this critical process remains unclear. Here we show that in mice, a strong aversive experience drives offline ensemble reactivation of not only the recent aversive memory but also a neutral memory formed 2 days before, linking fear of the recent aversive memory to the previous neutral memory. Fear specifically links retrospectively, but not prospectively, to neutral memories across days. Consistent with previous studies, we find that the recent aversive memory ensemble is reactivated during the offline period after learning. However, a strong aversive experience also increases co-reactivation of the aversive and neutral memory ensembles during the offline period. Ensemble co-reactivation occurs more during wake than during sleep. Finally, the expression of fear in the neutral context is associated with reactivation of the shared ensemble between the aversive and neutral memories. Collectively, these results demonstrate that offline ensemble co-reactivation is a neural mechanism by which memories are integrated across days. In mice, a strong aversive experience drives offline ensemble reactivation of not only the recent aversive memory but also a neutral memory formed 2 days before, linking fear of the recent aversive memory to the previous neutral memory.",
      "subjects": [
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, multidisciplinary",
        "Life Sciences",
        "Physical Sciences",
        "Technology and Engineering",
        "Mathematics and Computing",
        "Humanities and Social Sciences"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1038/s41586-024-08279-y",
      "title": "Endogenous self-peptides guard immune privilege of the central nervous system",
      "abstract": "Despite the presence of strategically positioned anatomical barriers designed to protect the central nervous system (CNS), it is not entirely isolated from the immune system^ 1 , 2 . In fact, it remains physically connected to, and can be influenced by, the peripheral immune system^ 1 . How the CNS retains such responsiveness while maintaining an immunologically unique status remains an outstanding question. Here, in searching for molecular cues that derive from the CNS and enable its direct communication with the immune system, we identified an endogenous repertoire of CNS-derived regulatory self-peptides presented on major histocompatibility complex class II (MHC-II) molecules in the CNS and at its borders. During homeostasis, these regulatory self-peptides were found to be bound to MHC-II molecules throughout the path of lymphatic drainage from the brain to its surrounding meninges and its draining cervical lymph nodes. However, in neuroinflammatory disease, the presentation of regulatory self-peptides diminished. After boosting the presentation of these regulatory self-peptides, a population of suppressor CD4^+ T cells was expanded, controlling CNS autoimmunity in a CTLA-4- and TGFβ-dependent manner. CNS-derived regulatory self-peptides may be the molecular key to ensuring a continuous dialogue between the CNS and the immune system while balancing overt autoreactivity. This sheds light on how we conceptually think about and therapeutically target neuroinflammatory and neurodegenerative diseases. Central nervous system (CNS)-derived regulatory self-peptides are essential for maintaining a continuous dialogue between the CNS and the immune system while balancing overt autoreactivity.",
      "subjects": [
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, multidisciplinary",
        "Life Sciences",
        "Physical Sciences",
        "Technology and Engineering",
        "Mathematics and Computing",
        "Humanities and Social Sciences"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1038/s41586-024-08222-1",
      "title": "Gut microbiome strain-sharing within isolated village social networks",
      "abstract": "When humans assemble into face-to-face social networks, they create an extended social environment that permits exposure to the microbiome of others, thereby shaping the composition and diversity of the microbiome at individual and population levels^ 1 – 6 . Here we use comprehensive social network mapping and detailed microbiome sequencing data in 1,787 adults within 18 isolated villages in Honduras^ 7 to investigate the relationship between network structure and gut microbiome composition. Using both species-level and strain-level data, we show that microbial sharing occurs between many relationship types, notably including non-familial and non-household connections. Furthermore, strain-sharing extends to second-degree social connections, suggesting the relevance of a person’s broader network. We also observe that socially central people are more microbially similar to the overall village than socially peripheral people. Among 301 people whose microbiome was re-measured 2 years later, we observe greater convergence in strain-sharing in connected versus otherwise similar unconnected co-villagers. Clusters of species and strains occur within clusters of people in village social networks, meaning that social networks provide the social niches within which microbiome biology and phenotypic impact are manifested. An investigation into the relationship between network structure and gut microbiome composition among people living in 18 isolated Honduras villages reveals that strain-sharing can be mediated by complex, village-wide social interactions.",
      "subjects": [
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, Humanities and Social Sciences, multidisciplinary",
        "Science, multidisciplinary",
        "Life Sciences",
        "Physical Sciences",
        "Technology and Engineering",
        "Mathematics and Computing",
        "Humanities and Social Sciences"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6095-4_3",
      "title": "Cases",
      "abstract": "The case illustrates that the patentee’s possibilities to avoid exhaustion by tailoring the patent claims are limited. It is generally up to the patentee to define the product for which he claims protection. As long as the patent covers products which are available on the market, the patentee’s decision may be relevant for the question of exhaustion.",
      "subjects": [
        "Law",
        "Private International Law, International & Foreign Law, Comparative Law",
        "IT Law, Media Law, Intellectual Property",
        "History of China",
        "Private International Law, International and Foreign Law, Comparative Law",
        "IT Law, Media Law, Intellectual Property",
        "History of China"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-61194-0_1",
      "title": "Introduction",
      "abstract": "The IEA International Computer and Information Literacy Study (ICILS) investigates the capacities of young people to use information and communications technology (ICT) productively for a range of different purposes, in ways that go beyond a basic use of ICT. ICILS 2023 includes authentic computer? Based assessments that are administered to students in their eighth year of schooling. These generate data reflecting two dimensions of ICT? Related capacities: computer and information literacy (CIL); and computational thinking (CT). This chapter describes the place of ICILS as part of the history of IEA studies, the relationship between ICT and educational processes, as well as factors related to the pedagogical use of ICT, since the late? 1980s. The relevance of ICILS to supranational policy development and monitoring (such as by the United Nations and the European Commission) monitoring of digital skills) is discussed, as are national policy and program initiatives in CIL and CT education in ICILS countries. The chapter further includes a summary recent research publications using ICILS data. The chapter concludes with summary information describing the ICILS study design, including the study research questions, new areas of focus in the study and the target population definitions and sampling procedures.",
      "subjects": [
        "Education",
        "Education, general",
        "International and Comparative Education",
        "Digital Education and Educational Technology",
        "Assessment and Testing",
        "International and Comparative Education"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_24",
      "title": "A Pyramid Of (Formal) Software Verification",
      "abstract": "Over the past few years there has been significant progress in the various fields of software verification resulting in many useful tools and successful deployments, both academic and commercial. However much of the work describing these tools and ideas is written by and for the research community. The scale, diversity and focus of the literature can act as a barrier, separating industrial users and the wider academic community from the tools that could make their work more efficient, more certain and more productive. This tutorial gives a simple classification of verification techniques in terms of a pyramid and uses it to describe the six main schools of verification technologies. We have found this approach valuable for building collaborations with industry as it allows us to explain the intrinsic strengths and weaknesses of techniques and pick the right tool for any given industrial application. The model also highlights some of the cultural differences and unspoken assumptions of different areas of verification and illuminates future directions.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-61194-0_3",
      "title": "Computational Thinking Framework",
      "abstract": "The International Computer and Information Literacy Study (ICILS) 2023 computational thinking (CT) framework delves into the evolving concept of CT within the context of educational curricula. The chapter traces the history of CT, from its early conceptualizations focusing on logical reasoning and programming, to the advent of block-based coding platforms like Scratch and Blockly, which have made coding more accessible. It also discusses the integration of CT in the International Computer and Information Literacy Study (ICILS) and the development of an internationally comparable CT scale. The chapter further explores the differing perspectives on CT, ranging from viewing it as a subset of computer science to recognizing its broader problem-solving applications. We present and discuss various definitions of CT and the constituent components identified in the literature, underscoring the diversity of interpretations and representations of CT.The framework for ICILS 2023 CT is presented in detail, including its structure, strands, aspects, and the underlying rationale. We emphasize the importance of understanding and framing real-world problems for computational formulation, alongside the development of algorithmic solutions operationalizable by computers. The chapter concludes with insights into the future directions of CT assessment and its potential implications for educational practices and policies.",
      "subjects": [
        "Education",
        "Education, general",
        "International and Comparative Education",
        "Digital Education and Educational Technology",
        "Assessment and Testing",
        "International and Comparative Education"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_6",
      "title": "GigaVision: When Computer Vision Meets Gigapixel Videography",
      "abstract": "In previous chapters, we have explored advanced plenoptic imaging and reconstruction techniques, enabling images and videos to reach gigapixel-level resolution. This breakthrough unlocks new possibilities for a wide range of applications and industries. However, traditional computer vision methods, tailored for megapixel-level data, are ill-equipped to handle the complexities of gigapixel-level data, which often feature large-scale scenes with hundreds of objects and intricate interactions. As a result, these methods face significant limitations in both precision and efficiency.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_5",
      "title": "Toward Large-Scale Plenoptic Reconstruction",
      "abstract": "Reconstructing real-world scenes with unparalleled levels of realism and detail has been a long-standing goal in the fields of computer vision and graphics. Achieving this goal necessitates coordinated efforts in both sensing techniques and plenoptic reconstruction algorithms.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_32",
      "title": "The Java Verification Tool KeY:A Tutorial",
      "abstract": "The KeY tool is a state-of-the-art deductive program verifier for the Java language. Its verification engine is based on a sequent calculus for dynamic logic, realizing forward symbolic execution of the target program, whereby all symbolic paths through a program are explored. Method contracts make verification scalable. KeY combines auto-active and fine-grained proof interaction, which is possible both at the level of the verification target and its specification, as well as at the level of proof rules and program logic. This makes KeY well-suited for teaching program verification, but also permits proof debugging at the source code level. The latter made it possible to verify some of the most complex Java code to date. The article provides a self-contained introduction to the working principles and the practical usage of KeY for anyone with basic knowledge in logic and formal methods.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_11",
      "title": "Efficient Formally Verified Maximal End Component Decomposition for MDPs",
      "abstract": "Identifying a Markov decision process’s maximal end components is a prerequisite for applying sound probabilistic model checking algorithms. In this paper, we present the first mechanized correctness proof of a maximal end component decomposition algorithm, which is an important algorithm in model checking, using the Isabelle/HOL theorem prover. We iteratively refine the high-level algorithm and proof into an imperative LLVM bytecode implementation that we integrate into the Modest Toolset ’s existing mcsta model checker. We bring the benefits of interactive theorem proving into practice by reducing the trusted code base of a popular probabilistic model checker and we experimentally show that our new verified maximal end component decomposition in mcsta performs on par with the tool’s previous unverified implementation.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_33",
      "title": "Parameterized Verification of Round-Based Distributed Algorithms via Extended Threshold Automata",
      "abstract": "Threshold automata are a computational model that has proven to be versatile in modeling threshold-based distributed algorithms and enabling their completely automatic parameterized verification. We present novel techniques for the verification of threshold automata, based on well-structured transition systems, that allow us to extend the expressiveness of both the computational model and the specifications that can be verified. In particular, we extend the model to allow decrements and resets of shared variables, possibly on cycles, and the specifications to general coverability. While these extensions of the model in general lead to undecidability, our algorithms provide a semi-decision procedure. We demonstrate the benefit of our extensions by showing that we can model complex round-based algorithms such as the phase king consensus algorithm and the Red Belly Blockchain protocol (published in 2019), and verify them fully automatically for the first time.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-60931-2_1",
      "title": "From Science to Society: The Open Science and Innovation and Network Approach",
      "abstract": "Public investment in fundamental scientific research generates societal benefits (Mazzucato in Public Aff, 2018 [ 1 ]; Barrett et al. in Why basic science matters for economic growth. Public investment in basic research will pay for itself. International Monetary Fund Blog, 2011 [ 2 ]; Zuniga and Wunsch-Vincent in Harnessing the benefits of publicly-funded research. WIPO Magazine, 2012 [ 3 ]; Adams in Calif Manage Rev 48(1):29–51, 2005 [ 4 ]; European Physical Society in Physics and the economy. Report. Centre for Economics and Business Research, 2019 [ 5 ]). At first sight it seems counterintuitive that public funding of a curiosity driven activity that does not address immediate societal challenges or urgent needs can produce wealth and be even long-term sustainable. We are rather tempted to argue that on the contrary, only applied research and targeted investments such as for instance addressing climate change, advancing microelectronics, increasing the effectiveness of battery-based energy storage or the developments of space technologies can satisfy this criterion. It is important to engage both, public and private funds to address such challenges, but science is a key ingredient to come up with the truly disruptive solutions. The funds required to address grand challenges call for globally concerted approaches over several decades with effects that will become only visible after several generations. Funding alone will, however, not be sufficient to effectively respond to societal challenges. Looking at the private sector, it turns out that a significant share of high-tech companies are ultimately results of initial public funding for curiosity driven scientific research.",
      "subjects": [
        "Physics",
        "Particle and Nuclear Physics",
        "Economic Growth",
        "Investment Appraisal",
        "Data Structures and Information Theory",
        "Artificial Intelligence",
        "Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)",
        "Nuclear and Particle Physics",
        "Economic Development, Innovation and Growth",
        "Investment Appraisal",
        "Data Science",
        "Space Physics",
        "Measurement Science and Instrumentation"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-72848-8_6",
      "title": "MART: MultiscAle Relational Transformer Networks for Multi-agent Trajectory Prediction",
      "abstract": "Multi-agent trajectory prediction is crucial to autonomous driving and understanding the surrounding environment. Learning-based approaches for multi-agent trajectory prediction, such as primarily relying on graph neural networks, graph transformers, and hypergraph neural networks, have demonstrated outstanding performance on real-world datasets in recent years. However, the hypergraph transformer-based method for trajectory prediction is yet to be explored. Therefore, we present a M ultisc A le R elational T ransformer ( MART ) network for multi-agent trajectory prediction. MART is a hypergraph transformer architecture to consider individual and group behaviors in transformer machinery. The core module of MART is the encoder, which comprises a Pair-wise Relational Transformer (PRT) and a Hyper Relational Transformer (HRT). The encoder extends the capabilities of a relational transformer by introducing HRT, which integrates hyperedge features into the transformer mechanism, promoting attention weights to focus on group-wise relations. In addition, we propose an Adaptive Group Estimator (AGE) designed to infer complex group relations in real-world environments. Extensive experiments on three real-world datasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves state-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA dataset. Code is available at https://github.com/gist-ailab/MART .",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Image Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73257-7_16",
      "title": "Large and Parallel Human Sorting Networks",
      "abstract": "This paper presents two innovative extensions of the classic Human Sorting Network (HSN) activity from the CS Unplugged program. First, we describe the implementation of a large-scale HSN with 50 input nodes, realized with high school students in Vienna, Austria. We detail the logistical challenges and solutions for creating an HSN of this magnitude, including location selection, network layout, and participant coordination. Second, we report on using parallel 6-input HSNs, which introduce a competitive element and enhance engagement. This parallel setup allows for races between teams and can be adapted for various age groups and knowledge levels. Both extensions aim to increase the educational impact and enjoyment of the HSN activity. We provide comprehensive insights into our experiences, enabling other educators and researchers to replicate or further develop these HSN variants.",
      "subjects": [
        "Computer Science",
        "Computer Science, general",
        "Mathematics of Computing",
        "Computer Applications",
        "Computers and Education",
        "Computer Science",
        "Mathematics of Computing",
        "Computer and Information Systems Applications",
        "Computers and Education"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_14",
      "title": "Reusable Specification Patterns for Verification of Resilience in Autonomous Hybrid Systems",
      "abstract": "Autonomous hybrid systems are systems that combine discrete and continuous behavior with autonomous decision-making, e.g., using reinforcement learning. Such systems are increasingly used in safety-critical applications such as self-driving cars, autonomous robots or water supply systems. Thus, it is crucial to ensure their safety and resilience, i.e., that they function correctly even in the presence of dynamic changes and disruptions. In this paper, we present an approach to obtain formal resilience guarantees for autonomous hybrid systems using the interactive theorem prover KeYmaera X. Our key ideas are threefold: First, we derive a formalization of resilience that is tailored to autonomous hybrid systems. Second, we present reusable patterns for modeling stressors, detecting disruptions, and specifying resilience as a service level response in the differential dynamic logic (d $$\\mathcal {L}$$ L ). Third, we combine these concepts with an existing approach for the safe integration of learning components using hybrid contracts, and extend it towards dynamic adaptations to stressors. By combining reusable patterns for stressors, observers, and adaptation contracts for learning components, we provide a systematic approach for the deductive verification of resilience of autonomous hybrid systems with reduced specification effort. We demonstrate the applicability of our approach with two case studies, an autonomous robot and an intelligent water distribution system.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_31",
      "title": "Satisfiability Modulo Theories: A Beginner’s Tutorial",
      "abstract": "Great minds have long dreamed of creating machines that can function as general-purpose problem solvers. Satisfiability modulo theories (SMT) has emerged as one pragmatic realization of this dream, providing significant expressive power and automation. This tutorial is a beginner’s guide to SMT. It includes an overview of SMT and its formal foundations, a catalog of the main theories used in SMT solvers, and illustrations of how to obtain models and proofs. Throughout the tutorial, examples and exercises are provided as hands-on activities for the reader. They can be run using either Python or the SMT-LIB language, using either the cvc5 or the Z3 SMT solver.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_4",
      "title": "Plenoptic Reconstruction",
      "abstract": "Empowered by advanced plenoptic sensing systems, light-field imaging becomes one of the most extensively used methods for capturing 3D views of a scene. In contrast to the traditional input to a 3D graphics system, namely, scenes consisting of pre-defined geometric primitives with different materials and sets of lights, the input to a light field is only a set of 2D images which are informative and cost effective. Unfortunately, due to the limited sensor resolution, existing systems must balance the spatial and angular resolution, i.e., one can obtain dense sampling images in the spatial dimension but only sparse sampling images in the angular (viewing angle) dimension or vice versa.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_28",
      "title": "Proving Functional Program Equivalence via Directed Lemma Synthesis",
      "abstract": "Proving equivalence between functional programs is a fundamental problem in program verification, which often amounts to reasoning about algebraic data types (ADTs) and compositions of structural recursions . Modern theorem provers provide structural induction for such reasoning, but a structural induction on the original theorem is often insufficient for many equivalence theorems. In such cases, one has to invent a set of lemmas, prove these lemmas by additional induction, and use these lemmas to prove the original theorem. There is, however, a lack of systematic understanding of what lemmas are needed for inductive proofs and how these lemmas can be synthesized automatically. This paper presents directed lemma synthesis , an effective approach to automating equivalence proofs by discovering critical lemmas using program synthesis techniques. We first identify two induction-friendly forms of propositions that give formal guarantees to the progress of the proof. We then propose two tactics that synthesize and apply lemmas, thereby transforming the proof goal into induction-friendly forms. Both tactics reduce lemma synthesis to a set of independent and typically small program synthesis problems that can be efficiently solved. Experimental results demonstrate the effectiveness of our approach: Compared to state-of-the-art equivalence checkers employing heuristic-based lemma enumeration, directed lemma synthesis saves 95.47% runtime on average and solves 38 more tasks over an extended version of the standard benchmark set.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_7",
      "title": "Automated Static Analysis of Quality of Service Properties of Communicating Systems",
      "abstract": "We present , a bounded to statically analyse Quality of Service ( ) properties of message-passing systems. We consider QoS properties on measurable application-level attributes as well as resource consumption metrics, for example, those relating monetary cost to memory usage. The applicability of is evaluated through case studies and experiments. A first case study is based on the AWS cloud while a second one analyses a communicating system automatically extracted from code. Additionally, we consider synthetically generated experiments to assess the scalability of . These experiments showed that our model can faithfully capture and effectively analyse QoS properties in industrial-strength scenarios.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_5",
      "title": "Nonlinear Craig Interpolant Generation Over Unbounded Domains by Separating Semialgebraic Sets",
      "abstract": "Interpolation-based techniques become popular in recent years, as they can improve the scalability of existing verification techniques due to their inherent modularity and local reasoning capabilities. Synthesizing Craig interpolants is the cornerstone of these techniques. In this paper, we investigate nonlinear Craig interpolant synthesis for two polynomial formulas of the general form, essentially corresponding to the underlying mathematical problem to separate two disjoint semialgebraic sets. By combining the homogenization approach with existing techniques, we prove the existence of a novel class of non-polynomial interpolants called semialgebraic interpolants. These semialgebraic interpolants subsume polynomial interpolants as a special case. To the best of our knowledge, this is the first existence result of this kind. Furthermore, we provide complete sum-of-squares characterizations for both polynomial and semialgebraic interpolants, which can be efficiently solved as semidefinite programs. Examples are provided to demonstrate the effectiveness and efficiency of our approach.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_30",
      "title": "Misconceptions in Finite-Trace and Infinite-Trace Linear Temporal Logic",
      "abstract": "With the growing use of temporal logics in areas ranging from robot planning to runtime verification, it is critical that users have a clear understanding of what a specification means. Toward this end, we have been developing a catalog of semantic errors and a suite of test instruments targeting various user-groups. The catalog is of interest to educators, to logic designers, to formula authors, and to tool builders, e.g., to identify mistakes. The test instruments are suitable for classroom teaching or self-study. This paper reports on five sets of survey data collected over a three-year span. We study misconceptions about finite-trace $$\\textsc {ltl}_{f}$$ L T L f in three ltl -aware audiences, and misconceptions about standard ltl in novices. We find several mistakes, even among experts. In addition, the data supports several categories of errors in both $$\\textsc {ltl}_{f}$$ L T L f and ltl that have not been identified in prior work. These findings, based on data from actual users, offer insights into what specific ways temporal logics are tricky and provide a groundwork for future interventions.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-75387-9_1",
      "title": "QuAK: Quantitative Automata Kit",
      "abstract": "System behaviors are traditionally evaluated through binary classifications of correctness, which do not suffice for properties involving quantitative aspects of systems and executions. Quantitative automata offer a more nuanced approach, mapping each execution to a real number by incorporating weighted transitions and value functions generalizing acceptance conditions. In this paper, we introduce QuAK, the first tool designed to automate the analysis of quantitative automata. QuAK currently supports a variety of quantitative automaton types, including $${\\textsf{Inf}}$$ Inf , $${\\textsf{Sup}}$$ Sup , $${\\textsf{LimInf}}$$ LimInf , $${\\textsf{LimSup}}$$ LimSup , $${\\textsf{LimInfAvg}}$$ LimInfAvg , and $${\\textsf{LimSupAvg}}$$ LimSupAvg automata, and implements decision procedures for problems such as emptiness, universality, inclusion, equivalence, as well as for checking whether an automaton is safe, live, or constant. Additionally, QuAK is able to compute extremal values when possible, construct safety-liveness decompositions, and monitor system behaviors. We demonstrate the effectiveness of QuAK through experiments focusing on the inclusion, constant-function check, and monitoring problems.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Mathematical Logic and Formal Languages",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Control Structures and Microprogramming",
        "Software Engineering",
        "Formal Languages and Automata Theory",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Control Structures and Microprogramming"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_23",
      "title": "Accurate Static Data Race Detection for C",
      "abstract": "Data races are a particular kind of subtle, unintended program behaviour arising from thread interference in shared-memory concurrency. In this paper, we propose an automated technique for static detection of data races in multi-threaded C programs with POSIX threads. The key element of our technique is a reduction to reachability. Our prototype implementation combines such reduction with context-bounded analysis. The approach proves competitive against state-of-the-art tools, finding new issues in the implementation of well-known lock-free data structures, and shows a considerably superior accuracy of analysis in the presence of complex shared-memory access patterns.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_15",
      "title": "Switching Controller Synthesis for Hybrid Systems Against STL Formulas",
      "abstract": "Switching controllers play a pivotal role in directing hybrid systems (HSs) towards the desired objective, embodying a “correct-by-construction” approach to HS design. Identifying these objectives is thus crucial for the synthesis of effective switching controllers. While most of existing works focus on safety and liveness, few of them consider timing constraints. In this paper, we delves into the synthesis of switching controllers for HSs that meet system objectives given by a fragment of STL, which essentially corresponds to a reach-avoid problem with timing constraints. Our approach involves iteratively computing the state sets that can be driven to satisfy the reach-avoid specification with timing constraints. This technique supports to create switching controllers for both constant and non-constant HSs. We validate our method’s soundness, and confirm its relative completeness for a certain subclass of HSs. Experiment results affirms the efficacy of our approach.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_15",
      "title": "Model Driven Development for AI-Based Healthcare Systems: A Review",
      "abstract": "We review our experience with integrating Artificial Intelligence (AI) into healthcare systems following the Model-Driven Development (MDD) approach. At a time when AI has the potential to instigate a paradigm shift in the health sector, better integrating healthcare experts in the development of these technologies is of paramount importance. We see MDD as a useful way to better embed non-technical stakeholders in the development process. The main goal of this review is to reflect on our experiences to date with MDD and AI in the context of developing healthcare systems. Four case studies that fall within that scope but have different profiles are introduced and summarised: the MyMM application for Multiple Myeloma diagnosis; CNN-HAR, that studies the ability to do AI on the edge for IoT-supported human activity recognition; the HIPPP web based portal for patient information in public health; and Cinco de Bio, a new model driven platform used for the first time to support a better cell-level understanding of diseases. Based on the aforementioned case studies we discuss the characteristics, the challenges faced and the postive outcomes achieved.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_21",
      "title": "\n              \n             A \n              \n            obustness \n              \n            fication Tool for \n              \n            uantum Machine Learning Models",
      "abstract": "Adversarial noise attacks present a significant threat to quantum machine learning (QML) models, similar to their classical counterparts. This is especially true in the current Noisy Intermediate-Scale Quantum era, where noise is unavoidable. Therefore, it is essential to ensure the robustness of QML models before their deployment. To address this challenge, we introduce VeriQR , the first tool designed specifically for formally verifying and improving the robustness of QML models, to the best of our knowledge. This tool mimics real-world quantum hardware’s noisy impacts by incorporating random noise to formally validate a QML model’s robustness. VeriQR supports exact (sound and complete) algorithms for both local and global robustness verification. For enhanced efficiency, it implements an under-approximate (complete) algorithm and a tensor network-based algorithm to verify local and global robustness, respectively. As a formal verification tool, VeriQR can detect adversarial examples and utilize them for further analysis and to enhance the local robustness through adversarial training, as demonstrated by experiments on real-world quantum machine learning models. Moreover, it permits users to incorporate customized noise. Based on this feature, we assess VeriQR using various real-world examples, and experimental outcomes confirm that the addition of specific quantum noise can enhance the global robustness of QML models. These processes are made accessible through a user-friendly graphical interface provided by VeriQR , catering to general users without requiring a deep understanding of the counter-intuitive probabilistic nature of quantum computing.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-64451-1_4",
      "title": "Processing Multimodal Information: Challenges and Solutions for Multimodal Sentiment Analysis and Hate Speech Detection",
      "abstract": "This chapter explores the challenges and solutions for processing multimodal information, specifically in the context of multimodal sentiment analysis and hate speech detection. The increasing amount of multimodal data, such as text, images and videos, presents unique challenges for machine learning algorithms. These challenges include the integration and fusion of information from multiple modalities to acquire the overall context. In this chapter, first, we present an overview of recent developments on multimodal learning techniques in the context of sentiment and hate speech detection; second, we present a multimodal model that combines different visual aspects and features for multimodal sentiment detection; and third, we present a multi-task multimodal model for misogyny detection in multimodal memes.",
      "subjects": [
        "Computer Science",
        "Data Structures and Information Theory",
        "Artificial Intelligence",
        "Data Mining and Knowledge Discovery",
        "Statistics, general",
        "Natural Language Processing (NLP)",
        "Digital/New Media",
        "Data Science",
        "Data Mining and Knowledge Discovery",
        "Data Analysis and Big Data",
        "Natural Language Processing (NLP)",
        "Digital and New Media"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_13",
      "title": "Fast Attack Graph Defense Localization via Bisimulation",
      "abstract": "System administrators, network engineers, and IT managers can learn much about the vulnerabilities of an organization’s cyber system by constructing and analyzing analytical attack graphs (AAGs). An AAG consists of logical rule nodes, fact nodes, and derived fact nodes. It provides a graph-based representation that describes ways by which an attacker can achieve progress towards a desired goal, a.k.a. a crown jewel. Given an AAG, different types of analyses can be performed to identify attacks on a target goal, measure the vulnerability of the network, and gain insights on how to make it more secure. However, as the size of the AAGs representing real-world systems may be very large, existing analyses are slow or practically impossible. In this paper, we introduce and show how to compute an AAG’s defense core : a locally minimal subset of the AAG’s rules whose removal will prevent an attacker from reaching a crown jewel. Most importantly, in order to scale-up the performance of the detection of a defense core, we introduce a novel application of the well-known notion of bisimulation to AAGs. Our experiments show that the use of bisimulation results in significantly smaller graphs and in faster detection of defense cores, making them practical.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-64451-1_11",
      "title": "Claim Detection in Social Media",
      "abstract": "In recent years, the problem of misinformation on the web has become widespread across languages, countries and various social media platforms. One problem central to stopping the spread of misinformation is identifying claims and prioritising them for fact-checking. Although there has been much work on automated claim detection from text recently, the role of images and their variety still need to be explored. As posts and content shared on social media are often multimodal, it has become crucial to view the problem of misinformation and fake news from a multimodal perspective. In this chapter, first, we present an overview of existing claim detection methods and their limitations; second, we present a unimodal approach to identify check-worthy claims; third, and lastly, we introduce a dataset that takes both the image and text into account for detecting claims and benchmark recent multimodal models on the task.",
      "subjects": [
        "Computer Science",
        "Data Structures and Information Theory",
        "Artificial Intelligence",
        "Data Mining and Knowledge Discovery",
        "Statistics, general",
        "Natural Language Processing (NLP)",
        "Digital/New Media",
        "Data Science",
        "Data Mining and Knowledge Discovery",
        "Data Analysis and Big Data",
        "Natural Language Processing (NLP)",
        "Digital and New Media"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_16",
      "title": "Learning Branching-Time Properties in CTL and ATL via Constraint Solving",
      "abstract": "We address the problem of learning temporal properties from the branching-time behavior of systems. Existing research in this field has mostly focused on learning linear temporal properties specified using popular logics, such as Linear Temporal Logic (LTL) and Signal Temporal Logic (STL). Branching-time logics such as Computation Tree Logic (CTL) and Alternating-time Temporal Logic (ATL), despite being extensively used in specifying and verifying distributed and multi-agent systems, have not received adequate attention. Thus, in this paper, we investigate the problem of learning CTL and ATL formulas from examples of system behavior. As input to the learning problems, we rely on the typical representations of branching behavior as Kripke structures and concurrent game structures, respectively. Given a sample of structures, we learn concise formulas by encoding the learning problem into a satisfiability problem, most notably by symbolically encoding both the search for prospective formulas and their fixed-point based model checking algorithms. We also study the decision problem of checking the existence of prospective ATL formulas for a given sample. We implement our algorithms in a Python prototype and have evaluated them to extract several common CTL and ATL formulas used in practical applications.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-75434-0_2",
      "title": "Certainty vs. Intelligence",
      "abstract": "Mathematical models can yield certainty, as can probabilistic models where the probabilities degenerate. The field of formal methods emphasizes developing such certainty about engineering designs. In safety-critical systems, such certainty is highly valued and, in some cases, even required by regulatory bodies. But achieving reasonable performance for sufficiently complex environments appears to require the use of AI technologies, which resist such certainty. This paper suggests that certainty and intelligence may be fundamentally incompatible. First, Bayes Theorem shows, rather trivially, that certainty implies an inability to learn when presented with new data. A more subtle issue, however, is that logic and mathematics, necessary for certainty, may be a result of intelligence rather than the foundations of intelligence. This paper makes the case that intelligence is an evolved form of prediction, that logic and mathematics were not discovered but rather were invented because of their predictive value, and that the certainty they can give us cannot be about systems that exhibit intelligence.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73039-9_7",
      "title": "Elucidating the Hierarchical Nature of Behavior with Masked Autoencoders",
      "abstract": "Natural behavior is hierarchical. Yet, there is a paucity of benchmarks addressing this aspect. Recognizing the scarcity of large-scale hierarchical behavioral benchmarks, we create a novel synthetic basketball playing benchmark (Shot7M2). Beyond synthetic data, we extend BABEL into a hierarchical action segmentation benchmark (hBABEL). Then, we develop a masked autoencoder framework (hBehaveMAE) to elucidate the hierarchical nature of motion capture data in an unsupervised fashion. We find that hBehaveMAE learns interpretable latents on Shot7M2 and hBABEL, where lower encoder levels show a superior ability to represent fine-grained movements, while higher encoder levels capture complex actions and activities. Additionally, we evaluate hBehaveMAE on MABe22, a representation learning benchmark with short and long-term behavioral states. hBehaveMAE achieves state-of-the-art performance without domain-specific feature extraction. Together, these components synergistically contribute towards unveiling the hierarchical organization of natural behavior. Models and benchmarks are available at https://github.com/amathislab/BehaveMAE .",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Image Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-3752-9_4",
      "title": "Human-Level Knowledge and Concept Acquisition",
      "abstract": "To increase productivity, it is expected that a single user is able to operate multiple cybernetic avatars (CAs). However, the limited attention span of the user makes it difficult to send direct instructions to all CAs. Therefore, this chapter describes the essential technologies for CAs that solve these problems and behave autonomously according to the user's intentions. First, the realization of spatio-temporal recognition capabilities that enable CAs to move autonomously in an environments that change from moment to moment is described. Following that, methods to implement continuous learning and memory mechanisms to facilitate acquired information reuse in the future are described. In general, the observed data are time series, and future predictions are important to provide appropriate support to users. The time series analysis method is then explained, which is the most important technology. Advanced natural language processing technology is necessary to capture intentions through dialogue with the user and to process large amounts of textual data as prior knowledge and common sense. Examples of the application of these fundamental technologies in the medical field are also presented.",
      "subjects": [
        "Computer Science",
        "User Interfaces and Human Computer Interaction",
        "Robotics",
        "User Interfaces and Human Computer Interaction",
        "Robotics"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-61194-0_2",
      "title": "Computer and Information Literacy Framework",
      "abstract": "The assessment of computer and information literacy (CIL) is at the core of the International Computer and Information Literacy Study (ICILS). In this chapter we define and describe the CIL construct that underpins the assessment used in ICILS. Computer and information literacy was first defined and described for use in ICILS 2013, and is reviewed at the beginning of each new ICILS cycle, with reference to developments in CIL-related research, policies and curriculums, and with respect to its operationalization in previous ICILS cycles. In the chapter we trace the history of the CIL construct from its origins in the second half of last century through to its contemporary instantiation as a combination of technological proficiency with facets of information literacy and communication. In ICILS, the term “Computer and Information Literacy” underscores the significance of internet-based information search and evaluation within the broader competency of utilizing contemporary technology. We continue with an explanation of the process of deriving the CIL construct definition and structure from preexisting and preeminent definitions of related constructs. We then describe the structure of the CIL constructs and elaborate on the content of the four strands divided into eight aspects that comprise the CIL construct.",
      "subjects": [
        "Education",
        "Education, general",
        "International and Comparative Education",
        "Digital Education and Educational Technology",
        "Assessment and Testing",
        "International and Comparative Education"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_4",
      "title": "DFAMiner: Mining Minimal Separating DFAs from Labelled Samples",
      "abstract": "We propose DFAMiner , a passive learning tool for learning minimal separating deterministic finite automata (DFA) from a set of labelled samples. Separating automata are an interesting class of automata that occurs generally in regular model checking and has raised interest in foundational questions of parity game solving. We first propose a simple and linear-time algorithm that incrementally constructs a three-valued DFA (3DFA) from a set of labelled samples given in the usual lexicographical order. This 3DFA has accepting and rejecting states as well as don’t-care states, so that it can exactly recognise the labelled examples. We then apply our tool to mining a minimal separating DFA for the labelled samples by minimising the constructed automata via a reduction to SAT solving. Empirical evaluation shows that our tool outperforms current state-of-the-art tools significantly on standard benchmarks for learning minimal separating DFAs from samples. Progress in the efficient construction of separating DFAs can also lead to finding the lower bound of parity game solving, where we show that DFAMiner can create optimal separating automata for simple languages with up to 7 colours. Future improvements might offer inroads to better data structures.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_16",
      "title": "On Completeness of SDP-Based Barrier Certificate Synthesis over Unbounded Domains",
      "abstract": "Barrier certificates, serving as differential invariants that witness system safety, play a crucial role in the verification of cyber-physical systems (CPS). Prevailing computational methods for synthesizing barrier certificates are based on semidefinite programming (SDP) by exploiting Putinar Positivstellensatz . Consequently, these approaches are limited by the Archimedean condition , which requires all variables to be bounded, i.e., systems are defined over bounded domains. For systems over unbounded domains, unfortunately, existing methods become incomplete and may fail to identify potential barrier certificates. In this paper, we address this limitation for the unbounded cases. We first give a complete characterization of polynomial barrier certificates by using homogenization , a recent technique in the optimization community to reduce an unbounded optimization problem to a bounded one. Furthermore, motivated by this formulation, we introduce the definition of homogenized systems and propose a complete characterization of a family of non-polynomial barrier certificates with more expressive power. Experimental results demonstrate that our two approaches are more effective while maintaining a comparable level of efficiency.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_9",
      "title": "B2SAT: A Bare-Metal Reduction of B to SAT",
      "abstract": "We present a new SAT backend for the B-Method to enable new applications of formal methods. The new backend interleaves low-level SAT solving with high-level constraint solving. It provides a “bare metal” access to SAT solving, while pre- and post-calculations can be done in the full B language, with access to higher-order or even infinite data values. The backend is integrated into ProB, not as a general purpose backend, but as a dedicated backend for solving hard constraint satisfaction and optimisation problems on complex data. In the article we present the approach, its origin in the proof of Cook’s theorem, and illustrate and evaluate it on a few novel applications of formal methods, ranging from biology to railway applications.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_18",
      "title": "CauMon: An Informative Online Monitor for Signal Temporal Logic",
      "abstract": "In this paper, we present a tool for monitoring the traces of cyber-physical systems (CPS) at runtime, with respect to Signal Temporal Logic (STL) specifications. Our tool is based on the recent advances of causation monitoring , which reports not only whether an executing trace violates the specification, but also how relevant the increment of the trace at each instant is to the specification violation. In this way, it can deliver more information about system evolution than classic online robust monitors. Moreover, by adapting two dynamic programming strategies, our implementation significantly improves the efficiency of causation monitoring, allowing its deployment in practice. The tool is implemented as a C++ executable and can be easily adapted to monitor CPS in different formalisms. We evaluate the efficiency of the proposed monitoring tool, and demonstrate its superiority over existing robust monitors in terms of the information it can deliver about system evolution.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_25",
      "title": "Detecting Speculative Execution Vulnerabilities on Weak Memory Models",
      "abstract": "Speculative execution attacks affect all modern processors and much work has been done to develop techniques for detection of associated vulnerabilities. Modern processors also operate on weak memory models which allow out-of-order execution of code. Despite this, there is little work on looking at the interplay between speculative execution and weak memory models. In this paper, we provide an information flow logic for detecting speculative execution vulnerabilities on weak memory models. The logic is general enough to be used with any modern processor, and designed to be extensible to allow detection of vulnerabilities to specific attacks. The logic has been proven sound with respect to an abstract model of speculative execution in Isabelle/HOL.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-64451-1_2",
      "title": "Multimodal Geolocation Estimation in News Documents",
      "abstract": "With the proliferation of news documents on the Internet, online news reading has become an important approach for information acquisition in people’s daily lives. There has, however, been increasing concern with the growing infusion of misinformation. As a complement to news text, associated photos provide readers with additional information to facilitate their ability to find the information they need. To contextualise the vast amount of news that is published worldwide, the geographic content is crucial. On the other hand, the geographic content plays an important role in news recommendation to facilitate user desires. Existing approaches for geolocation estimation are primarily based on either text or photos as separate tasks. However, news photos can lack geographical cues, and text can include multiple locations. Therefore, it is challenging to recognise the focus location of the news story based on only one modality. We introduce novel datasets for multimodal geolocation estimation of news documents. We evaluate current methods on the benchmark datasets and suggest new methods for news geolocalisation using textual and visual content. In addition, we introduce a news retrieval system called GeoWINE based on the geographic content of news photos to emphasise the importance of geolocation estimation in the news domain.",
      "subjects": [
        "Computer Science",
        "Data Structures and Information Theory",
        "Artificial Intelligence",
        "Data Mining and Knowledge Discovery",
        "Statistics, general",
        "Natural Language Processing (NLP)",
        "Digital/New Media",
        "Data Science",
        "Data Mining and Knowledge Discovery",
        "Data Analysis and Big Data",
        "Natural Language Processing (NLP)",
        "Digital and New Media"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_6",
      "title": "From Data Science to Modular Workflows Changing Perspectives from Data to Platform: DBDIrl 1864-1922 Case Study",
      "abstract": "Many historical data collections foot on handwritten documents and registers, whose consultation is often very difficult due to the conservation state of the physical artefacts, and whose comprehension is also made difficult by the handwriting, difficult to interpret, and the language used, different from the modern terminology. Therefore significant research efforts by historians, demographers, population health scientists and others have been started in the past with the aim of making such data collections digitally available, first on the basis of images and then as readily available repositories of transcribed data in electronically queryable formats. For the purpose of extracting data from the Irish Civil registers of deaths in the DBDIrl 1864-1922 project ( https://www.dbdirl.com ), an AI-ML Data Analytics Pipeline was proposed as a working approach validated on a subset of the data. However, the pipeline requires manual steps and it is not applicable as is on similar datasets without significant modifications to its inner workings. We are currently transforming this prototyped, single purpose product to a modular, fully automated workflow, intended to be used and reconfigured for new data in a low-code/no-code fashion by domain experts like historians. We explain our adopted analysis and refactoring process, illustrate it on part of the pipeline, including how we faced obstacles and handled pitfalls. We also evaluate its potential to become a methodical approach to transforming an interactive program to a fully automated process, in a low-code/no-code workflow style, that can be easily reused, reconfigured and extended to be able to tailor it to other datasets as needed.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-8727-2_2",
      "title": "Characteristics of Grey System Theory",
      "abstract": "Characteristics of grey system theory will be analyzed based on analysis of general characteristics of uncertain systems. Then, the simplicity principle of sciences will be introduced. Similarities and differences of several uncertainty methods, such as probability statistics, fuzzy mathematics, grey system theory and rough set theory will be analyzed. At last of the chapter, The author will showcase successful applications of grey system theory in the field of natural sciences, social sciences and engineering technologies.",
      "subjects": [
        "Business and Management",
        "Operations Research/Decision Theory",
        "Applied Statistics",
        "Operations Research, Management Science",
        "Operations Research and Decision Theory",
        "Applied Statistics",
        "Operations Research, Management Science"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-62634-0_14",
      "title": "Cognitive Mechanisms of Being Imitated",
      "abstract": "Being mimicked (BeMim) arises when one person copies the actions or choices of another person, and several studies link BeMim to liking and affiliation. BeMim effects might occur for matching of motor actions but have also been reported for the imitation of preferences and values. In this chapter we discuss various approaches to studying BeMim, from live interactions to controlled methods in the lab and from virtual reality to observation studies. We suggest that the fundamental cognitive mechanism that support BeMim effects is still unknown and it is not yet clear if various BeMim paradigms tap the same cognitive mechanisms. Three possible neurocognitive models of BeMim are considered: a specialized BeMim model, a universal model which is domain general based on cognitive predictability and a social learning model. The latter seems to be the most promising based on the current evidence. We highlight the non-monotonic character of the BeMim effects—there may be a “sweet spot” where BeMim has positive consequences but too much or too little mimicry can mean that the mimicker’s action is judged negatively rather than positively. People also dislike mimickers if they have awareness of being mimicking by them. Finally, we discuss the gaps in the BeMim literature that need to be addressed to move the BeMim field forward.",
      "subjects": [
        "Psychology",
        "Psychology, general",
        "Neuropsychology",
        "Clinical Psychology",
        "Cognitive Psychology",
        "Personality and Social Psychology",
        "Behavioral Sciences and Psychology",
        "Neuropsychology",
        "Clinical Psychology",
        "Cognitive Psychology",
        "Social Psychology"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_24",
      "title": "cfaults: Model-Based Diagnosis for Fault Localization in C with Multiple Test Cases",
      "abstract": "Debugging is one of the most time-consuming and expensive tasks in software development. Several formula-based fault localization (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs with multiple faults. This paper introduces a novel fault localization approach for C programs with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified MaxSAT formula. Consequently, our method guarantees consistency across observations and simplifies the fault localization procedure. Experimental results on two benchmark sets of C programs, TCAS and C-Pack-IPAs , show that CFaults is faster than other FBFL approaches like BugAssist and SNIPER . Moreover, CFaults only generates subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_27",
      "title": "Unifying Weak Memory Verification Using Potentials",
      "abstract": "Concurrency verification for weak memory models is inherently complex. Several deductive techniques based on proof calculi have recently been developed, but these are typically tailored towards a single memory model through specialised assertions and associated proof rules. In this paper, we propose an extension to the logic $${\\textsf{Piccolo}}$$ Piccolo to generalise reasoning across different memory models. $${\\textsf{Piccolo}}$$ Piccolo is interpreted on the semantic domain of thread potentials . By deriving potentials from weak memory model states, we can define the validity of $${\\textsf{Piccolo}}$$ Piccolo formulae for multiple memory models. We moreover propose unified proof rules for verification on top of $${\\textsf{Piccolo}}$$ Piccolo . Once (a set of) such rules has been shown to be sound with respect to a memory model $${\\textsf{MM}} $$ MM , all correctness proofs employing this rule set are valid for $${\\textsf{MM}}$$ MM . We exemplify our approach on the memory models $${\\textsf{SC}}$$ SC , $${\\textsf{TSO}}$$ TSO and $${\\textsf{SRA}}$$ SRA using the standard litmus tests Message-Passing and IRIW.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-3752-9_9",
      "title": "Cybernetic Avatars and Society",
      "abstract": "Toward a future symbiotic society with Cybernetic Avatars (CAs), it is crucial to develop socially well-accepted CAs and to discuss legal, ethical, and socioeconomic issues to update social rules and norms. This chapter provides interdisciplinary discussions for these issues from the perspectives of technological and social sciences. First, we propose avatar social implementation guidelines and present studies that contribute to the development of socially well-accepted CAs. The second part of this chapter addresses the ethical and legal issues in installing CAs in society and discusses solutions for them.",
      "subjects": [
        "Computer Science",
        "User Interfaces and Human Computer Interaction",
        "Robotics",
        "User Interfaces and Human Computer Interaction",
        "Robotics"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_31",
      "title": "Sound and Complete Witnesses for Template-Based Verification of LTL Properties on Polynomial Programs",
      "abstract": "We study the classical problem of verifying programs with respect to formal specifications given in the linear temporal logic (LTL). We first present novel sound and complete witnesses for LTL verification over imperative programs. Our witnesses are applicable to both verification (proving) and refutation (finding bugs) settings. We then consider LTL formulas in which atomic propositions can be polynomial constraints and turn our focus to polynomial arithmetic programs, i.e. programs in which every assignment and guard consists only of polynomial expressions. For this setting, we provide an efficient algorithm to automatically synthesize such LTL witnesses. Our synthesis procedure is both sound and semi-complete. Finally, we present experimental results demonstrating the effectiveness of our approach and that it can handle programs which were beyond the reach of previous state-of-the-art tools.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_18",
      "title": "Certified Quantization Strategy Synthesis for Neural Networks",
      "abstract": "Quantization plays an important role in deploying neural networks on embedded, real-time systems with limited computing and storage resources (e.g., edge devices). It significantly reduces the model storage cost and improves inference efficiency by using fewer bits to represent the parameters. However, it was recently shown that critical properties may be broken after quantization, such as robustness and backdoor-freeness. In this work, we introduce the first method for synthesizing quantization strategies that verifiably maintain desired properties after quantization, leveraging a key insight that quantization leads to a data distribution shift in each layer. We propose to compute the preimage for each layer based on which the preceding layer is quantized, ensuring that the quantized reachable region of the preceding layer remains within the preimage. To tackle the challenge of computing the exact preimage, we propose an MILP-based method to compute its under-approximation. We implement our method into a tool Quadapter and demonstrate its effectiveness and efficiency by providing certified quantization that successfully preserves model robustness and backdoor-freeness.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_8",
      "title": "Digitised Historical Sources and Non-digital Humanists: An Interdisciplinary Challenge?",
      "abstract": "The digitisation of sources has opened new perspectives for humanities scholars. Digitisation allowed a larger access to sources, removing some financial and geographical limits, and the use of digital tools provided new perspectives for humanities scholars, who are able to read the sources differently. However, working with digitised sources also created new challenges that humanities scholars are not always equipped to overcome. The ‘MedIcal Literature and Communication about Child Health’ (MILC) project uses historical medical books for a non-specialist audience to analyse discourses on children’s health in England, France and Italy between 1850 and 1914. Despite being born a non-digital humanities project, with a focus on manual qualitative analysis and a combination of history and literature methods, it took a digital turn when using digitised sources, with issues of digitisation and Optical Character Recognition (OCR) among others. The team working on the project is composed of three humanities scholars, with limited computer science skills. This required us to find digital humanities and in general IT tools adapted to our skillset, and suited to our needs. These tools did not always fit all our needs, and often presented issues in terms of accessibility and compatibility with the general standards of digital humanities. Using examples from the issues faced by this project, and from the solutions found, this paper will argue that the challenges encountered by humanities scholars are interdisciplinary, not only because they overcome the traditional disciplinary boundaries inside the humanities, but also because they mirror challenges that computer scientists are working to solve. This paper will also argue that collaboration is a necessity which would benefit both humanities scholars and computer scientists in their work on the improvement and development of new tools, with the help of AI for example. Using the work done by a team of non-digital humanities scholars, it will argue that accessibility is a central issue in digital humanities and in the creation of IT tools, which needs to be addressed.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_9",
      "title": "Understanding Synthesized Reactive Systems Through Invariants",
      "abstract": "In many applications for which reactive synthesis is attractive, computed implementations need to have understandable behavior. While some existing synthesis approaches compute finite-state machines with a structure that supports their understandability, such approaches do not scale to specifications that can only be realized with a large number of states. Furthermore, asking the engineer to understand the internal structure of the implementation is unnecessary when only the behavior of the implementation is to be understood. In this paper, we present an approach to computing understandable safety invariants that every implementation satisfying a generalized reactivity(1) specification needs to fulfill. Together with the safety part of the specification, the invariants completely define which transitions between input and output proposition valuations any correct implementation can take. We apply the approach in two case studies and demonstrate that the computed invariants highlight the strategic decisions that implementations for the given specification need to make, which not only helps the system designer with understanding what the specification entails, but also supports specification debugging.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_33",
      "title": "A Tutorial on Stream-Based Monitoring",
      "abstract": "Stream-based runtime monitoring frameworks are safety assurance tools that check the runtime behavior of a system against a formal specification. This tutorial provides a hands-on introduction to RTLola, a real-time monitoring toolkit for cyber-physical systems and networks. RTLola processes, evaluates, and aggregates streams of input data, such as sensor readings, and provides a real-time analysis in the form of comprehensive statistics and logical assessments of the system’s health. RTLola has been applied successfully in monitoring autonomous systems such as unmanned aircraft. The tutorial guides the reader through the development of a stream-based specification for an autonomous drone observing other flying objects in its flight path. Each tutorial section provides an intuitive introduction, highlighting useful language features and specification patterns, and gives a more in-depth explanation of technical details for the advanced reader. Finally, we discuss how runtime monitors generated from RTLola specifications can be integrated into a variety of systems and discuss different monitoring applications.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_14",
      "title": "State Matching and Multiple References in Adaptive Active Automata Learning",
      "abstract": "Active automata learning (AAL) is a method to infer state machines by interacting with black-box systems. Adaptive AAL aims to reduce the sample complexity of AAL by incorporating domain specific knowledge in the form of (similar) reference models. Such reference models appear naturally when learning multiple versions or variants of a software system. In this paper, we present state matching, which allows flexible use of the structure of these reference models by the learner. State matching is the main ingredient of adaptive $$L^{\\#}$$ L # , a novel framework for adaptive learning, built on top of $$L^{\\#}$$ L # . Our empirical evaluation shows that adaptive $$L^{\\#}$$ L # improves the state of the art by up to two orders of magnitude.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_11",
      "title": "Challenges for AI in Healthcare Systems",
      "abstract": "This paper overviews the challenges of using artificial intelligence (AI) methods when building healthcare systems, as discussed at the AIsola Conference in 2023. It focuses on the topics (i) medical data, (ii) decision support, (iii) software engineering for AI-based health systems, (iv) regulatory affairs as well as (v) privacy-preserving machine learning and highlights the importance and challenges involved when utilizing AI in healthcare systems.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-61194-0_4",
      "title": "Contextual Framework",
      "abstract": "This chapter describes the contextual information collected during the International Computer and Information Literacy Study (ICILS) 2023 in order to aid understanding of variation in the primary outcome achievement measures of the study: students’ computer and information literacy (CIL) and computational thinking (CT). Both outcome measures may be potentially influenced by a given set of contextual information. We provide a classification of contextual factors that accords with the multilevel structure inherent in the process of student CIL/CT learning. The learning of individual students happens in the overlapping contexts of school learning and out-of-school learning, both of which are embedded in the context of the wider community that comprises local, national, supranational, and international contexts. We distinguish between four contexts: wider community, schools and classrooms, home environment and the individual. In addition, we consider the relationship of these contextual factors to the learning process (antecedents or processes). We also list the different kinds of variables that are collected via the different ICILS 2023 contextual instruments and briefly outline prior findings from educational research in order to explain why these variables are included in ICILS 2023.",
      "subjects": [
        "Education",
        "Education, general",
        "International and Comparative Education",
        "Digital Education and Educational Technology",
        "Assessment and Testing",
        "International and Comparative Education"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_10",
      "title": "Combining Classical and Probabilistic Independence Reasoning to Verify the Security of Oblivious Algorithms",
      "abstract": "We consider the problem of how to verify the security of probabilistic oblivious algorithms formally and systematically. Unfortunately, prior program logics fail to support a number of complexities that feature in the semantics and invariants needed to verify the security of many practical probabilistic oblivious algorithms. We propose an approach based on reasoning over perfectly oblivious approximations, using a program logic that combines both classical Hoare logic reasoning and probabilistic independence reasoning to support all the needed features. We formalise and prove our new logic sound in Isabelle/HOL and apply our approach to formally verify the security of several challenging case studies beyond the reach of prior methods for proving obliviousness.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_2",
      "title": "Rigorous Floating-Point Round-Off Error Analysis in PRECiSA 4.0",
      "abstract": "Small round-off errors in safety-critical systems can lead to catastrophic consequences. In this context, determining if the result computed by a floating-point program is accurate enough with respect to its ideal real-number counterpart is essential. This paper presents PRECiSA 4.0, a tool that rigorously estimates the accumulated round-off error of a floating-point program. PRECiSA 4.0 combines static analysis, optimization techniques, and theorem proving to provide a modular approach for computing a provably correct round-off error estimation. PRECiSA 4.0 adds several features to previous versions of the tool that enhance its applicability and performance. These features include support for data collections such as lists, records, and tuples; support for recursion schemas; an updated floating-point formalization that closely characterizes the IEEE-754 standard; an efficient and modular analysis of function calls that improves the performances for large programs; and a new user interface integrated into Visual Studio Code.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_10",
      "title": "PyBDR: Set-Boundary Based Reachability Analysis Toolkit in Python",
      "abstract": "We present PyBDR, a Python reachability analysis toolkit based on set-boundary analysis, which centralizes on widely-adopted set propagation techniques for formal verification, controller synthesis, state estimation, etc. It employs boundary analysis of initial sets to mitigate the wrapping effect during computations, thus improving the performance of reachability analysis algorithms without significantly increasing computational costs. Beyond offering various set representations such as polytopes and zonotopes, our toolkit particularly excels in interval arithmetic by extending operations to the tensor level, enabling efficient parallel interval arithmetic computation and unifying vector and matrix intervals into a single framework. Furthermore, it features symbolic computation of derivatives of arbitrary order and evaluates them as real or interval-valued functions, which is essential for approximating behaviours of nonlinear systems at specific time instants. Its modular architecture design offers a series of building blocks that facilitate the prototype development of reachability analysis algorithms. Comparative studies showcase its strengths in handling verification tasks with large initial sets or long time horizons. The toolkit is available at https://github.com/ASAG-ISCAS/PyBDR .",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6095-4_1",
      "title": "Main Amendments of Chinese Intellectual Property Law",
      "abstract": "Strengthening the protection of intellectual property plays the most important role in improving the system of property rights protection, and also serves as the biggest momentum to enhance our country's economic competitiveness.",
      "subjects": [
        "Law",
        "Private International Law, International & Foreign Law, Comparative Law",
        "IT Law, Media Law, Intellectual Property",
        "History of China",
        "Private International Law, International and Foreign Law, Comparative Law",
        "IT Law, Media Law, Intellectual Property",
        "History of China"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_29",
      "title": "Practical Deductive Verification of OCaml Programs",
      "abstract": "In this paper, we provide a comprehensive, hands-on tutorial on how to apply deductive verification to programs written in OCaml . In particular, we show how one can use the GOSPEL specification language and the Cameleer tool to conduct mostly-automated verification on OCaml code. In our presentation, we focus on two main classes of programs: first, purely functional programs with no mutable state; then on imperative programs, where one can mix mutable state with subtle control-flow primitives, such as locally-defined exceptions.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-75387-9_11",
      "title": "Intersymbolic AI",
      "abstract": "This perspective piece calls for the study of the new field of Intersymbolic AI , by which we mean the combination of symbolic AI , whose building blocks have inherent significance/meaning, with subsymbolic AI , whose entirety creates significance/effect despite the fact that individual building blocks escape meaning. Canonical kinds of symbolic AI are logic, games and planning. Canonical kinds of subsymbolic AI are (un)supervised machine and reinforcement learning. Intersymbolic AI interlinks the worlds of symbolic AI with its compositional symbolic significance and meaning and of subsymbolic AI with its summative significance or effect to enable culminations of insights from both worlds by going between and across symbolic AI insights with subsymbolic AI techniques that are being helped by symbolic AI principles. For example, Intersymbolic AI may start with symbolic AI to understand a dynamic system, continue with subsymbolic AI to learn its control, and end with symbolic AI to safely use the outcome of the learned subsymbolic AI controller in the dynamic system. The way Intersymbolic AI combines both symbolic and subsymbolic AI to increase the effectiveness of AI compared to either kind of AI alone is likened to the way that the combination of both conscious and subconscious thought increases the effectiveness of human thought compared to either kind of thought alone. Some successful contributions to the Intersymbolic AI paradigm are surveyed here but many more are considered possible by advancing Intersymbolic AI.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Mathematical Logic and Formal Languages",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Control Structures and Microprogramming",
        "Software Engineering",
        "Formal Languages and Automata Theory",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Control Structures and Microprogramming"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_20",
      "title": "Bridging Dimensions: Confident Reachability for High-Dimensional Controllers",
      "abstract": "Autonomous systems are increasingly implemented using end-to-end learning-based controllers. Such controllers make decisions that are executed on the real system, with images as one of the primary sensing modalities. Deep neural networks form a fundamental building block of such controllers. Unfortunately, the existing neural-network verification tools do not scale to inputs with thousands of dimensions—especially when the individual inputs (such as pixels) are devoid of clear physical meaning. This paper takes a step towards connecting exhaustive closed-loop verification with high-dimensional controllers. Our key insight is that the behavior of a high-dimensional vision-based controller can be approximated with several low-dimensional controllers. To balance the approximation accuracy and verifiability of our low-dimensional controllers, we leverage the latest verification-aware knowledge distillation. Then, we inflate low-dimensional reachability results with statistical approximation errors, yielding a high-confidence reachability guarantee for the high-dimensional controller. We investigate two inflation techniques—based on trajectories and control actions—both of which show convincing performance in three OpenAI gym benchmarks.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73229-4_4",
      "title": "Quality Assured: Rethinking Annotation Strategies in Imaging AI",
      "abstract": "This paper does not describe a novel method. Instead, it studies an essential foundation for reliable benchmarking and ultimately real-world application of AI-based image analysis: generating high-quality reference annotations. Previous research has focused on crowdsourcing as a means of outsourcing annotations. However, little attention has so far been given to annotation companies, specifically regarding their internal quality assurance (QA) processes. Therefore, our aim is to evaluate the influence of QA employed by annotation companies on annotation quality and devise methodologies for maximizing data annotation efficacy. Based on a total of 57,648 instance segmented images obtained from a total of 924 annotators and 34 QA workers from four annotation companies and Amazon Mechanical Turk (MTurk), we derived the following insights: (1) Annotation companies perform better both in terms of quantity and quality compared to the widely used platform MTurk. (2) Annotation companies’ internal QA only provides marginal improvements, if any. However, improving labeling instructions instead of investing in QA can substantially boost annotation performance. (3) The benefit of internal QA depends on specific image characteristics. Our work could enable researchers to derive substantially more value from a fixed annotation budget and change the way annotation companies conduct internal QA.",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Computer Imaging, Vision, Pattern Recognition and Graphics"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73024-5_9",
      "title": "Hierarchical Conditioning of Diffusion Models Using Tree-of-Life for Studying Species Evolution",
      "abstract": "A central problem in biology is to understand how organisms evolve and adapt to their environment by acquiring variations in the observable characteristics or traits of species across the tree of life. With the growing availability of large-scale image repositories in biology and recent advances in generative modeling, there is an opportunity to accelerate the discovery of evolutionary traits automatically from images. Toward this goal, we introduce Phylo-Diffusion, a novel framework for conditioning diffusion models with phylogenetic knowledge represented in the form of HIERarchical Embeddings (HIER-Embeds). We also propose two new experiments for perturbing the embedding space of Phylo-Diffusion: trait masking and trait swapping, inspired by counterpart experiments of gene knockout and gene editing/swapping. Our work represents a novel methodological advance in generative modeling to structure the embedding space of diffusion models using tree-based knowledge. Our work also opens a new chapter of research in evolutionary biology by using generative models to visualize evolutionary changes directly from images. We empirically demonstrate the usefulness of Phylo-Diffusion in capturing meaningful trait variations for fishes and birds, revealing novel insights about the biological mechanisms of their evolution. (Model and code can be found at imageomics.github.io/phylo-diffusion )",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_1",
      "title": "Adversarial Robustness Certification for Bayesian Neural Networks",
      "abstract": "We study the problem of certifying the robustness of Bayesian neural networks (BNNs) to adversarial input perturbations. Specifically, we define two notions of robustness for BNNs in an adversarial setting: probabilistic robustness and decision robustness. The former deals with the probabilistic behaviour of the network, that is, it ensures robustness across different stochastic realisations of the network, while the latter provides guarantees for the overall (output) decision of the BNN. Although these robustness properties cannot be computed analytically, we present a unified computational framework for efficiently and formally bounding them. Our approach is based on weight interval sampling, integration and bound propagation techniques, and can be applied to BNNs with a large number of parameters independently of the (approximate) inference method employed to train the BNN. We evaluate the effectiveness of our method on tasks including airborne collision avoidance, medical imaging and autonomous driving, demonstrating that it can compute non-trivial guarantees on medium size images (i.e., over 16 thousand input parameters).",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-7447-0_7",
      "title": "From Backwardness to a Great Tech Power, the Chinese Modernization of Science and Technology",
      "abstract": "This article explores the development mechanism, growth process and key achievements of the Chinese modernization of science and technology. Over the past 70 years since the founding of the People’s Republic of China, the Chinese modernization of science and technology experienced a transformation from rapidly catching up with developed countries to surpassing its competitors in innovation. This highlights that “innovation is the primary driving force for development”. What is also at play is the integrated result as well as interaction between three key capabilities (the capability of introducing technologies, the capability of technology imitation, and the capability of independent innovation of technologies) and two major effects (the scale effect of a giant market of China and the scale effect of the world market). As a result, China created its own and unique path of opening up to the outside world, catching up with and surpassing advanced countries at a faster pace in spite of its status as a latecomer and pursuing independent innovation. This is what makes China a technological pioneer in the world now instead of that poor and backward country. China has the world’s largest integrated and high-quality scientific and technological team, one of the world’s largest R&D expenditure, the world’s second largest digital economy and the world’s largest amount of IPR usage fee (import and export). As the largest grain producer, it also ranks among the top countries in terms of papers published in science and technology journals, invention patent application and high-tech export. As China’s scientific and technological contribution rate continues to rise, it is now an innovative power in the world; by 2025, China’s scientific and technological modernization will be at a new level, and this will further change the future world’s science and technology development landscape. When China becomes one of the world’s three major science and technology centers, it will make greater contribution to the development of science and technology in the world.",
      "subjects": [
        "Economics",
        "Political Economy/Economic Systems",
        "Public Policy",
        "Political Economy and Economic Systems",
        "Public Policy"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_10",
      "title": "The GraphBRAIN Framework for Knowledge Graph Management and Its Applications to Cultural Heritage",
      "abstract": "The traditional record-based approach to the description of Cultural Heritage is nowadays obsolete. It is unable to properly handle complex descriptions and it cannot support advanced functions provided by Artificial Intelligence techniques for helping practitioners, scholars, researchers and end-users in carrying out their tasks. A graph-based, semantic approach is needed, such as that provided by Semantic Web solutions. Also, a ‘holistic’ description approach is needed, that includes and inter-connects all branches and types of Cultural Heritage, and that is not limited to describing just the formal metadata of cultural objects, but can deal with their content, physicality, context and lifecycle, as well. The GraphBRAIN framework and technology for Knowledge Graph management enforces all these ideas and enjoys improved efficiency, expressiveness, and flexibility thanks to the use of the LPG model for knowledge representation. This paper describes GraphBRAIN and its application to several Cultural Heritage-related fields, including digital libraries, archives and museums, history of computing, and tourism as a way to boost fruition of these items.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_26",
      "title": "No Risk, No Fun",
      "abstract": "The aim of this tutorial is to explain to the formal methods community the area of risk management and its most prominent concepts: the definition of risk, strategies for managing risk, the risk management cycle, and the role of ISO standards. For each of these concepts, I explain how formal methods relate and contribute, making risk management more accountable: systematic, transparent, and quantitative. I will also argue that viewing Formal Methods through the lens of risk management, and making the relevance of formal methods in risk analysis explicit, helps our community to better communicate the merits of formal methods to industry.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_3",
      "title": "High-Resolution Plenoptic Sensing",
      "abstract": "The high-resolution plenoptic sensing system can capture light field with a high level of detail and clarity. Resolution refers to the amount of detail that can be discerned in the reconstructed image or light field. The cutting edge of high-resolution plenoptic sensing is gigapixel plenoptic sensing, specifically refers to a system capable of capturing images with billions of pixels, resulting in extremely high-resolution light field.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-78593-1_8",
      "title": "3-2-3 Multi-AI Segmentation Framework: LoD-Based, Incremental Segmentation of 3D Scan Data Using Any 2D AI",
      "abstract": "In the age of spatial computing , computer vision is central, and efficient segmentation of 3D scan data becomes a fundamental task. Existing segmentation methods are often locked to specific AI models, lack level-of-detail (LoD) capabilities, and do not support efficient incremental segmentation. These limitations hinder their application to XR systems that integrate architectural and urban scales, which demand both at scale and detailed, up-to-date segmentation information, while leveraging limited local hardware in distributed computing environments. In this work, we present a novel framework that integrates multiple 2D AI through AI-agnostic 3D geometry feature fusion, ensuring spatial consistency while taking advantage of the rapid advancements in 2D AI models. Our framework performs LoD segmentation, enabling swift segmentation of downsampled geometry and full detail on needed segments. Additionally, it progressively builds a segmentation database, processing only newly added data, thereby avoiding point cloud reprocessing, a common limitation in previous methods. In our use case, our framework analyzed a public building based on three scans: a drone LiDAR capture of the exterior, a static LiDAR capture of a room, and a user-held RGB-D camera capture of a section of the room. Our approach provided a fast understanding of building volumes, room elements, and a fully detailed geometry of a requested object, a “ panel with good lighting and a view to a nearby building ”, to implement an XR activity. Our preliminary results are promising for applications in other urban and architectural contexts and point to further developments in our Geometric Data Inference AI as a cornerstone for deeper, more accurate Multi-AI integration.",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Software Engineering/Programming and Operating Systems",
        "Computer Applications",
        "User Interfaces and Human Computer Interaction",
        "Computer Communication Networks",
        "Special Purpose and Application-Based Systems",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Software Engineering",
        "Computer and Information Systems Applications",
        "User Interfaces and Human Computer Interaction",
        "Computer Communication Networks",
        "Special Purpose and Application-Based Systems"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_2",
      "title": "Plenoptic Sensing Systems",
      "abstract": "Plenoptic sensing systems are a type of camera that can capture the multidimensional information of the light field, e.g., capture both the light rays’ intensities and directions. This allows for reconstructing the high-dimensional light fields and supporting various post-capture features such as depth perception, refocusing, synthetic aperture, etc. As the widely used CMOS-based image sensor can only record the intensity of light rays, conventional camera cannot directly capture the multidimensional light field. To address this challenge, a variety of plenoptic sensing systems with specialized hardware and algorithms have been proposed.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_3",
      "title": "A Local Search Algorithm for MaxSMT(LIA)",
      "abstract": "MaxSAT modulo theories (MaxSMT) is an important generalization of Satisfiability modulo theories (SMT) with various applications. In this paper, we focus on MaxSMT with the background theory of Linear Integer Arithmetic, denoted as MaxSMT(LIA). We design the first local search algorithm for MaxSMT(LIA) called PairLS, based on the following novel ideas. A novel operator called pairwise operator is proposed for integer variables. It extends the original local search operator by simultaneously operating on two variables, enriching the search space. Moreover, a compensation-based picking heuristic is proposed to determine and distinguish the pairwise operations. Experiments are conducted to evaluate our algorithm on massive benchmarks. The results show that our solver is competitive with state-of-the-art MaxSMT solvers. Furthermore, we also apply the pairwise operation to enhance the local search algorithm of SMT, which shows its extensibility.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-7447-0_8",
      "title": "The Great Leap Development and Outlook of China’s Scientific and Technological Strength (2000–2035)",
      "abstract": "As the ability to realize the national scientific and technological strategic goals, scientific and technological strength is not only an important part of the country’s comprehensive national strength, but also the basis for scientific and technological innovation to continuously improve the comprehensive national strength. In this work, I have carried out quantitative evaluations of the leapfrog development of China’s scientific and technological strength from 2000 to 2020. Transitioning from catch-up development to innovation-oriented development, from the world’s second phalanx to the first phalanx, from quantitative accumulation to qualitative leap, China’s science and technology has achieved historic leapfrog development. This fully demonstrates the political advantages of the Party’s overall leadership, the strategic advantages of the country’s innovation-driven development, the advantages of the new national system under the socialist market economic system, and the advantages of scientific and technological human resources. Based on China’s insistence on taking self-reliance and self-improvement in science and technology as the support of the national development strategies, as well as the advantages and favorable conditions of future development, policy suggestions have been put forward for the national scientific and technological innovation goals. This has been alongside additional measures for strengthening the national strategic scientific and technological strength and implementing the innovation-driven development strategies. We can look forward to the completion of the long-term goals of China’s science and technology in 2025 and 2035, that is, the strength of science and technology will jump sharply, and China will enter the forefront of the world’s innovative countries.",
      "subjects": [
        "Economics",
        "Political Economy/Economic Systems",
        "Public Policy",
        "Political Economy and Economic Systems",
        "Public Policy"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_12",
      "title": "Introducing SWIRL: An Intermediate Representation Language for Scientific Workflows",
      "abstract": "In the ever-evolving landscape of scientific computing, properly supporting the modularity and complexity of modern scientific applications requires new approaches to workflow execution, like seamless interoperability between different workflow systems, distributed-by-design workflow models, and automatic optimisation of data movements. In order to address this need, this article introduces SWIRL, an intermediate representation language for scientific workflows. In contrast with other product-agnostic workflow languages, SWIRL is not designed for human interaction but to serve as a low-level compilation target for distributed workflow execution plans. The main advantages of SWIRL semantics are low-level primitives based on the send/receive programming model and a formal framework ensuring the consistency of the semantics and the specification of translating workflow models represented by Directed Acyclic Graphs (DAGs) into SWIRL workflow descriptions. Additionally, SWIRL offers rewriting rules designed to optimise execution traces, accompanied by corresponding equivalence. An open-source SWIRL compiler toolchain has been developed using the ANTLR Python3 bindings.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_13",
      "title": "Future Opportunities for Systematic AI Support in Healthcare",
      "abstract": "Artificial Intelligence (AI) holds transformative potential to revolutionize healthcare delivery and outcomes. However, the literature suggests that focusing solely on AI algorithms leads to low adoption rates. AI needs to be introduced systematically into healthcare. This paper builds on this approach and synthesizes existing literature and authors’ insights to critically examine the current landscape and future opportunities for systematic AI support in healthcare. The multifaceted applications of AI, ranging from disease prediction to personalized medicine, are explored with a focus on AI’s potential to optimize employee performance, alleviate healthcare staff burdens, and enhance patient care. However, challenges such as limited access to unbiased data sets, connectivity issues, and ethical concerns pose significant barriers to AI adoption in healthcare.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-74234-7_18",
      "title": "Approximate Distributed Monitoring Under Partial Synchrony: Balancing Speed & Accuracy",
      "abstract": "In distributed systems with processes that do not share a global clock, partial synchrony is achieved by clock synchronization that guarantees bounded clock skew among all applications. Existing solutions for distributed runtime verification under partial synchrony against temporal logic specifications are exact but suffer from significant computational overhead. In this paper, we propose an approximate distributed monitoring algorithm for Signal Temporal Logic (STL) that mitigates this issue by abstracting away potential interleaving behaviors. This conservative abstraction enables a significant speedup of the distributed monitors, albeit with a tradeoff in accuracy. We address this tradeoff with a methodology that combines our approximate monitor with its exact counterpart, resulting in enhanced efficiency without sacrificing precision. We evaluate our approach with multiple experiments, showcasing its efficacy in both real-world applications and synthetic examples.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Mathematical Logic and Formal Languages",
        "Logics and Meanings of Programs",
        "Artificial Intelligence",
        "Algorithms",
        "Programming Languages, Compilers, Interpreters",
        "Software Engineering",
        "Formal Languages and Automata Theory",
        "Computer Science Logic and Foundations of Programming",
        "Artificial Intelligence",
        "Algorithms",
        "Compilers and Interpreters"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_25",
      "title": "Advancing Quantum Computing with Formal Methods",
      "abstract": "This tutorial introduces quantum computing with a focus on the applicability of formal methods in this relatively new domain. We describe quantum circuits and convey an understanding of their inherent combinatorial nature and the exponential blow-up that makes them hard to analyze. Then, we show how weighted model counting (#SAT) can be used to solve hard analysis tasks for quantum circuits. This tutorial is aimed at everyone in the formal methods community with an interest in quantum computing. Familiarity with quantum computing is not required, but basic linear algebra knowledge (particularly matrix multiplication and basis vectors) is a prerequisite. The goal of the tutorial is to inspire the community to advance the development of quantum computing with formal methods.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-75434-0_28",
      "title": "Towards Verifying Robotic Systems Using Statistical Model Checking in STORM",
      "abstract": "Robust autonomy and interaction of robots with their environment, even in rare or new situations, is an ultimate goal of robotics research. We settle on Statistical Model Checking (SMC) for the benefit of robustness of robot deliberation and base our implementation on STORM, one of the most performant and comprehensive open-source model checkers, so far lacking an SMC extension. The SMC extension introduced in this paper offers various statistical methods, from which the user can choose to find the best trade-off between accuracy of the result and runtime. We demonstrate the efficiency of our SMC implementation by comparing it to other state-of-the-art SMC tools on well-established benchmarks and on a robotics-related example. The results indicate that our implementation, which will be continuously extended in the future to improve support for robotics use cases, is performant enough to bridge the gap between robotic systems and model checking in industry.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71177-0_22",
      "title": "Code-Level Safety Verification for Automated Driving: A Case Study",
      "abstract": "The formal safety analysis of automated driving vehicles poses unique challenges due to their dynamic operating conditions and significant complexity. This paper presents a case study of applying formal safety verification to adaptive cruise controllers. Unlike the majority of existing verification approaches in the automotive domain, which only analyze (potentially imperfect) controller models, employ simulation to find counter-examples or use online monitors for runtime verification, our method verifies controllers at code level by utilizing bounded model checking. Verification is performed against an invariant set derived from formal specifications and an analytical model of the required behavior. For neural network controllers, we propose a scalable three-step decomposition, which additionally uses a neural network verifier. We show that both traditionally implemented as well as neural network controllers are verified within minutes. The dual focus on formal safety and implementation verification provides a comprehensive framework applicable to similar cyber-physical systems.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-72244-8_1",
      "title": "Belenios with Cast-as-Intended: Towards a Usable Interface",
      "abstract": "In this work we consider Belenios-CaI, a protocol offering a cast-as-intended mechanism and building upon Belenios, a voting system used in about 7000 elections to date. We modify the design of Belenios-Cai from the user perspective without changing its core cryptographic mechanism. The goal is to increase its usability by letting the voter simply check whether two symbols are equal or different. We conducted a user-study among 165 participants in a research center to evaluate the usability of our implementation of Belenios-CaI. Since the cast-as-intended mechanism assumes that voters make some random choices, we also evaluate whether the choices made by voters are sufficiently “random” to provide verifiability and whether it could affect their privacy. The study shows that, for our population, Belenios-CaI is considered as usable with the random choices of the voters seeming sufficient for verifiability and privacy.",
      "subjects": [
        "Computer Science",
        "Cryptology",
        "Artificial Intelligence",
        "Mobile and Network Security",
        "Computer Communication Networks",
        "Cryptology",
        "Artificial Intelligence",
        "Mobile and Network Security",
        "Computer Communication Networks"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_32",
      "title": "The Opacity of Timed Automata",
      "abstract": "Opacity serves as a critical security and confidentiality property, which concerns whether an intruder can unveil a system’s secret based on structural knowledge and observed behaviors. Opacity in timed systems presents greater complexity compared to untimed systems, and it has been established that opacity for timed automata is undecidable. However, the original proof cannot be applied to decide the opacity of one-clock timed automata directly. In this paper, we explore three types of opacity within timed automata: language-based timed opacity, initial-location timed opacity, and current-location timed opacity. We begin by formalizing these concepts and establishing transformation relations among them. Subsequently, we demonstrate the undecidability of the opacity problem for one-clock timed automata. Furthermore, we offer a constructive proof for the conjecture regarding the decidability of opacity for timed automata in discrete-time semantics. Additionally, we present a sufficient condition and a necessary condition for the decidability of opacity in specific subclasses of timed automata.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_26",
      "title": "Staged Specification Logic for Verifying Higher-Order Imperative Programs",
      "abstract": "Higher-order functions and imperative states are language features supported by many mainstream languages. Their combination is expressive and useful, but complicates specification and reasoning, due to the use of yet-to-be-instantiated function parameters. One inherent limitation of existing specification mechanisms is its reliance on only two stages  : an initial stage to denote the precondition at the start of the method and a final stage to capture the postcondition. Such two-stage specifications force abstract properties to be imposed on unknown function parameters, leading to less precise specifications for higher-order methods. To overcome this limitation, we introduce a novel extension to Hoare logic that supports multiple stages for a call-by-value higher-order language with ML-like local references. Multiple stages allow the behavior of unknown function-type parameters to be captured abstractly as uninterpreted relations; and can also model the repetitive behavior of each recursion as a separate stage. In this paper, we define our staged logic with its semantics, prove its soundness and develop a new automated higher-order verifier, called H eifer, for a core ML-like language.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-6915-5_1",
      "title": "Introduction to Plenoptic Imaging",
      "abstract": "Plenoptic is derived from the Latin words plenus (“full”) + optic and was proposed by Edward Adelson in 1991. The plenoptic function is a seven-dimensional function describing the three-dimensional viewing position, two-dimensional visual angle, one-dimensional wavelength, and one-dimensional time of a light ray in space.",
      "subjects": [
        "Computer Science",
        "Image Processing and Computer Vision",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Materials Science, general",
        "Computer Vision",
        "Image Processing",
        "Imaging Techniques"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-981-97-8943-6_8",
      "title": "Quantum Programming Without the Quantum Physics",
      "abstract": "We propose a quantum programming paradigm where all data are familiar classical data, and the only non-classical element is a random number generator that can return results with negative probability. Currently, the vast majority of quantum programming languages instead work with quantum data types made up of qubits. The description of their behavior relies on heavy linear algebra and many interdependent concepts and intuitions from quantum physics, which takes dedicated study to understand. We demonstrate that the proposed view of quantum programming explains its central concepts and constraints in more accessible, computationally relevant terms. This is achieved by systematically reducing everything to the existence of that negative-probability random generator, avoiding mention of advanced physics. This makes quantum programming more accessible to programmers without a deep background in physics or linear algebra. The bulk of this paper is written with such an audience in mind. As a working vehicle, we lay out a simple quantum programming language under this paradigm, showing that not only can it express all quantum algorithms, it also naturally captures the semantics of measurement without ever mentioning qubits or collapse.",
      "subjects": [
        "Computer Science",
        "Programming Languages, Compilers, Interpreters",
        "Programming Techniques",
        "Theory of Computation",
        "Artificial Intelligence",
        "Compilers and Interpreters",
        "Programming Techniques",
        "Theory of Computation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-66708-4_1",
      "title": "Methodological Resilience Assessment of Smart Cyber Infrastructures",
      "abstract": "The race for digitization created a real need to protect smart infrastructures. Environments are becoming highly connected and automated. Their growing complexity and connectivity make it hard to assure and assess their cyber resilience, i.e., protecting them from cyberattacks, failures, and errors. Traditional strategies for ensuring the cyber resilience of smart infrastructures suffer from a lack of holism. Indeed, since smart infrastructures are often structured in layers, traditional protection methods can lead to conflicting and competing goals. For instance, they may increase the resilience of specific layers at the expense of decreasing the performance of others. This chapter reviews existing methods aiming to address this problem. We focus on two leading methodological assessment families: quantitative and qualitative. The former includes numerical metrics to quantify and assist system-dependent decision-making processes. The latter builds upon symbolic modeling to offer a system-agnostic assessment. The chapter provides an in-depth exploration of quantitative and qualitative methodologies with significant potential to enhance the resilience of layered smart infrastructures. Our exploration covers classical technological aspects (e.g., cascading effects) and socio-technical factors (e.g., human-in-the-loop interaction).",
      "subjects": [
        "Computer Science",
        "Systems and Data Security",
        "Computer Communication Networks",
        "Computer Applications",
        "Software Engineering/Programming and Operating Systems",
        "Data and Information Security",
        "Computer Communication Networks",
        "Computer and Information Systems Applications",
        "Software Engineering"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73030-6_17",
      "title": "Lossy Image Compression with Foundation Diffusion Models",
      "abstract": "Incorporating diffusion models in the image compression domain has the potential to produce realistic and detailed reconstructions, especially at extremely low bitrates. Previous methods focus on using diffusion models as expressive decoders robust to quantization errors in the conditioning signals. However, achieving competitive results in this manner requires costly training of the diffusion model and long inference times due to the iterative generative process. In this work we formulate the removal of quantization error as a denoising task, using diffusion to recover lost information in the transmitted image latent. Our approach allows us to perform less than 10% of the full diffusion generative process and requires no architectural changes to the diffusion model, enabling the use of foundation models as a strong prior without additional fine tuning of the backbone. Our proposed codec outperforms previous methods in quantitative realism metrics, and we verify that our reconstructions are qualitatively preferred by end users, even when other methods use twice the bitrate.",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Signal, Image and Speech Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Image Processing",
        "Computer Communication Networks",
        "User Interfaces and Human Computer Interaction",
        "Machine Learning",
        "Special Purpose and Application-Based Systems"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-76821-7_11",
      "title": "Serious Games Beyond Entertainment and Learning: An Evaluation Methodology for Assessing Awareness Raising, Empathy, and Social Change",
      "abstract": "Serious games have emerged as a powerful tool for achieving targeted outcomes beyond entertainment, such as learning or raising awareness about a topic. Considering their pervasiveness and wide adoption in the educational domain, traditional assessment approaches of these games have predominantly focused on their entertainment value and achievement of learning objectives. This paper proposes a comprehensive evaluation framework that goes beyond traditional dimensions to include aspects relevant to empathy raising and attitude change. The proposed framework has been validated through three user studies, assessing entertainment, historical awareness, empathy raising, and attitude change for three games, involving in total 98 high school students. Results from the studies are presented, as well as implications and lessons learned regarding the overall methodological approach, the evaluation instruments used, and the procedures followed.",
      "subjects": [
        "Computer Science",
        "User Interfaces and Human Computer Interaction",
        "User Interfaces and Human Computer Interaction"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-71162-6_17",
      "title": "A Zonotopic Dempster-Shafer Approach to the Quantitative Verification of Neural Networks",
      "abstract": "The reliability and usefulness of verification depend on the ability to represent appropriately the uncertainty. Most existing work on neural network verification relies on the hypothesis of either set-based or probabilistic information on the inputs. In this work, we rely on the framework of imprecise probabilities, specifically p-boxes, to propose a quantitative verification of ReLU neural networks, which can account for both probabilistic information and epistemic uncertainty on inputs. On classical benchmarks, including the ACAS Xu examples, we demonstrate that our approach improves the tradeoff between tightness and efficiency compared to related work on probabilistic network verification, while handling much more general classes of uncertainties on the inputs and providing fully guaranteed results.",
      "subjects": [
        "Computer Science",
        "Software Engineering/Programming and Operating Systems",
        "Logics and Meanings of Programs",
        "Special Purpose and Application-Based Systems",
        "Professional Computing",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)",
        "Software Engineering",
        "Computer Science Logic and Foundations of Programming",
        "Special Purpose and Application-Based Systems",
        "Programming Language",
        "Control Structures and Microprogramming",
        "Natural Language Processing (NLP)"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_12",
      "title": "Towards a Multi-dimensional Health Data Analysis Framework",
      "abstract": "Healthcare processes need to be streamlined to offer better healthcare services. Data analysis can be crucial in reducing costs, optimizing processes, and analyzing treatment effectiveness. However, data analysis in healthcare is complex due to the variety and complexity of patient data. This paper proposes a multi-dimensional comparative analysis method that offers healthcare professionals a lens to delve into healthcare datasets from various perspectives. The paper discusses the importance of comparative analysis in healthcare illustrated by two examples on how we can understand the pattern of comorbidity and how we can analyze the effectiveness of internet delivered psychological interventions. The paper presents a multi-dimensional comparative analysis framework covering various use cases in analysing healthcare data. The framework allows healthcare professionals to compare and contrast healthcare data across multiple dimensions, including clinical dimensions such as diagnosis, outcome measures, time dimension, patient dimensions (engagement, involvement), cost dimension, and other relevant factors. This approach offers a more insightful understanding of healthcare data and facilitates informed decision-making in healthcare practices.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-78590-0_7",
      "title": "Publishing and Long-Term Archiving 3D Data in Humanities",
      "abstract": "We present here the French solution for long-term archiving combined with online publication of 3D research data in the humanities. The focus is on the paradata that document the technical process involved in obtaining the 3D result. Our schema, initially limited to the fields of archaeology and cultural heritage, is now open to other areas of the human sciences.  The choice of data organization, metadata, paradata, standards and infrastructure is in line with the FAIR principles of the semantic web. It is aligned with standard vocabularies and mapped to the Europeana Data Model (EDM). The CINES (Centre Informatique National de l’Enseignement Supérieur.), the Open Archival Information System (OAIS) infrastructure for research data in France, is in charge of archiving. We take care of data documentation and propose to publish part of these documented data at the same time. On the user side, we developed aLTAG3D, a desktop UI software to help research teams to create their OAIS Submission Information Package (SIP). On the publication side, we provide a DOI and a 3D viewer on the online plateform to meet the needs of researchers and public communication. On the archiving side, long-term archiving has given direction to the way our description schema works: it is focused on reproducibility. The content of the SIP is centered on the 3D data, its build process and sources. Paradata describing the process to the 3D file is under development and several options are under study with CIDOC CRM-Dig or W3C prov-O ontologies.",
      "subjects": [
        "Computer Science",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Information Storage and Retrieval",
        "Computer Applications",
        "Computer Imaging, Vision, Pattern Recognition and Graphics",
        "Information Storage and Retrieval",
        "Computer and Information Systems Applications"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-65603-3_3",
      "title": "Civic Knowledge",
      "abstract": "In this chapter we report on students’ civic knowledge achievement in the International Civic and Citizenship Education Study (ICCS). The chapter begins with a description of the test instrument used to assess civic knowledge. This is followed by an explanation of the development and content of the ICCS civic knowledge proficiency scale used to measure and describe students’ civic knowledge achievement. The student test and civic knowledge scale are illustrated using example items from each level. We then describe students’ civic knowledge achievement within and across ICCS participants. We first report on students’ civic knowledge in ICCS 2022 and trends in achievement across cycles. While civic knowledge varied across countries, a consistent finding reported across all first three cycles of ICCS was that the variation of civic knowledge within countries exceeded the variation across countries. Furthermore, we observed a pattern of increases in student civic knowledge between 2009 and 2016 followed by decreases between 2016 and 2022. We then report on the associations between aspects of students’ background and their civic knowledge achievement. Consistent with findings from pervious ICCS cycles, female students demonstrated higher civic knowledge than male students, and student socioeconomic status, reported across a range of measures, was positively associated with student civic knowledge.",
      "subjects": [
        "Education",
        "Educational Policy and Politics",
        "Education, general",
        "Citizenship Education",
        "Educational Policy and Politics",
        "Assessment and Testing"
      ]
    },
    {
      "source": "Springer",
      "identifier": "10.1007/978-3-031-73741-1_19",
      "title": "From Explanation Correctness to Explanation Goodness: Only Provably Correct Explanations Can Save the World",
      "abstract": "Explainability Engineering gets evermore important in the era of self-learning and automated systems. We motivate the necessity for interdisciplinary research to engineer verifiably correct and good explanations: Systems engineering research must ensure that correct and machine-understandable explanations can be derived from system specifications and social sciences research must ensure that a context-dependent and stakeholder-tailored explanation can be provided in a fitting manner. We describe our first steps in the direction of a holistic and interdisciplinary explainability engineering process for tackling these challenges.",
      "subjects": [
        "Computer Science",
        "Logics and Meanings of Programs",
        "Software Engineering/Programming and Operating Systems",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence",
        "Computer Science Logic and Foundations of Programming",
        "Software Engineering",
        "Special Purpose and Application-Based Systems",
        "Computer System Implementation",
        "Artificial Intelligence"
      ]
    },
    {
      "source": "IEEE",
      "identifier": "0",
      "title": "Bargaining Game Based Time Scheduling Scheme for Ambient Backscatter Communications",
      "abstract": "Backscatter communications have been acknowledged as an essential key technology in the Internet of Things (IoT) applications. Considering the fact that it needs the coordination from network agents, cooperative bargaining theory is an effective method to strike an appropriate system performance. In this paper, we investigate time scheduling algorithms for a backscatter-aided radio-frequency (RF) powered cognitive radio (CR) network, where multiple secondary transmitters can switch among the backscatter, the energy harvest, and active data transmission modes. Our objective is to maximize the RF-CR system performance while exploring the mutual benefits to leverage a reciprocal consensus between different control issues. According to the ideas of two different bargaining solutions - \nmodified Nash bargaining solution\n and \nequitable Nash bargaining solution\n, we design a new dual bargaining game model to effectively share the limited time resources. The main novelty of our proposed approach is its adaptability, flexibility and responsiveness to current RF-CR system conditions. At last, numerical simulations are carried out to evaluate the performance of the proposed scheme, and we demonstrate the benefits of our dual bargaining game approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "1",
      "title": "The Use of Tangible User Interfaces in K12 Education Settings: A Systematic Mapping Study",
      "abstract": "Tangible User Interfaces have enriched and expanded the user experience when interacting with computers and smart devices. The monopoly of graphical user interfaces has been broken thanks to the emergence of new complementary technologies that allow for new ways of interacting with computer systems, such as tangible interaction, among others. Due to the scope and number of research articles addressing the Tangible User Interface that have been published, it can now be considered an interaction mechanism that is relatively mature and integrated within society. However, while the application of tangible interfaces in different areas is described as a success, there are only a limited number of research articles about their impact on education and learning systems. As a result, it is difficult to show the actual impact of Tangible User Interface technology in K12 education settings. This study tries to fill this gap by performing a systematic mapping study that shows the current state of research on the impact of this technology in these settings, analyzing the findings and identifying the main advances and limitations of this novel technology.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "2",
      "title": "Transient Surface Charge Characteristics of DC-GIL Insulator Under Thermal-Electric Coupled Fields",
      "abstract": "The insulator in direct current gas-insulated transmission lines (DC-GIL) would suffer discharge risk due to surface charge accumulation under thermal-electric coupled fields. In this paper, the transient surface charge accumulation characteristics of a basin-type DC-GIL insulator is investigated via finite element method based on a three-dimension horizontally installed GIL model. The stationary temperature distribution of the model is obtained and then applied to the transient simulation of charge. Weak form partial differential equation is employed to deal with the ion transportation equation. Equations and parameters in the simulation are optimized to reduce the computing memory and time. Results indicate that the charge accumulation is accelerated due to the promotion of conduction through the insulator under thermal gradient. Higher charge density is obtained under thermal gradient. And the surface charge density of the convex surface is higher due to the promoted conduction. The highest field strength increases and the corresponding location moves along the convex surface during the transient process. This could attribute to the influence of transient charge behavior under thermal gradient on the electric field distribution. This study indicates that the thermal gradient and transient charge accumulation should be considered when dealing with the insulation characteristics of DC-GIL with insulators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "3",
      "title": "Electromagnetic Vibration Characteristics Analysis of a Squirrel-Cage Induction Motor Under Different Loading Conditions",
      "abstract": "Electromagnetic vibration is an important excitation source for squirrel-cage induction motors. However, the electromagnetic vibration under various loadings has not been sufficiently analyzed. It is proposed in this paper that the electromagnetic vibration of motors under different loads can be obtained by analyzing the amplitude of the electromagnetic force wave. The Maxwell tensor method is employed to derive the spatial and temporal distributions of the radial force. This paper also calculates the radial force using the finite element method and decodes the calculated results using two dimensional fast Fourier transform (2D-FFT) to determine the amplitude of the electromagnetic force at the spatial order under different loads. In addition, through the modal analysis of the stator core, it can be concluded that in the case of nonresonance, the vibration response increases when the electromagnetic force of the first-order and second-order rotor slot harmonic increases. Finally, the conclusion is verified by separating the electromagnetic vibration of the motor using a vibration test rig.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "4",
      "title": "kNN-STUFF: kNN STreaming Unit for Fpgas",
      "abstract": "This paper presents kNN STreaming Unit For Fpgas (kNN-STUFF), a modular, scalable and efficient Hardware/Software implementation of k-Nearest Neighbors (kNN) classifier targeting System on Chip (SoC) devices. It takes advantage of custom accelerators, implemented on the reconfigurable fabric of the SoC device, to perform most of the classifier’s workload, whereas the processor coordinates the accelerators and runs the remaining workload of the kNN algorithm. kNN-STUFF offers a highly flexible framework, where the designer has the possibility to define the number of parallel instances of the classifier and the parallelism within each instance. This capability allows creating the most suitable implementation for a target device of any size. Results show that kNN-STUFF, with 24 accelerators, attains performance improvements up to \n 67.4\\times 67.4×67.4\\times  \n, when compared to an optimized (−O3) software-only implementation of the kNN running on a single core of the ARM Cortex-A9 CPU. Furthermore, its energy efficiency improvements are as high as \n 50.6\\times 50.6×50.6\\times  \n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "5",
      "title": "Dynamic Order-Based Scheduling Algorithms for Automated Retrieval System in Smart Warehouses",
      "abstract": "In typical e-commerce warehouse operations, upon receiving the orders from customers, the purchased items need to be retrieved from shelves and then packaged accordingly for delivery. To automate and speed up the item retrieval process, a Smart Warehouse usually employs a management system, called the Automated Retrieval System (ARS), to control and schedule the retrieval jobs. The working principle of ARS is crucial to the Smart Warehouse because it will have a great impact on the subsequent downstream processes. In short, all the items in a particular order should be considered as an integral part; if one of these items encounters a much larger retrieval delay than others do, then the entire order may experience an unnecessary latency. In the past, the integrality of order has not received much attention for the parallel retrieval process of multiple stackers. To take this into account, this paper proposes using an Order Tag to label all the items that belong to the same order for retrieval job scheduling. The way of calculating the Order Tags will then determine the scheduling discipline of the ARS. With the objectives of minimizing the average delay and ensuring the fairness, two algorithms are proposed. They are named as Dynamic Order-Based (DOB) and Dynamic Order-Based with Threshold (DOBT) Scheduling Algorithms, respectively. Compared with the First-Come-First-Serve and other approaches, the simulation results show that DOB and DOBT are able to reduce the average order retrieval delay by at least 30%, and generate less backlog pressure to the downstream operations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "6",
      "title": "A Matheuristic Algorithm for the Multiple-Depot Vehicle and Crew Scheduling Problem",
      "abstract": "This work addresses the multiple-depot vehicle and crew scheduling problem (MDVCSP). In MDVCSP, we deal with two NP-hard problems in an integrated way: the multiple-depot vehicle scheduling problem (MDVSP) and the crew scheduling problem (CSP). For solving the MDVCSP, we define the vehicles’ operational routine and the workdays of the crews of a public bus transport system with multiple depots. Given the difficulty of solving real-world instances of the MDVCSP using exact mathematical methods, we propose a matheuristic algorithm for solving it. This matheuristic algorithm combines two strategies into an iterated local search (ILS) based framework: a branch-and-bound algorithm for solving the MDVSP and a variable neighborhood descent (VND) based algorithm for treating the associated CSPs. We compared the proposed ILS-MDVCSP with five approaches in the literature that use the same benchmark test instances. We also solved a real-world problem of one of Brazil’s largest cities. For this problem, we proposed a formulation based on a time-space network to address the MDVSP subproblem. The results obtained showed the effectiveness of ILS-MDVCSP, mainly to deal with real-world and large-scale problems. The algorithm was able to solve the largest instances from the literature, for which there was no reported solution. Regarding the run time, as the instances’ size increases, our approach becomes substantially less costly than the others from the literature. For the Brazilian instances, the ILS-MDVCSP saved, on average, the use of 12 vehicles per day and reduced by up to 15% the daily operational time of the vehicles.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "7",
      "title": "Smart Optical Sensors for Internet of Things: Integration of Temperature Monitoring and Customized Security Physical Unclonable Functions",
      "abstract": "Nowadays, the Internet of Things (IoT) has an astonishingly societal impact in which healthcare services stand out. Amplified by the COVID-19 pandemic scenario, challenges include the development of authenticatable smart IoT devices with the ability to simultaneously track people and sense in real-time human body temperature aiming to infer a health condition in a contactless and remote way through user-friendly equipment such as a smartphone. Univocal smart labels based on quick response (QR) codes were designed and printed on medical substrates (protective masks and adhesive) using flexible organic-inorganic luminescent inks. Luminescence thermometry and physical unclonable functions (PUFs) are simultaneously combined allowing non-contact temperature detection, identification, and connection with the IoT environment through a smartphone. This is an intriguing example where luminescent inks based on organic-inorganic hybrids modified by lanthanide ions are used to fabricate a smart label that can sense temperature with remarkable figures of merit, including maximum thermal sensitivity of \n Sr=1.46S_{\\mathrm {r}}=1.46 \n %K\n−1\n and temperature uncertainty of \n δT=0.2\\delta T=0.2 \n K, and an authentication methodology accuracy, precision, and recall of 96.2%, 98.9%, and 85.7%, respectively. The methodology proposed is feasibly applied for the univocal identification and mobile optical temperature monitoring of individuals, allowing the control of the access to restricted areas and the information transfer to medical entities for post medical evaluation towards a new generation of mobile-assisted \neHealth\n (\nmHealth\n).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "8",
      "title": "Sub-6 GHz Highly Isolated Wideband MIMO Antenna Arrays",
      "abstract": "This study proposes a compact four-port multiple-input multiple-output (MIMO) antenna system to operate within a frequency range of 3.2–5.75 GHz to serve in 5G new radio (NR) sub-6 GHz n77/n78/n79 and 5 GHz WLAN with good impedance matching. To increase the isolation between the MIMO antenna elements with low complexity and cost, the antenna elements are orthogonally oriented to each other with distance spacing of \n 0.3\\lambda _{\\text {o}}0.3λo0.3\\lambda _{\\text {o}} \n between elements, including electromagnetic bandgap (EBG) structure, defected ground structure (DGS), capacitive elements (CE), and neutralization line (NL). The simulation results show that the measured mutual coupling between the array elements is improved from −20 to −45 dB. The envelope correlation coefficient is enhanced. In addition, the diversity gain, mean effective gain, and total active reflection coefficient are improved simultaneously. The suggested structure has been designed on CST Microwave Studio 2019. The antennas’ overall dimensions for all methods are the same as they approach 46 mm \n \\times46×46\\times46 \n mm \n \\times1.6×1.6\\times1.6 \n mm. The measured gain of the proposed designs ranges from 6 to 9 dBi, and the radiation efficiency approaches 90%. The antennas are fabricated and tested, where better experimental results are noticed compared to the simulation results. Our antennas are designed over FR-4 substrate with a noticeable cost reduction. Each antenna element has a dimension of 15 mm \n \\times23×23\\times23 \n mm \n \\times1.6×1.6\\times1.6 \n mm. An “EL” slot into the radiating element and two identical stubs coupled to the partial ground are used to improve the impedance matching and radiation characteristics across the bands of interest. The isolation decreases by 22 dB using the EBG method, reaching the value of −65 dB. Meanwhile, the isolation decreases by 19 dB using the DGS method, reaching −60 dB. Due to gaps between adjacent unit cells and the capacitance generated from the dielectric gap between the top metallic patch and ground plane, ...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "9",
      "title": "Robust Charging Schedule for Autonomous Electric Vehicles With Uncertain Covariates",
      "abstract": "Autonomous electric vehicles (AEVs) will become an inevitable trend in the future transportation network and have an important impact on the power grid. It is difficult to find the optimal distributed charging solution for AEVs to minimize the system cost with some uncertainties. In this paper, we investigate an AEVs charging and discharging problem with vehicle-to-grid (V2G) services. We aim to minimize the total electricity cost and battery degradation cost of AEVs and charging station batteries with V2G services, which takes the random arrival and departure of AEVs into account. We first propose a distributed charging framework of AEVs and charging stations by clustering method with the constraint of limited AEVs for each charging station in a region and formulate a distributed offline optimization problem. Then we formulate a distributed online charging optimization problem and propose a distributed online AEV charging scheduling (DOAS) algorithm to get an optimal charging solution. To study a more practical case, we reformulate the distributed online optimization problem with the uncertainties from base loads, renewable energy and charging demands. Furthermore, to improve the time efficiency of DOAS algorithm, we reduce the dimension of the distributed problem and design a dimension-reduction DOAS (DDOAS) algorithm. To seek a robust solution with some uncertainties, we propose a DDOAS algorithm with DRO based on Wasserstein distance (DDODW). Simulation results show that DOAS and DDOAS algorithms can have a close-to-optimal charging cost and a significantly less battery degradation cost of charging stations, compared with centralized online charging scheduling algorithm and DDOAS algorithm is more time-efficient than DOAS algorithm. The proposed DDODW algorithm can provide a robust solution for the energy schedule",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "10",
      "title": "An Improved SVM-Based Spatial Spectrum Sensing Scheme via Beamspace at Low SNRs",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "11",
      "title": "Opportunistic Relay in Multicast Channels With Generalized Shadowed Fading Effects: A Physical Layer Security Perspective",
      "abstract": "Through ordinary transmissions over wireless multicast networks are greatly hampered due to the simultaneous presence of fading and shadowing of wireless channels, secure transmissions can be enhanced by properly exploiting random attributes of the propagation medium. This study focuses on the utilization of those attributes to enhance the physical layer security (PLS) performance of a dual-hop wireless multicast network over \n κ−μ\\kappa -\\mu  \n shadow-fading channel under the wiretapping attempts of multiple eavesdroppers. In order to improve the secrecy level, the best relay selection strategy among multiple relays is employed. Performance analysis is carried out based on the mathematical modeling in terms of analytical expressions of non-zero secrecy capacity probability, secure outage probability, and ergodic secrecy capacity over multicast relay networks. Capitalizing on those expressions, the effects of system parameters, i.e., fading, shadowing, the number of antennas, destination receivers, eavesdroppers, and relays, on the secrecy performance are investigated. Numerical results show that the detrimental impacts caused by fading and shadowing can be remarkably mitigated using the well-known opportunistic relaying technique. Moreover, the proposed model unifies secrecy analysis of several classical models, thereby exhibiting enormous versatility than the existing works. Finally, all the numerical results are authenticated utilizing Monte-Carlo simulations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "12",
      "title": "Advances in Adversarial Attacks and Defenses in Computer Vision: A Survey",
      "abstract": "Deep Learning is the most widely used tool in the contemporary field of computer vision. Its ability to accurately solve complex problems is employed in vision research to learn deep neural models for a variety of tasks, including security critical applications. However, it is now known that deep learning is vulnerable to adversarial attacks that can manipulate its predictions by introducing visually imperceptible perturbations in images and videos. Since the discovery of this phenomenon in 2013, it has attracted significant attention of researchers from multiple sub-fields of machine intelligence. In 2018, we published the first-ever review of the contributions made by the computer vision community in adversarial attacks on deep learning (and their defenses). Many of those contributions have inspired new directions in this area, which has matured significantly since witnessing the first generation methods. Hence, as a legacy sequel of our first literature survey, this review article focuses on the advances in this area since 2018. We thoroughly discuss the first generation attacks and comprehensively cover the modern attacks and their defenses appearing in the prestigious sources of computer vision and machine learning research. Besides offering the most comprehensive literature review of adversarial attacks and defenses to date, the article also provides concise definitions of technical terminologies for the non-experts. Finally, it discusses challenges and future outlook of this direction based on the literature since the advent of this research direction.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "13",
      "title": "Multicriteria Classifier Ensemble Learning for Imbalanced Data",
      "abstract": "One of the vital problems with the imbalanced data classifier training is the definition of an optimization criterion. Typically, since the exact cost of misclassification of the individual classes is unknown, combined metrics and loss functions that roughly balance the cost for each class are used. However, this approach can lead to a loss of information, since different trade-offs between class misclassification rates can produce similar combined metric values. To address this issue, this paper discusses a multi-criteria ensemble training method for the imbalanced data. The proposed method jointly optimizes \nprecision\n and \nrecall\n, and provides the end-user with a set of Pareto optimal solutions, from which the final one can be chosen according to the user’s preference. The proposed approach was evaluated on a number of benchmark datasets and compared with the single-criterion approach (where the selected criterion was one of the chosen metrics). The results of the experiments confirmed the usefulness of the obtained method, which on the one hand guarantees good quality, i.e., not worse than the one obtained with the use of single-criterion optimization, and on the other hand, offers the user the opportunity to choose the solution that best meets their expectations regarding the trade-off between errors on the minority and the majority class.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "14",
      "title": "Autonomous Control of Combat Unmanned Aerial Vehicles to Evade Surface-to-Air Missiles Using Deep Reinforcement Learning",
      "abstract": "This paper proposes a new reinforcement learning approach for executing combat unmanned aerial vehicle (CUAV) missions. We consider missions with the following goals: guided missile avoidance, shortest-path flight and formation flight. For reinforcement learning, the representation of the current agent state is important. We propose a novel method of using the coordinates and angle of a CUAV to effectively represent its state. Furthermore, we develop a reinforcement learning algorithm with enhanced exploration through amplification of the imitation effect (AIE). This algorithm consists of self-imitation learning and random network distillation algorithms. We assert that these two algorithms complement each other and that combining them amplifies the imitation effect for exploration. Empirical results show that the proposed AIE approach is highly effective at finding a CUAV's shortest-flight path while avoiding enemy missiles. Test results confirm that with our method, a single CUAV reaches its target from its starting point 95% of the time and a squadron of four simultaneously operating CUAVs reaches the target 70% of the time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "15",
      "title": "Energy-Saving Algorithm and Simulation of Wireless Sensor Networks Based on Clustering Routing Protocol",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "16",
      "title": "Toward Performing Image Classification and Object Detection With Convolutional Neural Networks in Autonomous Driving Systems: A Survey",
      "abstract": "Nowadays Convolutional Neural Networks (CNNs) are being employed in a wide range of industrial technologies for a variety of sectors, such as medical, automotive, aviation, agriculture, space, etc. This paper reviews the state-of-the-art in both the field of CNNs for image classification and object detection and Autonomous Driving Systems (ADSs) in a synergetic way. Layer-based details of CNNs along with parameter and floating-point operation number calculations are outlined. Using an evolutionary approach, the majority of the outstanding image classification CNNs, published in the open literature, is introduced with a focus on their accuracy performance, parameter number, model size, and inference speed, highlighting the progressive developments in convolutional operations. Results of a novel investigation of the convolution types and operations commonly used in CNNs are presented, including a timing analysis aimed at assessing their impact on CNN performance. This extensive experimental study provides new insight into the behaviour of each convolution type in terms of training time, inference time, and layer level decomposition. Building blocks for CNN-based object detection are also discussed, such as backbone networks and baseline types, and then representative state-of-the-art designs are outlined. Experimental results from the literature are summarised for each of the reviewed models. This is followed by an overview of recent ADSs related works and current industry activities, aiming to bridge academic research and industry practice on CNNs and ADSs. Design approaches targeted at solving problems of automakers in achieving real-time implementations are also proposed based on a discussion of design constraints, human vs. machine evaluations and trade-off analysis of accuracy vs. size. Current technologies, promising directions, and expectations from the literature on ADSs are introduced including a comprehensive trade-off analysis from a human-machine perspecti...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "17",
      "title": "Detection of Application Layer DDoS Attack Based on SIS Epidemic Model",
      "abstract": "Distrusted Denial of Service attack (DDoS) is one of the major threats to network security. The HTTP flooding attack is the hardest type of DDoS attacks to detect since the malicious packets are hidden in a huge amount of normal traffic. In this work, we introduce a new detection scheme for HTTP flooding attack by using Susceptible-Infective-Susceptible (SIS) model of an infectious disease which used in dynamic systems. During any time interval, the server can measure various values of attributes for its users like number of total connections, number of open connections and number of closed connections. These values can be used to detect any abnormal behavior or infected connections in a server by mapping this attributes with SIS model. Thus we can get suspected and infected connections during every time interval. Extensive trace driven simulation has been conducted to demonstrate the efficiency of the proposed scheme in terms of its detection rate and probability of false positive.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "18",
      "title": "Hiding Secret Messages in Living Cells in the Age of Next-Generation Sequencing",
      "abstract": "Hiding secret messages (SMs) based on DNA technologies plays a critical role in DNA computing. In recent years, scientists have hidden SMs at a specific site in the plasmids of various living cells. Unfortunately, this strategy was proposed without considering the attack of next-generation sequencing (NGS). Nowadays, NGS, which is a revolutionary massively parallel sequencing technique, is developing rapidly. With the help of NGS, sequencing completely unknown genomes is becoming popular in various laboratories throughout the world. The ability to sequence completely unknown genomes is a major threat to existing hiding strategies in living cells. To prevent against the attack of NGS, this paper proposes a scheme to hide SMs in living cells (SHSM). Compared with previous studies, the main contribution of SHSM is changing the specific single hiding site into random multiple hiding sites through the application of seamless clustered regularly interspaced short palindromic repeats/CRISPR-associated9 (CRISPR/Cas9) technique. In SHSM, SMs are hidden in living cells with different puzzling messages at different sites every time to prevent against the attack of NGS. To read the SM, high-fidelity polymerase chain reaction (PCR) and Sanger sequencing are used. A hash function is used to ensure the integrity of the message. These measures mean that an attacker would not be able to determine the location of the SM using NGS. The feasibility of SHSM was validated by a wet-lab experiment, and the security was demonstrated by the system's entropy. The author hopes this study will bring attention to the threat of NGS, and advance the development of hiding SMs in living cells.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "19",
      "title": "Vehicle-to-Grid Aggregator to Support Power Grid and Reduce Electric Vehicle Charging Cost",
      "abstract": "This paper presents an optimised bidirectional Vehicle-to-Grid (V2G) operation, based on a fleet of Electric Vehicles (EVs) connected to a distributed power system, through a network of charging stations. The system is able to perform day-ahead scheduling of EV charging/discharging to reduce EV ownership charging cost through participating in frequency and voltage regulation services. The proposed system is able to respond to real-time EV usage data and identify the required changes that must be made to the day-ahead energy prediction, further optimising the use of EVs to support both voltage and frequency regulation. An optimisation strategy is established for V2G scheduling, addressing the initial battery State Of Charge (SOC), EV plug-in time, regulation prices, desired EV departure time, battery degradation cost and vehicle charging requirements. The effectiveness of the proposed system is demonstrated using a standardized IEEE 33-node distribution network integrating five EV charging stations. Two case studies have been undertaken to verify the contribution of this advanced energy supervision approach. Comprehensive simulation results clearly show an opportunity to provide frequency and voltage support while concurrently reducing EV charging costs, through the integration of V2G technology, especially during on-peak periods when the need for active and reactive power is high.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "20",
      "title": "A New Hybrid Cascaded Switched-Capacitor Reduced Switch Multilevel Inverter for Renewable Sources and Domestic Loads",
      "abstract": "This multilevel inverter type summarizes an output voltage of medium voltage based on a series connection of power cells employing standard configurations of low-voltage components. The main problems of cascaded switched-capacitor multilevel inverters (CSCMLIs) are the harmful reverse flowing current of inductive loads, the large number of switches, and the surge current of the capacitors. As the number of switches increases, the reliability of the inverter decreases. To address these issues, a new CSCMLI is proposed using two modules containing asymmetric DC sources to generate 13 levels. The main novelty of the proposed configuration is the reduction of the number of switches while increasing the maximum output voltage. Despite the many similarities, the presented topology differs from similar topologies. Compared to similar structures, the direction of some switches is reversed, leading to a change in the direction of current flow. By incorporating the lowest number of semiconductors, it was demonstrated that the proposed inverter has the lowest cost function among similar inverters. The role of switched-capacitor inrush current in the selection of switch, diode, and DC source for inverter operation in medium and high voltage applications is presented. The inverter performance to supply the inductive loads is clarified. Comparison of the simulation and experimental results validates the effectiveness of the proposed inverter topology, showing promising potentials in photovoltaic, buildings, and domestic applications. A video demonstrating the experimental test, and all manufacturing data are attached.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "21",
      "title": "Entropy Method for Structural Health Monitoring Based on Statistical Cause and Effect Analysis of Acoustic Emission and Vibration Signals",
      "abstract": "Acoustic emission (AE) and vibration signal are significant criteria of damage identification in structural health monitoring (SHM) engineering. Multi-disciplinary knowledge and synergistic parameter effects are technical challenges for damage assessment modelling. This study proposes a structural damage cause-and-effect analysis method based on parameter information entropy. Monitoring data is used to form a time-domain feature wave (TFW). The structural strength degradation factor (DF) would be used to define structural damage information entropy (SDIE) vector. The structural damage cause and effect model is developed in a probability sense. A fatigue index is adopted for damage assessment, and a causal strength index is proposed to locate the most likely damage cause. A sandstone-truss structure experiment was conducted to show that the proposed method is effective for damage evaluation and the experimental results provide strong support. This is a statistical damage identification method based on causal logic uncertainty, meaning a complicated mechanics calculation can be avoided.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "22",
      "title": "Development of a Multi-Dimensional Parametric Model With Non-Pharmacological Policies for Predicting the COVID-19 Pandemic Casualties",
      "abstract": "Coronavirus Disease 2019 (COVID-19) has spread the world resulting in detrimental effects on human health, lives, societies, and economies. The state authorities mostly take non-pharmacological actions against the outbreak since there are no confirmed vaccines or treatments yet. In this paper, we developed Suspicious-Infected-Death with Non-Pharmacological policies (SpID-N) model to analyze the properties of the COVID-19 casualties and also estimate the future behavior of the outbreak. We can state the key contributions of the paper with three folds. Firstly, we propose the SpID-N model covering the higher-order internal dynamics which cause the peaks in the casualties. Secondly, we parametrize the non-pharmacological policies such as the curfews on people with chronic disease, people age over 65, people age under 20, restrictions on the weekends and holidays, and closure of the schools and universities. Thirdly, we explicitly incorporate the internal and coupled dynamics of the model with these multi-dimensional non-pharmacological policies. The corresponding higher-order and strongly coupled model has utterly unknown parameters and we construct a batch type Least Square (LS) based optimization algorithm to learn these unknown parameters from the available data. The parametric model and the predicted future casualties are analyzed extensively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "23",
      "title": "Credit-Based Distributed Real-Time Energy Storage Sharing Management",
      "abstract": "In this paper, energy storage sharing among a group of cooperative households with integrated renewable generations in a grid-connected microgrid is studied. In such a microgrid, a group of households, who are willing to cooperatively operate a shared energy storage via a central coordinator, aims to minimize their long term time-averaged costs, by jointly taking into account the operational constraints of the shared energy storage, the stochastic solar power generations and the time-varying load demands from all households, as well as the fluctuating electricity prices. This energy management problem, which comprises storage management and load control, is first formulated as a constrained stochastic programming problem. Based on the Lyapunov optimization theory, a distributed real-time sharing control algorithm is proposed to solve the constrained stochastic programming problem without requiring any statistical knowledge of the stochastic renewable energy generations and the uncertain power loads. The credit-based distributed sharing algorithm, in which each household independently solves a simple convex optimization problem without requiring any statistics of the system, is designed to quickly adapt to the system dynamics while facilitating a fair allocation of the shared energy storage with respect to individual households' energy contributions. The performance of the proposed low-complexity distributed sharing algorithm is evaluated via theoretical analysis. Numerical simulations using a practical system setup are conducted to investigate the effectiveness of the proposed sharing control algorithm in terms of energy cost saving and fairness. The simulation results show that the proposed credit-based distributed sharing algorithm can save power consumption cost by coordinating the use of the shared battery among households in a fair manner while improving the utilization of renewable energy generation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "24",
      "title": "On the Link Between Subjective Score Prediction and Disagreement of Video Quality Metrics",
      "abstract": "Several video quality metrics (VQMs) have been proposed in many publications to predict how humans perceive video quality. It is common to observe significant disagreements amongst the quality predictions of these VQMs for the same video sequence. Following an extensive literature search, we found no publicised work that has investigated if such disagreements convey useful information on the accuracy of VQMs. Herein, a measure for quantifying the disagreement between VQMs is proposed. A small-scale subjective study is carried out to assess the effectiveness of our proposal. In particular, the proposed disagreement measure is shown to be extremely effective in determining whether the quality of any given processed video sequence (PVS) can be accurately predicted by the VQMs. This type of information is particularly useful for identifying video sequences that are likely to degrade the end-user’s quality of experience (QoE). Our proposal is also useful in selecting the most effective PVSs to be employed in a subjective test. We show that the proposed disagreement measure can be effectively predicted from bitstream features. This establishes a link between the capability to accurately assess the quality of a PVS and the way it is encoded. In addition, an analysis is conducted to compare the performances of some well-known and widely used open-source metrics and two proprietary metrics. The two proprietary metrics are used by a large media company for enhancing its delivery pipeline. The outcome of this comparison highlights the suitability of the open-source VQM, Video Multi-method Assessment Fusion (VMAF), as a good benchmark quality measure for both the industrial and academic environments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "25",
      "title": "Selective Encryption of the Versatile Video Coding Standard",
      "abstract": "versatile video coding (VVC) is the next generation video coding standard developed by the joint video experts team (JVET) and released in July 2020. VVC introduces several new coding tools providing a significant coding gain over the high efficiency video coding (HEVC) standard. It is well known that increasing the coding efficiency adds more dependencies in the video bitstream making format-compliant encryption with the standard more challenging. In this paper we tackle the problem of selective encryption of the VVC standard in format-compliant and constant bitrate. These two constraints ensure that the encrypted bitstream can be decoded by any VVC decoder while the bitrate remains unchanged by the encryption. The selective encryption of all possible VVC syntax elements is investigated. A new algorithm is proposed to encrypt in format-compliant and constant bitrate the transform coefficients (TCs) together with other syntax elements at the level of the entropy encoder. The proposed solution was integrated and assessed under the VVC reference software model version 6.0. Experimental results showed that encryption drastically decreases the video quality while the encryption is robust against several types of attacks. The encryption space is estimated in the range of 15% to 26% of the bitstream size resulting in a lightweight encryption process. The web page of this work is publicly available at \nhttps://gugautie.github.io/sevvc/\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "26",
      "title": "Semantic Constraint GAN for Person Re-Identification in Camera Sensor Networks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "27",
      "title": "Solid-Electrolyte-Gated Graphene-Covered Metal-Insulator-Silicon-Insulator-Metal Waveguide With a Remarkably Large Modulation Depth",
      "abstract": "Silicon photonic modulators are an essential element in providing fast and massive connectivity to the data-centric world. Ever-increasing data usage requires them to be smaller, faster, and easier to fabricate. Graphene with exceptional properties has been emerging as a material for such next-generation silicon photonic modulators, and a variety of graphene-based photonic or plasmonic modulators have been realized and verified. However, due to weak light-graphene interaction in them, they have a modulation depth smaller than 0.16 dB/μm, which is similar to those of existing germanium-silicon electroabsorption modulators. This work reports a graphene-covered hybrid plasmonic waveguide that has truly strong light-graphene interaction. The hybrid plasmonic waveguide is realized with standard CMOS technology and efficiently coupled to a conventional Si waveguide. To prove the strong light-graphene interaction, solid-electrolyte gating is used to modulate the intensity of the waveguide although its modulation speed is slow. It is demonstrated that the waveguide has a remarkably large modulation depth of 0.276 dB/μm even though just one single-layer graphene covers the waveguide. This demonstration opens the door to the waveguide covered with a graphene-oxide-graphene capacitor, which may have a larger modulation depth and a large 3-dB bandwidth, and it is theoretically analyzed. This work may be the solid base for a graphene-based silicon photonic modulator which is theoretically expected to surpass current silicon photonic modulators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "28",
      "title": "Enhancing Rescue Operations With Virtualized Mobile Multimedia Services in Scarce Resource Devices",
      "abstract": "The aim of this article is to present an architecture to support reconfigurable multimedia services for a practical emergency environment use case of rescue operations. Specifically, radio communication and video surveillance services are provided by means of a small device carried by a mobile vehicle. This solution is validated by implementing a digital mobile radio (DMR) standard radio hotspot and a video streaming server in an unmanned aerial vehicle (UAV) that conveys a device with scarce resources in order to minimize power consumption. To achieve a fast and flexible deployment of the envisioned services, a virtualization-based approach is proposed. Namely, a Kubernetes orchestrator is used to manage the life-cycle of services deployed on a small resource device, endowing the architecture with scalability and management flexibility. This article describes the executed performance tests that measured key parameters such as deployment time and recovery time after disconnection. Highly promising results were obtained, showing that the proposed architecture can be deployed in less than 4 minutes and can recover from network disconnections in less than 10 seconds. Thus, the performance, reliability and flexibility of the overall solution are demonstrated.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "29",
      "title": "Random Sampling-Arithmetic Mean: A Simple Method of Meteorological Data Quality Control Based on Random Observation Thought",
      "abstract": "The quality control of meteorological data has lately received great attention for its important significance to national ecological security and military security. However, the observational quality of the data has made it challenging to the quality control of meteorological data. In an effort to overcome this challenge, a random sampling-arithmetic mean (RS-AM) method based on the random observation method is proposed to solve the problem. Firstly, the reason why the arithmetic mean is not ideal for truth estimation is proved in the paper. Secondly, the method evaluates the goodness of fit between the expected distribution and the sampling distribution by repeatedly extracting the random observation vector based on the random sampling model, to find the random observation vector closest to the expected distribution. Then, the distance between the median and arithmetic mean of each set of claims is calculated by the distance formula, and the claims with the minimum distance are selected. The random extraction is continued on the selected set of claims until the stop condition is met. Finally, the truth is calculated by the method of arithmetic mean from the selected claims. Moreover, the convergence of this method is proved by theoretical derivation. Experimental results show that the proposed RS-AM method can effectively solve the problem of data observation quality. And, compared with the conflict resolution on heterogeneous data (CRH) method, the RS-AM method reduces 1.5% on MSE and 2.9% on RMSE while ensuring the error rate is basically the same.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "30",
      "title": "Adaptive Iterative Learning Control for Robot Manipulators With Time-Varying Parameters and Arbitrary Initial Errors",
      "abstract": "In this paper, a novel error-tracking adaptive iterative learning control scheme is proposed to solve trajectory-tracking problem for a class of robot manipulators with time-varying parameters and arbitrary initial errors. Firstly, desired error trajectories are constructed for implementing error tracking strategy in the robotic systems, so as to relax the requirement of zero initial errors, which is usually assumed to be met in traditional iterative learning control algorithms. Secondly, with the help of reasonable parameterization to the robotic dynamics, the adaptive iterative control law is designed by using Lyapunov approach. Projection-free combined time-domain and iteration-domain adaptive learning strategy is adopted to estimate the unknown time-invariant parametric uncertainties, and difference learning strategy is adopted to estimate unknown time-varying parametric uncertainties. As the iteration number increases, the system error follows its desired error trajectory over the whole interval. As a result, system state can perfectly track the reference signal in the predetermined part interval. In the end, several numerical simulations are presented to demonstrate the effectiveness of the designed control scheme.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "31",
      "title": "Self-Supervised Representation Learning for Document Image Classification",
      "abstract": "Supervised learning, despite being extremely effective, relies on expensive, time-consuming, and error-prone annotations. Self-supervised learning has recently emerged as a strong alternate to supervised learning in a range of different domains as collecting a large amount of unlabeled data can be achieved by simply crawling the internet. These self-supervised methods automatically discover features relevant to represent an input example by using self-defined proxy tasks. In this paper, we question the potential of commonly employed purely supervised training (starting either from ImageNet pretrained networks or pure random initialization) in contrast to self-supervised representations that can be learned directly using self-supervised representation learning methods on large document image datasets. For this purpose, we leverage a large-scale document image collection (RVL-CDIP) to train ResNet-50 image encoder using two different self-supervision methods (SimCLR and Barlow Twins). Employing a linear classifier on top of self-supervised embeddings from ResNet-50 results in an accuracy of 86.75% as compared to 71.43% from the corresponding ImageNet pretrained embeddings. Similarly, evaluating on Tobacco-3482 dataset using self-supervised embeddings from ResNet-50 yields an accuracy of 88.52% in contrast to 74.16% from the corresponding ImageNet pretrained embeddings. We show that in the case of limited labeled data, this wide gap in performance between self-supervised and fully supervised models persists even after fine-tuning pretrained models. However, a significant reduction in this gap is observed with an increasing amount of data including the case where the model is trained from scratch. Our results show that representations learned using self-supervised representation learning techniques are a viable option for document image classification, specifically in the context of limited labeled data, which is a usual restriction in industrial use cases.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "32",
      "title": "An Efficient Stochastic Reconfiguration Model for Distribution Systems With Uncertain Loads",
      "abstract": "Active power losses of distribution systems are higher than transmission ones, in which these losses affect the distribution operational costs directly. One of the efficient and effective methods for power losses reduction is distribution system reconfiguration (DSR). In this way, the network configuration is changed based on a specific power demand that has been already predicted by load forecasting techniques. The ohmic loss level in distribution system is affected by energy demand level, this is while an error in load forecasting can influence losses. Accordingly, including load uncertainty in DSR formulation is essential but this issue should not lead to change of the reconfiguration results significantly (i.e. the model should be robust). This paper presents a robust and efficient model for considering load uncertainty in network reconfiguration that is simple enough to implement in available commercial software packages and it is precise enough to find accurate solutions with low computational time. The analysis of results shows high efficiency and robustness of the proposed model for reconfiguration of distribution systems under demand uncertainty.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "33",
      "title": "Single-Point Crossover and Jellyfish Optimization for Handling Imbalanced Data Classification Problem",
      "abstract": "The imbalanced datasets and their classification has pulled in as a hot research topic over the years. It is used in different fields, for example, security, finance, health, and many others. The imbalanced datasets are balanced by applying resampling and various solutions are designed to tackle such datasets that mainly focus on class distribution issues. The imbalanced data is rebalanced using these methods. This paper introduces a technique for balancing data through two stages: first, oversampling methods are utilized in the process of rebalancing such imbalanced dataset using the single-point crossover to generate the new data of minority classes, second, it searches for an optimal subset of the imbalanced and balanced datasets by Jellyfish Search (JS) which is an optimization method. Experiments are performed on 18 real imbalanced datasets, and results are compared with famous oversampling methods and the recently published ACOR (Ant Colony Optimization Resampling) method in terms of different appraisal measurements. Higher performance is recorded by the proposed method and comparability with well-known and recent techniques.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "34",
      "title": "Sentiment Analysis of Customers’ Reviews Using a Hybrid Evolutionary SVM-Based Approach in an Imbalanced Data Distribution",
      "abstract": "Online media has an increasing presence on the restaurants’ activities through social media websites, coinciding with an increase in customers’ reviews of these restaurants. These reviews become the main source of information for both customers and decision-makers in this field. Any customer who is seeking such places will check their reviews first, which usually affect their final choice. In addition, customers’ experiences can be enhanced by utilizing other customers’ suggestions. Consequently, customers’ reviews can influence the success of restaurant business since it is considered the final judgment of the overall quality of any restaurant. Thus, decision-makers need to analyze their customers’ underlying sentiments in order to meet their expectations and improve the restaurants’ services, in terms of food quality, ambiance, price range, and customer service. The number of reviews available for various products and services has dramatically increased these days and so has the need for automated methods to collect and analyze these reviews. Sentiment Analysis (SA) is a field of machine learning that helps analyze and predict the sentiments underlying these reviews. Usually, SA for customers’ reviews face imbalanced datasets challenge, as the majority of these sentiments fall into supporters or resistors of the product or service. This work proposes a hybrid approach by combining the Support Vector Machine (SVM) algorithm with Particle Swarm Optimization (PSO) and different oversampling techniques to handle the imbalanced data problem. SVM is applied as a machine learning classification technique to predict the sentiments of reviews by optimizing the dataset, which contains different reviews of several restaurants in Jordan. Data were collected from Jeeran, a well-known social network for Arabic reviews. A PSO technique is used to optimize the weights of the features, as well as four different oversampling techniques, namely, the Synthetic Minority Oversampling T...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "35",
      "title": "Exploring the Determinants of Users’ Continuance Usage Intention of Smart Voice Assistants",
      "abstract": "The use of personal voice-assistants like Amazon \nAlexa\n and Google \nAssistant\n has been on the rise recently. To ensure a long-term success and widespread diffusion of these products it is important to evaluate their continued usage scenario instead of the initial adoption intention. Majority of research evaluating the continuance usage scenario do so via an expectation-confirmation approach. However, in this work a user engagement-based approach is taken for evaluating the utilitarian and hedonic attitudes of the users towards the continued usage scenario. This is augmented with additional contextual constructs like trust, privacy risk, and satisfaction. At present, there is little empirical evidence of user engagement with voice-assistants. Moreover, the present work focuses on the continuance usage of late adopters by considering two unique personal factors (slowness of adoption and skepticism). By evaluating the engagement aspect of the laggard group, the current findings contribute to theory by providing a better understanding of how the proposed antecedents determine the continuance intention. Data is collected from 244 late adopters of voice-assistants who use these devices in their daily life for building the research framework. All the proposed hypotheses are supported except the effect of privacy risk. The implications for both theory and practice are provided based on the findings.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "36",
      "title": "Improved Ground Target Detecting System Based on Both Miniaturized FMCW Radar and Radiometer",
      "abstract": "The frequency-modulated continuous-wave (FMCW) radar is generally applied in ground target detecting devices mounted on small shells or projectiles because of its compact size. However, the FMCW radar often produces false alarms when detecting ground targets surrounded by heavy clutter. To overcome this problem, this paper proposes a ground target detection system based on both the miniaturized FMCW radar and the total power radiometer (TPR), consisting of the common millimeter-wave (MMW) front ends and an antenna. However, its intermediate frequency (IF) parts are separated using different frequency bands to miniaturize the entire system. The minimum detectable temperature (MDT) increases and the sensitivity is thus degraded because the TPR for the hybrid sensor inevitably includes an undesirable transmitter section owing to the widespread usage of the front ends with the radar. The proposed system employs optimization of the physical path delay and duplexing the IF band for the TPR and FMCW radar to improve the sensitivity of the TPR in the proposed hybrid sensors and reduce the system noise. The system includes a matching circuit and a voltage doubler to improve the sensitivity of the detector. Therefore, the MDT of TPR in the proposed hybrid system can be reduced to 47.5 K from 734.6 K in the initial design. The drop test demonstrates that the proposed hybrid sensor can reduce false alarms when compared to using either the FMCW radar or only the TPR.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "37",
      "title": "Comparative Case Study of a Metamodel-Based Electric Vehicle Powertrain Design",
      "abstract": "In a variety of engineering applications, metamodels replace detailed computer models in order to reduce the computational effort of simulation processes. Unfortunately, metamodels also degrade the quality of the simulation results. However, no attention has been paid to this trade-off in previous research. Thus, we compare the computational effort and solution quality of a metamodel-based system design. As a use case for this comparison, we define a particular automotive powertrain design task and formulate it as a multi-objective optimization problem with two design objectives and three design variables. First, we solve this use case with a physics-based vehicle model, which is a typical detailed model for powertrain design. Second, we solve the same problem with metamodels. Here, we create several metamodels with different approximation accuracies to analyze the trade-off between computational effort and solution quality. The metamodel solution with the smallest deviation (<1 %) is computed about 9 times faster than the benchmark solution on the target computer used. The fastest metamodel solution is about 42 times faster and causes deviations between 5 % to 10 % compared to the benchmark. This case study can be used to develop metamodel schemes for other applications that provide fast yet accurate solutions. We also demonstrate the practicality of metamodels in real-world system design by comparing the computational effort quantitatively for the first time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "38",
      "title": "Recurrent NEAT Assisted 2D-DOA Estimation With Reduced Complexity for Satellite Communication Systems",
      "abstract": "Direction-of-arrival (DOA) estimation plays a vital role in the field of array signal processing. However, the need for heavy computing tasks in most traditional DOA algorithms, e.g., multiple signal classification (MUSIC), makes their engineering practicality significantly compromised in satellite communication systems. The neuroevolution of augmenting topologies (NEAT) can quickly search for appropriate topologies and weights of neural network functions, but its computational complexity is still too high for satellite systems. This paper proposes a modified NEAT architecture featuring a recurrent structure (RNEAT) that only needs a small number of phase components of the received signal covariance matrix as inputs to reduce the complexity and simplify the neural network architecture. The proposed RNEAT incorporated with multiple signal classification (RNEAT-MUSIC) features low complexity to achieve high resolution and low complexity simultaneously. Validation has been done by applying the proposed method in a two-dimensional direction of arrival estimation (2D-DOA) problem. Results show that the proposed RNEAT-MUSIC efficiently restricts the scanning region before forwarding the covariance matrix to the MUSIC stage. Consequently, the computational workload is reduced by 3/4 compared with the traditional 2D-MUSIC algorithm while maintaining satisfactory DOA resolution.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "39",
      "title": "The Effect of Fake Reviews on e-Commerce During and After Covid-19 Pandemic: SKL-Based Fake Reviews Detection",
      "abstract": "The outbreak of Covid-19 and the enforcement of lockdown, social distancing, and other precautionary measures lead to a global increase in online shopping. The increasing significance of online shopping and extensive use of e-commerce has increased competition between companies for online selling. Highlights that online reviews play a significant role in boosting a business or slandering it. Product review is an essential factor in customers’ decision-making, leading to an intense topic known as fraudulent or fake reviews detection. Given these reviews’ power over a business, the treacherous acts of giving false reviews for personal gains have increased with time. In our research, we proposed a fake review detection model by using Text Classification and techniques related to Machine Learning. We used classifiers such as Support Vector Machine, K-Nearest Neighbor, and logistic regression (SKL), using a bigram model that detects fraudulent reviews based on the number of pronouns, verbs, and sentiments. Our proposed methodology for detecting fake online reviews outperforms on the yelp dataset and the TripAdvisor dataset compared to other state-of-the-art techniques with 95% and 89.03% accuracy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "40",
      "title": "Battery Aging-Aware Online Optimal Control: An Energy Management System for Hybrid Electric Vehicles Supported by a Bio-Inspired Velocity Prediction",
      "abstract": "In this manuscript, we address the problem of online optimal control for torque splitting in hybrid electric vehicles that minimises fuel consumption and preserves battery life. We divide the problem into the prediction of the future velocity profile (i.e. driver intention estimation) and the online optimal control of the hybrid powertrain following a Model Predictive Control (MPC) scheme. The velocity prediction is based on a bio-inspired driver model, which is compared on various datasets with two alternative prediction algorithms adopted in the literature. The online optimal control problem addresses both the fuel consumption and the preservation of the battery life using an equivalent cost given the estimated speed profile (i.e. guaranteeing the desired performance). The battery degradation is evaluated by means of a state-of-the-art electrochemical model. Both the predictor and the Energy Management System (EMS) are evaluated in simulation using real driving data divided into 30 driving cycles from 10 drivers characterised by different driving styles. A comparison of the EMS performances is carried out on two different benchmarks based on an offline optimization, in one case on the entire dataset length and in the second on an ideal prediction using two different receding horizon lengths. The proposed online system, composed of the velocity prediction algorithm and the optimal control MPC scheme, shows comparable performances with the previous ideal benchmarks in terms of fuel consumption and battery life preservation. The simulations show that the online approach is able to significantly reduce the capacity loss of the battery, while preserving the fuel saving performances.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "41",
      "title": "System Dynamics Modeling and Simulation of Enterprise Patent Management Optimization",
      "abstract": "Taking the perspective of cybernetics theory, enterprise patent management can be described as a controllable information system which includes various activities and performances. This paper aims to analysis the relationship between enterprise patent activities and patent performance, and to help convert technological innovation achievements into patent rights more effectively and consolidate technology superiority. This paper uses System Dynamics method to construct a multiscale nonlinear enterprise patent management model. Validity of this model is tested, simulation is conducted in VENSIM, sensitivity analysis of this model shows that: Technology Disclosure Sufficiency does not have much influence on patent application quantity, but it has strongly positive effect on patent grant rate and patent portfolio diversity, it can also lower the risk of patent circumvention. Simulation shows that technology disclosure sufficiency is a key determinant to reduce information loss and improve output efficiency of enterprise patent management system. Collaboration of R&D personnel, patent engineers and patent agencies should be enhanced to improve TDS, so as to promote enterprise patent management efficiency. This SD model provides a foundation for future research in patent management optimization.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "42",
      "title": "Robot-Assisted Joint Attention: A Comparative Study Between Children With Autism Spectrum Disorder and Typically Developing Children in Interaction With NAO",
      "abstract": "Robots have been used in joint attention (JA) tasks with children with autism spectrum disorder (ASD). However, very few studies compared JA performance of children with ASD with typically developing children (TD) when interacting with a robotic partner and a traditional human partner. This study aims to: (a) to explore whether there are differences in response to and initiation of JA between ASD and TD children with two interactive partners: an adult and a social robot (NAO); and (b) to explore which characteristics of ASD children predicting their performance in robot-assisted JA tasks. Twenty-seven ASD and forty TD children were involved in this study in which they were exposed to diffident JA tasks. Mixed results were found per type of JA behavior over groups and conditions. Our results show that both ASD and TD children performed better with the human partner than with the robot in response to JA tasks. Among the characteristics of ASD children, ADOS total score is associated with response to JA performance. No significant result related to initiation of JA was found.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "43",
      "title": "Evolving Pre-Trained CNN Using Two-Layers Optimizer for Road Damage Detection From Drone Images",
      "abstract": "There are numerous pre-trained Convolutional Neural Networks (CNN) introduced in the literature, such as AlexNet, VGG-19, and ResNet. These pre-trained CNN models could be reused and applied to tackle different image recognition problems. Unfortunately, these pre-trained CNN models are complex and have a large number of convolutional filters. To tackle such a complexity challenge, this research aims to evolve a pre-trained VGG-19 using an efficient two-layers optimizer. The proposed optimizer performs filters selection of the last layers of VGG-19 guided by the accuracy of the linear SVM classifier. The proposed approach has three main advantages. Firstly, it adopts a powerful two-layers optimizer that works with a micro swarm population. Secondly, it automatically evolves a lightweight deep model which uses a small number of VGG-19 convolutional filters. Thirdly, It applies the developed model for real-world road damage detection from drone-based images. To evaluate the effectiveness of the proposed approach, a total of 529 images were captured by using a drone-based camera for various road damages. Reported results indicated that the proposed model achieved 96.4% F1-score accuracy with a reduction of VGG-19 filter up to 52%. In addition, the proposed two-layers optimizer was able to outperform several related optimizers such as Arithmetic Optimization Algorithm (AOA), Wild Geese Algorithm (WGO), Particle Swarm Optimization (PSO), Comprehensive Learning Particle Swarm Optimization (CLPSO), and Reinforcement Learning-based Memetic Particle Swarm Optimization (RLMPSO).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "44",
      "title": "Neural Network Approach to Program Synthesis for Tabular Transformation by Example",
      "abstract": "Data transformation is a laborious and time-consuming task for analysts. Programming by example (PBE) is a technique that can simplify this difficult task for data analysts by automatically generating programs for data transformation. Most of the previously proposed PBE methods are based on search algorithms, but recent improvements in machine learning (ML) have led to its application in PBE research. For example, RobustFill was proposed as an ML-based PBE method for string transformation by using long short-term memory (LSTM) as the sequential encoder–decoder model. However, an ML-based PBE method has not been developed for tabular transformations, which are used frequently in data analysis. Thus, in the present study, we propose an ML-based PBE method for tabular transformations. First, we consider the features of tabular transformations, which are more complex and data intensive than string transformations, and propose a new ML-based PBE method using the state-of-the-art Transformer sequential encoder–decoder model. To our knowledge, this is the first ML-based PBE method for tabular transformations. We also propose two decoding methods comprising multistep beam search and program validation-beam search, which are optimized for program generation, and thus generate correct programs with higher accuracy. Our evaluation results demonstrated that the Transformer-based PBE model performed much better than LSTM-based PBE when applied to tabular transformations. Furthermore, the Transformer-based model with the proposed decoding method performed better than the conventional PBE model using the search-based method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "45",
      "title": "SignBERT: A BERT-Based Deep Learning Framework for Continuous Sign Language Recognition",
      "abstract": "Continuous sign language recognition (CSLR) is a very challenging task in intelligent systems, since it requires to produce real-time responses while performing computationally intensive video analytics and language modeling. Previous studies mainly focus on adopting hidden Markov models or recurrent neural networks with a limited capability to model specific sign languages, and the accuracy can drop significantly when recognizing the signs performed by different signers with non-standard gestures or non-uniform speeds. In this work, we develop a deep learning framework named SignBERT, integrating the bidirectional encoder representations from transformers (BERT) with the residual neural network (ResNet), to model the underlying sign languages and extract spatial features for CSLR. We further propose a multimodal version of SignBERT, which combines the input of hand images with an intelligent feature alignment, to minimize the distance between the probability distributions of the recognition results generated by the BERT model and the hand images. Experimental results indicate that when compared to the performance of alternative approaches for CSLR, our method has better accuracy with significantly lower word error rate on three challenging continuous sign language datasets.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "46",
      "title": "The Effect of Stakeholders’ Satisfaction and Project Management Performance on Transitions in a Project Management Office",
      "abstract": "This paper aims, through a longitudinal case study, to present and analyze the transitions in operational activities and the performance of a Project Management Office (PMO) in a technology-based company. The paper discusses functions, tensions, stakeholders' interfaces, performance and how they drove the major changes faced by the PMO. The changes in the PMO were mainly based on non-planned events rather than in a change of the management process. The results demonstrated that political tensions in the organization, rather than project management performance, explained the PMO transitions. Managers must look for identifying tensions in the project management environment, project performance and stakeholders' satisfaction in order to propose and direct PMO changes and the sustainability of project ongoing best-practices. This study also contributes to the collection of evidences that corroborate previous literature appointments, as well as to question some results that need to be contextualized according contingencies for avoiding mimicry in the PMO implementation and transformation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "47",
      "title": "Towards Knowledge Enhanced Language Model for Machine Reading Comprehension",
      "abstract": "Machine reading comprehension is a crucial and challenging task in natural language processing (NLP). Recently, knowledge graph (KG) embedding has gained massive attention as it can effectively provide side information for downstream tasks. However, most previous knowledge-based models do not take into account the structural characteristics of the triples in KGs, and only convert them into vector representations for direct accumulation, leading to deficiencies in knowledge extraction and knowledge fusion. In order to alleviate this problem, we propose a novel deep model KCF-NET, which incorporates knowledge graph representations with context as the basis for predicting answers by leveraging capsule network to encode the intrinsic spatial relationship in triples of KG. In KCF-NET, we fine-tune BERT, a highly performance contextual language representation model, to capture complex linguistic phenomena. Besides, a novel fusion structure based on multi-head attention mechanism is designed to balance the weight of knowledge and context. To evaluate the knowledge expression and reading comprehension ability of our model, we conducted extensive experiments on multiple public datasets such as WN11, FB13, SemEval-2010 Task 8 and SQuAD. Experimental results show that KCF-NET achieves state-of-the-art results in both link prediction and MRC tasks with negligible parameter increase compared to BERT-Base, and gets competitive results in triple classification task with significantly reduced model size.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "48",
      "title": "A Hybrid Scheduling Mechanism Based on Agent Cooperation Mechanism and Fair Emergency First in Smart Factory",
      "abstract": "Smart factory also known as smart manufacturing is an emerging field with the revolution of industry 4.0. With the help of all these concepts, the smart factory integrates the manufacturing assets and represents industrial networks. In this paper, we focus on integrated solutions for smart factory concerns; by proposing an efficient task management mechanism based on an efficient and resource-aware scheduling scheme named as ACM-FEF. The scheduling algorithm used for the efficient task management is hybrid of the two scheduling approaches as agent cooperation mechanism (ACM) and fair emergency first (FEF) scheduling scheme. ACM is a decentralized scheduling approach which focuses on the production maximization goals per machine, and also pays attention to the production goals of all the machine networks involved in the smart factory. FEF scheduling scheme focuses on minimizing the tasks starvation rate and maximizing the machine utilization by efficiently using the machine slots. The proposed hybrid mechanism aims to efficiently plan tasks execution, maximize machines' resource utilization, maximize productivity, minimize production delays, efficiently handle exceptions and efficiently control smart factory actuators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "49",
      "title": "Land Use Classification Using High-Resolution Remote Sensing Images Based on Structural Topic Model",
      "abstract": "Remote sensing images are primary data sources for land use classification. High spatial resolution images enable more accurate analysis and identification of land cover types. However, a higher spatial resolution also brings new challenges to the existing classification methods. In the low-level feature spaces of remote sensing images, it is difficult to improve classification performance by modifying classifiers. Probabilistic topic models can connect low-level features and high-level semantics of remote sensing images. Latent Dirichlet allocation (LDA) models are representatives of probabilistic topic models. However, at present, probabilistic topic models are mainly adopted for scene classification and image retrieval in remote sensing image analysis only. In this study, multiscale segmentation was employed to construct bag-of-words (BoW) representations of high-resolution images. The segmented patches were then utilized as “image documents.” A structural topic model was used with an LDA model to import spatial information from the image documents at two levels: topical prevalence and topical content in the form of covariates. In this way, latent topic features in image documents can be more accurately deduced. The proposed method showed more satisfactory classification performance than standard LDA models and demonstrated a certain degree of robustness against the changes in the segmentation scale. Acknowledgement for the data support from “Yangtze River Delta Science Data Center, National Earth System Science Data Center, National Science & Technology Infrastructure of China (http://nnu.geodata.cn:8008)”.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "50",
      "title": "Transverse Flux Machine—A Review",
      "abstract": "For applications with high torque demand, gearboxes are commonly used to convert torque and speed in order to receive higher specific values for torque and power. This causes additional losses, cost, inaccuracies, effort, and noise. Eliminating the need of a mechanical gear and the associated disadvantages, Transverse Flux Machines with their high torque density are a very promising alternative. Despite a high torque density and a high efficiency, these types of machines are not commonly used. Due to the complex structure, challenges with mechanical design, and modeling of the machine behavior arise. Additionally, there are high requirements for the inverter due to the low power factor. This paper provides an overview of the state of the art including the potentials and advantages but also the problems and hindrances of these types of machines. Relating to linear and rotary machines from research and industry, the machine is introduced with its history, application and classification. Further, the general technical aspects, the influence of materials for flux guidance, the methods of modeling, methods for a minimization of torque ripples, as well as methods for power factor improvement are presented.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "51",
      "title": "An Efficient Building Evacuation Algorithm in Congested Networks",
      "abstract": "This paper proposes a new network model for the building evacuation problem considering congestion levels and provides a mixed integer linear programming (MILP) model and an efficient heuristic algorithm solving the problem. Constructing an optimization model with several congestion levels, we introduce a new network called the multi-class time-expanded (MCTE) network having several exclusive arcs connecting the same tail and head nodes. The MCTE networks make both the MILP model and the heuristic algorithm reflect a realistic situation in congested networks. Considering MCTE networks makes the problem difficult to solve, which motivates us to develop an efficient heuristic algorithm. We test our heuristic algorithm using several real-world networks such as a multiplex cinema, a subway station, and a large-size complex shopping mall in addition to an artificial network for clear comparison between the proposed algorithm and the MILP approaches. The results indicate that the proposed algorithm runs fast and produces a near-optimal solution compared with those from MILP models with a commercial solver.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "52",
      "title": "MSPL: Multimodal Self-Paced Learning for Multi-Omics Feature Selection and Data Integration",
      "abstract": "Rapid advances in high-throughput sequencing technology have led to the generation of a large number of multi-omics biological datasets. Integrating data from different omics provides an unprecedented opportunity to gain insight into disease mechanisms from different perspectives. However, integrative analysis and predictive modeling from multi-omics data are facing three major challenges: i) heavy noises; ii) the high dimensions compared to the small samples; iii) data heterogeneity. Current multi-omics data integration approaches have some limitations and are susceptible to heavy noise. In this paper, we present MSPL, a robust supervised multi-omics data integration method that simultaneously identifies significant multi-omics signatures during the integration process and predicts the cancer subtypes. The proposed method not only inherits the generalization performance of self-paced learning but also leverages the properties of multi-omics data containing correlated information to interactively recommend high-confidence samples for model training. We demonstrate the capabilities of MSPL using simulated data and five multi-omics biological datasets, integrating up three omics to identify potential biological signatures, and evaluating the performance compared to state-of-the-art methods in binary and multi-class classification problems. Our proposed model makes multi-omics data integration more systematic and expands its range of applications.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "53",
      "title": "Simultaneous Allocation of Multi-Type Distributed Generations and Capacitors Using Generic Analytical Expressions",
      "abstract": "This paper proposes a method for determining the optimal sites and sizes of multi-type distributed generations (DG) and capacitors for minimizing reactive power losses (RPL) in distribution systems. The proposed method is developed based on generic closed-form analytical expressions for calculating optimal sizes of DG units and capacitors at their candidate sites. The reduction in RPL with DG and capacitors is evaluated using another analytical expression that relates power injections of DG and capacitors with RPL. An optimal power flow algorithm (OPF) is incorporated in the proposed method to consider the constraints of the distribution systems, DG, and capacitors. Various types of DG are considered, and their optimal power factors can be accurately computed while optimizing the sizes of capacitors in a simultaneous manner to reduce RPL. The 69-bus distribution system is used to test the proposed method. An exact search method is employed to verify the accuracy of the proposed method. The effectiveness of the proposed method is demonstrated for solving the optimal allocation problem with different combinations of multi-type DG units and capacitors.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "54",
      "title": "Predicting Canine Posture With Smart Camera Networks Powered by the Artificial Intelligence of Things",
      "abstract": "In today's society, the number of people rearing pets has increased and their awareness of the need to protect pets' health has increased. Pet posture behaviour analysis and prediction are providing assistance in the medical treatment of pets. Hence, the demand for pet skeleton drawing applications has risen dramatically. Our proposed system predicts pet posture using smart camera networks powered by the artificial intelligence of things. This system is built on a platform using a Raspberry Pi embedded system. The system can determine from an image whether there is a detection target and generate a contour mask based on Mask R-CNN Technology. According to object detection, poses and key parts can be identified to predict and draw pet skeletons. Simultaneously, the behavioural action of a pet can be determined according to continuous skeleton data and then the system will actively inform the owner to perform subsequent processing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "55",
      "title": "Joint Optimization of Transmit Waveform and Receive Filter for Target Detection in MIMO Radar",
      "abstract": "In this paper, we consider the joint optimization of transmit waveform and receive filter in colocated multiple-input multiple-output (MIMO) radar to enhance target detection performance in the presence of signal-dependent interference. It is noticed that in the detection stage, the output energy is mainly concentrated in the mainlobe region. Therefore, we decompose the receive filter as the cascade of a receive beamformer and a temporal filter. Then, under the peak-to-average ratio (PAR) constraint, a problem is formulated to realize a trade-off between the signal-to-interference-plus-noise ratio (SINR) and the integrated sidelobe level (ISL) at the pulse compression output of mainlobe synthesized signal. A non-decreasing algorithm, which is the combination of sequential optimization algorithm and minorization-maximization (MM) method, is developed to solve this problem. Besides, in order to reduce computation burden, a special case is proposed, where we fix the temporal filter as the mainlobe synthesized signal. Then, another non-decreasing algorithm based on the MM method is proposed to solve the special case. Numerical experiments show that the proposed algorithms can obtain high output SINR and low output ISL efficiently.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "56",
      "title": "Design Issues of Digital and Analog Chaotic RoF Link Using Chaos Message Masking",
      "abstract": "This work presents the joint use of Radio Over Fiber and optical chaos to investigate the secure ROF link. Merging the two technologies, optical chaos for physical layer communication security and Radio over Fiber creates new design issues which have been identified and studied in detail in this paper for both analog Radio Frequency/Intermediate Frequency and digitized data. A semiconductor laser diode is driven into chaotic region using direct modulation scheme and RoF signal is added by chaos message masking scheme. The chaotically masked signal is transmitted over an optical communication link to investigate the propagation issues and synchronization of chaos at the receiver. The transmitted chaos is synchronized at the receiver to unmask the signal by using subtraction rule. To investigate the performance of chaotic communication system for Radio over Fiber transmission, the figure of merits like Bit error rate, Quality factor, Eye Opening Penalty and Root-mean-squared phase jitter are studied for digital data and Signal to Noise ratio and Total Harmonic Distortion are studied for analog waveform to address the effects of link length and data rate/message bandwidth.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "57",
      "title": "Aircraft Trajectory Prediction With Enriched Intent Using Encoder-Decoder Architecture",
      "abstract": "Aircraft trajectory prediction is a challenging problem in air traffic control, especially for conflict detection. Traditional trajectory predictors require a variety of inputs such as flight-plans, aircraft performance models, meteorological forecasts, etc. Many of these data are subjected to environmental uncertainties. Further, limited information about such inputs, especially the lack of aircraft tactical intent, makes trajectory prediction a challenging task. In this work, we propose a deep learning model that performs trajectory prediction by modeling and incorporating aircraft tactical intent. The proposed model adopts the encoder-decoder architecture and makes use of the convolutional layer as well as Gated Recurrent Units (GRUs). The proposed model does not require explicit information about aircraft performance and wind data. Results demonstrate that the provision of enriched aircraft intent, together with appropriate model design, could improve the prediction error up to 30% at a prediction horizon of 10 minutes (from 4.9 nautical miles to 3.4 nautical miles). The model also guarantees the mean error growth rate with increasing look-ahead time to be lower than 0.2 nautical miles per minute. In addition, the model offers a very low variance in the prediction, which satisfies the variance-standard specified by EUROCONTROL (EU Organization for Safety and Navigation of Air Traffic) for trajectory predictors. The proposed model also outperforms the state-of-the-art trajectory prediction model, where the Root Mean Square Error (RMSE) is reduced from 0.0203 to 0.0018 for latitude prediction, and from 0.0482 to 0.0021 for longitude prediction in a single prediction step of 15 seconds look-ahead. We showed that the pre-trained model on ADS-B data maintains its high performance, in terms of cross-track and along-track errors, when being validated in the Bluesky Air Traffic Simulator. The proposed model would significantly improve the performance of conflict detecti...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "58",
      "title": "G2P-SLAM: Generalized RGB-D SLAM Framework for Mobile Robots in Low-Dynamic Environments",
      "abstract": "In this paper, we propose a generalized grouping and pruning method for RGB-D SLAM in low-dynamic environments. The conventional grouping and pruning methods successfully reject the effect of dynamic objects in pose graph optimization (PGO). However, these methods sometimes fail when high-dynamic objects are dominant in the images captured by RGB-D sensors. Furthermore, once it is determined whether the features from dynamic objects are included in some nodes, the corresponding nodes are entirely removed even though these nodes partially include true constraints, which leads to an inaccurate PGO. To tackle these problems, we propose a novel method with intra-grouping, inter-grouping, and selective pruning, called G2P-SLAM. Accordingly, our method successfully rejects false constraints from dynamic objects selectively, thus preserving true constraints from static objects as many as possible. As experimentally verified on both our own datasets and public datasets, our proposed method shows promising performance compared with the state-of-the-art methods. Furthermore, experimental results corroborate that our G2P-SLAM enables robust PGO in both dynamic and low-dynamic environments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "59",
      "title": "A TaOx-Based Electronic Synapse With High Precision for Neuromorphic Computing",
      "abstract": "Neuromorphic computing is a promising candidate for breaking the von Neumann bottleneck and developing high-efficient computing systems. Here we present a W/TaO\nx\n/Pt high-precision electronic synapse with excellent analog properties for neuromorphic computing. The device exhibits the potential of 10-bit weight precision, which is state of the art in conductance levels. Furthermore, the device shows linear weight update behavior in a specific conductance range, linear I-V curves in low voltage regime, long time retention, and precise modulation of weight. These characteristics are very helpful for improving the accuracy of neuromorphic networks. Finally, a 400 × 60 × 10 three-layer perceptron was constructed with W/TaO\nx\n/Pt synapses for MNIST classification and ~92% accuracy was achieved.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "60",
      "title": "Electrical Phenotyping of Human Brain Tissues: An Automated System for Tumor Delineation",
      "abstract": "Precise surgical excision of brain tumors depends on the surgeon’s ability to accurately differentiate tumors from healthy brain tissues. We have developed an automated system integrated with biochips, an actuation unit, and electronics to measure the electrical resistivity of ex vivo human brain tissues for differentiating normal and tumor. The electrical resistivity of fresh (n = 48), formalin-fixed for one week (n = 48), and long-term (six months) formalin-fixed (n = 27) healthy human brain samples from different anatomical regions and tumor samples (glioma n = 6; fresh, formalin-fixed for one week, and formalin-fixed for six months) were measured using the automated system. The resistivity of glioma (22.4 ± \n 1.6 Ω1.6~\\Omega \n.cm) was significantly lesser than the normal region (98.6 ± \n 1.4 Ω1.4~\\Omega \n.cm) for fresh tissue samples (p = 5e-8). The trend of lower resistivity of glioma compared to normal was preserved after one week and six months of formalin fixation. We also report the effects of heterogeneity of normal brain tissue and formalin-fixation on the electrical properties of tissues. White matter regions were found to have higher resistivity compared to grey matter regions. The heterogeneity associated with grey matter regions was lower than the white matter regions. Formalin-fixation was observed to increase the magnitude of resistivity measured while retaining the observed trend across the different regions of the brain and tumors. The study shows that the electrical resistivity could potentially be used as an additional biomarker for delineating normal from the tumor.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "61",
      "title": "Next-Generation Indoor Wireless Systems: Compatibility and Migration Case Study",
      "abstract": "The indoor connected environment has witnessed significant research and development attention from industries and academia due to the growing number of smaller smart indoor devices around us. Developing an effective and efficient wireless access standard is one of the challenging tasks to enable the next generation indoor connected environment. The technical characteristics of existing wireless access standards, including IEEE 802.11a, 802.11n, and 802.11ac, are considerably limited for realizing indoor connected environments, particularly with a growing number of smaller intelligent devices. Moreover, their backward compatibility and migration strategies are significant for developing the next-generation wireless access standard for the indoor Internet of Things environment. In this context, this paper presents an indoor environmental experimental study focusing on the backward compatibility and migration-centric performance analysis of existing wireless access standards. Three wireless access standards that operate in the 5 GHz frequency spectrum are evaluated considering the metrics, including throughput, range, efficiency, and backward compatibility in an indoor environment. The experimental results are also compared with the analytical path loss model to observe the attributes for next-generation wireless access between the observed and analytical models. The evaluation can attest to the suitable migration strategy for stable next-generation wireless access development and deployment for an indoor smart Internet of Things environment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "62",
      "title": "Provable Secure Group Key Establishment Scheme for Fog Computing",
      "abstract": "In the fog computing paradigms, fog nodes are closer to terminal devices and can extend services to the edge of the network, thereby reducing the impact of high latency and restricted networks in the Internet of Things (IoTs). Fog computing applications usually organize the terminal devices in groups and require some form of security protection. Previous studies on the establishment of group keys for fog computing architectures have high communication costs and cannot verify the authenticity of each entity. Therefore, in this paper, we propose a mutual authentication group key establishment scheme for the fog computing architecture by using elliptic curve cryptography. After mutual authentication, the cloud server can transfer the computing overhead to the fog node, which will be responsible for authenticating the device group and distributing the established group session key. The group session key consists of the private key of each entity and some random and temporarily stored values. We prove that the established group session key is protected by the Canetti-Krawczyk (CK) adversary model. Finally, we evaluate performance based on calculation and communication costs. Compared with previous studies, the proposed scheme is lightweight and effective because it only involves elliptic curve operations and symmetric cryptographic operations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "63",
      "title": "A New Control Strategy for SR Generation System Based on Modified PT Control",
      "abstract": "The Switched Reluctance generator (SRG) has been widely used as a constant voltage source due to its advantages of simple structure, low cost and high control flexibility. However, the output voltage ripples cannot be ignored due to its unique operating principle with phase commutation. In this paper, the influence of the control parameters on the output voltage ripples are analyzed, and a fly-wheeling pulse train (FW-PT) control strategy is proposed to suppress the voltage ripple. The output voltage can be regulated by the FW-PT control strategy by using two or more sets of preset control pulse combinations, therefore it has the advantages of simple circuit implementation, no Network compensation and fast response speed. The characteristics of steady-state and dynamic behaviors of the switched reluctance power generation system by using different control strategies are simulated and compared, and a platform of 200W 8/6 SRG is built for experimental verification. Simulation and experimental results confirm that compared with the traditional PID control strategy, the FW-PT control strategy can be used to not only suppress the output voltage ripple, but also achieve faster response and dynamic characteristics.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "64",
      "title": "Rapid Quality Evaluation of Camellia Oleifera Seed Kernel Using a Developed Portable NIR With Optimal Wavelength Selection",
      "abstract": "Moisture content is one of the factors measured to evaluate the quality of Camellia oleifera seeds. High quality \nC. oleifera\n seeds used for trading must have a low moisture content, specifically not more than 15% on a dry basis (db). Moisture content analysis requires a prolonged laboratory investigation so that the development of fast and effective determination methods is helpful. The objective of this paper was to develop a low-cost portable NIR reflectance spectrometer collaborating with an android application for the rapid prediction of the moisture content in \nC. oleifera\n seeds. To calibrate the prediction model, an effective chemometric algorithm, based on partial least squares regression was established, and models based on wavelength selection algorithms such as backward interval partial least squares (\nbi\nPLS) and partial least squares coupled with variable importance projection (VIP-PLS) were implemented as an improved version of PLS. Both algorithms (\nbi\nPLS and VIP-PLS) improved the predictive performance and accuracy of the model. The experimental results showed that the \nbi\nPLS model with the 1\nst\n derivative transformation provided the best prediction for measuring the moisture content of \nC. oleifera\n seeds with a coefficient of determination (R\n2\n) value of 0.927, standard error of prediction (SEP) of 0.848%db, bias of −0.067%db, function slope of 1.005, and ratio of performance deviation (RPD) of 3.696. Finally, the device was tested according to the ISO 12099:2017(E) standard and confirmed the reliability of the device for in-field use.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "65",
      "title": "Greedy Optimization Method for Extractive Summarization of Scientific Articles",
      "abstract": "This work presents a method for summarizing scientific articles from the arXive and PubMed datasets using a greedy Extractive Summarization algorithm. We used the approach along with Variable Neighborhood Search (VNS) to learn what is the top-line exists in the area of Extractive Text Summarization quality in terms of ROUGE scores. The algorithm is based on first selecting for the summary the sentences from the text containing the maximum number of words with the higher TFIDF values along with minimum document frequency parameter tuning for TFIDF vectorization. As a result, the method achieves 0.43/0.12 and 0.40/0.13 for ROUGE-1/ROUGE-2 scores on arXive and PubMed datasets, respectively. These results are comparable to the state-of-the-art models using complex neural network architectures and serious computational resources together with the large amounts of training data. In contrast, our method uses a straightforward statistical inference methodology.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "66",
      "title": "UWB Radar Features for Distinguishing Humans From Animals in an Actual Post-Disaster Trapped Scenario",
      "abstract": "Distinguishing humans from animals using ultra-wideband (UWB) radar is necessary in post-disaster emergency rescues to prioritize and thereby optimize the distribution of labor and material resources. However, current studies are few and have only been implemented in simple laboratory environments, such that the effectiveness of these approaches cannot be guaranteed in rescue situations. This study describes experiments under actual post-disaster emergency rescue scenarios, for which the signal-to-noise ratio of UWB radar is seriously degraded owing to multipath effects and a complicated ruin environment. Four distinguishing features are extracted from aspects of wavelet entropy, correlation coefficient, and energy to classify humans from animals. Analysis of feature effectiveness showed that each feature could identify humans from animals individually. The largest difference between humans and animals was found in a feature which combines advantages of the correlation coefficient and energy simultaneously. There was no overlap between the human and animal values for this feature among the 20 sets of radar data collected. This is the first attempt to distinguish humans from animals in an actual post-disaster trapped condition, and it yielded four features of strong classification ability. We envision this study to advance real-world applicability of UWB radar in post-disaster emergency rescue.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "67",
      "title": "User Preference-Based Demand Response for Smart Home Energy Management Using Multiobjective Reinforcement Learning",
      "abstract": "A well-designed demand response (DR) program is essential in smart home to optimize energy usage according to user preferences. In this study, we proposed a multiobjective reinforcement learning (MORL) algorithm to design a DR program. The proposed approach improved conventional algorithms by mitigating the effect of the change in user preferences and addressed the uncertainty induced by future price and renewable energy generation. Because two Q-tables were used, the proposed algorithm simultaneously considers electricity cost and user dissatisfaction; when user preference changes, the proposed MORL algorithm uses the previous experience to customize appliances’ scheduling and swiftly achieve the best objective value. The generalizability of the proposed algorithm is high. Therefore, the algorithm can be implemented in a smart home equipped with an energy storage system, renewable energy source, and various types of appliances such as inflexible, time-flexible, and power-flexible ones. Numerical analysis using real-world data revealed that in case of price and renewable uncertainty, the proposed approach can deliver excellent performance after a change of user preference; it achieved 8.44% cost reduction as compared with mixed-integer nonlinear programming based DR while increasing the dissatisfaction level only by 1.37% on average.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "68",
      "title": "Correction to “Tear-and-Interconnect Domain Decomposition Scheme for Solving Multiscale Composite Penetrable Objects”",
      "abstract": "In the above article \n[1]\n, the paragraph of support information, sponsor, and financial support acknowledgment should read “This work was supported in part by the European Regional Development Fund (ERDF) and the Spanish Ministerio de Ciencia, Innovacioìn y Universidades under Project TEC2017-85376-C2-1-R and Project TEC2017-85376-C2-2-R, in part by the ERDF and the Galician Regional Government as part of the agreement for funding the Atlantic Research Center for Information and Communication Technologies (AtlantTIC), and in part by the ERDF and the Extremadura Regional Government under Project IB18073 and Project GR18055.”",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "69",
      "title": "Reducing the Bandwidth of Block Propagation in Bitcoin Network With Erasure Coding",
      "abstract": "With the popularity of Bitcoin, there is a greater demand for the scalability of the Bitcoin blockchain, which is susceptible to the efficiency of block propagation. In the Bitcoin blockchain, efficient block propagation approach can reduce the computing power and the risk of forks. Meanwhile, larger blocks help to improve the throughput of transactions. Thus, the block propagation is a major issue of the scalability of the Bitcoin network. This paper introduces a method to reduce the required bandwidth of block propagation with erasure coding. To begin with, the network nodes are classified into several clusters. When a node wants to propagate a block, the node does not need to propagate the whole information of the block. Instead, the node can only transmit the transaction IDs and the coded information to each cluster. The simulation shows that the proposed method can significantly ease the network traffic among these clusters.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "70",
      "title": "Privacy Protection for Telecare Medicine Information Systems with Multiple Servers Using a Biometric-based Authenticated Key Agreement Scheme",
      "abstract": "Telecare medical information systems (TMIS) allow patients remotely login medical service providers to acquire their medical information and track their health status through unsecured public networks. Hence, the privacy of patients is vulnerable to various types of security threats and attacks, such as the leakage of medical records or login footprints and the forgery attacks. Many anonymous three-factor authentication and key agreement (AKA) schemes have been proposed for TMIS with single server, but none of them is suited for TMIS with multiple servers. In this paper, we propose a biometric-based three-factor AKA scheme to protect user anonymity and untraceability in TMIS with multiple servers. We will construct a security model of a three-factor AKA scheme with user anonymity in TMIS with multiple servers, and give a formal security proof of the proposed scheme. The security of the proposed scheme is based on the elliptic curve decisional Diffie-Hellman problem assumption and hash function assumption. We will show that the proposed scheme is efficient enough for low-power mobile devices.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "71",
      "title": "Dim and Small Target Detection Based on Spiral Gradient Optimization Estimation and High-Order Correlation Enhancement",
      "abstract": "In order to reduce the influence of strong halo effect on dim small target detection in daytime, a dim small target detection algorithm based on spiral gradient optimization estimation and high-order correlation enhancement is proposed in this paper. In this paper, we first design a spiral motion model to obtain the local gradient information in the central image point by perturbing the designed motion direction, then estimate the optimal background by establishing a gradient optimization model to achieve background suppression while effectively removing the halo phenomenon. Considering the original high-order correlation model only uses a single pixel for motion correlation, there is insufficient information utilization, an improved high-order correlation energy enhancement model is proposed to enhance the target signal, the algorithm first constructs an attention discrimination model based on inner and outer windows to obtain the salient region of the image, and then carries out multi frame high-order motion correlation of neighborhood blocks to enhance the target energy. After experiments, it is shown that compared with the traditional algorithm, the algorithm proposed in this paper can effectively weaken the halo effect while suppressing most of the background and can effectively enhance the local signal-to-noise ratio of the target.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "72",
      "title": "Content-Adaptable ROI-Aware Video Storage for Power-Quality Scalable Mobile Streaming",
      "abstract": "The demand for mobile video streams is constantly increasing. With this demand comes a need for mobile devices to receive more videos at ever increasing quality. However, due to the large size of video data and intensive computational requirements, video streaming requires frequent memory access that consume a substantial amount of mobile device power; as a result, the battery life of mobile devices is limited. In this paper, we present a video content-adaptable Region-of-Interest (ROI)-aware video storage technique that promotes power savings. During the video encoding process on the transmitting server, based on the macroblock variance and ROI characterization, the “macroblocks of interest” are identified and embedded in the encoded bitstream. In the decoding process, a new frame buffer with dynamic power-quality trade-off is presented to adapt to the macroblock characteristics during run-time. Results from the system-level and circuit-level simulations show that the proposed technique enables substantially more truncated bits and significant power savings while delivering similar or better video quality as compared to other state-of-the-art solutions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "73",
      "title": "Non-Isolated High Gain Quadratic Boost Converter Based on Inductor’s Asymmetric Input Voltage",
      "abstract": "This paper introduces the concept of inductors asymmetric input voltage to derive a new high voltage gain converter. The proposed converter has continuous input, positive output, and high-power density features suitable for renewable energy applications. The operating principle, steady-state performance, practical voltage gain, small-signal analysis, and efficiency of the converter are presented in this work. A comprehensive comparison is made with the high voltage gain converters available in literature in terms of component count, voltage gain, effectiveness index, voltage and current stress on the power devices, per unit switching device rating, and other features like output polarity and availability of common ground. The proposed topology possesses a higher effectiveness index and lower switching device power rating (SDP), resulting in a good form factor. To validate the performance of the proposed converter, the experiments are conducted on the 150 W laboratory prototype, and corresponding results are presented in this work.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "74",
      "title": "FAM: Featuring Android Malware for Deep Learning-Based Familial Analysis",
      "abstract": "To handle relentlessly emerging Android malware, deep learning has been widely adopted in the research community. Prior work proposed deep learning-based approaches that use different features of malware, and reported a high accuracy in malware detection, i.e., classifying malware from benign applications. However, familial analysis of real-world Android malware has not been extensively studied yet. Familial analysis refers to the process of classifying a given malware into a family (or a set of families), which can greatly accelerate malware analysis as the analysis gives their fine-grained behavioral characteristics. In this work, we shed light on deep learning-based familial analysis by studying different features of Android malware and how effectively they can represent their (malicious) behaviors. We focus on string features of Android malware, namely the Abstract Syntax Trees (AST) of all functions extracted from each malware, which faithfully represent all string features of Android malware. We thoroughly study how different string features, such as how security-sensitive APIs are used in malware, affect the performance of our deep learning-based familial analysis model. A convolutional neural network was trained and tested in various configurations on 28,179 real-world malware dataset appeared in the wild from 2018 to 2020, where each malware has one or more labels assigned based on their behaviors. Our evaluation reveals how different features contribute to the performance of familial analysis. Notably, with all features combined, we were able to produce up to an accuracy of 98% and a micro F1-score of 0.82, a result on par with the state-of-the-art.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "75",
      "title": "Energy-Aware Real-Time Data Processing for IoT Systems",
      "abstract": "In many real-time processing systems for the Internet of Things (IoT), the correctness of real-time data objects that model physical world entities, such as the status of mobile robotics, depends not only on the functional correctness, but also on the temporal consistency. Maintaining temporal consistency of real-time data while reducing energy cost is of critical importance when designing such IoT systems. In this paper, we formulate the energy-aware real-time data processing problem on multicore platforms and prove it to be NP-hard. In view of the intractability of the problem, we adopt a divide-and-conquer strategy. We first propose a per-CPU solution, which can result in significant power savings. Next, in order to save energy in a fine-grained granularity, we propose an efficient per-Task solution by adopting the per-CPU solution as a building block. Finally, by developing new energy-aware mapping techniques, we further explore energy savings on multicore platforms. Extensive simulation results show that the proposed methods offer remarkable performance improvement in terms of energy savings, as compared to the state-of-the-art schemes.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "76",
      "title": "Circuit Model of Parallel Corrugated Transmission Lines for Differential Signal Propagating in Microwave Band",
      "abstract": "A viable wide-band circuit model of parallel corrugated differential transmission line is established. By solving for the even- and odd-modes in this structured differential transmission line, the equivalent capacitance, inductance, resistance, and conductance per unit length are calculated, then the characteristic impedances of differential and common signals are obtained. The S-parameters obtained from the equivalent circuit model agree well with the full-wave simulation results with a deviation of only about 0.036 dB in the frequency range of 10 GHz. Experimentally, the characteristic impedances are measured for the differential and common signals using a time domain reflectometer (TDR). The deviation between the experimental and theoretical results was less than 1.05%. Based on the equivalent circuit model, it is feasible to implement this type of structured differential line directly into real circuits.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "77",
      "title": "Design of a Wideband dB-Linear Variable Gain Amplifier With Continuous Gain Adjusting in 90-nm CMOS Technology",
      "abstract": "This paper presents a wideband dB-linear variable-gain amplifier (VGA) with a DC-offset cancellation network in a 90-nm CMOS technology for high-speed applications. The VGA consists of a four-stage Cherry-Hooper amplifier, which is based on a feedback resistor and negative Miller capacitance to obtain wide bandwidth without inductors in the main circuit. A unique method for this structure to generate pseudo-exponential function is analyzed in detail. Therefore, an accurate dB-linear characteristic is realized in this VGA without any exponential generator circuits. The linear control voltage is applied directly to the gate of the transistor and this simple control method exhibits good robustness to process and temperature variation. Measurement results show that the voltage gain varies from −28 dB to 27 dB continuously with more than 4.3 GHz bandwidth and a dB-linear range of 32 dB with less than ±0.6 dB gain error. Without the output buffer, it consumes 8.5 mW from a 1.2V supply and occupies a small die area of only 0.04 mm\n2\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "78",
      "title": "Dermatologist-Level Classification of Skin Cancer Using Cascaded Ensembling of Convolutional Neural Network and Handcrafted Features Based Deep Neural Network",
      "abstract": "Skin cancer is caused due to unusual development of skin cells and deadly type cancer. Early diagnosis is very significant and can avoid some categories of skin cancers, such as melanoma and focal cell carcinoma. The recognition and the classification of skin malignant growth in the beginning time is expensive and challenging. The deep learning architectures such as recurrent networks and convolutional neural networks (ConvNets) are developed in the past, which are proven appropriate for non-handcrafted extraction of complex features. To additional expand the efficiency of the ConvNet models, a cascaded ensembled network that uses an integration of ConvNet and handcrafted features based multi-layer perceptron is proposed in this work. This offered model utilizes the convolutional neural network model to mine non-handcrafted image features and colour moments and texture features as handcrafted features. It is demonstrated that accuracy of ensembled deep learning model is improved to 98.3% from 85.3% of convolutional neural network model.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "79",
      "title": "Cognitive Habitat, Strategy Ecosystem: A Predictive Model of Emergence for Cognitive and Computer Science",
      "abstract": "Cognitive research has found people are sometimes adept and sometimes inept at handling complexity. Complexity is a key concept in much of cognitive science, yet the field has scarcely incorporated any of the work in complexity theory. Complexity theory may generally be too abstract to easily apply to human cognition studies. Here, the problem is addressed by considering complexity through constructing a model of epistemic emergence, Cognitive-Habitat Strategy-Ecosystem, (CHSE) to act as an overarching framework into which different conceptions of complexity and cognition can be integrated, describing how they will interact to affect cognition in complex systems. This model provides value both at the micro level, by generating specific predictions, and at the macro level, through hypothesizing interactions between other cognitive theories such as cognitive load and adaptation from failure. We detail the model’s assumptions, functionality, and possible ways to measure variables.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "80",
      "title": "A Simplified Extension of Physics-Based Single Particle Model for Dynamic Discharge Current",
      "abstract": "The prediction of the battery temperature and terminal voltage under dynamic load condition is crucial for a satellite battery management system. Restricted by parameter measurability and computing resources, equivalent circuit model has been commonly used in battery management system. But this model cannot satisfy the necessary performance under dynamic load for usual work of satellites. On account of this problem, a combined temperature single particle model is developed for 18650 cells in this paper. The proposed model consists of two sub-models, an electrochemical model and a thermal model, which are coupled together in an iterative manner through physicochemical temperature dependent parameters. The electrochemical sub-model mainly simplifies the calculation of lithium-ion concentration in electrode, while an expression for battery temperature distribution is employed in the thermal sub-model. In addition, genetic algorithm is adopted to estimate model parameters by exciting the battery under different operation conditions. This proposed model can provide accurate predictions of terminal voltage and surface temperature at various operating conditions and the proper simplification of mathematical structure making it ideal for real-time battery management system application. Finally, the model is validated against both constant and dynamic load conditions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "81",
      "title": "DFT Spread-Optical Pulse Amplitude Modulation for Visible Light Communication Systems",
      "abstract": "DC-biased optical orthogonal frequency division multiplexing (DCO-OFDM) has been proposed in visible light communication (VLC) to overcome the limited modulation bandwidth of light emitting diode (LED). Due to the implementation of the inverse fast Fourier transform at the DCO-OFDM transmitter, DCO-OFDM suffers from its high peak-to-average power ratio (PAPR), which restricts its use in some VLC applications, especially where the optical power efficiency is a crucial requirement. That is because the LEDs used in VLC systems have a limited optical power-current linear range. To this end, a novel discrete Fourier transform spread-optical pulse amplitude modulation (DFTS-OPAM) signal scheme based on the single carrier-interleaved frequency division multiple access (SC-IFDMA) signal is introduced in this paper to address the high PAPR issue of OFDM. DFTS-OPAM is achieved by considering a PAM as an SC-IFDMA data symbol and duplicate the output vector of the fast Fourier transform at the SC-IFDMA transmitter side. Simulation results show that the PAPR of the proposed scheme is 7 dB lower than that of DCO-OFDM. Furthermore, this significant PAPR improvement is experimentally investigated where the practical results show that the proposed scheme can provide more 2.5 dB reduction in the average transmitted power requirement compared to DCO-OFDM and can subsequently increase the maximum achieved distance between the transmitter and the receiver up to 44%.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "82",
      "title": "Differential Privacy Preservation in Robust Continual Learning",
      "abstract": "Enhancing the privacy of machine learning (ML) algorithms has become crucial with the presence of different types of attacks on AI applications. Continual learning (CL) is a branch of ML with the aim of learning a set of knowledge sequentially and continuously from a data stream. On the other hand, differential privacy (DP) has been extensively used to enhance the privacy of deep learning (DL) models. However, the task of adding DP to CL would be challenging, because on one hand the DP intrinsically adds some noise that reduce the utility, on the other hand the endless learning procedure of CL is a serious obstacle, resulting in the catastrophic forgetting (CF) of previous samples of ongoing stream. To be able to add DP to CL, we have proposed a methodology by which we cannot only strike a tradeoff between privacy and utility, but also mitigate the CF. The proposed solution presents a set of key features: (1) it guarantees theoretical privacy bounds via enforcing the DP principle; (2) we further incorporate a robust procedure into the proposed DP-CL scheme to hinder the CF; and (3) most importantly, it achieves practical continuous training for a CL process without running out of the available privacy budget. Through extensive empirical evaluation on benchmark datasets and analyses, we validate the efficacy of the proposed solution.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "83",
      "title": "A Graph Analysis Method to Improve Peer Grading Accuracy for Blended Teaching Courses",
      "abstract": "Peer grading is a tool widely used by instructors to provide fast reviews for homework that consists of open-ended questions. As the grades obtained from peer grading are not as accurate as those provided by the instructors, many methods have been proposed to improve the accuracy of peer grading. However, the current methods mainly focus on the scenario of online teaching, and they lose effectiveness in blended teaching courses because the mandatory of task and affinity among students may make the students perform irresponsibly in the grading task. This paper proposes a method based on graph analysis to improve the accuracy of peer grading. The peer grading system is modeled as a bipartite graph. In the graph, three interdependent metrics are defined to measure the dutifulness of the grader, the reliability of the rating and the true score of the submission. The stable values of the metrics are computed in an iterative way to obtain the peer grading results. Experiments demonstrate the proposed method is effective in blended teaching settings, and outperforms the current methods. Compared to the baseline of the mean value method, the proposed method decreases the root mean square error by 2.31% in the worst case and 30.72% in the best case on real-world data. It is robust to irresponsible graders, where the root mean square error keeps small even when the proportion of irresponsible graders increases to 30%.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "84",
      "title": "A Novel Emotion Control System for Embedded Human–Computer Interaction in Green Iot",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "85",
      "title": "A Novel Particulate Matter 2.5 Concentration Prediction Model Based on Double-Layer Decomposition and Feedback of Model Learning Effect",
      "abstract": "Accurate and effective particulate matter 2.5(PM2.5) concentration prediction can provide early warning information for decision-making departments, so as to take governance and preventive measures. A combined model based on double-layer decomposition(DLD) and feedback of model learning effect for PM 2.5 concentration prediction is proposed in this paper. Firstly, ensemble empirical mode decomposition(EEMD) and variational mode decomposition (VMD) were used for double-layer decomposition for the PM2.5 concentration series, to reduce the nonstationarity and nonlinearity of the concentration series and improve the predictability; Secondly, a wavelet neural network (WNN) prediction model based on the feedback of model learning effect is established for the subsequence obtained by double-layer decomposition. Finally, the prediction results of each subsequence are superimposed to obtain the final prediction results. The case study shows that the prediction model proposed in this paper is scientific.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "86",
      "title": "Using Features Specifically: An Efficient Network for Scene Segmentation Based on Dedicated Attention Mechanisms",
      "abstract": "Semantic segmentation is a challenging task in computer vision, which requires both context information and rich spatial detail. To this end, most methods introduce low-level features for spatial detail. However, low-level features lack global information. Too much low-level features will disturb the segmentation result. In this paper, we extract low-level features guided by abstract semantic features to improve segmentation results. Specifically, we propose a Pixel-wise Attention Module (PAM) to select low-level features adaptively and a Dual Channel-wise Attention Fusion Module (DCAFM) to fuse the context information further. These two modules use the attention mechanism from a more macro perspective, which is not limited to the inter-layer feature adjustments. There are not complicated and redundant processing modules in our architecture. By using features efficiently, the complexity of the network was significantly reduced. We evaluate our approach on Cityscapes, PASCAL VOC 2012, and PASCAL Context datasets, and we achieve 82.3% Mean IoU on PASCAL VOC 2012 test dataset without pre-training on the MS-COCO dataset.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "87",
      "title": "Research on Losses and Heat Dissipation of Saturable Reactor Used in Converter Valve",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "88",
      "title": "Analysis and Verification on the Equivalence Between Jerk-Level and Acceleration-Level Schemes Applied to Manipulators Controlling",
      "abstract": "Two different-level schemes are researched in this article for achieving the kinematic control of redundant manipulators, one of which is exploited at the acceleration level, and the other is at the jerk level. Firstly, they are both reconstructed as a standard quadratic programming problem with different parameter definitions and addressed by a gradient neural network (GNN) method. Secondly, from the perspective of the GNN algorithm, a theoretical interpretation of the intrinsic equivalence between the acceleration-level scheme and jerk-level scheme is performed. Further, simulations on the manipulator synthesized by the two schemes aided with the GNN method tracking two different trajectories are conducted. Finally, comparisons of relevant joint data (i.e., joint angles, joint velocities, and joint accelerations) are presented to substantiate the equivalence between the two schemes, and simulative experiments are carried out at the same time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "89",
      "title": "SELCOM: Selective Compression Scheme for Lightweight Nodes in Blockchain System",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "90",
      "title": "Generalized Approximate Message Passing Detector for GSM-OTFS Systems",
      "abstract": "Orthogonal Time Frequency Space (OTFS) as a two-dimensional modulation scheme designed in the delay-Doppler domain, is realized by inverse symplectic finite Fourier transform (ISFFT) and symplectic finite Fourier transform (SFFT), for combating the high Doppler channels toward future wireless communications. Meanwhile, generalized spatial modulation (GSM) offers an efficient implementation for multi-input multi-output (MIMO) systems, by activating only part of the transmit antennas to alleviate inter-channel interference (ICI). In this paper, the combination of the above two concepts is exploited, for bridging their unique advantages. On the other hand, an iterative detector based on generalized approximate message passing (GAMP) is also developed for GSM-OTFS. Simulation results demonstrate that the proposed GAMP detector can achieve better performance than the conventional minimum mean square error (MMSE) detector.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "91",
      "title": "Mapping the Knowledge Structure and Research Evolution of Urban Rail Transit Safety Studies",
      "abstract": "To better grasp the status quo of urban rail transit (URT) safety research and explore the knowledge base and hotspot trends, 1249 URT safety research papers from 1983-2018 were collected from the SCIE and SSCI databases of the WOS search platform as data samples. Co-occurrence analysis, burst analysis of keywords and co-citation analysis were adopted to analyze the current research situation of URT safety in the world by means of information visualization. The study found that risk analysis in the construction/operational phase, methods for predicting ground movements, and cause analyses of tunnel deformation and settlement are the knowledge bases in the field of URT safety research. Tunneling and Underground Space Technology, Safety Science, Atmospheric Environment, Lancet and Transportation Research Record are the core journals in the field. At present, the basic theory and research system of URT safety have been basically completed, but the research directions are too concentrated, and the frontier branches are too few. The research themes of URT safety were roughly grouped into three core paths: the “health risk” path, the “risk analysis - safety management” path and the “tunnel displacement/deformation” path. In the process of research and evolution, the research paths are refined step-by-step, and the research directions are transformed from macro to micro. The emergency evacuation of personnel in subway stations, the effects of particulate matter in subway air on human health and the use of computer technology for engineering optimization are the current frontiers of URT safety. URT safety research also tends toward risk analysis in the operational phase.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "92",
      "title": "Fault Diagnosis of a Propeller Using Sub-Nyquist Sampling and Compressed Sensing",
      "abstract": "The fault diagnosis of rotating machinery is generally performed using methods that employ vibration and sound. These methods are simple and accurate. However, all of these methods measure vibration data on the basis of the sampling theorem. Thus, they require a high measurement frequency, resulting in a large data volume and expensive measurement equipment. In recent years, a method that uses compressed sensing has been proposed to solve this problem, but it requires dedicated hardware to realize random sampling. To overcome this drawback, we developed a random start uniform sampling method (RSUSM) and combined it with compressed sensing (CS). RSUSM is a method of measuring data at a fixed frequency with a random start time. Numerical experiments demonstrate how the specific constant changes for each RSUSM parameter. This allows us to know the limit of how many measurement points are required for the number of non-zero components. We also applied CS by RSUSM to the sound pressure measurement results of the failed propeller, and found that the signal could be recovered less than 25% error even in a noisy real environment within the aforementioned limit. In this case, we found that the measurement frequency could be compressed to 1/80th of the frequency required by the sampling theorem, and the measurement data size to 1%. This approach is expected to diagnose faults in more rotating machines by significantly reducing the costs associated with data collection and storage.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "93",
      "title": "State-Dependent Parameter Tuning of the Apparent Tardiness Cost Dispatching Rule Using Deep Reinforcement Learning",
      "abstract": "The apparent tardiness cost (ATC) is a dispatching rule that demonstrates excellent performance in minimizing the total weighted tardiness (TWT) in single-machine scheduling. The ATC rule’s performance is dependent on the lookahead parameter of an equation that calculates the job priority index. Existing studies recommend a fixed value or a value derived through a handcrafted function as an estimate of the lookahead parameter. However, such parameter estimation inevitably entails information loss from using summarized job data and generates an inferior schedule. This study proposes a reinforcement learning-based ATC dispatching rule that estimates the lookahead parameter directly from raw job data (processing time, weight, and slack time). The scheduling agent learns the relationship between raw job data and the continuous lookahead parameter while interacting with the scheduling environment using a deep deterministic policy gradient (DDPG) algorithm. We trained the DDPG model to minimize the TWT through a simulation in a single-machine scheduling problem with unequal job arrival times. Based on a preliminary experiment, we verified that the proposed dispatching rule, ATC-DDPG, successfully performed intelligent state-dependent parameter tuning. ATC-DDPG also displayed the best performance in the main experiment, which compared the performance with five existing dispatching rules.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "94",
      "title": "Faster-RCNN Based Robust Coverless Information Hiding System in Cloud Environment",
      "abstract": "Key distribution is the foundation for protecting users' privacy and communication security in cloud environment. Information hiding is an effective manner to hide the transmission behavior of secret information such as keys, and thus it makes the secure key distribution possible. However, the traditional information hiding systems usually embed the secret information by modifying the carrier, which inevitably leaves modification traces on the carrier. Thus, they cannot resist the detection of the steganalysis algorithm effectively. To avoid this issue, the coverless information hiding technique has been proposed accordingly, in which the original images of which features can express the secret information are directly used as stego-images. Since the existing coverless information hiding methods use the low-level handcrafted image features to express secret information, it is hard for them to realize desirable robustness against common image attacks. Moreover, their hiding capacity is limited. To conquer these problems, we design a novel robust image coverless information hiding system using Faster Region-based Convolutional Neural Networks (Faster-RCNN). We employ Faster-RCNN to detect and locate objects in images and utilize the labels of these objects to express secret information. Since the original images without any modification are used as stego-images, the proposed method can effectively resist steganalysis and will not cause attackers' suspicion. The experimental results demonstrate that the proposed system has higher performance in terms of robustness and capacity compared to the typical coverless information hiding methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "95",
      "title": "Research Trends, Challenges, and Emerging Topics in Digital Forensics: A Review of Reviews",
      "abstract": "Due to its critical role in cybersecurity, digital forensics has received significant attention from researchers and practitioners alike. The ever increasing sophistication of modern cyberattacks is directly related to the complexity of evidence acquisition, which often requires the use of several technologies. To date, researchers have presented many surveys and reviews on the field. However, such articles focused on the advances of each particular domain of digital forensics individually. Therefore, while each of these surveys facilitates researchers and practitioners to keep up with the latest advances in a particular domain of digital forensics, the global perspective is missing. Aiming to fill this gap, we performed a qualitative review of all the relevant reviews in the field of digital forensics, determined the main topics on digital forensics topics and identified their main challenges. Despite the diversity of topics and methods, there are several common problems that are faced by almost all of them, with most of them residing in evidence acquisition and pre-processing due to counter analysis methods and difficulties of collecting data from devices, the cloud etc. Beyond pure technical issues, our study highlights procedural issues in terms of readiness, reporting and presentation, as well as ethics, highlighting the European perspective which is traditionally stricter in terms of privacy. Our extensive analysis paves the way for closer collaboration among researcher and practitioners among different topics of digital forensics.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "96",
      "title": "Automated Asphalt Highway Pavement Crack Detection Based on Deformable Single Shot Multi-Box Detector Under a Complex Environment",
      "abstract": "Pavement cracks are severely affecting highway performance. Thus, implementing high-precision highway pavement crack detection is important for highway maintenance. However, the asphalt highway pavement environment is complex, and different pavement backgrounds are more difficult than others for detecting highway pavement cracks. Interference from road markings and surface repairs also complicate the environments and thus the detection of crack. To reduce interference, we collected many images from different highway pavement backgrounds. We also improved the single shot multi-box detector (SSD) network and proposed a novel network named deformable SSD by adding a deformable convolution to the backbone feature extraction network VGG16. We verified our model using the PASCAL VOC2007 dataset and obtained a mean average precision (\nmAP\n) 3.1% higher than that of the original SSD model. We then trained and tested the proposed model using our crack detection dataset. We calculated precision, recall, F1 score, AP, \nmAP\n, and FPS to examine the performance of our model. The \nmAP\n of all categories in the test data was 85.11% using the proposed model 10.4% and 0.55% more than that of YOLOv4 and the original SSD model, respectively. These findings show that our model outperforms YOLOv4 and the original SSD model and confirm that incorporating a deformable convolution into the SSD network can improve the model’s performance. The proposed model is appropriate for detecting pavement crack categories and locations in complicated environments. It can also provide important technical support for highway maintenance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "97",
      "title": "A Surrogate-Assisted Many-Objective Evolutionary Algorithm Using Multi- Classification and Coevolution for Expensive Optimization Problems",
      "abstract": "Surrogate-assisted evolutionary algorithms have received a surge of attentions for their promising ability of solving expensive optimization problems. Existing surrogate-assisted evolutionary algorithms usually adopt the regression models and the binary classification models to guide the evolution of the population for solving the multiobjective optimization problems. However, the regression models will make the algorithm to be increasingly computation-expensive as the number of objectives increases, while the use of the binary classification models might suffer from the poor diversity since the diversified information of solutions cannot be reflected in these classification models. For this issue, this paper proposes a surrogate-assisted many-objective evolutionary algorithm using the cooperation of the multi-classification and regression models to improve the search quality while reducing the computational cost. Our approach includes two parts: At the model training stage, a multi-classification model is constructed to divide the whole population into several classes for ensuring diversity, a distance regression model and an angle regression model are used to select solutions with better convergence and diversity in each class; At the evolution stage, a coevolutionary framework is used to guide the evolution according to a new selection criterion. Experimental results verify the effectiveness of the proposed algorithm on a set of expensive test problems with up to 10 objectives.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "98",
      "title": "An Active Metamaterial Absorber With Ultrawideband Continuous Tunability",
      "abstract": "In this paper, an active metamaterial (MM) absorber loaded with PIN diodes is proposed. By adjusting the bias currents of PIN diodes to change the value of the introduced equivalent resistance, the Q factors of multiple resonances of the whole structure are altered. Therefore, multiple broadband absorption states with moderate absorption performance at different frequencies are obtained. These states cover continuously tunable absorption frequencies in an ultrabroad frequency band. Bias circuits for PIN diodes are also specially designed to obtain polarization-insensitive absorption performance. Optimizing works were carried out by analyzing the operating mechanism based on the simulated field distribution and power loss distribution. The presented absorber covers an ultrawideband absorption bandwidth with a reflection coefficient below -10 dB from 0.78 GHz to 4.62 GHz (142.2% in relative bandwidth) by adjusting the PIN diodes. It is worth noting that the absorption bandwidth of the low-resistance state reaches 21.0% in the P band, which greatly improves performance in the low-frequency regime. The absorber also shows good angular stability under oblique incident angles from 0° to 30°. In addition, the total thickness of the absorber is only 1/16 of the wavelength at the lowest operating frequency with an areal density of 2.06 kg/m\n2\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "99",
      "title": "A Novel Array Configuration Technique for Improving the Power Output of the Partial Shaded Photovoltaic System",
      "abstract": "Power conversion efficiency is the most important factor to be considered in PV systems because it is affected by various environmental conditions. The effect of partial shading is the most influenced factor in the reduction of power output. Various research schemes like Maximum Power Point Tracking (MPPT), array configuration scheme, reconfiguration, etc., work on the PV system to reduce the impact of partial shading. This paper presents a new kind of array configuration scheme that forms the PV array based on the moves of the Knight coin in the chess game. This arrangement creates the squared PV array of rows with distinct PV modules which is capable of evenly dispersing the shading in the partially shaded PV array. Also, this scheme is applicable for the non-squared PV arrays to create PV rows with the PV modules from a distinct location or from the same row with optimized distance to disperse the maximum level of shading. The proposed method has been discussed with the proper mathematical formulation with all necessary constraints and also it been validated with the hardware arrangements and MATLAB/Simulink\n®\n model.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "100",
      "title": "A Novel Combined Conductance Sensor for Water Cut Measurement of Low-Velocity Oil-Water Flow in Horizontal and Slightly Inclined Pipes",
      "abstract": "This paper studied conductance-based method for water cut measurement to dynamically monitor the horizontal oil-producing wells. Existing conductance tools cannot obtain the response values corresponding to the water phase in horizontal wells due to the characteristics of the ring-shaped electrode structure and the horizontal well structure. In order to tackle this issue, this paper designed a novel Combined Conductance Sensor (CCS), which mainly consists of the Ring-Shaped Conductance Probe (RSCP) and the novel Clock-like Conductance Probe Array (CCPA). Specifically, we first established the structure model of CCS, optimized the geometry of CCPA by analyzing the uniformity of electric field distribution generated by the exciting electrodes of CCPA and then analyzed the local sensitivity field region of the optimized CCPA. Then we studied the flow pattern distribution of the horizontal oil-water two-phase flow and analyzed the response characteristics and the linear relation between RSCP and CCPA. In addition, this research developed the CCS-based tool and conducted the experiments about different inclined angles in horizontal and slightly inclined pipes. Extensive experiments demonstrated that the developed CCS can cover the three-quarter scale of water cut measurement(25%-100%) in horizontal and slightly inclined pipes, and the experimental results verified the validity of CCS for the water cut measurement. Comparing to the existing methods, the proposed CCS is more suitable for water cut measurement with the advantages of simple structure and low cost for the horizontal oil wells with the characteristics of the low production, which could be used widely in the actual logging.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "101",
      "title": "Improving IoT Federation Resiliency With Distributed Ledger Technology",
      "abstract": "Despite the rapid spread of Internet of Things (IoT) systems, the lack of interoperability between the systems significantly hinders their business and societal potential. Moreover, a major challenge for wider interoperability is that the IoT systems can be owned by multiple independent entities, whose collaboration will need to be organised to ensure their interoperability. One approach for achieving this is to establish federations supported by Distributed Ledger Technologies (DLTs), as this enables interoperability between entities and collaboration between business platforms, thereby overcoming many technical and administrative difficulties. DLTs can provide the required transparency and immutability for management of the federations, thus increasing trust and reducing the risk of misbehaviour that could destabilise the federation. This paper presents two system dynamics simulation models, which demonstrate that the success of a federation (with or without DLT support) is inversely related to the short-term selfishness of its members, and we then proceed to show that DLTs can improve the feedback received by the federation members on their actions by promoting a common consensus, which in turn can make the federation more resilient.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "102",
      "title": "Multivariate Nonlinear Sparse Mode Decomposition and Its Application in Gear Fault Diagnosis",
      "abstract": "Multi-channel signal has more abundant and accurate state characteristic information than single channel signal. How to separate fault characteristic information from the multi-channel signal is the key of fault diagnosis. As two typical multi-channel signal decomposition methods, multivariate empirical mode decomposition (MEMD) and multivariate variational mode decomposition (MVMD) are widely used in multi-channel signal analysis. However, MEMD and MVMD use cyclic iteration to complete the analysis of multi-channel signals, and it is difficult to overcome their inherent defects. In view of this, based on nonlinear sparse mode decomposition (NSMD), this paper proposes a multivariate nonlinear sparse mode decomposition (MNSMD) by constraining singular local linear operators to separate the natural oscillation modes in multi-channel signal. By constraining singular local linear operators into signal decomposition, MNSMD has obvious advantages in restraining mode aliasing and robustness. In addition, the local narrow-band component is used as the basis function for iteration, and the component signal is obtained by approaching the original signal. Through the simulation signal and gear fault signal analysis, the results show that, compared with MEMD and MVMD methods, MNSMD method can effectively complete gear fault diagnosis.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "103",
      "title": "An Efficient Deep Learning Framework for Distracted Driver Detection",
      "abstract": "The number of road accidents has constantly been increasing recently around the world. As per the national highway traffic safety administration’s investigation, 45% of vehicle crashes are done by a distracted driver right around each. We endeavor to build a precise and robust framework for distinguishing diverted drivers. The existing work of distracted driver detection is concerned with a limited set of distractions (mainly cell phone usage). This paper uses the first publicly accessible dataset that is the state farm distracted driver detection dataset, which contains eight classes: calling, texting, everyday driving, operating on radio, inactiveness, talking to a passenger, looking behind, and drinking performed by 26 subjects to prepare our proposed model. The transfer values of the pertained model EfficientNet are used, as it is the backbone of EfficientDet. In contrast, the EfficientDet model detects the objects involved in these distracting activities and the region of interest of the body parts from the images to make predictions strong and accomplish state-of-art results. Also, in the Efficientdet model, we implement five variants: Efficientdet (D0-D4) for detection purposes and compared the best Efficientdet version with Faster R-CNN and Yolo-V3. Experimental results show that the proposed approach outperforms earlier methods in the literature and conclude that EfficientDet-D3 is the best model for detecting distracted drivers as it achieves Mean Average Precision (MAP) of 99.16% with parameter setting: learning rate of \n le−3le-3 \n, 50 epoch, batch size of 4, and step size of 250, demonstrating that it can potentially help drivers maintain safe driving habits.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "104",
      "title": "Two-Dimensional RSSI-Based Indoor Localization Using Multiple Leaky Coaxial Cables With a Probabilistic Neural Network",
      "abstract": "Received signal strength indicator (RSSI) based indoor localization technology has its irreplaceable advantages for many location-aware applications. It is becoming obvious that in the development of fifth-generation (5G) and future communication technology, indoor localization technology will play a key role in location-based application scenarios including smart home systems, manufacturing automation, health care, and robotics. Compared with wireless coverage using conventional monopole antenna, leaky coaxial cables (LCX) can generate a uniform and stable wireless coverage over a long-narrow linear-cell or irregular environment such as railway station and underground shopping-mall, especially for some manufacturing factories with wireless zone areas from a large number of mental machines. This paper presents a localization method using multiple leaky coaxial cables (LCX) for an indoor multipath-rich environment. Different from conventional localization methods based on time of arrival (TOA) or time difference of arrival (TDOA), we consider improving the localization accuracy by machine learning RSSI from LCX. We will present a probabilistic neural network (PNN) approach by utilizing RSSI from LCX. The proposal is aimed at the two-dimensional (2-D) localization in a trajectory. In addition, we also compared the performance of the RSSI-based PNN (RSSI-PNN) method and conventional TDOA method over the same environment. The results show the RSSI-PNN method is promising and more than 90% of the localization errors in the RSSI-PNN method are within 1 m. Compared with the conventional TDOA method, the RSSI-PNN method has better localization performance especially in the middle area of the wireless coverage of LCXs in the indoor environment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "105",
      "title": "Partial Reachability Graph Analysis of Petri Nets for Flexible Manufacturing Systems",
      "abstract": "Petri nets are an important and popular tool to model and analyze deadlocks in flexible manufacturing systems. The state space of a Petri net model can be divided into two disjoint parts: a live-zone and a dead-zone. Reachability graph analysis plays an important role in the modeling and control of Petri nets. Most existing studies have to fully enumerate the reachable markings of a Petri net to obtain the first-met bad markings (FBMs), which exacerbates the computational overheads. In this paper, a computationally efficient method to find dead markings in Petri nets is presented. We first introduce an algorithm to find dead markings by solving an integer linear programming problem. Then, the set of markings in the dead-zone is calculated, including the set of dead markings and the set of bad markings. Then we can find all the FBMs. By using a vector covering approach, the minimal covered set of FBMs is computed. The proposed approach can obtain the dead markings and FBMs by searching only a part of a reachability graph. Finally, examples are provided to demonstrate the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "106",
      "title": "Outage Probability Analysis for NOMA Downlink and Uplink Communication Systems With Generalized Fading Channels",
      "abstract": "This work considers multiple user power-domain non-orthogonal multiple access (NOMA)based downlink (DL) and uplink (UL) communication systems with potentially dissimilar fading links for all the users that can follow one of several possible distributions such as Rayleigh, Rician, Nakagami-m, Nakagami-q, κ - μ, η - μ, Nakagami-lognormal. The presented analysis, which is based on approximating the probability density function (PDF) of the channel gain as a sum of Gamma distributions, is sufficiently general and applicable in a multitude of NOMA scenarios. For both the UL and DL, closed-form expressions are determined for the outage probability at the users considering both statistical channel state information (CSI)-based as well as instantaneous CSI-based ordering techniques. Analytical expressions for the outage probability and the ensuing diversity orders have also been obtained for the NOMA DL system at high SNRs. Furthermore, similar expressions for the outage probability and outage floor for the NOMA UL system have been derived at high SNRs. Finally, simulation results have been presented to authenticate the analytical results derived and provide insights into the NOMA system performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "107",
      "title": "Machine Learning and Deep Learning Approaches for CyberSecurity: A Review",
      "abstract": "The rapid evolution and growth of the internet through the last decades led to more concern about cyber-attacks that are continuously increasing and changing. As a result, an effective intrusion detection system was required to protect data, and the discovery of artificial intelligence’s sub-fields, machine learning, and deep learning, was one of the most successful ways to address this problem. This paper reviewed intrusion detection systems and discussed what types of learning algorithms machine learning and deep learning are using to protect data from malicious behavior. It discusses recent machine learning and deep learning work with various network implementations, applications, algorithms, learning approaches, and datasets to develop an operational intrusion detection system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "108",
      "title": "Critical Challenges to Adopt DevOps Culture in Software Organizations: A Systematic Review",
      "abstract": "DevOps is a set of practices and a cultural movement that aims to break down barriers between development and operation teams to improve collaboration and communication. Different organizations have embraced DevOps principles due to the massive potential, such as a much shorter time to production, increased reliability and stability. However, despite the widespread adoption of DevOps and its infrastructure, there is a lack of understanding and literature on the key concepts, practices, tools, and challenges associated with implementing DevOps strategies. The main goal of this research paper is to explore and discuss challenges related to DevOps culture and practices. Moreover, it describes how DevOps works in an organization, provides a detailed explanation of DevOps, and investigates the cultural challenges that organizations face when implementing DevOps. The proposed paper reveals ten critical challenges that need to be addressed in adopting the DevOps culture. The challenges are further analyzed on the basis of the various continents. According to the findings, the following critical challenges are considered during the implementation of a DevOps culture: lack of collaboration and communication, Lack of skill and knowledge, complicated infrastructure, Lack of management, Lack of DevOps approach, and trust confidence problems.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "109",
      "title": "SARD: Towards Scale-Aware Rotated Object Detection in Aerial Imagery",
      "abstract": "Multi-class object detection in remote sensing imagery is an important and challenging topic in computer vision. Compared with the object detection of natural scenes, remote sensing object detection has some challenges such as scale diversity, arbitrary directions and densely packed objects. To resolve these problems, this paper presents a scale-aware rotated object detection. Firstly, we propose a novel feature fusion module, which takes full advantage of high-level semantic information and low-level high resolution feature. The new feature maps are more suitable for detecting objects with a large difference in scale. Meanwhile, we design a specific weighted loss, which contains an intersection-over-union (IoU) loss and a smooth L1 loss to further address the scale diversity. Besides, in order to detect oriented and densely packed objects more accurately, we propose a normalization strategy for the representation of rotating bounding box. Our method is evaluated on two public aerial datasets DOTA and HRSC2016, and achieves competitive performances. On DOTA, we boost the mean Average Precision (mAP) to 72.95% on oriented object detection.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "110",
      "title": "Wind Speed Prediction Using Hybrid 1D CNN and BLSTM Network",
      "abstract": "As the world witnesses population increase, the global power demand is increasing and the need for exploring other alternative clean and self-renewable sources of energy such as wind has become necessary. For optimal operation of the wind farms and stability of the grid, wind prediction ahead of time is of key importance. An accurate forecast of wind speed is often difficult due to the unpredictable nature of the wind. In this work, we utilized different machine learning models and proposed a hybrid machine learning approach. This approach combines 1D convolutional neural network (CNN) and bidirectional long short term memory (BLSTM) network for accurate prediction of short term wind prediction at different heights above ground level (AGL). The 1D CNN model extracts high-level features of the input wind speed data. The extracted features are then fed as input to the BLSTM network for wind speed prediction. The wind speed time series data used in this study are measured at 18, and 98 meters AGL. The study further presents a relationship between the utilized models and prediction accuracy at different heights. The forecasting performance of the models tends to increase as the height AGL increases. A real-world case study is implemented to demonstrate the effectiveness of the proposed CNN-BLSTM method in Saudi Arabia. The mean absolute error (MAE), mean squared error (MSE), root mean squared error (RMSE), and mean absolute percentage error (MAPE) are used as performance indices to evaluate the performance of the proposed CNN-BLTSM model. The corresponding results show that the proposed method outperforms other benchmark models.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "111",
      "title": "A Linear Fractional Transformation Based Approach to Robust Model Predictive Control Design in Uncertain Systems",
      "abstract": "A novel robust model predictive control (RMPC) scheme is developed for uncertain nonlinear systems. To the RMPC design, firstly, the uncertain system would be described using a linear fractional transformation (LFT). Then, regarding the system's uncertainties and control limitations, a linear matrix inequality (LMI) based control strategy is addressed to translate the RMPC synthesis into a minimization problem. Thus the controller's gains are automatically updated at some time-instants by the solution of such optimization problem. Finally, the outcomes are numerically applied in some control examples. The simulation results show the effectiveness of the suggested robust predictive controller in comparison to similar RMPC techniques.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "112",
      "title": "Enhanced Remote Areas Communications: The Missing Scenario for 5G and Beyond 5G Networks",
      "abstract": "The next generation of mobile communication system will allow a plethora of new services and use cases. By offering support for high throughput connections, low latency response and massive number of connections, the fifth generation of the mobile network will trigger applications unseen in any other network. However, one important application scenario is not being properly addressed by the players responsible for the mobile networks' standardization, that is the remote and rural areas network. This scenario requires large cells with high throughput, flexibility to opportunistically exploit free bands below 1 GHz and spectrum agility to change the operational frequency when an incumbent is detected. Incipient actions are being considered for the Release 17 but based on the new radio specification as starting point. The limitations imposed by orthogonal waveforms in the physical layers hinder the exploitation of vacant TV channels in rural and remote areas. 5G-RANGE, a Brazil-Europe bilateral cooperation project, aims at conceiving, implementing and deploying an innovative mobile network, designed to provide reliable and cost-effective connection in these regions. This network can be seamlessly integrated with the other 5G scenarios, closing the connectivity gap between the urban, rural and remote areas. Hence, 5G-RANGE network is an interesting complementary solution for beyond 5G standards. This paper presents the major achievements of the 5G-RANGE project, from the design of the physical, medium access control and network layers, to the field demonstrations. The paper also covers the business models that can be used to make the deployment of this technology a reality.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "113",
      "title": "Delay-Dependent H∞ Control for Singular Markovian Jump Systems With Generally Uncertain Transition Rates",
      "abstract": "This article is devoted to the problem of H control for a class of singular Markovian jump systems with time-varying delay and generally uncertain transition rates, which means each transition rate is completely unknown or only its estimated value is known. By using Lyapunov stability theory, a new delay-dependent H admissible criterion in terms of strict linear matrix inequalities is obtained, which guarantees that the singular Markovian jump system with known transitions rates is regular, impulse-free and stochastically stable with a prescribed H disturbance attenuation level γ. Based on this obtained criterion, some suitable state feedback controllers are designed such that the closed-loop delayed singular Markovian jump system with generally uncertain transition rates is H stochastically admissible. Finally, numerical examples are included to illustrate the effectiveness and the less conservativeness of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "114",
      "title": "Investigating Frontal Neurovascular Coupling in Response to Workplace Design-Related Stress",
      "abstract": "This research seeks to examine the impact of workstation types on the coupling of neural and vascular activities of the prefrontal cortex (PFC). The design of the workstations was found to impair the performance, physical and mental health of employees. However, the mechanism underlying cognitive activity involved during workstation design-related stress effects in the PFC has not been fully understood. We used electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) to simultaneously measure electrical activity and hemoglobin concentration changes in the PFC. The multimodal signal was collected from 23 healthy adult volunteers who completed the Montreal imaging stress task in ergonomic and non-ergonomic workstations. A supervised machine learning method based on temporally embedded canonical correlation analysis (tCCA) was utilized to obtain the association between neural activity and local changes in hemoglobin concentrations to enhance localization and accuracy. The results showed deactivation in alpha power rhythms and oxygenated hemoglobin, as well as declined activation pattern of the fused data in the right PFC at the non-ergonomic workstation. Additionally, all participants at the non-ergonomic workstation experienced a substantial rise in salivary alpha-amylase activity in comparison with the ergonomic workstation, indicating the existence of high-stress levels. The proposed tCCA approach obtains excellent results in discriminating workstation types achieving accuracies of 98.8% and a significant improvement of 8.0% (p <; 0.0001) and 9.4% (p <; 0.0001) over EEG-only and fNIRS-only, respectively. Our study suggests the use of functional neuroimaging in designing the workplace as it provides critical information on the causes of workplace-related stress.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "115",
      "title": "Automated Software Test Data Generation With Generative Adversarial Networks",
      "abstract": "With the rapid increase of software scale and complexity, the cost of traditional software testing methods will increase faster than the scale of software. In order to improve test efficiency, it is particularly important to automatically generate high-quality test cases. This paper introduces a framework for automatic test data generation based on the generative adversarial network (GAN). GAN is employed to train a generative model over execution path information to learn the behavior of the software. Then we can use the trained generative model to produce new test data, and select the test data that can improve the branch coverage according to our proposed selection strategy. Compared to prior work, our proposed method is able to handle programs under test with large-scale branches without analyzing branch expressions. In the experiment, we exhibit the performance of our method by using two modules in GNU Scientific Library. In particular, we consider the application of our method in two testing scenarios; unit testing and integration testing, and conduct a series of experiments to compare the performance of three types of GAN models. Results indicate that the WGAN-GP shows the best performance in our framework. Compared with the random testing method, the WGAN-GP based framework improves the test coverage of five functions out of the seven in the unit testing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "116",
      "title": "Automatic Data Clustering Using Hybrid Firefly Particle Swarm Optimization Algorithm",
      "abstract": "The firefly algorithm is a nature-inspired metaheuristic optimization algorithm that has become an important tool for solving most of the toughest optimization problems in almost all areas of global optimization and engineering practices. However, as with other metaheuristic algorithms, the performance of the firefly algorithm depends on adequate parameter tuning. In addition, its diversification as a global metaheuristic can lead to reduced speed, as well as an associated decrease in the rate of convergence when applied to solve problems with large number of variables such as data clustering problems. Clustering is an unsupervised data analysis technique used for identifying homogeneous groups of objects based on the values of their attributes. To mitigate the aforementioned drawbacks, an improved firefly algorithm is hybridized with the well-known particle swarm optimization algorithm to solve automatic data clustering problems. To investigate the performance of the proposed hybrid algorithm, it is compared with four popular metaheuristic methods from literature using twelve standard datasets from the UCI Machine Learning Repository and the two moons dataset. The extensive computational experiments and results analysis carried out shows that the proposed algorithm not only achieves superior performance over the standard firefly and particle swarm optimization algorithms, but also exhibits high level of stability and can be efficiently utilized to solve other clustering problems with high dimensionality.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "117",
      "title": "Multi-Objective Optimization of 400 kV Composite Insulator Corona Ring Design",
      "abstract": "The electric field distribution is one of the main factors governing the long-term reliability of high voltage composite insulators. However, under severe pollution conditions, electric field stresses, when exceeding thresholds and applying for long periods, could lead to degradation and deterioration of the housing materials and, therefore, to failures of the composite insulators. This paper is intended to improve the distributions of the electric field and potential by minimizing the corona ring on a 400 kV AC transmission line composite insulator. The performances of three powerful multi-objective meta-heuristic algorithms, namely Ant Lion Optimizer (MOALO), Particle Swarm Optimizer (MOPSO), and non-dominated sorting genetic algorithm (NSGA-II) are established to achieve this goal. First, variations of electrical fields on the critical parts of the string are obtained using three-dimensional finite element method (FEM) software. Then, three objective functions are developed to establish the relationships between the electric field and the guard ring parameters. Finally, the optimization parameters consist of diameter, tube diameter, and installation height of the corona ring. The obtained results confirm the effectiveness of the three algorithms; the MOLAO is the better in terms of computing time and solution quality.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "118",
      "title": "A Hybrid Markov and LSTM Model for Indoor Location Prediction",
      "abstract": "Accurate and robust indoor location prediction plays an important role in indoor location services. Markov chains (MCs) have been widely adopted for location prediction due to their strong interpretability. However, multi-order Markov chains (k -MCs) are not suitable for predicting long sequences due to problems of dimensionality. This study proposes a hybrid Markov model for location prediction that integrates a long short-term memory model (LSTM); this hybrid model is referred to as the Markov-LSTM. First, a multi-step Markov transition matrix is defined to decompose the k -MC into multiple first-order MCs. The LSTM is then introduced to combine multiple first-order MCs to improve prediction performance. Extensive experiments are conducted using real indoor Wi-Fi positioning datasets collected in a shopping mall. The results show that the Markov-LSTM model significantly outperforms five existing baseline methods in terms of its predictive performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "119",
      "title": "CMOS Plasmon Detector With Three Different Body-Biasing MOSFETs",
      "abstract": "A complementary metal-oxide-semiconductor (CMOS) plasmon detector using metal-oxide-semiconductor field-effect transistors (MOSFETs) biased at three different body voltages is proposed for high sensitivity and a wide dynamic range. The detection core consists of three differential MOSFET detectors biased at different body voltages based on the photoresponse variation depending on the body potential. The sensitivity of the proposed detector is improved through an increase in the nonlinearity owing to the uses of transistors biased by negative body voltages, and the dynamic range of the detector is widened through the parallel-connected detectors individually biased at different body voltages. A 200-GHz signal is simultaneously incident to the detection cores configured in-parallel through the integrated differential antenna, and DC voltages converted using the different photoresponsivity of the cores are current-combined at the preamplifier and amplified with a three-stage folded-cascode operational amplifier. Simulation and measurement results of the proposed detector designed using TSMC 0.25-μm\\mu \\text{m} CMOS technology show that the negative body-biasing (set to 0, -0.2, and -0.4 V), in the MOSFET can improve the voltage responsivity of 2.63 times, the sensitivity by 2.9-fold compared to zero body-biasing, reaching a dynamic range of 11.1% in the CMOS plasmon detector. Raster-scanned imaging for 60-μm\\mu \\text{m} thick copper tapes with a line width of 6-12 mm attached to 10-mm thick Styrofoam demonstrates that the signal-to-noise ratio of 200-GHz images can be improved from 25.5 dB to 30.6 dB when using the proposed detector with three different body-biased MOSFETs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "120",
      "title": "A Smart Cell Monitoring System Based on Power Line Communication—Optimization of Instrumentation and Acquisition for Smart Battery Management",
      "abstract": "Energy density of current generation battery packs is insufficient for next generation electric vehicles nor the electrification of the aerospace industry. Currently, approximately a third of energy density is lost due to ancillary demands (e.g., cooling and instrumentation) within a pack, relative to cell energy density. Smart cells, instrumented cells with sensors and circuitry, offer a means to monitor cell performance (e.g. temperature, voltage, current data). Uniquely here we demonstrate our 21700 cells instrumented with internal thermistor sensing arrays with custom miniature interface circuitry including data acquisition and communication components. This circuitry including a power line communication (PLC) system, enables sensor data to be collected and transmitted to a master controller without requiring additional wiring, and can achieve an excellent <0.005 % message error rate. The control and communication system includes the use of adaptive sampling algorithms (during identified periods of low demand, through temperature and current measurements) the cells transmit data at 0.2 Hz, increasing to 5 Hz (normal operation) or 10 Hz (beyond operating limits). This method was demonstrated via drive cycling and external heating to alert the master controller to abnormal operating conditions (rapidly, to avoid missing key features) while saving 65% volume of data during a 90 minute experiment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "121",
      "title": "Configurable Mixed-Radix Number Theoretic Transform Architecture for Lattice-Based Cryptography",
      "abstract": "Lattice-based cryptography continues to dominate in the second-round finalists of the National Institute of Standards and Technology post-quantum cryptography standardization process. Computational efficiency is primarily considered to evaluate promising candidates for final round selection. In lattice-based cryptosystems, polynomial multiplication is the most expensive computation and critical to improve the performance. This paper proposes an efficient number theoretic transform (NTT) architecture to accelerate the polynomial multiplication. The proposed design applies mixed-radix multi-path delay feedback architecture and flexibly adopts various polynomial sizes. Configurable NTT design is realized to perform forward and inverse NTT computations on a unified hardware, which is then used to develop an efficient polynomial multiplier. The proposed architectures were successfully accelerated on several Xilinx FPGA platforms to directly compare with state-of-the-art works. The implementation results show that the proposed NTT architectures have comparable area-time product and demonstrate \n 1.7∼17×1.7\\sim 17\\times  \n performance improvement, and the proposed polynomial multipliers achieve higher performance compared with previous works. Experimental results confirmed the proposed design’s applicability for high-speed large-scale data cryptoprocessors.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "122",
      "title": "Correction to “A Novel Unbalance Compensation Method for Distribution Solid-State Transformer Based on Reduced Order Generalized Integrator”",
      "abstract": "1. In page 108598, the title “IV ICOMPENSATION ABILITY ANALYSIS” should be “IV COMPENSATION ABILITY ANALYSIS”.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "123",
      "title": "Finite-Time Attitude Control With Chattering Suppression for Quadrotors Based on High-Order Extended State Observer",
      "abstract": "This article investigates a finite-time attitude control with chattering suppression for quadrotors based on a high-order extended state observer (HESO). To improve the anti-disturbance capacity of quadrotors, a HESO capable of estimating fast time-varying disturbances is presented to enhance system robustness by regarding higher-order disturbance derivatives as extended arguments. Then, with the estimates of HESO, a finite-time attitude control policy including a double hyperbolical reaching law (DHRL) is introduced, alleviating control chattering and guaranteeing rapid response. The most significant feature is a finite time regulation for quadrotors without incurring severe oscillations can be obtained in the event of fast time-varying uncertainties. Moreover, the stability analysis is proved by a Lyapunov theorem. Finally, the effectiveness of proposed control scheme is demonstrated by numerical and experimental results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "124",
      "title": "Exponential Loss Minimization for Learning Weighted Naive Bayes Classifiers",
      "abstract": "The naive Bayesian classification method has received significant attention in the field of supervised learning. This method has an unrealistic assumption in that it views all attributes as equally important. Attribute weighting is one of the methods used to alleviate this assumption and consequently improve the performance of the naive Bayes classification. This study, with a focus on nonlinear optimization problems, proposes four attribute weighting methods by minimizing four different loss functions. The proposed loss functions belong to a family of exponential functions that makes the optimization problems more straightforward to solve, provides analytical properties of the trained classifier, and allows for the simple modification of the loss function such that the naive Bayes classifier becomes robust to noisy instances. This research begins with a typical exponential loss which is sensitive to noise and provides a series of its modifications to make naive Bayes classifiers more robust to noisy instances. Based on numerical experiments conducted using 28 datasets from the UCI machine learning repository, we confirmed that the proposed scheme successfully determines optimal attribute weights and improves the classification performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "125",
      "title": "Vibration Signal Extraction Based on FFT and Least Square Method",
      "abstract": "Fast Fourier Transform (FFT), widely used in spectrum analysis, is a powerful processing vibration signal to obtain the signal amplitude, frequency, and phase. However, the discrepancy between the FFT derived values and the real values could be introduced due to spectral leakage and spectral interference. This inconsistency is prohibited in some applications, for example, the extraction of vibration characteristics for power machinery and failure diagnostics. Therefore, the methodology to obtain the frequency domain's exact characteristics becomes one of the most concerning topics in vibration and signal processing. In this paper, a newly developed iterative method is presented in detail for high-accuracy characteristic extraction of multiple frequencies periodic vibration signals based on FFT and least square method. In the situation where the attenuation signal is superposed onto the periodic signal, the accurate characteristics of these two signals are also obtainable. Besides, simulation examples are provided, showing that the proposed method can be applied to the single-frequency signal, multiple frequency signals (including the signals of which the adjacent frequencies are close), and attenuation signal. The experimental results show that using the data processing method in this paper to extract the attenuation signals' characteristics, and the fitted attenuation curves are in good agreement with the actual attenuation signals. The method shown in this paper can be used for precisely extracting the characteristics of the periodic signal and attenuation signals in engineering.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "126",
      "title": "Overview of Loss Sensitivity Analysis in Modern Distribution Systems",
      "abstract": "Distribution system planning and operation has seen many structural changes due to the increased participation of consumers in the energy market and the adaptation of new technologies such as distributed energy resources (DERs), electric vehicles (EV) and local energy storage systems (ESSs). Despite the convenience of such technologies and the gradual drop in their prices, new technical challenges (e.g., excessive power losses) have emerged at the system level. Over the past few decades, power loss minimization in distribution systems has gained popularity and the need for loss sensitivity analysis (LSA) frameworks has become a necessity for its successful implementation. Existing work on LSA mostly focuses on system planning aspects through DER optimal placement and sizing. However, enabling LSA-based system operational applications is a vital step toward the successful transition to modern distribution systems (MDSs). Therefore, this paper presents a comprehensive overview on the state of the art in LSA for MDSs. First, the theoretical formulations of existing LSA methods are summarized. Then, the applications of LSA in distribution systems are highlighted. Finally, based on the analysis of literature, open research gaps and future research pathways are discussed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "127",
      "title": "Learning Depth Estimation From Memory Infusing Monocular Cues: A Generalization Prediction Approach",
      "abstract": "Depth estimation from a single image is a challenging task, yet this field has a promising prospect in automatic driving and augmented reality. However, the prediction accuracy is degraded significantly when the trained network is transferred from the training dataset to real scenarios. To solve this issue, we propose MonoMeMa, a novel deep architecture based on the human monocular cue, which means humans can perceive depth information with one eye through the relative size of objects, light and shadow, etc. based on previous visual experience. Our method simulates the process of the formation and utilization of human monocular visual memory, including three steps: Firstly, MonoMeMa perceives and extracts real-world objects feature vectors (encoding). Then, it maintains and replaces the extracted feature vector over time (storing). Finally, MonoMeMa combines query objects feature vectors and memory to inference depth information (retrieving). According to the simulation results, our model shows the state-of-the-art results on the KITTI driving dataset. Moreover, MonoMema exhibits remarkable generalization performance when our model is migrated to other driving datasets without any finetune.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "128",
      "title": "Research on Parallelization of Microblog Emotional Analysis Algorithms Using Deep Learning and Attention Model Based on Spark Platform",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "129",
      "title": "Robust Anomaly Detection for Multivariate Data of Spacecraft Through Recurrent Neural Networks and Extreme Value Theory",
      "abstract": "Spacecraft anomaly detection which could find anomalies in the telemetry or test data in advance and avoid the occurrence of catastrophic failures after taking corresponding measures has elicited the attention of researchers both in academia and aerospace industry. Current spacecraft anomaly detection systems require costly knowledge and human expertise to identify a true anomaly. Moreover, some new problems and challenges such as large volume of test data, imbalanced data distribution and the scarcity of faulty labeled samples have emerged. In this work, we propose an unsupervised anomaly detection algorithm combining Gated Recurrent Unit (GRU) based Recurrent Neural Network (RNN) and Extreme Value Theory (EVT). First, we develop a two-layer ensemble learning based predictor framework which stacks three GRU-based networks with different architectures to learn and capture the normal behavior of multiple channels of data. Then, the prediction errors are calculated and smoothed using Exponentially Weighted Moving Average (EWMA) algorithm. Next, we propose a detection rule setting anomaly threshold automatically through EVT which does not assume any parent distribution on the prediction errors. To the best of our knowledge, it is the first attempt that stacked GRU-based predictors with EVT has been employed into the spacecraft anomaly detection. Through extensive experiments conducted on public datasets as well as real data sampled from a launch vehicle, we show that the proposed detection algorithm is superior to other state-of-the-art anomaly detection approaches in terms of model performance and robustness.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "130",
      "title": "Fault Diagnosis and Prognosis for Satellite Formation Flying: A Survey",
      "abstract": "Fault diagnostics and prognosis are vital functions of engineering systems, mainly fault prognosis, which is a relatively novel area and requires further development. By applying these methods, the system can be enriched with the ability to detect and isolate faults before they result in failures; in addition, fault propagation can be predicted, and maintenance can be considered to reduce the risk of severe failure. This paper focuses on the problem of satellite formation fault diagnosis and prognosis in the literature. Multi-satellite networks that cooperate as multi-agent systems are primarily used to implement cutting-edge technologies and improve future Earth and space observing missions. Space systems constantly encounter numerous failures due to the hazards and challenges of the space environment that need to be tackled. The current starts with an overview of the main concepts and motivations behind the deployment of small satellites in constellation settings and the detection and prediction of their faults. Next, recent papers on fault diagnosis and prognosis of single and multiple agent(s) or satellite(s), working individually or in collaboration, are reviewed. Comprehensive comparisons and categorization of the reviewed literature are included throughout the paper leading to existing research gaps for future work.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "131",
      "title": "Dynamic Output Feedback Control of Cyber-Physical Systems Under DoS Attacks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "132",
      "title": "Practical Methods for Efficient Resource Utilization in Augmented Reality Services",
      "abstract": "This work presents a novel approach that adopts content caching techniques towards reducing computation and communication costs of Augmented Reality (AR) services. The application scenario under investigation assumes an environment of static objects, each one associated to a holographic content. The goal is to devise practical low-overhead methods so as to reduce the amount of resources above that are needed for the most resource-demanding AR process, namely object recognition. The proposed method is based on caching images using a combination of metrics to rank them such as: (i) an object popularity index which favours objects that are most probable to be requested for recognition, (ii) the percentage of times when the object label has been encountered in the past, (iii) the probability that an image is similar enough with already encountered past images with the same label. The aforementioned image caching method drastically reduces database searches and returns the matched object that satisfies the needs of object recognition. We also devise a binary decision operator that initiates the object recognition process only upon comparison of spatial data of the AR device with the targeted object. The resulting performance is measured using a client-server architecture and components such as Wireshark, Unity Profiler, and Python. For our proposed architecture we deploy an edge server to satisfy the demands of the AR service. Results indicate that the proposed methods can significantly reduce both the computational resources and the induced network traffic, thus improving user experience.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "133",
      "title": "Joint Optimization of Data Offloading and Resource Allocation With Renewable Energy Aware for IoT Devices: A Deep Reinforcement Learning Approach",
      "abstract": "A large number of connected sensors and devices in Internet of Things (IoT) can generate large amounts of computing data and increase massive energy consumption. Real-time states monitoring and data processing of IoT nodes are of great significance, but the processing power of IoT devices is limited. Using the emerging mobile edge computing (MEC), IoT devices can offload computing tasks to an MEC server associated with small or macro base stations. Moreover, the use of renewable energy harvesting capabilities in base stations or IoT nodes may reduce energy consumption. As wireless channel conditions vary with time and the arrival rates of renewable energy, computing tasks are stochastic, and data offloading and renewable energy aware for IoT devices under a dynamic and unknown environment are major challenges. In this work, we design a data offloading and renewable energy aware model considering an MEC server performing multiple stochastic computing tasks and involving time-varied wireless channels. To optimize data transmission delay, energy consumption, and bandwidth allocation jointly, and to avoid the curse of dimensionality caused by the complexity of the action space, we propose a joint optimization method for data offloading, renewable energy aware, and bandwidth allocation for IoT devices based on deep reinforcement learning (JODRBRL), which can handle the continuous action space. JODRBRL can minimize the total system cost(including data buffer delay cost, energy consumption cost, and bandwidth cost) and obtain an efficient solution by adaptively learning from the dynamic IoT environment. The numerical results demonstrate that JODRBRL can effectively learn the optimal policy, which outperforms Dueling DQN, Double DQN (DDQN), and greedy policy in stochastic environments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "134",
      "title": "Vehicle Exhaust Concentration Estimation Based on an Improved Stacking Model",
      "abstract": "This paper aims to estimate the carbon monoxide (CO) and hydrocarbon (HC) concentrations of vehicle exhaust. For this purpose, an improved Stacking model is designed. Compared with individual estimation models, the improved Stacking model can achieve better concentration estimation performance. That model has a three-layer structure. The first layer is made up of multiple estimation models, which produce intermediate estimation results from the original exhaust data based on the KK -fold cross-validation. The second layer takes these intermediate estimation results as input and trains a statistical learning model which generates preliminary estimation results of the concerned exhaust concentrations. The first two layers actually constitute the Stacking model, which is extended by the additional third layer of our improved one. The third layer implements a weighted summation method. More specifically, the preliminary estimation results generated by the second layer are linearly combined with the concentration estimation results of some strong estimation models, such as XGBoost and LightGBM, to produce the final estimation results in the third layer. Our improved Stacking model is verified through experimental data, which were collected by a Urban Road Network Vehicle Emissions Monitoring System and small weather stations in two Chinese cities, including Beijing and Jiaozuo. Experimental results show that compared with some regression and neural network estimation models, especially the Stacking model and Boosting models, our improved Stacking model achieves higher exhaust concentration estimation accuracy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "135",
      "title": "K-Means Clustering Guided Generative Adversarial Networks for SAR-Optical Image Matching",
      "abstract": "Synthetic Aperture Radar and optical (SAR-optical) image matching is a technique of finding correspondences between SAR and optical images. SAR-optical image matching can be simplified to single-mode image matching through image synthesis. However, the existing SAR-optical image synthesis methods are unable to provide qualified images for SAR-optical image matching. In this work, we present a K-means Clustering Guide Generative Adversarial Networks (KCG-GAN) to improve the image quality of synthesizing by constraining spatial information synthesis. KCG-GAN uses k-means segmentations as one of the image generator's inputs and introduces feature matching loss, segmentation loss, and L1 loss to the objective function. Meanwhile, to provide repeatable k-means segmentations, we develop a straightforward 1D k-means algorithm. We compare KCG-GAN with a leading image synthesis method-pix2pixHD. Qualitative results illustrate that KCG-GAN preserves more spatial structures than pix2pixHD. Quantitative results show that, compared with pix2pixHD, images synthesized by KCG-GAN are more similar to original optical images, and SAR-optical image matching based on KCG-GAN obtains at most 3.15 times more qualified matchings. Robustness tests demonstrate that SAR-optical image matching based on KCG-GAN is robust to rotation and scale changing. We also test three SIFT-like algorithms on matching original SAR-optical image pairs and matching KCG-GAN synthesized optical-optical image pairs. Experimental results show that our KCG-GAN significantly improves the performances of the three algorithms on SAR-optical image matching.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "136",
      "title": "Concentration and Spatial Clustering of Forest-Based Thermoelectric Plants in Brazil",
      "abstract": "This study analyzes the concentration and conglomerate spatial distribution of forest-based thermoelectric plants in Brazil, in 2018. Herein, we spatially identified thermoelectric plants in different Brazilian regions and states, and measured the state concentrations (levels 1 and 2 of forest) using various indicators, including the concentration ratio (CR(k)), the Herfindahl-Hirschman index (HHI), Theil's entropy (E), and the Gini coefficient (G). Meanwhile, each state's conglomerates were evaluated using the Scan statistic. We found that there are 98 forest-base thermoelectric plants in Brazil, most of which are located in the south-central portion of the country where there is rapid forest growth. The southern region contains 32.65% of the identified plants as a result of the presence of level 2 forest resources (black liquor and forest waste). Regarding the state's concentration (forest level 1), CR(k) revealed a moderate concentration, the HHI and E indices demonstrated low concentrations, and G suggested null to weak inequality. Of these Brazilian forest bioelectricity plants (level 1), 4 clusters were identified, but only one was statistically significant, located in the southern region. Concerning level 2 sources, the only statistically significant conglomerate regarding charcoal was centered in Açailândia (Maranhão). These findings will provide information to assist industry decision-making processes and help guide public policies for forest bioelectricity development in Brazil that favor energy security and improve resource utilization.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "137",
      "title": "Development of Smart Battery Cell Monitoring System and Characterization on a Small-Module Through In-Vehicle Power Line Communication",
      "abstract": "Current generation battery electric vehicles lack sufficient systems to monitor battery degradation and aging; consumers demand longer range, faster charging and longer vehicle lifetime. Smart cells, incorporating sensors (e.g. temperature, voltage, and current) offer manufacturers a means to develop longer lasting packs, enabling faster charging and extending range. In this work, instrumented cells (cylindrical, 21700) have been developed. Our novel data logging solution (using power line communication, PLC) permits a comprehensive range of sensors to be installed on each cell. Utilizing the cell bus bars, this reduces the necessary wiring harness size and complexity to instrument packs, which can enable higher density energy storage per volume and weight within the vehicle. In this initial feasibility study, a module (4S2P cells) was tested using two diverse cycles (stepped current, 200 mins ×10 cycles, and transient drive, 50 min) in a laboratory climate chamber. The interface system enables research-prototype or traditional sensors to be connected via the PLC network. Miniature sensors (6 temperature, 1 current, 1 voltage) were installed externally on each cell. Excellent performance was observed from the communication system; maximum 0.003% bit error rate, 50ms message receive time (compared to dedicated wired link). Variation in the measured parameters (originally identical cells, temperature 1.0 °C, voltage 5% state-of-charge, current ~ 10%) support the need for improved cell instrumentation to understand cell manufacturing tolerances and aging. This work shows a proof-of-concept study using PLC with instrumented cells, and leads to future work to further reduce the cost and physical size of smart cells.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "138",
      "title": "Constrained Optimization Based on Ensemble Differential Evolution and Two-Level-Based Epsilon Method",
      "abstract": "Constrained optimization problems (COPs) are common in many fields, and the search algorithm and constraint handling technique play important roles in the constrained evolution algorithms. In this article, we propose a new optimization algorithm named CETDE based on ensemble differential evolution (DE) and a two-level epsilon-constrained method. In the ensemble DE variant, some promising parameters and mutation strategies constitute the candidate pool, and each element in the pool coexists throughout the search process and competes to generate new solutions. The two-level epsilon method is proposed by incorporating a generation and a population comparison level to retain more promising solutions without degrading the solution quality. Moreover, a diversity promotion scheme is developed to improve the population distribution when the search becomes trapped in a small region. The superior performance of CETDE is validated by comparison with some state-of-the-art COEAs over two sets of artificial benchmarks and five real-world problems. The competitive results show that CETDE is an effective method for solving COPs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "139",
      "title": "On the Signal-to-Noise Ratio Wall of Energy Detection in Spectrum Sensing",
      "abstract": "In this paper, a comprehensive analysis of the signal-to-noise ratio wall (SNRw) of cognitive radio (CR)-based non-cooperative spectrum sensing (nCSS) and cooperative spectrum sensing (CSS) using energy detection (ED) is presented. The analysis considers a novel realistic noise uncertainty (NU) model in which it is assumed that the estimated noise variance used to determine the decision threshold is unbiased and follows a truncated-Gaussian random distribution with configurable limits. Expressions are derived for the individual detection performances at CRs and global detection performances at the fusion center in terms of probability of false alarm and probability of detection and the SNRw of ED in nCSS and CSS in hard-decision fusion under the \n kk  \n-out-of- \n MM  \n rule, and soft-decision fusion, considering the proposed NU model, respectively. Empirical SNRw algorithms are also proposed, allowing for the SNRw computation of any detector, including the ED, in nCSS and CSS. All theoretical findings are verified through computer simulations or empirical results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "140",
      "title": "Towards an Machine Learning-Based Edge Computing Oriented Monitoring System for the Desert Border Surveillance Use Case",
      "abstract": "The design of border surveillance systems is critical for most countries in the world, having each border specific needs. This paper focuses on an Internet of Things oriented surveillance system to be deployed in the Sahara Desert, which is composed of many unattended fixed platforms, where the nodes in the edge have a Forward Looking InfraRed (FLIR) camera for field monitoring. To reduce communications and decentralise the processing, IR images should be fully computed on the edge by an Automated Target Recognition (ATR) algorithm, tracking and identifying targets of interest. As edge nodes are constrained in energy and computing capacity, this work proposes two ATR systems to be executed in low-power microprocessors. Both proposals are based on using Bag-of-Features for feature extraction and a supervised algorithm for classification, both differing in segmenting the InfraRed image in regions of interest or working directly with the whole image. Both proposals are successfully applied to infer about a dataset generated to this end, getting a trade-off between computing cost and detection capacity. As a result, the authors obtained a detection capacity of up to 97% and a frame rate of up to 5.71 and 59.17, running locally on the edge device and the workstation, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "141",
      "title": "Robust Model Predictive Control for Takagi-Sugeno Model With Bounded Disturbances—Pólya Approach",
      "abstract": "This paper proposes a general robust model predictive control (MPC) approach for the constrained Takagi-Sugeno (T-S) fuzzy model with additive bounded disturbances. We adopt the homogeneous polynomially parameter-dependent (HPP) Lyapunov matrix with the arbitrary complexity degree and the corresponding HPP control law for the controller design. By applying the Pólya’s theorem and the extended nonquadratic boundedness property, a systematic approach to construct a set of sufficient conditions for assessing robust stability described by parameter-dependent linear matrix inequalities (LMIs) is established. The proposed approach is an improvement over the existing approaches in terms of control performance and stabilizable model range. Numerical examples are provided to show the effectiveness of the proposed robust MPC approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "142",
      "title": "Low-Noise Resistive Bridge Sensor Analog Front-End Using Chopper-Stabilized Multipath Current Feedback Instrumentation Amplifier and Automatic Offset Cancellation Loop",
      "abstract": "Resistive bridge sensors are used in many application areas to measure changes in physical parameters. To amplify the resistive changes from sensing elements with high precision, various offset contributors in the resistive bridge and amplifiers should be minimized. This study proposes a low-noise resistive bridge sensor analog front-end (AFE) using a chopper-stabilized multipath current feedback instrumentation amplifier (CFIA) and an automatic offset cancellation loop. The proposed circuit exploits a multipath chopper-stabilized architecture for obtaining low noise performance and wide bandwidth characteristics. This circuit can minimize the offsets in the bridge and the high frequency and low frequency amplifiers, while achieving high precision resistive signal acquisition. The high frequency path of the multipath amplifier uses the CFIA topology with class-AB output stage. The offset in the high frequency path is stabilized by the low frequency path amplifier with a high gain and low noise chopper amplifier. The up-modulated offset in the low frequency chopper amplifier path is reduced by the AC-coupled ripple reduction loop (RRL). An automatic offset calibration loop (AOCL) circuit was designed to calibrate the offset due to the bridge mismatch. The AOCL reduces the bridge offset using a successive approximation register (SAR)-based binary-search algorithm. The gain of the proposed circuit is adjustable from 15.56 dB to 44.14 dB. The AFE is implemented in a \n 0.18~ \\boldsymbol {\\mu } \\text{m}0.18 μm0.18~ \\boldsymbol {\\mu } \\text{m} \n CMOS process and draws \n 123~ \\boldsymbol {\\mu } \\text{A}123 μA123~ \\boldsymbol {\\mu } \\text{A} \n current from a 3.3 V supply. The input referred noise and noise efficiency factor (NEF) are 14.6 nV/ \n \\boldsymbol {\\surd } √\\boldsymbol {\\surd }  \nHz and 6.1, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "143",
      "title": "Actionable Knowledge Discovery for Increasing Enterprise Profit, Using Domain Driven-Data Mining",
      "abstract": "Actionable Knowledge Discovery approaches to extract the business and technical significant actions/patterns to support direct decision making. These actions suggest how to transform an object from an undesirable status to a desirable status by incurring less cost and high profit. This article aims to propose a work that generates actionable patterns efficiently. It reduces the search space and number of iterations for attribute value change during action generation. Performance of the proposed method is compared with Yang's method and OF-CEAMA on the basis of four parameters i.e. the total number of rules required for action generation, run time of the methods, the total number of generated actions, total net profit and time and space complexity. Experiments have been carried out on four datasets retrieved from UCI Machine learning repository. Experimental results show that the proposed work takes less time than the other two methods to extract actions for all datasets. Also, the number of rules required to generate actions are less than the other two methods. Results also suggest that a decrease in execution time does not compromise the information and proposed work generates the same actions and net profit. Moreover, the proposed work tries to transfer an object from undesired status to the desired status.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "144",
      "title": "A Synthesis Approach to Output Feedback MPC for LPV Model With Bounded Disturbance",
      "abstract": "The model with polytopic parametric uncertainty and bounded disturbance is controlled by the approach named dynamic OFRMPC (Output Feedback Robust Model Predictive Control). A key knob for control performance and region of attraction for this approach is the selection of Lyapunov matrix. A Lyapunov matrix, which does not have structural restriction, is proposed. In the ICCA (Iterative Cone Complementary Approach), which is invoked in optimizing the control law parameters, the starting up steps are designed as a variant CCA (Cone Complementary Approach). ICCA designs an outer loop, over CCA, for searching the minimum cost bound, while the variant CCA omits the outer loop by adding the cost bound in CCA objective function. This starting up can reduce the computational burden. The suboptimal dynamic OFRMPC (where CCA is avoided) is discussed, and a previous approach is re-formulated. A numerical example is given to show the advantages of the proposed approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "145",
      "title": "Synthetic Benchmarks for Power Systems",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "146",
      "title": "Multi-Disease Deep Brain Stimulation",
      "abstract": "Current closed-loop deep brain stimulation (DBS) devices can generally tackle one disorder. This paper presents the design and evaluation of a multi-disease closed-loop DBS device that can sense multiple brain biomarkers, detect a disorder, and adaptively deliver electrical stimulation pulses based on the disease state. The device consists of: (i) a neural sensor, (ii) a controller involving a feature extractor, a disease classifier, and a control strategy, and (iii) neural stimulator. The neural sensor records and processes local field potentials and spikes from within the brain using two low-frequency and high-frequency channels. The feature extractor digitally processes the output of the neural sensor, and extracts five potential biomarkers: alpha, beta, slow gamma, high-frequency oscillations, and spikes. The disease classifier identifies the type of the neurological disorder through an analysis of the biomarkers' amplitude features. The control strategy considers the disease state and supplies the stimulation settings to the neural stimulator. Both the disease classifier and control strategy are based on fuzzy algorithms. The neural stimulator generates electrical stimulation pulses according to the control commands, and delivers them to the target area of the brain. The device can generate current stimulation pulses with specific amplitude, frequency, and duration. The fabricated device has the maximum radius of 15 mm. Its total weight including the circuit board, battery and battery holder is 5.1 g. The performance of the integrated device has been evaluated through six bench and in-vitro experiments. The experimental results are presented, analyzed, and discussed. Six bench and in-vitro experiments were conducted using sinusoidal, normal pre-recorded, and diseased neural signals representing normal, epilepsy, depression and PD conditions. The results obtained through these tests indicate the successful neural sensing, classification, control, and neural stim...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "147",
      "title": "Linear Quadratic Tracking With Reinforcement Learning Based Reference Trajectory Optimization for the Lunar Hopper in Simulated Environment",
      "abstract": "In this work, we provide a novel optimal guidance and control strategy for lunar hopper obstacle-avoidance, descent, and landing problem and demonstrate its behavior using numerical simulations. More specifically, the major contributions of this paper are three-fold: 1) proposed a feedback-based reference trajectory design for lunar hopper guidance, 2) developed the mathematical models and equations of linear quadratic tracking (LQT) controller for lunar hopper control, and 3) developed a method using reinforcement learning to optimize the designed reference trajectory in conjunction with the designed LQT controller, the so- called linear quadratic tracking with reinforcement learning based reference trajectory optimization (LQT-RTO). We demonstrated the LQT-RTO under a 2-dimensional (2D) lunar hopper simulation environment with 1) the LQT with heuristic reference trajectory design (LQT-HTD) and 2) reinforcement learning (reinforcement learning based controller, or RLC). We confirmed by numerical simulation that the LTQ-RTO outperformed the LQT-HTD in terms of fuel consumption, and outperformed the RLC in terms of landing success rate. Lastly, we provided theoretical interpretation to the simulation results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "148",
      "title": "Artificial Intelligence Vision-Based Monitoring System for Ship Berthing",
      "abstract": "This paper proposes a novel artificial intelligence vision-based monitoring system (AVMS) for ship berthing. To dock a ship, it is necessary to accurately estimate the relative distance between the quay wall and the ship. However, maneuvering large ships near a port is a complicated and difficult procedure. Thus, tugboats push the ship and dock it at the berth under the supervision of a pilot, who receives distance information from a berthing aid system (BAS). The conventional BAS based on laser distance sensors, which is the most widely used approach, is high-priced and limited by the size of the ship. Additionally, if there is an obstacle between the ship and the berth, the distance cannot be measured, since it obscures the laser signal. To address this problem, we develop an AVMS sensor module composed of a low-priced camera, a differential global positioning system (DGPS) receiver, and an inertial measurement unit (IMU) with an algorithm to estimate the distance between ship and berth. To evaluate the performance of the proposed AVMS, field tests are performed at Ulsan port in Korea, and the results are compared with a conventional BAS. From the field test results, the AVMS provides highly accurate estimates and shows robust performance in poor weather conditions compared to the conventional BAS. The AVMS can measure the distance between ship and berth regardless of the size of the ship, since it has a wide field of view. In addition, it provides the pilot with real-time image information of the ship approaching the berth to obtain safe ship berthing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "149",
      "title": "Robust Network Intrusion Detection System Based on Machine-Learning With Early Classification",
      "abstract": "Network Intrusion Detection Systems (NIDSs) using pattern matching have a fatal weakness in that they cannot detect new attacks because they only learn existing patterns and use them to detect those attacks. To solve this problem, a machine learning-based NIDS (ML-NIDS) that detects anomalies through ML algorithms by analyzing behaviors of protocols. However, the ML-NIDS learns the characteristics of attack traffic based on training data, so it, too, is inevitably vulnerable to attacks that have not been learned, just like pattern-matching machine learning. Therefore, in this study, by analyzing the characteristics of learning using representative features, we show that network intrusion outside the scope of the learned data in the feature space can bypass the ML-NIDS. To prevent this, designing the active session to be classified early, before it goes outside the detection range of the training dataset of the ML-NIDS, can effectively prevent bypassing the ML-NIDS. Various experiments confirmed that the proposed method can detect intrusion sessions early (before sessions terminate) significantly improving the robustness of the existing ML-NIDS. The proposed approach can provide more robust and more accurate classification with the same classification datasets compared to existing approaches, so we expect it will be used as one of feasible solutions to overcome weakness and limitation of existing ML-NIDSs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "150",
      "title": "Transverse Damage Localization and Quantitative Size Estimation for Composite Laminates Based on Lamb Waves",
      "abstract": "The damage detection method for composite laminates introduced in this research uses piezoelectric (lead zirconate titanate, PZT) transducers to excite/sense the Lamb wave signals. The complicated wave signals scattered by damage are accurately processed using a continuous wavelet transformation (CWT) based on the Gabor wavelet. The transducers are arranged on a composite laminate in the form of a network of square detection cells and triangular subcells. The damage location is estimated using the concept of centroid in two-stage detection method. The first stage detection is carried out by exciting a transducer at the center of each detection cell to locate the damaged cell and subcell. The damage localization is improved by exciting an additional transducer at the corner of the damaged subcell during the second stage detection. The damage size is then quantitatively estimated using cubic spline curve (CSC) and elliptical parametric (EP) methods based on the damage edge points. The damage location is estimated in two detection stages for high-accuracy because the damage edge points are calculated with reference to the estimated location of the damage. The arrangement of transducers and signal processing technique remain the same at all the stages of damage detection. Results from previous detection stages contribute to the improvement of damage detection in the subsequent stages. The size of detection cell plays a crucial role in designing the detection stages, and the proposed method can accurately quantify both location and size of the damage in composite laminate.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "151",
      "title": "MSDF-Net: Multi-Scale Deep Fusion Network for Stroke Lesion Segmentation",
      "abstract": "Lesion segmentation is of great research interest due to its capability in facilitating accurate stroke diagnosis and surgical planning. Existing deep neural networks, such as U-net, have demonstrated encouraging progress in biomedical image segmentation. Nevertheless, there are still many challenges related to the segmentation of stroke lesions, including dealing with diverse lesion locations, variations in lesion scales, and fuzzy lesion boundaries. In order to address these challenges, this paper proposes a deep neural network architecture denoted as the Multi-Scale Deep Fusion Network (MSDF-Net) with Atrous Spatial Pyramid Pooling (ASPP) for the feature extraction at different scales, and the inclusion of capsules to deal with complicated relative entities. The proposed method is essentially an end-to-end deep encoder-decoder neural network. The cross connection between the encoder and the decoder guarantees the high resolution of the feature mapping. Experimental results on the open-source Anatomical Tracings of Lesions After Stroke (ATLAS) dataset shows that the proposed model achieved a higher evaluating score compared to 5 existing models.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "152",
      "title": "Deep Learning for Improving the Robustness of Image Encryption",
      "abstract": "In this paper, we propose a method to increase the robustness of 2D/3D optical image encryption using the dilated deep convolutional neural network (CNN). In order to solve the problem that encrypted images suffer from some attacks in practical application, we utilize a fast and effective CNN denoiser based on the principle of deep learning. The CNN improves the robustness of the algorithm by improving the resolution of the reconstructed images. Besides, CNN has a high performance against blur and occlusion attacks. We introduce the pixel scrambling method to enhance the security level of the encryption by the private key of pixel scrambling operation. The proposed method can not only realize the encryption of a two-dimensional image but also implement three-dimensional image encryption by combining the integral imaging technology. Double random phase encoding in the fractional Fourier domain is selected for experimental verification, and the results show the capability for robustness, noise immunity, and security of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "153",
      "title": "Study on Energized Mixed-phase Icing of CFCCW and its Effect on AC Corona Onset Voltage",
      "abstract": "In winters, China witnesses frequent mixed-phase ice disasters, which have a detrimental impact on the secure operation of transmission lines. Most of the studies are focused on the conventional overhead lines, and little attention is paid to the novel carbon fiber composite core wire (CFCCW), which were widely used in recent years. Besides, the influence rule of frequent mixed-phase icing on the corona onset characteristics for CFCCW has not been extensively studied across extant literature. Thus, this article addresses the aforementioned issues by conducting Alternating Current (AC) corona tests for four kinds of CFCCW that would be coated by mixed-phase ice in a low-temperature laboratory. The results showed that the impact of mixed-phase ice on the wire corona onset voltage can be reduced by nearly 50%. With more icing the corona onset voltage would further decrease but at a slower pace. For the wires with a larger diameter, higher corona onset voltage with low distortion in the electric field strength was observed for the same icing time. For the freezing-water conductivity, no significant impact on both the icing morphology and the corona onset voltage was observed. Moreover, the validation for the simulation model was established by comparing the simulation results with the experimental results. These inferences drawn could act as a theoretical reference for transmission lines designing and calculating the wire corona onset voltage in the mixed-phase icing areas.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "154",
      "title": "A Distributed Survivable Routing Algorithm for Mega-Constellations With Inclined Orbits",
      "abstract": "Mega-constellations consisting of hundreds to thousands of low-earth-orbit (LEO) satellites are an attractive solution for providing global ubiquitous network access. Due to good coverage properties for populated areas, inclined orbits are gaining popularity among commercial constellations. A scalable routing algorithm with survivability plays a key role in such systems. In this paper, we propose a distributed survivable routing algorithm for mega-constellations with inclined orbits. First, the special topology characteristic of inclined constellations is identified and formalized. Based on the topology characterization, a basic X-Y routing algorithm is presented to determine multiple primary and secondary paths towards each destination utilizing the regularity of the network topology with minimal computation overhead. Then, a failure recovery mechanism which consists of a restricted flooding mechanism and a pre-detour mechanism is proposed to reduce end-to-end delay and signaling overhead in case of link failures. Besides, a partial-record loop avoidance mechanism is proposed to deal with routing loops with minimal overhead. Finally, a vector-based next hop selection mechanism is proposed to facilitate the selection of next hop while incorporating various criteria. The performance of the proposed routing algorithm is evaluated through simulation on the Starlink constellation. Simulation results show that our proposal achieves scalability by reducing signaling overhead and provides better quality of service in terms of end-to-end delay under link failures.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "155",
      "title": "A Hybrid Deep Learning Approach for Replay and DDoS Attack Detection in a Smart City",
      "abstract": "Today’s smart city infrastructure is predominantly dependant on Internet of Things (IoT) technologies. IoT technology essentially facilitates a platform for service automation through connections of heterogeneous objects via the Internet backbone. However, the security issues associated with IoT networks make smart city infrastructure vulnerable to cyber-attacks. For example, Distributed Denial of Service (DDoS) attack violates the authorization conditions in smart city infrastructure; whereas replay attack violates the authentication conditions in smart city infrastructure. Both attacks lead to physical disruption to smart city infrastructure, which may even lead to financial loss and/or loss of human lives. In this paper, a hybrid deep learning model is developed for detecting replay and DDoS attacks in a real life smart city platform. The performance of the proposed hybrid model is evaluated using real life smart city datasets (environmental, smart river and smart soil), where DDoS and replay attacks were simulated. The proposed model reported high accuracy rates: 98.37% for the environmental dataset, 98.13% for the smart river dataset, and 99.51% for the smart soil dataset. The results demonstrated an improved performance of the proposed model over other machine learning and deep learning models from the literature.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "156",
      "title": "Occlusion Handling and Multi-Scale Pedestrian Detection Based on Deep Learning: A Review",
      "abstract": "Pedestrian detection is an important branch of computer vision, and has important applications in the fields of autonomous driving, artificial intelligence and video surveillance. With the rapid development of deep learning and the proposal of large-scale datasets, pedestrian detection has reached a new stage and has achieved better performance. However, the performance of state-of-the-art methods is far behind expectations, especially when occlusion and scale variance exist. Therefore, many works focused on occlusion and scale variance have been proposed in the past few years. The purpose of this article is to make a detailed review of recent progress in pedestrian detection. First, a brief progress of pedestrian detection in the past two decades is summarized. Second, recent deep learning methods focusing on occlusion and scale variance are analyzed. Moreover, the popular datasets and evaluation methods for pedestrian detection are introduced. Finally, the development trends in pedestrian detection are discussed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "157",
      "title": "Pattern Matching Based on Object Graphs",
      "abstract": "Pattern matching has been widely adopted in functional programming languages, and is gradually getting popular in OO languages, from Scala to Python. The structural pattern matching currently in use has its foundation on algebraic data types from functional languages. To better reflect the pointer structures of OO programs, we propose a pattern matching extension to general statically typed OO languages based on object graphs. By this extension, we support patterns having aliasing and circular referencing, that are typically found in pointer structures. With the requirement of only an abstract subtyping preorder on types, our extension is not restricted to a particular hierarchical class model. We give the formal base of the graph model, that is able to handle aliases and cycles in patterns, together with the abstract syntax to construct the object graphs. More complex cases of conjunction and disjunction of multiple patterns are explored with resolution. We present the type checking rules and operational semantics to reason about the soundness by proving the type safety. We also discuss the design decisions, applicability and limitation of our pattern matching extension.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "158",
      "title": "Nondestructive Acoustic Testing of Ceramic Capacitors Using One-Class Support Vector Machine With Automated Hyperparameter Selection",
      "abstract": "The energy transition and electrification across many industries place increasingly more weight on the reliability of power electronics. A significant fraction of breakdowns in electronic devices result from capacitor failures. Multilayer ceramic capacitors, the most common capacitor type, are especially prone to mechanical damage, for instance, during the assembly of a printed circuit board. Such damage may dramatically shorten the life span of the component, eventually resulting in failure of the entire electronic device. Unfortunately, current electrical production line testing methods are often unable to reveal these types of damage. While recent studies have shown that acoustic measurements can provide information about the structural condition of a capacitor, reliable detection of damage from acoustic signals remains difficult. Although supervised machine learning classifiers have been proposed as a solution, they require a large training data set containing manually inspected damaged and intact capacitor samples. In this work, acoustic identification of damaged capacitors is demonstrated without a manually labeled data set. Accurate and robust classification is achieved by using a one-class support vector machine, a machine learning model trained solely on intact capacitors. Furthermore, a new algorithm for optimizing the classification performance of the model is presented. By the proposed approach, acoustic testing can be generalized to various capacitor sizes, making it a potential tool for production line testing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "159",
      "title": "A Cross-Disciplinary View of Testing and Bioinformatic Analysis of SARS-CoV-2 and Other Human Respiratory Viruses in Pandemic Settings",
      "abstract": "The SARS-Coronavirus-2 (SARS-CoV-2) infectious disease, COVID-19, has spread rapidly, resulting in a global pandemic with significant mortality. The combination of early diagnosis via rapid screening, contact tracing, social distancing and quarantine has helped to control the pandemic. The absence of real time response and diagnosis is a crucial technology shortfall and is a key reason why current contact tracing methods are inadequate to control spread. In contrast, current information technology combined with a new generation of near-real time tests offers consumer-engaged smartphone-based “lab-in-a-phone” internet-of-things (IoT) connected devices that provide increased pandemic monitoring. This review brings together key aspects required to create an entire global diagnostic ecosystem. Cross-disciplinary understanding and integration of both mechanisms and technologies for effective detection, incidence mapping and disease containment in near real-time is summarized. Available measures to monitor and/or sterilize surfaces, next-generation laboratory and smartphone-based diagnostic approaches can be brought together and networked for instant global monitoring that informs Public Health policy. Cloud-based analysis enabling real-time mapping will enable future pandemic control, drive the suppression and elimination of disease spread, saving millions of lives globally. A new paradigm is introduced – scaled and multiple diagnostics for mapping and spreading of a pandemic rather than traditional accumulation of individual measurements. This can do away with the need for ultra-precise and ultra-accurate analysis by taking mass measurements that can relax tolerances and build resilience through networked analytics and informatics, the basis for novel swarm diagnostics. These include addressing ethical standards, local, national and international collaborative engagement, multidisciplinary and analytical measurements and standards, and data handling and storage protocol...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "160",
      "title": "An Industry 4.0 Asset Administration Shell-Enabled Digital Solution for Robot-Based Manufacturing Systems",
      "abstract": "The increasing penetration of cyber-physical system (CPS) technologies in industry is transforming this environment into a multifaceted system featuring a tight combination of its physical and computational elements, including their digital (virtual) representations, contributing to the concept of an industrial CPS. The German “Industry 4.0” is a key innovation program aimed at realizing industrial CPS. Industry 4.0 is characterized by digital industrial components interacting with each other to become systems meeting flexible industrial demands, e.g., order-controlled production. An asset administration shell (AAS), as defined in the context of the Reference Architectural Model for Industry 4.0 (RAMI 4.0), is a practical embodiment of the latest buzzword, digital twin, and can be realized with the integration of operation technologies and information and communication technologies. AASs offer an interoperable way to capture key information pertaining to assets, such as intrinsic properties, operational parameters, and technical functionalities, and to enable straightforward interaction over standardized, secure communication with other Industry 4.0 components. The goal of this article is to present the status quo of AAS development, to design an intuitive method for implementing AASs, and to develop an AAS-enabled digital solution for cyber-physical applications in the manufacturing sector. Last but not least, we demonstrate a case study featuring an Industry 4.0 application scenario, i.e., plug-and-produce.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "161",
      "title": "High-Performance Time Series Prediction With Predictive Error Compensated Wavelet Neural Networks",
      "abstract": "Machine learning (ML) algorithms have gained prominence in time series prediction problems. Depending on the nature of the time series data, it can be difficult to build an accurate ML model with the proper structure and hyperparameters. In this study, we propose a predictive error compensation wavelet neural network model (PEC-WNN) for improving the prediction accuracy of chaotic and stochastic time series data. In the proposed model, an additional network is used for the prediction of the main network error to compensate the overall prediction error. The main network takes as inputs the time series data through moving frames in multiple-scales. The same structure and hyperparameter sets are applied for quite distinct four types of problems for verification of the robustness and accuracy of the proposed model. Specifically, the Mackey-Glass, Box-Jenkins, and Lorenz Attractor benchmark problems, as well as drought forecasting are used to characterize the performance of the model for chaotic and stochastic data cases. The results show that the PEC-WNN provides significantly more accurate predictions for all compared benchmark problems with respect to conventional machine learning and time series prediction methods without changing any hyperparameter or the structure. In addition, the time and space complexity of the PEC-WNN model is less than all other compared ML methods, including long short-term memory (LSTM) and convolutional neural networks (CNNs).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "162",
      "title": "IoTsecM: A UML/SysML Extension for Internet of Things Security Modeling",
      "abstract": "In this paper, an approach referred to as IoTsecM is proposed. This proposal is a UML/SysML extension for security requirements modeling within the analysis stage in a waterfall development life cycle in a Model-Based Systems Engineering Approach. IoTsecM allows the security requirements representation in two very well-known modeling languages, UML and SysML. With the utilization of this extension, IoT developers can consider the security requirements from the analysis stage in the design process of IoT systems. IoTsecM allows IoT systems to be designed considering possible threats and the corresponding security requirements analysis. The applicability of IoTsecM is demonstrated through applying it to analyze and represent the security requirements in an IoT real-life system in the context of collaborative autonomous vehicles in smart cities. In this use case, IoTsecM was able to represent the security requirements identified within the system architecture elements, in which all countermeasures identified were depicted using the proposed IoTsecM profile.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "163",
      "title": "Electrodynamics of Axial-Flow Rotary Blood Pumps",
      "abstract": "In this work, electric machine of implantable rotary blood pumps (RBPs) of axial-flow type was theoretically investigated. Electromagnetic coupling of rotor and stator in axial-flow RBPs was described with the Maxwell’s equations of the classical electrodynamics given quasi-magnetostatic approximation of electromagnetic field in the simplified model consisting of permanent magnet and conductive loop rotating in free space with one spatial degree of freedom. Additionally, relative field error, created by the neglect of geometric deviations introduced through manufacturing tolerances, was estimated for a typical axial-flow RBP. Upper limit of error introduced by the simplifications was estimated less than 0.2 %, leading to the finite accuracy of the description and clearly determining the influence on the control signal. Based on the presented description and additional engineering considerations, the electric machine of axial-flow RBPs was defined as a three-phase non-salient pole synchronous machine with a permanent magnet rotor. Two key features were shown: a) unlike the conventional electric motors, signal of back electromotive force tends to be a sinusoidal waveform in any construction of axial-flow RBP with significant non-magnetic gap; b) the optimal waveform of control signal in this case is sinusoidal. Initial design and control parameters of the electric machine in axial-flow RBPs can be accurately determined with presented theoretical description. Based on the description, control system of an axial-flow RBP with the optimal waveform of control signal can be developed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "164",
      "title": "An LSTM-Based Approach for Understanding Human Interactions Using Hybrid Feature Descriptors Over Depth Sensors",
      "abstract": "Over the past few years, automatic recognition of human interactions has drawn significant attention from researchers working in the field of Artificial Intelligence (AI). And feature extraction is one of the most critical tasks in developing efficient Human Interaction Recognition (HIR) systems. Moreover, recent researches in computer vision suggest that robust features lead to higher recognition accuracies. Hence, an improved HIR system has been proposed in this paper that combines 2D and 3D features extracted using machine learning and deep learning techniques. These discriminative features result in accurate classification and help avoid misclassification of similar interactions. Ten keyframes have been extracted from each video to reduce computational complexity. Next, these frames have been preprocessed using image normalization and noise removal techniques. The Region Of Interest (ROI), which contains the two humans involved in the interaction, has been extracted using motion detection. Then, the human silhouettes have been segmented using the GrabCut algorithm. Next, the extracted silhouettes have been converted into 3D meshes and their heat kernel signatures (HKS) have been obtained to extract key body points. A Convolutional Neural Network (CNN) has been used to extract full-body features from 2D full-body silhouettes. Then, topological and geometric features have been extracted from the key body points. Finally, the combined feature vector has been fed into Long Short-Term Memory (LSTM) and each interaction has been recognized using a Softmax classifier. The proposed system has been validated via extensive experimentation on three challenging RGB+D datasets. The recognition accuracies of 91.63%, 90.54%, and 90.13% have been achieved with the SBU Kinect Interaction, NTU RGB+D, and ISR-UoL 3D social activity datasets respectively. The results of extensive experiments performed on the proposed system suggest that it can be used effectively for various applic...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "165",
      "title": "Dynamic Metric Accelerated Method for Fuzzy Clustering",
      "abstract": "Features in data samples usually need a unified dimension by a standardization process before clustering. However, there still exists a non-standardized metric in which the distance between samples is greater than 1 after features are standardized. It is difficult to find the optimal search path if the data sample metrics are not standardized. To address this problem, we develop a dynamic-metric accelerated method for fuzzy clustering by introducing a metric matrix, whose diagonal elements consist of infinite norms of the metric matrix into the Fuzzy C-Means (FCM) clustering algorithm and its derived algorithms. More specifically, we focus on constructing a dynamic metric matrix that is used to unify the metric between data samples and updating cluster centers to optimize the search path of the cluster center. In addition, we propose a new evaluation index named the Coefficient of Variation Metric (CVM) to evaluate metric effectiveness. The dynamic metric accelerated method, whose complexity remains unchanged, can effectively accelerate the iteration speed of fuzzy clustering. The comparisons between the algorithm using the dynamic metric accelerated method and the corresponding algorithm on UCI, business district and COVID-19 CT image datasets show the superiority of the dynamic metric accelerated method in accelerating effect and clustering performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "166",
      "title": "CNN-Based Object Recognition and Tracking System to Assist Visually Impaired People",
      "abstract": "Visually impaired persons (VIPs) comprise a significant portion of the population, and they are present around the globe and in every part of the world. In recent times, technology proved its presence in every domain, and innovative devices assist humans in their daily lives. In this work, a smart and intelligent system is designed for VIPs to assist mobility and ensure their safety. The proposed system provides navigation in real-time using an automated voice. Though VIPs wouldn’t be able to see objects in their surroundings, they can sense and visualize the roaming environment. Moreover, a web-based application is developed to ensure their safety. The user of this application can turn the on-demand function for sharing his/her location with the family while compromising privacy. Through this application, the family members of VIPs would be able to track their movement (get location and snapshots) while being at their homes. Hence, the device allows VIPs to visualize the environment and ensure their security. Such a comprehensive device was a missing link in the existing literature. The application uses MobileNet architecture due to its low computational complexity to run on low-power end devices. To assess the efficacy of the proposed system, six pilot studies have been performed that reflected satisfactory results. For object detection and recognition, a deep Convolution Neural Network (CNN) model is employed with an accuracy of 83.3%, whereas the dataset contains more than 1000 categories. Moreover, a score-based quantitative comparative analysis is performed using the supported features of devices. It is found that the proposed system has outperformed the existing devices having a total score of 9.1/10, which is 8% higher than the second-best.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "167",
      "title": "A Two-Dimensional Sparse Matrix Profile DenseNet for COVID-19 Diagnosis Using Chest CT Images",
      "abstract": "COVID-19 is a newly identified disease, which is very contagious and has been rapidly spreading across different countries around the world, calling for rapid and accurate diagnosis tools. Chest CT imaging has been widely used in clinical practice for disease diagnosis, but image reading is still a time-consuming work. We aim to integrate an image preprocessing technology for anomaly detection with supervised deep learning for chest CT imaging-based COVID-19 diagnosis. In this study, a matrix profile technique was introduced to CT image anomaly detection in two levels. At one-dimensional level, CT images were simply flatted and transformed to a one-dimensional vector so that the matrix profile algorithm could be implemented for them directly. At two-dimensional level,a matrix profile was calculated in a sliding window way for every segment in the image. An anomaly severity score (CT-SS) was calculated, and the difference of the CT-SS between the COVID-19 CT images and Non-COVID-19 CT images was tested. A sparse anomaly mask was calculated and applied to penalize the pixel values of each image. The anomaly weighted images were then used to train standard DenseNet deep learning models to distinguish the COVID-19 CT from Non-COVID-19 CT images. A VGG19 model was used as a baseline model for comparison. Although extra finetuning needs to be done manually, the one-dimensional matrix profile method could identify the anomalies successfully. Using the two-dimensional matrix profiling method, CT-SS and anomaly weighted image can be successfully generated for each image. The CT-SS significantly differed among the COVID-19 CT images and Non-COVID-19 CT images (p−value<;0.05p-value <; 0.05 ). Furthermore, we identified a potential causal association between the number of underlying diseases of a COVID-19 patient and the severity of the disease through statistical mediation analysis. Compared to the raw images, the anomaly weighted images showed generally better performance in training th...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "168",
      "title": "Attention Guided Encoder-Decoder Network With Multi-Scale Context Aggregation for Land Cover Segmentation",
      "abstract": "Land cover segmentation is an important and challenging task in the field of remote sensing. Even though convolutional neural networks (CNNs) provide great support for semantic segmentation, standard models are still difficult to capture global information and long-range dependencies in remote sensing images. To overcome these limitations, we proposed an attention guided encoder-decoder network with multi-scale context aggregation to achieve more accurate segmentation of land cover. Based on the structure of the encoder-decoder network, we introduce a multi-scale feature fusion module with two attention modules to the top of the encoder. The multi-scale feature fusion module is employed to aggregate multi-scale features and capture global correlations. The attention modules are used to exploit the long-range dependencies and the interdependence between channels from the perspective of space and channel respectively. The experimental results on the GF-2 images show that our proposed method achieves state-of-the-art performance, with an OA of 84.1% and the mIoU of 62.3%. Compared with the baseline network, our method improves the OA by 3.3% and the mIoU by 4.4%. The comparative experiments also demonstrate that the proposed approach can significantly improve the accuracy of land cover segmentation than other compared methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "169",
      "title": "Towards Reinforcing Healthcare 4.0: A Green Real-Time IIoT Scheduling and Nesting Architecture for COVID-19 Large-Scale 3D Printing Tasks",
      "abstract": "With declaring the highly transmissible COVID-19 as a pandemic, an unprecedented strain on healthcare infrastructures worldwide occurred. An enormous shortage in the personal protective equipment (PPE) and the spare parts (SP) for the mechanical ventilators ensued as a consequence of the failure of the centralized global supply chains. Additive manufacturing and Industrial Internet of Things (IIoT), as the pillars of Industry 4.0, arose as the robust noncentralized alternatives. When gathered and properly managed in the IIoT, 3D Printers (3DPs) can complement and support Healthcare 4.0 to face the current and future pandemics. Thus, this paper proposes a real-time green allocation and scheduling architecture designed and dedicated particularly for the large-scale distributed 3D printing tasks (3DPTs) of both PPE and SPs. Our proposed architecture comprises; a broker (B) and a cluster manager (CM). Dynamic status check for the 3DPs and admission control for 3DPTs are among the interconnected roles of CM. CM also performs task allocation and scheduling according to our proposed Online Ascending Load-Balancing Modified Best-Fit (OALMBF) allocation algorithm and Green Real-time Nesting Priority-Based Adaptive (GRNPA) scheduling algorithm. The performance of the proposed architecture was investigated under extremely high-load environments which resulted in a success ratio and a response rate of 99.9667% and 10.9665 seconds, respectively, for the 3000 3DPTs trial. These results proved the robustness and the scalability of our architecture that surpasses its state-of-the-art counterparts. Besides respecting the real-time requirements of the 3DPTs, the proposed architecture improves the utilization of the 3DPs and guarantees an even workload distribution.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "170",
      "title": "Research on Optimization of Portrait Sculpture Data Based on 3D Image and Mobile Edge Computing",
      "abstract": "The traditional method of making portrait sculptures is hand-carving. The quality of sculpture is unstable, which mainly depends on the technical level of the sculptor. With the development of multi-coordinate numerical control processing technology and computer three-dimensional modeling technology, a new method of designing and making portrait sculptures has emerged. In order to improve the quality of sculpture and overcome the shortcomings of the existing scheme, a new optimization method for portrait sculpture data is proposed by combining mobile edge computing and 3D images. The paper first analyzes the existing portrait data collection methods based on 3D scanning and image reconstruction, and draws out the blind spots in the application of the existing data collection methods to the collection of portrait sculpture data. A method for data collection of portrait sculpture based on feature description is proposed. After determining the data optimization method, a portrait sculpture data optimization architecture is constructed through mobile edge computing technology. In order to verify the applicability of the method, the multi-angle and multi-dimensional simulation training test results show the efficiency and scalability of the realized sculpture data optimization method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "171",
      "title": "Deep Reinforcement Learning for Guidewire Navigation in Coronary Artery Phantom",
      "abstract": "In percutaneous intervention for treatment of coronary plaques, guidewire navigation is a primary procedure for stent delivery. Steering a flexible guidewire within coronary arteries requires considerable training, and the non-linearity between the control operation and the movement of the guidewire makes precise manipulation difficult. Here, we introduce a deep reinforcement learning (RL) framework for autonomous guidewire navigation in a robot-assisted coronary intervention. Using Rainbow, a segment-wise learning approach is applied to determine how best to accelerate training using human demonstrations, transfer learning, and weight initialization. ‘State’ for RL is customized as a focus window near the guidewire tip, and subgoals are placed to mitigate a sparse reward problem. The RL agent improves performance, eventually enabling the guidewire to reach all valid targets in ‘stable’ phase. For the last 300 out of 1000 episodes, the success rates of the guidewire navigation to the distal-main and side targets were 98% and 99% in 2D and 3D phantoms, respectively. Our framework opens a new direction in the automation of robot-assisted intervention, providing guidance on RL in physical spaces involving mechanical fatigue.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "172",
      "title": "A Model Predictive Control Strategy for Performance Improvement of Hybrid Energy Storage Systems in DC Microgrids",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "173",
      "title": "A Graph Convolution Network-Based Bug Triage System to Learn Heterogeneous Graph Representation of Bug Reports",
      "abstract": "Many bugs and defects occur during software testing and maintenance. These bugs should be resolved as soon as possible, to improve software quality. However, bug triage aims to solve these bugs by assigning the reported bugs to an appropriate developer or list of developers. It is an arduous task for a human triager to assign an appropriate developer to a bug report, when there are several developers with different skills, and several automated and semi-automated triage systems have been proposed in the last decade. Some recent techniques have suggested possibilities for the development of an effective triage system. However, these techniques require improvement. In previous work, we proposed a heterogeneous graph representation for bug triage, using word–word edges and word-bug document co-occurrences to build a heterogeneous graph of bug data. Cosine similarity is used to weight the word–word edges. Then, a graph convolution network is used to learn a heterogeneous graph representation. This paper extends our previous work by adopting different similarity metrics and correlation metrics for weighting word–word edges. The method was validated using different small and large datasets obtained from large-scale open-source projects. The top-k accuracy metric was used to evaluate the performance of the bug triage system. The experimental results showed that the point-wise mutual information of the proposed model was better than that of other word–word weighting methods, and our method had better accuracy for large datasets than other recent state-of-the-art methods. The proposed method with point-wise mutual information showed 3% to 6% higher top-1 accuracy than state-of-the-art methods for large datasets.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "174",
      "title": "Pollution Flashover Voltage of Transmission Line Insulators: Systematic Review of Experimental Works",
      "abstract": "Over the past decades, extensive experimental-based research works have been carried out to investigate the flashover phenomenon on the performance of polluted transmission line insulators. The critical focus has been on developing methods that can determine the safety, reliability, and sustainability of the overall power transmission network based on experimental results obtained from polluted insulators’ flashover voltage tests. In this paper, a systematic review of available scientific works, published as early as the 1990s, for the analysis of pollution flashover voltage, is undertaken. The review mainly focuses on factors influencing the efficiency of transmission line insulators under polluted conditions. Specifically, publication databases utilizing various synonyms and keywords associated with the terms “contaminated insulators” and “flashover voltage test” have been scrutinized. The search has resulted in 1364 articles, from which 97 articles have satisfied the review requirements and have been subsequently analyzed to determine the parameters associated with polluted insulators. Major factors that affect the performance of insulators, including electrical and environmental impacts, are discussed. Variations in factors affecting flashover test development and insulator efficiency are also considered. Overall, the current analysis provides an important insight toward successful evaluations of the health of transmission line insulators and research advancements of electric power transmission line insulators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "175",
      "title": "Automated Heart Valve Disorder Detection Based on PDF Modeling of Formant Variation Pattern in PCG Signal",
      "abstract": "Heart valve disorder (HVD) analysis from heart sound is being well known for a long period of time, and use of digital stethoscope gives opportunity to diagnose HVDs from phonocardiographic (PCG) signal. An automated HVD detection technique from PCG signal can play a key role as a first-hand diagnostic tool for the physicians. In this paper, in order to classify different HVDs, we propose to utilize the formant characteristic of the PCG signal, which is an acoustic property of the heart sound. PCG signals exhibit significant variations depending on different types of HVDs and thus conventional time frequency domain features or statistical features are extracted from PCG signal for disease classification. However, direct PCG signals are also used in sequential networks to classify HVDs. Similar to the formant peaks of voiced speech signal, the spectrum corresponding to the PCG signal exhibits distinguishable peaks, especially in the voiced part of the heart sound (lub-dub). Keeping this notable key point in consideration, Burg’s autoregressive model is used to find the parametric spectrum of the PCG signal. The first two formants of the PCG signal, that carry the most informative acoustic properties of the heart sound, are estimated from the Burg’s spectrum, and are used for feature extraction. The magnitude, frequency and phase of each formant are considered to evaluate these features. Instead of considering a long duration of PCG signal at a time, we consider the overlapping sub-frames, and extract formants from each sub-frame, which generates a temporal variation of the formants. Finally, we propose a PDF model fitting of the formant variation, and utilize the estimated model parameters along with some statistical features to classify the HVDs. Two famous publicly available PCG datasets are used to demonstrate the performance of the proposed method, that efficiently classify the binary/five classes of heart sounds. The results reveal that the proposed method has t...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "176",
      "title": "Bi-Level Programming Model and Algorithm for VNF Deployment With Data Centers Placement",
      "abstract": "Virtual network function (VNF) can provide various network services and is widely deployed in inter-data centers elastic optical networks (Inter-DC EONs). Routing and VNF deployment for VNF service chain (VNF-SC) in Inter-DC EONs is a very important and well-known NP-hard problem. For this problem, if determining the number and locations of data centers is additionally considered, it will be more complicated. In this paper, we investigate a network planning problem in Inter-DC EONs by determining all these factors, i.e, by determining not only the optimal routing and the optimal VNF deployment for VNF-SCs, but also the optimal number and locations of data centers. To achieve this purpose, we first establish a bi-level programming model in which the leader's objective is to minimize the number of data centers and find the best locations of data centers so that we can get a balanced VNF deployment on data centers. To determine the optimal routing and VNF deployment for VNF-SCs, the follower's objective is to minimize the maximum index of used frequency slots and the number of used frequency slots. Then, to solve the proposed model effectively, tailor-made crossover, mutation and local search operators are designed, and based on these operators, an efficient bi-level hybrid memetic algorithm (BiHMA) is proposed. Finally, to test the effectiveness of the proposed model and the efficiency of the proposed algorithm, the simulation experiments are conducted on two widely used networks, and experimental results indicate that the proposed algorithm has a higher efficiency than compared algorithms.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "177",
      "title": "Design of a Low Profile Flexible Tri-Band Frequency Surface Applied in X-Band, K-Band and Millimeter-Band",
      "abstract": "A low profile flexible miniaturized tri-band frequency surface is proposed by cascading three layers of periodic arrays. The top and bottom layers have the same square patch structure embedded in the bending gap, whereas the middle layer has an interlaced metal grid structure. The medium between each layer is made of flexible polyimide material with a thickness of only about 0.2mm. The coupling of the three metal layers gives rise to a first X-band passband, with a central frequency of 10.6 GHz. The interlaced metal grid structure generates a second K-band passband, with a central frequency of 24.1GHz. The two-layer symmetrical planar cascade structure produces double-peak resonances at 39.4 GHz and 46.2 GHz, forming a third millimeter-wave passband. Compared with the traditional tri-band FSSs, due to the combination of bending technology and multi-screen cascade technology, the reported structure generates the first and second passbands with miniaturization and good angle stability, and the third passband with rectangular filtering characteristics. Besides fabrication and tests, the corresponding equivalent circuit model is also established in order to analyze the transmission characteristics. The test results are well compatible with the simulation results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "178",
      "title": "Design and Multi-Objective Optimization of a Dexterous Mobile Parallel Mechanism for Fusion Reactor Vacuum Vessel Assembly",
      "abstract": "The present paper presents a newly designed dexterous mobile parallel mechanism for fusion reactor vacuum vessel assembly, the robot system has advantages in terms of compact design, the capability to carry out heavy-duty machining tasks, evacuation, and has less space occupation compared to other robot systems in existence. Despite different robot systems are studied in the fusion reactor, there is still a lack of research on mechanism development for vacuum vessel assembly, which is attractive to future fusion reactors. In the fusion reactor, the robot systems will carry out different tasks, such as welding and machining. The assembly tasks of the vacuum vessel will be performed from inside of the vacuum vessel on-site. Then the paper introduces the single-objective and multi-objective optimization design of the proposed mechanism, the optimized objective is considered to be a combination of parallel mechanism dynamic machining force, dexterity, stiffness, and workspace volume. The design variables are derived from the geometry of the fixed and movable platforms, which include mass, inertia, the sizes of the platforms, and distances between universal joints located on the platforms. In the multi-objective optimization, non-dominated sorting genetic algorithm II is adopted and different trajectories are designed to simulate the machining process, which further turns the local optimization problem into a global optimization problem. Finally, the optimized results are extracted and analyzed. Simulation results indicate the effectiveness of the proposed multi-objective optimization approaches and multi-objective optimization is found to be more reliable than single-objective optimization.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "179",
      "title": "State Estimation Approach of Lithium-Ion Batteries by Simplified Ultrasonic Time-of-Flight Measurement",
      "abstract": "This work presents an approach to monitoring the State-Of-Charge of Lithium-Ion battery cells via piezo disc-based ultrasonic Time-Of-Flight measurement by measuring the traveling time of a mechanical pulse through the cell between two surface-mounted sensors. The main advantage of this approach is the simplicity and the resulting low cost, which makes it suitable for future application in battery management systems. In detail, the excitation of the piezo actuator is done using a single semiconductor switch instead of a power amplifier, and the received signal is processed with an amplifier and Schmitt-trigger combination to condition the signal for the microprocessor, which is part of a battery management system. Both the functionality and the limits of the design are evaluated with a high energy density Lithium-Ion pouch cell under different operational scenarios. Several parameters such as temperature, current rates, and excitation frequency are varied to prove the design concept. For validation purposes, an estimation function is generated and a real-world driving cycle applied. An estimation with an error of 1.29% of the Time-Of-Flight total value or 16.85% of the State-Of-Charge value under challenging conditions is achieved with the current setup.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "180",
      "title": "Multistage Centrifugal Pump Fault Diagnosis by Selecting Fault Characteristic Modes of Vibration and Using Pearson Linear Discriminant Analysis",
      "abstract": "This paper proposes a three-stage fault diagnosis strategy for multistage centrifugal pumps. First, the proposed method identifies and selects fault characteristic modes of vibration to overcome the substantial noise produced by other unrelated macro-structural vibrations. In the second stage, raw hybrid statistical features are extracted from the fault characteristic modes of vibration in time, frequency, and the time-frequency domain. These extracted features result in a high-dimensional feature space. However, in general, not all of the features are best to characterize the ongoing processes in a centrifugal pump, and some of the extracted features might be irrelevant or even redundant, which can affect the fault classification capabilities of the classification algorithm. In the third stage, a novel dimensionality reduction technique, called Pearson Linear Discriminant Analysis (PLDA), is introduced. PLDA assesses the helpfulness of the feature parameters. This technique selects highly interclass-correlated features and adds them to a helpful feature pool. To achieve maximum intraclass separation while maintaining the original class information, linear discriminant analysis is then applied to the helpful feature pool. This combination of helpful feature pool formation and linear discriminant analysis forms the proposed application of PLDA. The reduced discriminant feature set obtained from PLDA is then classified using the k-nearest neighbor classification algorithm. The proposed method outperforms the previously presented methods in terms of classification accuracy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "181",
      "title": "Indexing and Search of Order-Preserving Submatrix for Gene Expression Data",
      "abstract": "Bicluster pattern discovery plays a key role in analysis of gene expression data. One vital model of bicluster mining is Order-Preserving SubMatrix (OPSM), which finds similar tendency of some genes on some conditions. Most of the OPSM discovery methods are batch mining techniques and not suitable for low latency data query. To make data analysis efficient and effective, in this paper, we first propose a prefix-tree based indexing method pfTree, then give an optimization technique pIndex that employs row and column header tables to search the positive, negative and time-delayed OPSMs. Meanwhile, we present an online sharing query technique to accelerate the frequent searches. Finally, we conduct extensive experiments and compare our methods with the existing approaches. Experimental results demonstrate the efficiency and effectiveness of the proposed methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "182",
      "title": "IEEE Access Special Section: Sequential Data Modeling and Its Emerging Applications",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "183",
      "title": "Electrical Energy Prediction of Combined Cycle Power Plant Using Gradient Boosted Generalized Additive Model",
      "abstract": "A combined cycle power plant (CCPP) employs gas and steam turbines to generate 50% more power while utilizing the same fuel as a normal single cycle plant. The performance of a CCPP under full load is affected by a variety of factors such as weather, process interactions, and coupling, which makes it challenging to operate. Therefore, a reliable assessment of the maximum output power of a CCPP is required to improve plant reliability and monetary performance. In this paper, a predictive model based on a generalized additive model (GAM) is proposed for the electrical power prediction of a CCPP at full load. In GAM, a boosted tree and gradient boosting algorithm are considered as shape function and learning technique for modeling a non-linear relationship between input and output attributes. Furthermore, predictive models based on linear regression (LR), Gaussian process regression (GPR), multilayer perceptron neural network (MLP), support vector regression (SVR), decision tree (DT), and bootstrap-aggregated tree (BBT) are also designed for comparison purposes. Results reveal that GAM improves the RMSE by 74%, 68.8%, 70.3%, 54.8%, 21.2%, and 17.3% compared to LR, GPR, MLP, SVR, DT, and BBT, respectively. Furthermore, the results of the Man-Whitney U test and rank analysis also confirm the effectiveness of GAM for energy prediction of CCPP. Finally, it can be concluded that the proposed method is effective, robust, and accurate for the assessment of the maximum output power of a CCPP to improve plant consistency and financial performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "184",
      "title": "An Efficient Implementation of Online Model Predictive Control With Field Weakening Operation in Surface Mounted PMSM",
      "abstract": "Model-predictive-controller (MPC), one of the optimal control policies, has gained more attention in servo drive and other industrial applications in recent years due to evident control performance benefits compared to more classical control methods. However, an MPC algorithm solves a constrained optimization problem at each step that brings a substantial computational burden over classical control policies. This study focuses on improving the computational efficiency of an online MPC algorithm and then demonstrates its practical feasibility on the field weakening operation in high-speed PMSM control applications where the sampling frequency is in the order of \n \\mu sμs\\mu s \n. We implement the existing dual active set solver by replacing two standard methods in the matrix update step to reduce the overall computational cost of the algorithm. We also rearrange the linear approximation for the constraints on voltage and current by taking the tradeoff between accuracy and speed into account. We finally verify the efficiency and effectiveness of the proposed structure via processor-in-the-loop simulations and physical platform experiments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "185",
      "title": "Low Complexity Correlation Power Analysis by Combining Power Trace Biasing and Correlation Distribution Techniques",
      "abstract": "Side channel attack (SCA) is a class of crypt-analytic attacks for security evaluation of cryptographic and embedded microprocessor implementations. Among several SCA approaches, the correlation power analysis (CPA) is an efficient way to recover the secret key of the specific cryptographic algorithms running on the target devices such as embedded microprocessors. However, the evaluation process is time-consuming since a large number of traces are required to overcome the impact of noise. Hence, this paper proposes new methods to reduce the computation time by using Point of Interest (POI) extractor with the power trace biasing technique and the correlation distribution for the low complexity correlation power analysis (CPA). The theoretical explanations are provided and the experiments on different platforms such as ASCAD and RISC-V processor based databases are conducted to justify the proposed techniques. Especially, our experiments are performed with different protected schemes such as masking, hiding and combined hiding-masking techniques. The experimental results indicate that our proposed methods provide reliable results in comparison with the standard CPA. By using only a half of the power traces for taking the POIs, our first proposal not only decreases the execution time approximately by half but also enhances the success rate of the attack. Moreover, the second method based on power trace biasing technique is proposed in order to achieve better results and reduce the number of traces needed for selecting the POIs. With only 28.9% of given power traces needed, our second proposed technique reduces the execution time to only 2.6 times of the standard CPA.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "186",
      "title": "Hybrid Stochastic Ranking for Constrained Optimization",
      "abstract": "Teaching learning based optimization (TLBO) algorithm is a distinguished nature-inspired population-based meta-heuristic, which is basically designed for unconstrained optimization. TLBO mimics teaching learning process through which learners acquire knowledge from their teachers, and improve their results/grades, accordingly. Stochastic ranking (SR) is a constrained handling technique (CHT), which produces greediness among solutions to improve their fitness values and feasibility. Violation constraint handling (VCH) technique produces more feasibility among the existing superiority of feasibility CHTs due to its additional factor of ranking based on the number of constraints violated (NCV). This work brings in a new variant of SR, namely hybrid stochastic ranking (HSR), which combines SR and VCH. For constrained optimization, the integration of some CHT with TLBO is essential. In this paper, HSR is integrated with TLBO and a new constrained version of TLBO called HSR-TLBO is designed. The efficiency of HSR-TLBO is checked on constrained test functions of the suit CEC 2017. The experimental results show that HSR-TLBO got prominent position when compared and ranked with the top four papers and our two newly designed constrained variants of TLBO, MSR-TLBO and MVCH-TLBO, based on the provided budget and ranking criteria of the mentioned suit.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "187",
      "title": "Feature Selection of Input Variables for Intelligence Joint Moment Prediction Based on Binary Particle Swarm Optimization",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "188",
      "title": "Audio Watermarking for Security and Non-Security Applications",
      "abstract": "The digitization of audiovisual data is significantly increasing. Thus, to guarantee the protection of the intellectual properties of this digital content, watermarking has appeared as a solution. Watermarking can be used in reality in several types of applications that target two different contexts: the first for security applications and the second for non-security ones. In this paper, we carry a big interest in studying these two types of applications. Moreover, we propose a first digital watermarking scheme for security copyright protection applications, where we have involved neural network architecture in the insertion and detection processes, and integrated some masking phenomena of the human psychoacoustic model with linear predictive coding spectral envelope estimation of the audio file. Experiments proved the efficiency of exploiting perceptual masking with spectral envelope consideration in terms of imperceptibility and robustness results. In addition, we suggest a second audio watermarking technique for non-security content characterization applications based on a deep learning classification architecture. In this scheme, the extracted watermark advises about the audio class: music or speech, speaker gender, and emotion. The reported results indicated that the suggested scheme achieved a higher performance at the classification level, as well as at the watermarking properties.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "189",
      "title": "A Novel Machine Learning-Based Load-Adaptive Power Supply System for Improved Energy Efficiency in Datacenters",
      "abstract": "Power Supplies are a key part of the modern Internet and Communications Technologies (ICT) industry. Modern Uninterruptible Power Supply (UPS) systems are modular and as such, consist of several Power Supply Units (PSUs). Even though various PSU designs are used to optimize operation efficiency at specific loading conditions they engender inefficient operation at other loading conditions. In order to optimize the energy efficiency in various loading conditions, this paper proposes a novel power supply multiplexing system engaging different combinations of PSUs which are controlled through machine learning techniques to maximize efficiency depending on the loading conditions. Each PSU combination is given a state number. Due to the vast number of combinations (states) that can occur in such systems and redundancy requirements, machine learning techniques are proposed. It is shown that by using the proposed novel system, an efficiency improvement of over 78% can be achieved in low loading conditions and an average 5.23% in all loading conditions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "190",
      "title": "Acoustic Enhanced Camera Tracking System Based on Small-Aperture MEMS Microphone Array",
      "abstract": "The camera tracking systems based on visual image processing face a problem that they are completely ineffective in their blind zones. To address this problem, a design of acoustic enhanced tracking system combining visual and auditory target tracking methods is reported in this article. The system holds the abilities of performing sound direction estimation and target tracking in real-time. Estimating direction of arrival of the sound accompanied with the target helps the camera turn towards the target outside the field of view. This sound-triggered mode of camera operation makes a significant supplement to conventional cameras' working state. Considering the embedded system is necessary in consideration of the cost and size of the system in practical application, we designed a small aperture array with 7 digital omnidirectional MEMS microphones and built the overall system based on FPGA and ARM. The experiments were carried out in a normal indoor environment and the results confirmed that the system can perform auditory and visual tracking in real-time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "191",
      "title": "Trapdoor Privacy in Public Key Encryption With Keyword Search: A Review",
      "abstract": "The public key encryption with keyword search (PEKS) scheme allows searches to be performed over ciphertext by a server in a public-key setting. The PEKS scheme suffers from a major drawback which is keyword guessing attack. A keyword guessing attack (KGA) allows the attacker to successfully guess the correct keyword encrypted in a searchable ciphertext and trapdoor. To overcome this vulnerability, security notions, such as keyword privacy and trapdoor privacy were introduced. Keyword privacy prevents any information leaked from the keyword itself, and similarly trapdoor privacy prevents any information leaked from the trapdoor side. A PEKS scheme that is secure against KGA should satisfy trapdoor privacy. In this paper, we compare various types of PEKS schemes in terms of their underlying computational hardness, system model, search function, security properties of keyword privacy and trapdoor privacy, and security against offline KGA and online KGA. From the comparison analysis, we highlight that trapdoor privacy and keyword privacy are essential for a PEKS scheme to be secure against KGA. Lastly, we draw some potential research directions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "192",
      "title": "A Survey on Event Extraction for Natural Language Understanding: Riding the Biomedical Literature Wave",
      "abstract": "Motivation:\n The scientific literature embeds an enormous amount of relational knowledge, encompassing interactions between biomedical entities, like proteins, drugs, and symptoms. To cope with the ever-increasing number of publications, researchers are experiencing a surge of interest in extracting valuable, structured, concise, and unambiguous information from plain texts. With the development of deep learning, the granularity of information extraction is evolving from entities and pairwise relations to events. Events can model complex interactions involving multiple participants having a specific semantic role, also handling nested and overlapping definitions. After being studied for years, automatic event extraction is on the road to significantly impact biology in a wide range of applications, from knowledge base enrichment to the formulation of new research hypotheses. \nResults:\n This paper provides a comprehensive and up-to-date survey on the link between event extraction and natural language understanding, focusing on the biomedical domain. First, we establish a flexible event definition, summarizing the terminological efforts conducted in various areas. Second, we present the event extraction task, the related challenges, and the available annotated corpora. Third, we deeply explore the most representative methods and present an analysis of the current state-of-the-art, accompanied by performance discussion. To help researchers navigate the avalanche of event extraction works, we provide a detailed taxonomy for classifying the contributions proposed by the community. Fourth, we compare solutions applied in biomedicine with those evaluated in other domains, identifying research opportunities and providing insights for strategies not yet explored. Finally, we discuss applications and our envisions about future perspectives, moving the needle on explainability and knowledge injection.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "193",
      "title": "A Hybrid Algorithm for Recognition of Power Quality Disturbances",
      "abstract": "An algorithm making use of hybrid features of Hilbert transform (HT) and Stockwell transform (ST) to identify the single-stage and multiple (multi-stage) power quality disturbances (PQDs) is introduced in this manuscript. A power quality index (PI) and time location index (TLI), based on the features computed from the voltage signal by the use of HT and ST are proposed for recognition of the PQDs. Four features extracted from the PI and TLI are considered for classification of the PQDs achieved using decision tree driven by rules. The algorithm is tested on the PQDs generated with the help of mathematical models (in conformity with standard IEEE-1159). Performance is evaluated on 100 data set of every disturbance computed by varying various parameters, and efficiency is found to be greater than 99%. It is established that an algorithm is effective for recognition of PQ events with an efficiency greater than 98% even in the presence of high-level noise. Algorithm is faster compared to many reported techniques and scalable for application to voltages of all range. Results are validated through comparison with the results of the algorithms reported in the literature. Performance of the algorithm is effectively validated on the practical utility network. This algorithm can be effectively implemented for designing the power quality (PQ) monitoring devices for the utility grids.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "194",
      "title": "A Novel Control Method to Improve Current Regulation and Harmonics in Navigation Dimming Power Supply",
      "abstract": "Regulating the output current and reducing the harmonic distortion are key control problems in the airport navigation dimming power supply (DPS). In this study, a new method which could dynamically adjust P and I gains is presented for the DPS based on the radial basis function (RBF) neural networks combined with the gradient descent method. To implement the proposed method, the key factors which influence the performance of DPS are revealed by analyzing the dynamic response of the control system. The controller design process is presented in detail along with a system stability analysis. The correctness of theoretical derivation is examined through extensive digital computer simulation analyses in MATLAB while the comparative analysis is carried out under different operation conditions through experiments in a 30kW experimental prototype. The results indicate that the DPS adopting the method proposed in this paper could obtain better dynamic response and less harmonic content in various complex working conditions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "195",
      "title": "Spectral and Energy Efficiency of Hybrid Precoding for mmWave Massive MIMO With Low-Resolution ADCs/DACs",
      "abstract": "In this paper, we investigate the spectral efficiency (SE) and energy efficiency (EE) of hybrid precoding in the point-to-point mmWave massive multiple-input multiple-output (MIMO) system with low-resolution analog-to-digital converters (ADCs) and digital-to-analog converters (DACs). First, considering the quantization noise of ADCs/DACs, an approximation expression for the SE is derived. Then, in order to solve the problem of non-convex hybrid precoding design, based on the derived analytical approximation expression, we propose a two-stage alternating minimization scheme to obtain the optimal hybrid precoder matrix. And the trade-offs between SE and EE with the full digital precoding and hybrid precoding are investigated. Numerical results verify that the system with the proposed scheme has nearly the same SE performance as with the full digital precoding. The fully connected hybrid precoding can be more energy-efficient compared to the full digital precoding, and the proposed hybrid precoding scheme can achieve the better trade-off between the SE and EE. Moreover, the increase in the resolution of ADCs/DACs can effectively improve the SE performance of the system, and 4-bits ADCs/DACs achieve the best EE performance for the hybrid precoding.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "196",
      "title": "Comparative Study of Optimum Medical Diagnosis of Human Heart Disease Using Machine Learning Technique With and Without Sequential Feature Selection",
      "abstract": "Predicting heart disease is regarded as one of the most difficult challenges in the health-care profession. To predict cardiac disease, researchers employed a variety of algorithms including LDA, RF, GBC, DT, SVM, and KNN, as well as the feature selection algorithm sequential feature selection. For verification, the system employs the K-fold cross-validation approach. These six strategies were used to conduct the comparative study. The Dataset for Cleveland, Hungray, Switzerland, and Long Beach V, as well as the Dataset Heart Statlog Cleveland Hungary, were used to assess the models performance. For both Hungary, Switzerland & Long Beach V and Heart Statlog Cleveland Hungary Dataset, Random Forest Classifier sfs and Decision Tree Classifier sfs produced the highest and almost identical accuracy values (100%, 99.40% and 100%, 99.76% respectively). The findings were compared to previous research that focused on cardiac prediction. In the future, we hope to extend the model even further so that it may be used with various feature selection techniques; another possibility is to use a random forest classifier. The major goal of this study is to improve on previous work by developing a new and unique technique for creating the model, as well as to make the model relevant and easy to use in real-world situations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "197",
      "title": "Prediction of the Remaining Useful Life of Lithium-Ion Batteries Based on Dempster-Shafer Theory and the Support Vector Regression-Particle Filter",
      "abstract": "Lithium-ion batteries (LIBs) have been widely used in various electronic equipment. The development of an effective method for predicting the remaining useful life (RUL) of LIBs can ensure the normal operation of equipment by providing an appropriate warning before the battery fails. This study presents a method for predicting the RUL of LIBs based on Dempster-Shafer theory (DST) and the support vector regression-particle filter (SVR-PF), which improves the prediction accuracy when the available data are relatively sparse. The model of LIB RUL prediction based on DST and SVR-PF was developed and proposed based on a DST algorithm and the central limit theorem. Moreover, this study proposes an approach to update the basic probability assignment (BPA) of DST, which represents the confidence of the prediction, at each iteration during the RUL prediction. The updated BPA at each iteration will increase the importance of the high confidence prediction method in the combined results. Thus, it will provide a more accurate prediction result. The proposed method can also be used as a framework to combine the prediction results obtained from various independent data. The simulation results and the comparison with the existing LIB RUL prediction methods show that the proposed method provides more accurate and reliable prediction results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "198",
      "title": "Adjacent Channel Compatibility Evaluation and Interference Mitigation Technique Between Earth Station in Motion and IMT-2020",
      "abstract": "The millimeter wave band is becoming popular for mobile broadband usage such as fifth-generation (5G) mobile and mobile satellite services utilizing earth stations in motion (ESIM). According to the 2019 World Radiocommunication Conference (WRC-19), the 5G and ESIM systems will operate in adjacent frequency bands bounded by 27.5 GHz; therefore, the adjacent channel compatibility between ESIM and 5G should be verified. Both, the minimum coupling loss (MCL) and Monte-Carlo (MC) methods are applied to assess the worst and most practical interference effects, respectively, for all types of ESIM including the following: maritime ESIM (M-ESIM), land ESIM (L-ESIM), and aeronautical ESIM (A-ESIM). The distance and guard band between the two systems are indicated by the compatibility conditions. In addition to the conventional interference-to-noise ratio (I/N), the throughput loss of a 5G system is proposed to assess the performance degradation caused by the ESIM interference. Two orthogonal frequency division multiplexing (OFDM) waveforms are proposed to suppress ESIM power leakage into an adjacent channel. A mathematical expression regarding the power spectral density (PSD) and frequency dependent rejection (FDR) is derived for these waveforms, suggesting that the interference can be alleviated. A measured single carrier waveform of a commercial ESIM equipment is used as the benchmark against the proposed OFDM waveforms. The windowed OFDM is able to reduce the guard band by 50-77%. The results obtained for various elevation angles of the ESIM antenna are determined to be applicable to various regions globally.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "199",
      "title": "Neural Networks-Based Adaptive Exponential Quasi-Passification and Output Tracking Control for Uncertain Switched Nonlinear Systems",
      "abstract": "In this paper, we mainly study the adaptive exponential quasi-passivity and adaptive tracking control of lower triangular uncertain switched nonlinear systems, even though the adaptive output tracking control problem of individual subsystem is unsolvable. First, the exponential quasipassivity concept is proposed to describe the energy changing of the overall switched nonlinear systems without the exponential quasi-passivity property of all the subsystems. Then, for switched nonlinear systems, the semiglobally uniformly ultimate boundedness is achieved by using exponential quasipassivity. Second, this result is applied to solve adaptive tracking control problem uncertain switched nonlinear systems in lower-triangular form. A new adaptive tracking control technique is developed by combining quasi-passification methods with adaptive backstepping techniques. The unknown nonlinear functions are approximated by the radial basis function neural networks. In contrast to the existing results, the multiple storage functions method reduces the conservativeness caused by a common Lyapunov function for all subsystems. Finally, the effectiveness of the proposed method is verified by an example.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "200",
      "title": "Fractional-Fuzzy PID Control Approach of Photovoltaic-Wire Feeder System (PV-WFS): Simulation and HIL-Based Experimental Investigation",
      "abstract": "The utilization of solar photovoltaic (PV) generator as a power source for wire feeder systems (WFSs) of arc welding machines is one of the promising domains in solar PV applications. This article proposes a new type of welding WFS and investigates the PV penetrated energy systems. The proposed system comprises of a solar PV generator, a DC/DC buck converter, and a permanent magnet DC (PMDC) motor. The power of the proposed standalone solar photovoltaic-wire feeder system (PV-WFS) can be widely improved using an intelligent fractional-order fuzzy proportional integral derivative (FO-Fuzzy-PID) regulator based on perturbing and observe (P&O) MPPT method. In this article, a FO-Fuzzy-PID regulator is also designed for a PMDC motor driven welding WFS system. Which will then control the wire feed rate of the welding WFS system. Furthermore, the dynamic reaction of the proposed solar PV-WFS depends on the coefficients of these FO-Fuzzy-PID regulators, which are adjusted by a meta-heuristic tuning algorithm based on particle swarm optimization (PSO) technique. The proposed strategy is tested using MATLAB simulations and experimentally verified in real-time on a Hardware-in-the-loop (HIL) testing platform using a dSPACE 1104 board-based laboratory setup. Simulation and experimental results are acceptable and demonstrate the effectiveness, precision, stability, and dynamic reaction of the suggested optimized wire feeder regulating system and the considered intelligent P&O MPPT technique.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "201",
      "title": "Twin Delayed Deep Deterministic Policy Gradient-Based Target Tracking for Unmanned Aerial Vehicle With Achievement Rewarding and Multistage Training",
      "abstract": "Target tracking using an unmanned aerial vehicle (UAV) is a challenging robotic problem. It requires handling a high level of nonlinearity and dynamics. Model-free control effectively handles the uncertain nature of the problem, and reinforcement learning (RL)-based approaches are a good candidate for solving this problem. In this article, the Twin Delayed Deep Deterministic Policy Gradient Algorithm (TD3), as recent and composite architecture of RL, was explored as a tracking agent for the UAV-based target tracking problem. Several improvements on the original TD3 were also performed. First, the proportional-differential controller was used to boost the exploration of the TD3 in training. Second, a novel reward formulation for the UAV-based target tracking enabled a careful combination of the various dynamic variables in the reward functions. This was accomplished by incorporating two exponential functions to limit the effect of velocity and acceleration to prevent the deformation in the policy function approximation. In addition, the concept of multistage training based on the dynamic variables was proposed as an opposing concept to one-stage combinatory training. Third, an enhancement of the rewarding function by including piecewise decomposition was used to enable more stable learning behaviour of the policy and move out from the linear reward to the achievement formula. The training was conducted based on fixed target tracking followed by moving target tracking. The flight testing was conducted based on three types of target trajectories: fixed, square, and blinking. The multistage training achieved the best performance with both exponential and achievement rewarding for the fixed trained agent with the fixed and square moving target and for the combined agent with both exponential and achievement rewarding for a fixed trained agent in the case of a blinking target. With respect to the traditional proportional differential controller, the maximum error reductio...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "202",
      "title": "Refining the Fusion of Pepper Robot and Estimated Depth Maps Method for Improved 3D Perception",
      "abstract": "As it is well known, some versions of the Pepper robot provide poor depth perception due to the lenses it has in front of the tridimensional sensor. In this paper, we present a method to improving that faulty 3D perception. Our proposal is based on a combination of the actual depth readings of Pepper and a deep learning-based monocular depth estimation. As shown, the combination of both of them provides a better 3D representation of the scene. In previous works we made an initial approximation of this fusion technique, but it had some drawbacks. In this paper we analyze the pros and cons of the Pepper readings, the monocular depth estimation method and our previous fusion method. Finally, we demonstrate that the proposed fusion method outperforms them all.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "203",
      "title": "Parallel Computing for Obtaining Regional Scale Rice Growth Conditions Based on WOFOST and Satellite Images",
      "abstract": "It is very important to obtain continuous regional crop parameters efficiently in the agricultural field. However, remote sensing data can provide spatial-continuous / temporal-disperse crop information while crop growth model can provide temporal-continuous / spatial-disperse crop information. Therefore, the assimilation between crop growth model and remote sensing data is an efficient way for obtaining continuous vegetation growth information. This study aims to present a parallel method based on graphic processing unit (GPU) to improve the efficiency of the assimilation between RS data and crop growth model to estimate rice growth parameters. Remote sensing data, Landsat and HJ-1 images, were collected and the World Food Studies (WOFOST) crop growth model which has a strong flexibility was employed. To acquire continuous regional crop parameters, particle swarm optimization (PSO) data assimilation method was used to combine remote sensing images and WOFOST and this process is accompanied by a parallel method based on the Compute Unified Device Architecture (CUDA) platform of NVIDIA GPU. With these methods, we obtained daily rice growth parameters of Zhuzhou City, Hunan, China and compared the efficiency and precision of parallel method and non-parallel method. Results showed that the parallel program has a remarkable speedup (reaching 240 times) compared with the non-parallel program with a similar accuracy. This study indicated that the parallel implementation based on GPU was successful in improving the efficiency of the assimilation between RS data and the WOFOST model.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "204",
      "title": "Reducing the System Overhead of Millimeter-Wave Beamforming With Neural Networks for 5G and Beyond",
      "abstract": "To accommodate the rapid change of radio propagation environment for mobile communication scenarios, millimeter-wave beamforming requires instantaneous channel state information (CSI) to update its operational parameters in real time, resulting in heavy system overhead. As the number of antennas increases, the system overhead associated with beam management will increase dramatically. To address this overarching problem, a neural network-aided millimeter-wave beamforming algorithm is proposed in this paper. A new parameter, referred to as “beam adjustment interval”, is proposed to evaluate the beamforming performance. It is defined as the maximum time duration in which the signal-to-interference-plus-noise ratio (SINR) of the user equipment can be maintained above the predefined threshold. Besides, a predictive method of beam adjustment to maximize the beam adjustment interval is developed, which considers the SINR not only at the current location but also future possible locations. Simulation results show that the proposed algorithm can significantly increase beam adjustment interval and reduce the total number of beam adjustments for the moving user equipment, thus reducing the system overhead 41.4% on average over 10 randomly generated test traces.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "205",
      "title": "Multidimensional Hierarchical Interpolation Method on Sparse Grids for the Absorption Problem",
      "abstract": "The numerical integration of multidimensional functions using some variables of the sparse grid method for the absorption problem is presented in this paper. The multivariate quadrature expressions are constructed by combining tensor of suited one dimensional formula. We develop a multidimensional adaptive quadrature algorithm for the implementation of sparse grid based on a hierarchical basis. Furthermore, we obtain a new error bound at each sparse grid point. The numerical examples are shown to demonstrate the efficiency of our algorithm for the absorption problem and confirm the theoretical estimates.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "206",
      "title": "An Efficient and Secure Public Key Authenticated Encryption With Keyword Search in the Logarithmic Time",
      "abstract": "Searchable encryption is an important cryptographic technique that achieves data security and keyword retrieval over encrypted data in cloud. In 2004, Boneh et.al proposed the first searchable encryption scheme based on asymmetric cryptography. Since then, many variants of public key searchable encryption schemes were proposed. However, most previous works are vulnerable to multi-ciphertext attack, and they cannot provide trapdoor indistinguishability. Another problem is how to improve the searching efficiency. To deal with two issues, we construct a fast and secure public key authenticated searchable encryption scheme with designed server. Our scheme can resist keyword guessing attacks, chosen multi-keyword attacks and multi-trapdoor attacks. The search function in our scheme achieves the logarithmic search time in number of keywords while most existing schemes required the linear time. By comparison with previous schemes in computational complexity, our scheme is very fast in keyword search.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "207",
      "title": "Identifying Incorrect Patches in Program Repair Based on Meaning of Source Code",
      "abstract": "Automatic Program Repair (APR) techniques have shown the potential of reducing debugging costs while improving software quality by generating patches for fixing bugs automatically. However, they often generate many overfitting patches which pass only a specific test-suite but do not fix the bugs correctly. This paper proposes MIPI, a novel approach to reducing the number of overfitting patches generated in the APR. We leverage recent advances in deep learning to exploit the similarity between the patched method’s name (which often encloses the developer’s intention about the code) and the semantic meaning of the method’s body (which represents the actual implemented behavior) for identifying and removing overfitting patches generated by APR tools. Experiments with a large dataset of patches for QuixBugs and Defects4J programs show the promise of our approach. Specifically, in a total of 1,191 patches generated by 23 existing APR tools, MIPI successfully filters out 254 (32%) of the total 797 overfitting patches with a precision of 90% while preserving 93% of the correct patches. MIPI is more precise and less damaging to the APR than existing heuristic patch assessment techniques, achieving a higher recall than automated testing-based techniques that do not have access to the test oracle. In addition, MIPI is highly complementary to existing automated patch assessment techniques.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "208",
      "title": "An LDPC Encoder Architecture With Up to 47.5 Gbps Throughput for DVB-S2/S2X Standards",
      "abstract": "Low-Density Parity-Check (LDPC) code is a type of forward error-correction code with excellent performance, and has been widely used in many modern communication standards. The second-generation satellite broadcasting standard (DVB-S2) and its extension (DVB-S2X) adopt a special Irregular Repeated Accumulate (IRA) LDPC code as inner coding scheme. However, due to the large block size, most of the architectures proposed so far use Random Access Memory (RAM) to store and update the encoding results, and the delay caused by address-controlled read and write operations and barrel shift during computation inevitably limits the upper bound of encoder throughput. In this paper, by extracting the periodicity of the parity-check matrix, we introduce a fast encoding algorithm that can efficiently process the multiplication of the information sequence and a large-dimensional sparse matrix, and propose an encoder architecture with low encoding delay and high throughput. The proposed architecture has been implemented and tested on a Xilinx Kintex-7 FPGA, and the result show that the encoder architecture can achieve the highest throughput of 47.5 Gbps at a clock frequency of 280 MHz.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "209",
      "title": "Magnetic Field and Temperature Dual-Parameter Sensor Based on Nonadiabatic Tapered Microfiber Cascaded With FBG",
      "abstract": "A kind of dual-parameter sensor based on magnetic-fluid-coated nonadiabatic tapered microfiber (NTF) cascaded with fiber Bragg grating (FBG) is proposed and experimentally demonstrated. Simultaneous measurement of magnetic field and temperature is realized by monitoring the variation of NTF interference spectrum and FBG characteristic dip. In the magnetic field range of 0–18 mT, the highest magnetic field sensitivity can reach 1.159 nm/mT. The maximum temperature sensitivity is up to −1.737 nm/°C in the temperature range of 25-50 °C. The proposed magnetic-fluid-coated NTF interferometer cascaded with FBG will find extensive application prospect due to its high sensitivity, easy fabrication, compactness, strong robustness, and low cost.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "210",
      "title": "Characterizing Scalar Metasurfaces Using Time-Domain Reflectometry",
      "abstract": "Two efficient methodologies for the determination of electromagnetic (EM) constitutive properties of scalar metasurfaces are introduced and discussed. In contrast to the available methods, and in line with the recent increasing interest in time-domain (TD) analyses of metasurfaces, we show that the material parameters of a scalar metasurface can be readily achieved directly in the TD merely from the EM reflected pulse shape. The two methodologies are based on an analytical TD reflectometry (TDR) approach and a modern stochastic optimization technique. A number of illustrative numerical examples demonstrating the validity and properties of the proposed techniques are presented.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "211",
      "title": "Blockchain-Enabled Integrated Market Platform for Contract Production",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "212",
      "title": "Exploiting Integrated Demand Response for Operating Reserve Provision Considering Rebound Effects",
      "abstract": "Electricity-driven thermostatically controlled loads (TCLs), e.g., air conditioners (ACs), have been widely utilized in demand response (DR) to provide operating reserve for power systems. However, the rebound effects may occur during the recovery process of DR, which can limit the operating reserve quality of ACs or even affect the reliable operation of power systems. With the community-level smart energy hubs (EH), the traditional electricity-driven TCLs can be expanded into multi-energy driven thermostatically controlled loads (MTCLs), e.g., household radiators. Under this circumstance, integrated demand response (IDR) can be exploited to coordinate the operation of MTCLs and provide more operating reserve resources while mitigating rebound effects. To this end, this paper proposes a two-stage IDR strategy to fully excavate the operating reserve provided by MTCLs. The first stage is to coordinate the energy consumption of ACs and household radiators to maximize the end-users’ thermal comfort and mitigate the rebound effects. To quantify the end-users’ thermal comfort, a modified predicted percentage of dissatisfied (PPD) index related to thermal environment parameters is introduced and simplified. Based on the energy consumption determined in the first stage, the energy conversion in EH is optimized in the second stage. Through the optimization in these two stages, a series of indices is established to evaluate the operating reserve in terms of aggregate capacity, duration, ramp rate, and smoothness. The case studies demonstrate that the proposed two-stage IDR strategy can provide high-aggregate-capacity and long-duration reserve resources in power systems while mitigating the rebound effects to maintain supply-demand balance and reliable operation of power systems. The analysis results of the test system show that the reserve capacity and duration obtained by the proposed model are 1.85 and 2.61 times those of the model without considering the multi-energy conve...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "213",
      "title": "Robust Multi-View Clustering With a Unified Weight Learning Paradigm",
      "abstract": "Multi-view clustering, which exploits multi-view information to improve the clustering performance has attracted much attention in recent years. However, existing methods seldom consider the diverse quality of data points in different views, and assign each data point with the same importance for clustering. This way degrades the clustering performance due to the interference of low quality data points on the learned clustering indicators. In this paper, a novel robust multi-view clustering method with a unified weight learning paradigm is proposed to address this issue. The unified weight learning paradigm adaptively learns the quality of data points and the clustering capability of each view. Specifically, the reconstruction error of each data point in each view is treated as a factor to depict the quality of data point in this view. Afterwards, the clustering capability of each view is captured from the diverse quality of data points in each view. The clustering capability of each view in turn improves the learning process of data quality. An alternating iterative optimization algorithm with theoretical convergence guarantee and complexity analysis is designed to optimize the objective function. Experimental results on real-world benchmark datasets demonstrate the superiority of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "214",
      "title": "Performance Analysis of Long Short-Term Memory-Based Markovian Spectrum Prediction",
      "abstract": "Dynamic Spectrum Access (DSA) solutions equipped with spectrum prediction can enable proactive spectrum management and tackle the increasing demand for radio frequency (RF) bandwidth. Among various prediction techniques, Long Short-Term Memory (LSTM) is a deep learning model that has demonstrated high performance in forecasting spectrum characteristics. Although well-performing, the theoretical characterization of LSTM prediction performance has not been well developed in the literature. Therefore, in this article, we examine an LSTM based temporal spectrum prediction model and characterize its prediction performance through theoretical analysis. To this end, we analyze the LSTM prediction outputs over simulated Markov-model-based spectrum data and spectrum measurements data. Our results suggest that the predicted scores of the LSTM based system model can be described using mixtures of truncated Gaussian distributions. We also estimate the performance metrics using the mixture model and compare the results with the observed prediction performance over simulated and measured datasets.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "215",
      "title": "Analysis of EV Charging Coordination Efficiency in Presence of Cheating Customers",
      "abstract": "Charging coordination is employed to efficiently serve electric vehicle (EV) charging requests without overloading the distribution network. Parameters such as parking duration, battery state-of-charge (SoC), and charging amount are provided by EVs to the charging coordination center to schedule their charging requests efficiently. The existing literature assumes that the customers always provide correct information. Unfortunately, customers may provide false information to gain higher charging priority. Assessing the impact of cheating behavior represents a significant and open problem. Herein paper, the impact of providing false information (e.g., parking duration) on the efficiency of the charging coordination mechanism is investigated. The charging coordination strategy is formulated as a linear optimization problem. Two different objectives are used to assess the impact of the objective function on the amount of performance degradation. Our investigations reveal that the degradation of the efficiency of the charging coordination mechanism depends on the percentage of cheating customers and cheating duration versus the typical parking duration. In addition, the impact of cheating behavior increases with the number of deployed chargers. Thus, the severity of the cheating impact will increase in the future as more fast chargers are allocated in charging networks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "216",
      "title": "Large-Aperture Metamaterial Lens Antenna for Multi-Layer MIMO Transmission for 6G",
      "abstract": "A metamaterial lens refers to a planar structure having multiple metamaterial unit cells capable of manipulating electromagnetic waves to improve antenna gains by changing their shape, geometry, size, or orientation. In this paper, we propose a large-aperture metamaterial lens antenna (MLA) designed to improve the gain of multiple beams emitted from a linear feed antenna array, taking multi-layer transmission into account. A new channel model incorporating MLA is presented to evaluate the performance of the proposed MLA on beam gain and system throughput gain. The channel model is derived by decomposing the entire propagation channel from the transmit antenna to the receive antenna through metamaterial lens into five serial channels. The measurement results of the MLA prototype prove that the channel model is valid to reflect the actual multiple beam patterns. Simulation results based on the channel model show that a single large-aperture MLA can achieve beam gain of up to 14 dB compared to the case without a lens. Finally, by adopting the proposed large-aperture MLA, it is shown through system-level simulation that the throughput of user equipment is increased on cellular networks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "217",
      "title": "Generating Multi-Issued Session Key by Using Semi Quantum Key Distribution With Time-Constraint",
      "abstract": "Information security refers to protect the information from unauthorized access or modification. Quantum Key Distribution (QKD) is a way to generate a key preventing those malicious activities. One of QKD protocol, namely Semi-quantum key distribution (SQKD) protocol, is designed to allow two users to establish a secure secret key when either of them is limited to performing certain “classical” operations. It is proven to be secure from any type of attack. However, it will be a problem in the multi-session communication since the SQKD activities follow the number of the session. In this paper, we propose two modified SQKDs with time-constraint approach. Time-constraint is beneficial in QKD activity since it could generate session key between two parties within a certain time-constraint. By setting the number of session key and its time-constraint before QKD activities, many scheduled communications would be prepared well. Furthermore, BAN Logic analysis is applied to analyze the goal of the protocol, the considered assumptions, wasted phase, and the demand for data encryption. Finally, the performance analysis of the protocols is presented, and it shows a better performance compared with other certain QKDs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "218",
      "title": "Multiscale Anisotropic Morphological Directional Derivatives for Noise-Robust Image Edge Detection",
      "abstract": "Different types of noise interference lead to low accuracy of image edge detection and severe loss of feature extraction details. A new noise-robust edge detection method is proposed, which uses a set of multiscale anisotropic morphological directional derivatives to extract the edge map of an input image. The main advantage of the method is that high edge resolution is maintained while reducing noise interference. The following five parts form the whole framework of this paper. First, multiscale anisotropic morphologic directional derivatives (MSAMDDs) are proposed to filter and obtain the local gray value of the image. Second, the edge strength map (ESM) is extracted by using spatial matching filters. In the third stage, multiscale edge direction maps (EDMs) based on the directional matched filters are fused, and the new EDM is constructed. Fourth, edge contours are obtained by embedding the ESM and the EDM into the standard route of Canny detection. Finally, the precision-recall curve and Pratt’s figure of merit (FOM) are used to evaluate the proposed method against eight state-of-the-art methods on three data sets. The experimental results show that the proposed method can perform better for noise-free (F-measure value of 0.776) and Gaussian noise (FOM value of 95.75%) and attains the best performance in impulse noise images (highest FOM value of 98.90%).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "219",
      "title": "Using Research Literature to Generate Datasets of Implicit Feedback for Recommending Scientific Items",
      "abstract": "In an age of information overload, we are faced with seemingly endless options from which a small number of choices must be made. For applications such as search engines and online stores, Recommender Systems have long become the key tool for assisting users in their choices. Interestingly, the use of Recommender Systems for recommending scientific items remains a rarity. One difficulty is that the development of such systems depends on the availability of adequate datasets of users' feedback. While there are several datasets available with the ratings of the users for books, music, or films, there is a lack of similar datasets for scientific fields, such as Astronomy and Life and Health Sciences. To address this issue, we propose a methodology that explores scientific literature for generating utility matrices of implicit feedback. The proposed methodology consists in identifying a list of items, finding research articles related to them, extracting the authors from each article, and finally creating a dataset where users are unique authors from the collected articles, and the rating values are the number of articles a unique author wrote about an item. Considering that literature is available for every scientific field, the methodology is in principle applicable to Recommender Systems in any scientific field. The methodology, which we call LIBRETTI (LIterature Based RecommEndaTion of scienTific Items), was assessed in two distinct study cases, Astronomy and Chemistry. Several evaluation metrics for the datasets generated with LIBRETTI were compared to those derived from other available datasets using the same set of recommender algorithms. The results were found to be similar, which provides a solid indication that LIBRETTI is a promising approach for generating datasets of implicit feedback for recommending scientific items.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "220",
      "title": "360 Degree Panorama Synthesis From Sequential Views Based on Improved FC-Densenets",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "221",
      "title": "An Interpretation of Long Short-Term Memory Recurrent Neural Network for Approximating Roots of Polynomials",
      "abstract": "This paper aims to present a flexible method for interpreting the Long Short-Term Memory Recurrent Neural Network (LSTM-RNN) for the relational structure between the roots and the coefficients of a polynomial. A database is first developed for randomly selected inputs based on the degrees of the univariate polynomial which is then used to approximate the polynomial roots through the proposed LSTM-RNN model. Furthermore, an adaptive learning optimization algorithm is used specifically to update the network weights iteratively based on training deep neural networks data. Thus, the method can exploit the ability to find the individual learning rates for each variable through adaptive learning rate strategies to effectively prevent the weights from fluctuating in a wide spectrum. Finally, several experimental results are performed which shows that the proposed LSTM-RNN model can be used as an alternative approach to compute an approximation of each root for a given polynomial. Furthermore, the results are compared with the conventional feedforward neural network based artificial neural network model. The results clearly demonstrate the superiority of the proposed LSTM-RNN model for roots approximation in terms of accuracy, mean square error and faster convergence.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "222",
      "title": "A Novel Fuzzy Monotone Relationship Method With its Application on Inclusion Degree",
      "abstract": "This paper introduces a new fuzzy monotone relationship and its associated method, which are applied to feature selection and correlation analysis. Specifically, after the concept of a fuzzy monotone is introduced, this paper first defines a new fuzzy monotone relationship between inputs and output. Second, a fuzzy inclusive monotone model is constructed on inclusion degree through several proved propositions, together with presenting a fuzzy inclusive monotone decision membership function. Third, a new algorithm is developed according to the proposed model for feature selection or correlation analysis. Compared with several methods, the proposed algorithm has been validated on several data sets. The results indicate that the proposed algorithm is effective for the selection of numeric attributes, and the correlation analysis. The novel fuzzy monotone relationship and the method are validated through theoretic proof and experimental results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "223",
      "title": "Three-Dimensional Reconstruction of Fuzzy Medical Images Using Quantum Algorithm",
      "abstract": "In order to deal with the problems of poor anti-interference, low reconstruction clarity and large errors in the traditional medical image reconstruction methods, we proposed a fuzzy medical images three-dimensional (3D) reconstruction method using quantum algorithm. First of all, a feature matching model of fuzzy medical image was built. Secondly, this study decomposed the edge contour features by using the Gaussian mixture feature matching method, extracted the edge contour vectors of fuzzy medical image, and enhanced the information of fuzzy medical images by adopting the region edge sharpening. Thirdly, this study reorganized the 3D texture structure of images and reconstructed the sparse scattered points according to its texture and detail regions. Finally, we combined with the gray histogram of fuzzy medical images to achieve the adaptive pixel reconstruction of fuzzy medical images, and completed the 3D reconstruction of fuzzy medical images by employing the quantum algorithm. The results show that the proposed method is characterized by high matching degree of image features and balanced distribution of point clouds, and the self-similarity coefficient of the reconstructed texture can reach 0.994; in addition, the SINR value of the reconstruction result can be maintained around 100dB, and it has lower error rate than the traditional method, thereby improving the detection and recognition capability of medical images, and the algorithm has certain practical application.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "224",
      "title": "Enhanced Moth Search Algorithm for the Set-Union Knapsack Problems",
      "abstract": "As an important and novel model with multitudinous practical applications, the set-union knapsack problem (SUKP) is a challenging issue in combinatorial optimization. In this paper, we present an enhanced moth search algorithm (EMS) for solving SUKP, which introduces an enhanced interaction operator (EIO) by integrating differential mutation into the global harmony search and then Lévy flight is replaced by EIO. Comparative experimental results, which were conducted on three types of 30 popular SUKP benchmark instances, demonstrate that EMS algorithm is superior to or competitive with the other state-of-the-art metaheuristic algorithm. In particular, EMS reaches the best-known solutions for the great majority of test instances and improves the best-known solutions for six instances. Two critical ingredients of EIO is investigated to confirm their impact on the performance of EMS. The results show that both components have an important role in improving the performance of EMS.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "225",
      "title": "Guided Soft Actor Critic: A Guided Deep Reinforcement Learning Approach for Partially Observable Markov Decision Processes",
      "abstract": "Most real-world problems are essentially partially observable, and the environmental model is unknown. Therefore, there is a significant need for reinforcement learning approaches to solve them, where the agent perceives the state of the environment partially and noisily. Guided reinforcement learning methods solve this issue by providing additional state knowledge to reinforcement learning algorithms during the learning process, allowing them to solve a partially observable Markov decision process (POMDP) more effectively. However, these guided approaches are relatively rare in the literature, and most existing approaches are model-based, meaning that they require learning an appropriate model of the environment first. In this paper, we propose a novel model-free approach that combines the soft actor-critic method and supervised learning concept to solve real-world problems, formulating them as POMDPs. In experiments performed on OpenAI Gym, an open-source simulation platform, our guided soft actor-critic approach outperformed other baseline algorithms, gaining 7~20% more maximum average return on five partially observable tasks constructed based on continuous control problems and simulated in MuJoCo.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "226",
      "title": "LinRegDroid: Detection of Android Malware Using Multiple Linear Regression Models-Based Classifiers",
      "abstract": "In this study, a framework for Android malware detection based on permissions is presented. This framework uses multiple linear regression methods. Application permissions, which are one of the most critical building blocks in the security of the Android operating system, are extracted through static analysis, and security analyzes of applications are carried out with machine learning techniques. Based on the multiple linear regression techniques, two classifiers are proposed for permission-based Android malware detection. These classifiers are compared on four different datasets with basic machine learning techniques such as support vector machine, k-nearest neighbor, Naive Bayes, and decision trees. In addition, using the bagging method, which is one of the ensemble learning, different classifiers are created, and the classification performance is increased. As a result, remarkable performances are obtained with classification algorithms based on linear regression models without the need for very complex classification algorithms.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "227",
      "title": "Analysis of Sensor-Based Real-Time Balancing of Humanoid Robots on Inclined Surfaces",
      "abstract": "An experimental and theoretical study of real-time robot balancing on inclined surfaces with electrical feedback circuitry is presented. Force sensors are experimentally shown to extend the sustainability of a stable robot posture beyond a critical surface inclination. For this purpose, the inclination feedback from the force sensors is used to adjust the robot's ankle-pitch-motor angle above the critical inclination, thus enabling the maintenance of a stable robot posture. Further, the Inverted Pendulum Model (IPM) (Hemami and Golliday, 1977, Hemami et al., 1973, and McGhee and Kuhner, 1969) is extended to the case of inclined surfaces. Through application of this extended IPM it is demonstrated, that simultaneous use of gyro-sensor data can minimize the necessary initial adjustment of the motor angle for controlled robot-body rotation, which additionally has the positive effect of reducing possible overshoots of the motor's rotation angle during feedback. Consequently, the reported feedback control improves the robot-body stability on inclined surfaces. Efficient implementation of the developed control scheme into an existing robot's electrical system is proposed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "228",
      "title": "Direct Drop-on-Demand Printing of Molten Solder Bumps on ENIG Finishing at Ambient Conditions Through StarJet Technology",
      "abstract": "In this paper, we report on a detailed experimental study carried out with the StarJet technology to investigate the mechanical adhesion properties of directly printed solder bumps on electroless nickel immersion gold (ENIG) plated PCB boards. The aim of this study is to determine the maximum bond strength achievable by this method and to find suitable printing parameters that allow for the production of reliable and consistent solder bumps by non-contact printing of molten solder (type SAC305). Molten solder droplets of about 250 μm diameter were printed at melt temperatures between 250 and 400 °C onto ENIG surfaces kept at temperatures in the range of 100 to 200 °C. Using shear force tests, the adhesion of the printed bumps was investigated as a function of the main process parameters: 1. printhead temperature, 2. substrate temperature, and 3. substrate preheating time. The formation of an intermetallic compound (IMC) between the solder and the ENIG was confirmed by scanning electron microscopy (SEM) and energy-dispersive X-ray spectroscopy (EDX) measurements. As a result of the comprehensive experimental parameter study, suitable printing parameters for establishing bond strengths corresponding to maximum shear force values of 3000 to 4000 mN could be found, i.e. high printhead temperature of 400 °C, short preheating and time of <; 2 min, and substrate heating at 180 °C The use of flux was found to slightly improve the bond strength and to improve the consistency of the printing results for extended operation times. The achieved high bond strength and the reasonable reproducibility of the printing results qualify the StarJet technology for further investigations regarding applications in the field of direct soldering of microelectronic chips and devices to PCB boards as well as other micro-assembly tasks in the future.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "229",
      "title": "Building Energy Management With Reinforcement Learning and Model Predictive Control: A Survey",
      "abstract": "Building energy management has been recognized as of significant importance on improving the overall system efficiency and reducing the greenhouse gas emission. However, the building energy management system is now facing more challenges and uncertainties with the increasing penetration of renewable energy and increasing adoption of different types of electrical appliances and equipment. Classical model predictive control (MPC) has shown effective in building energy management, although it suffers from labour-intensive modelling and complex online control optimization. Recently, with the growing accessibility to building control and automation data, data-driven solutions such as data-driven MPC and reinforcement learning (RL)-based methods have attracted more research interest. However, the potential of integrating these two types of methods and how to choose suitable control algorithms have not been well discussed. In this work, we first present a compact review of the recent advances in data-driven MPC and RL-based control methods for building energy management. Furthermore, the main challenges in these approaches and general discussions on the selection of control methods are discussed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "230",
      "title": "Behavior Recognition Based on Category Subspace in Crowded Videos",
      "abstract": "Crowd behavior refers to a collective behavior composed of two or more individuals who influence, interact, and depend on each other for a specific goal. Compared with an ordinary crowd behavior, the probability of a dangerous crowd behavior is much smaller. Video-based crowd behavior recognition can be categorized as one multi-label classification task, which is characterized by complex scenes and imbalanced samples. Aimed at tackling problems of imbalanced samples and multi-label task, a classification method of associative subspace is proposed. For a single category (called main category) with fewer samples, this paper generates a special subspace wherein it is relatively easy to distinguish these samples by association with other categories. A classifier that can weaken the main category and strengthen relationship between the main category and other categories is designed in the subspace. Therefore, the main category can contribute to reducing dependence on the number of samples with the above-mentioned classifier in the corresponding subspace. In order to make full use of the relevant information concerning categories, multi-label information is further injected into spatio-temporal features of video action representation. Experiments on a challenging WWW dataset show that both the proposed subspace method and multi-label information fusion mechanism are efficient.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "231",
      "title": "Ensemble Feature Ranking for Cost-Based Non-Overlapping Groups: A Case Study of Chronic Kidney Disease Diagnosis in Developing Countries",
      "abstract": "Chronic kidney disease (CKD) is one of the leading medical ailments in developing countries. Due to the limited healthcare infrastructure and the lack of trained human resources, the CKD problem aggravates if it is not addressed in its earlier stages. In this regard, the role of machine learning-based automated diagnosis systems plays a vital role to deal with the CKD problem. In most of the studies conducted on the automated CKD decision modeling, the main emphasis is given to enhancing the predictive accuracy of the system. In this study, we focus on the applicability challenges of automated decision systems taking CKD diagnosis as a case study within the purview of developing countries. In this regard, we propose a cost-sensitive ensemble feature ranking method that takes a more realistic approach to group-based feature selection. Two candidate solutions are proposed for group-based feature selection to meet different objectives. Subsequently, both the candidate solutions are combined into a consolidated solution. It is pertinent to note that it is one of the first studies in which cost-sensitive ensemble feature ranking for non-overlapping groups is successfully demonstrated to achieve the stated objectives i.e. low-cost and high-accuracy solution. Based on an extensive set of experiments, we demonstrate that a cost-effective and accurate solution for the CKD problem can be obtained. The experimentation includes 7 well-known classification algorithms and 8 comparative feature selection methods to show the efficacy of the proposed approach. It is concluded that the applicability of the automated CKD systems can be enhanced by including the cost consideration into the objective space of the solution formulation. Therefore, a trade-off solution can be obtained that is cost-effective and yet accurate enough to serve as a CKD screening system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "232",
      "title": "A Novel Miniaturized Ultra-Wideband Frequency Selective Surface With Rapid Band Edge",
      "abstract": "This paper presents a novel frequency selective surface (FSS) structure with miniaturized, rapid band edge, ultra-wideband (UWB) passband, and UWB out of band shielding. The proposed FSS is formed by using two air foam layers to cascade three single layers with the unit cell dimension in 6mm\n ×6\\times 6 \nmm(\n 0.023λ×0.023λ0.023\\lambda \\times 0.023\\lambda  \n. The corresponding equivalent circuit models are developed for interpretation of the physical mechanism and formulate the relevant design equations. Finally, a prototype of the proposed structure is fabricated and measured to verify the full-wave simulation and theoretical analysis results. The measured results show the proposed FSS has a −3 dB passband from 1.17 GHz to 7.08 GHz and a −10 dB stopband from 7.34 GHz to 15.0 GHz. The corresponding relative bandwidths calculated from the measured results are 143.3% and 68.6%, respectively, which exhibits the stable performance against the variation of the incident angles from 0° to 45° for both TE and TM polarizations. All these results demonstrate that the proposed FSS is suitable for the actual miniaturized EMI shielding scene application.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "233",
      "title": "On the Scalability of Vision-Based Drone Swarms in the Presence of Occlusions",
      "abstract": "Vision-based drone swarms have recently emerged as a promising alternative to address the fault-tolerance and flexibility limitations of centralized and communication-based aerial collective systems. Although most vision-based control algorithms rely on the detection of neighbors, they usually neglect critical perceptual factors such as visual occlusions and their effect on the scalability of the swarm. To estimate the impact of occlusions on the detection of neighbors, we propose a simple but perceptually realistic visual neighbor selection model that discards obstructed agents. We evaluate the visibility model using a potential-field-based flocking algorithm with up to one thousand agents, showing that occlusions have adverse effects on the inter-agent distances and velocity alignment as the swarm scales up, both in terms of group size and density. In particular, we find that small agent displacements have considerable effects on neighbor visibility and lead to control discontinuities. We show that the destabilizing effects of visibility switches, i.e., agents continuously becoming visible or invisible, can be mitigated if agents select their neighbors from adjacent Voronoi regions. We validate the resulting flocking algorithm using up to one hundred agents with quadcopter dynamics and subject to sensor noise in a high-fidelity physics simulator. The results show that Voronoi-based interactions enable vision-based swarms to remain collision-free, ordered, and cohesive in the presence of occlusions. These results are consistent across group sizes, agent number densities, and relative localization noise. The source code and experimental data are available at \nhttps://github.com/lis-epfl/vmodel\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "234",
      "title": "A Novel Moving Target Defense Scheme With Physical Unclonable Functions-Based Authentication",
      "abstract": "Recent studies have discovered possible security issues on Supervisory Control and Data Acquisition systems (SCADA) in the critical architecture and focus on developing protection mechanisms on this system. Moving Target Mobile IPv6 Defense II is one of these schemes, in which the node in SCADA system employs the moving target’s mobile IPv6 mechanism to solve the possible security problem the attacker targeting the specific node and launching attacks. However, the node in this novel scheme still should need to send update binding message with its new IP address to other nodes, which still possibly causes IP leakage security problem. Hence, in our study, we propose a moving target defense scheme with Physical Unclonable Functions (PUF) based authentication in SCADA system. In our scheme, PUF based authentication scheme ensures the security of the whole IP updating process. Once the nodes finish authentication process, they can perform IP generation mechanism based on unique parameter resulting from PUF outputs. Hence, our proposed scheme can ensure the unique characteristic of our generated IP address and no packet loss in the duration of IP rotation. Compared with other MTD-based schemes, our performance evaluation also shows that our proposed scheme can achieve good security performance in SCADA systems.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "235",
      "title": "IEEE Access Special Section Editorial: Recent Advances on Radio Access and Security Methods in 5G Networks",
      "abstract": "Serviceability is the ability of a network to serve user equipments (UEs) within desired requirements (e.g., throughput, delay, and packet loss). High serviceability is considered as one of the key foundational criteria towards a successful fog radio access infrastructure satisfying the Internet of Things paradigm in the 5G era. In the article by Dao \net al.\n, \"Adaptive resource balancing for serviceability maximization in fog radio access networks,\" the authors propose an adaptive resource balancing (ARB) scheme for serviceability maximization in fog radio access networks wherein the resource block (RB) utilization among remote radio heads (RRHs) is balanced using the backpressure algorithm with respect to a time-varying network topology issued by potential RRH motilities. The optimal UE selection for service migration from a high-RB-utilization RRH to its neighboring low RB-utilization RRHs is determined by the Hungarian method to minimize RB occupation after moving the service. Analytical results reveal that the proposed ARB scheme provides substantial gains compared to the standalone capacity-aware, max-rate, and cache-aware UE association approaches in terms of serviceability, availability, and throughput.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "236",
      "title": "A Deep Learning Framework for Transforming Image Reconstruction Into Pixel Classification",
      "abstract": "A deep learning framework is presented that transforms the task of MR image reconstruction from randomly undersampled k-space data into pixel classification. A DL network was trained to remove incoherent undersampling artifacts from MR images. The underlying, fully sampled, target image was represented as a discrete quantized image. The quantization step enables the design of a convolutional neural network (CNN) that can classify each pixel in the input image to a discrete quantized level. The reconstructed image quality of the proposed DL classification model was compared with conventional compressed sensing (CS) and a DL regression model. The reconstructed images using the DL classification model outperformed the state-of-the-art compressed sensing and DL regression models with a similar number of parameters assessed using quantitative measures. The experiments reveal that the proposed deep learning method is robust to noise and is able to reconstruct high-quality images in low SNR scenarios where conventional CS reconstructions and DL regression networks perform poorly. A generic design framework for transforming MR image reconstruction into pixel classification is developed. The proposed method can be easily incorporated into other DL-based image reconstruction methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "237",
      "title": "IEEE Access Special Section Editorial: Advanced Energy Storage Technologies and Their Applications",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "238",
      "title": "Multilayer ToI Detection Approach for Nested NER",
      "abstract": "Nested entities commonly exist in news articles and biomedical corpora. The performance of nested NER is still a great challenge in the field of named entity recognition (NER). Unlike the structural models in previous work, this paper presents a comprehensive study of nested NER by means of text-of-interest (ToI) detection. This paper presents a novel ToI-CNN with dual transformer encoders (ToI-CNN + DTE) model for this solution. We design a directional self-attention mechanism to encode contextual representation over the whole-sentence in the forward and backward directions. The features of the entities are extracted from the contextual token representations by a convolutional neural network. Moreover, we use HAT pooling operation to convert the various length ToIs to a fixed length vector and connect with a fully connected network for classification. The layer where the nested entities are located can be evaluated by multi-task learning jointly with layer classification. The experimental results show that our model achieves excellent performance in F1 score, training cost and layer evaluation on the nested NER datasets.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "239",
      "title": "Effectiveness of Kinesthetic Game-Based Training System in Children With Visual-Perceptual Dysfunction",
      "abstract": "Visual perceptual dysfunctions were common in children with developmental delays, and have severe adverse impacts on children’s daily activities. Recent studies have shown that technologies such as virtual reality and imaging can provide a motivating and engaging tool for remediating visual perceptual dysfunctions. This study was aimed to present the work we were conducting in experimenting with augmented reality (AR) for visual perceptual rehabilitation in children with developmental delay. Sixty participants (mean age = 7.96 ± 1.4) were equally divided into an experimental group trained with proposed KBTS (KBTS group) and a control group trained using traditional visual perceptual training (TVPT group). Each group completed an 8-week training program (two 30-minute sessions per week). Visual perceptual assessments (Test of Visual Perceptual Skill- 3rd Edition, Beery-Buktenica Developmental Test of Visual-Motor Integration- 6th Edition) and functional outcome measures (Vineland Adaptive Behavior Scale- Chinese Version, School Function Assessment- Chinese Version) were administered to investigate the effectiveness of the intervention. The KBTS group significantly outperformed the TVPT group in assessments of visual-motor integration, visual perceptual skills, and school functions. The effectiveness of the KBTS was supported by robust effect sizes for the pre- and post-intervention comparisons of visual perceptual and visual motor integrative functions between the KBTS group and the TVPT group. This study suggests that KBTS effectively improves visual-motor integration and overall visual perceptual functions in children with developmental delays. This study has discussed the ideas for incorporating several principles of game scenarios for visual perceptual rehabilitation, and the proposed KBTS still have raised a number of issues requiring further work. Enabling users to perform visual motor integrative tasks in an augmented reality world offers the potential for dev...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "240",
      "title": "An Effective Algorithm for Specular Reflection Image Enhancement",
      "abstract": "Specular highlights often exist in real-world images due to the material property of objects and the capturing environments. High light in real-life scenes can reduce image quality and cause loss of image information, to overcome this, we propose an effective specular reflection image enhancement algorithm. First, the scene depth map of specular reflection image was obtained by the color attenuation prior method; then, two adaptive adjustment factors were developed to optimize the transmission map for specular reflection images and \n L0L_{0} \n gradient minimization filter was used to eliminate halo artifacts. Finally, the nonuniform illumination compensation strategy based on the YUV color space was used to expand the dynamic range of the image and increase the saturation of the image. Experimental results via subjective and objective evaluations demonstrate that the proposed method can provide better visual quality than other methods and can effectively enhance the information in the specular reflection image.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "241",
      "title": "Complex Network–Based Change Propagation Path Optimization in Mechanical Product Development",
      "abstract": "Change propagation is a process in which a change to one part or element of a developed mechanical product tends to induce additional changes to other elements of the product, and the changes can propagate further iteratively. Different change propagation paths yield different change fulfillment costs (development expenditures, lead times, quality losses, etc.). In this study, we seek an optimal change propagation path based on complex theories, and by using this approach the cost of the change can be minimized. In particular, we introduce a modified Dijkstra algorithm coupled with a complex network described based on two variables: change probability and change impact. The network depicting the components of a mechanical product and their dependencies is directional while considering both node weights and edge weights. The roles of the components such as change absorbers, carriers, and multipliers are identified. Moreover, the loop change propagation paths and “AND” logical relations between sibling components are investigated. The practical application of the proposed models and methods is assessed using an industrial case example of an elevator system, and satisfactory results are obtained. The proposed method can be employed for analyzing different change propagation paths and their optimization in terms of overall costs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "242",
      "title": "Hybrid PSO-TS Based Distribution System Expansion Planning for System Performance Improvement Considering Energy Management",
      "abstract": "Energy management (EM) has become very attractive in smart grid era for both industry and academia. EM in a power distribution system (PDS) can reduce the system losses, operational costs and emissions, and increases system's reliability, voltage stability and efficiency. This article expands the PDS using different distributed energy resources (DERs) and observes their impacts on EM success, operational costs, system losses, and emissions. Moreover, the impacts of integrating reactive sources (RSs), energy storage systems (ESSs), and electric vehicles (EVs) on the system's operational performance is investigated. An index is defined to measure the energy management success rate (EMSR) and several case studies are created for investigating variety of system expansion options individually and collectively. Furthermore, a new reliability index, namely reliability index success rate (RISR), is defined and sensitivity analysis are presented to investigate the DERs impacts on system's voltage controllability and the defined reliability index. A new hybrid PSO-TS optimization algorithm is developed, and the well-known PG&E 69-bus distribution network is selected for the simulations. Several case studies presented in the paper provide a clear understanding of the impacts of integrating different resources on the EM as well as other operational aspects of a PDS. The results reveal that the system expansion using DERs with different capacities along with EM strategies could have significant impacts on PDS performance depending on the DERs types' and capacities. Due to their availability and low operational costs, gas turbine further improves the performance indices comparing to the renewables that have uncertain availability and to diesel generators with their high operational costs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "243",
      "title": "Comments on “On Favorable Propagation in Massive MIMO Systems and Different Antenna Configurations”",
      "abstract": "It is shown that the condition of Theorem 1 in (X. Wu, N. C. Beaulieu, D. Liu, “On favorable propagation in massive MIMO systems and different antenna configurations,” IEEE Access, vol. 5, pp. 5578-5593, May 2017) never holds in practice and that Theorem 2 is incorrect under the stated condition. Extra assumptions or/and modifications are needed to make the conclusions of Theorem 1 and 2 above valid, which are provided below.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "244",
      "title": "Spurious Vanishing Problem in Approximate Vanishing Ideal",
      "abstract": "Approximate vanishing ideal is a concept from computer algebra that studies the algebraic varieties behind perturbed data points. To capture the nonlinear structure of perturbed points, the introduction of approximation to exact vanishing ideals plays a critical role. However, such an approximation also gives rise to a theoretical problem-the spurious vanishing problem-in the basis construction of approximate vanishing ideals; namely, obtained basis polynomials can be approximately vanishing simply because of the small coefficients. In this paper, we propose a first general method that enables various basis construction algorithms to overcome the spurious vanishing problem. In particular, we integrate coefficient normalization with polynomial-based basis constructions, which do not need the proper ordering of monomials to process for basis constructions. We further propose a method that takes advantage of the iterative nature of basis construction so that computationally costly operations for coefficient normalization can be circumvented. Moreover, a coefficient truncation method is proposed for further accelerations. From the experiments, it can be shown that the proposed method overcomes the spurious vanishing problem, resulting in shorter feature vectors while sustaining comparable or even lower classification error.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "245",
      "title": "Development of Serious Games for Teaching Information Security Courses",
      "abstract": "Serious games have been used effectively in many educational domains. Games may be utilized efficiently to attract students to information security track. Learning practical knowledge about information security from a game is more engaging and less time consuming than learning through textbooks. Games that closely emulate real-world systems can improve learning about computer security above and beyond just reading technical documents and textbooks. From this perspective, this paper presents six serious games with various genres for teaching information security courses and evaluate their effectiveness as an efficient teaching tool. The study also determines which game genre is the most suitable for delivering educational contents. The obtained results proved and confirmed the hypothesis that educational games have a positive impact as a pedagogic tool on the educational process. According to users preferences', action/adventure game genre is the most preferred game genre followed by role-play.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "246",
      "title": "A Fast Fusion Method for Visible and Infrared Images Using Fourier Transform and Difference Minimization",
      "abstract": "Images of different modalities play important roles in the fields of military, navigation, and target detection, including visible and infrared images. Existing fusion methods can reach relatively good fusion effects, but often make the processing speed slow. To achieve the purpose of faster fusion, this paper proposes a fast fusion of visible and infrared images (FFVI) based on Fourier transform and difference minimization. First, both visible and infrared images are transformed using Fourier transform, and the contour information of infrared image is extracted out at the same time. Then the two transformed images are added together to obtain a composite image, the inverse Fourier transform and the grayscale normalization are performed on the composite transformation image, which will generate an image that reflects the target features. Finally, the resulting image is reconstructed by fusing visible and the generated images according to the principle of “difference minimization”. The experimental results show that the novel method FFVI proposed in this paper can attain remarkable fusion effects in terms of the subjective qualitative and the objective quantitative analysis. In addition, this method outperforms several representative image fusion algorithms in the computational speed, which will be beneficial to practical application.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "247",
      "title": "Fast Multicast With Adjusting Transmission Power and Active Slots in Software Define IoT",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "248",
      "title": "Robust Deep Learning-Based Driver Distraction Detection and Classification",
      "abstract": "Driver distraction is a major cause of road accidents. Distracting activities while driving include text messaging and talking on the phone. In this paper, we propose a robust driver distraction detection system that extracts the driver’s state from the recordings of an onboard camera using Deep Learning. We consider ten driving activities, which consist of one normal driving and nine distracted driving behaviors. Nine drivers were included in the experiments, and each one was asked to perform the ten activities in naturalistic and simulated driving situations. The main feature of the proposed solution is the extraction of the driver’s body parts, using deep learning-based segmentation, before performing the distraction detection and classification task. Experimental results show that the segmentation module significantly improves the classification performance. The average accuracy of the proposed solution exceeds 96% on our dataset and 95% on the public AUC dataset.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "249",
      "title": "You Can’t Fool All the Models: Detect Adversarial Samples via Pruning Models",
      "abstract": "Many adversarial attack methods have investigated the security issue of deep learning models. Previous works on detecting adversarial samples show superior in accuracy but consume too much memory and computing resources. In this paper, we propose an adversarial sample detection method based on pruned models and evaluate four different pruning methods. We find that pruned neural network models are sensitive to adversarial samples, i.e., the pruned models tend to output labels different from the original model when given adversarial samples. Moreover, the pruned model has an extremely small model size and computational cost. Based on the detection result, we further propose a simple but effective defense approach to identify the true label of the adversarial sample. Experiments show that, on average, four different pruning methods outperform the SOTA multi-model based detection method (64.15% and 73.70%) by 28.65% and 18.73% on CIFAR10 and SVHN, respectively, with significantly fewer models used. The FLOPs of our structured pruned model are only 49.41% and 25.62% of the original model. Our defense approach achieves 68.60% and 72.03% average classification accuracy on CIFAR10 and SVHN, exceeding other advanced defense methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "250",
      "title": "Opportunistic Spectrum Access for UAV Communications Towards Ultra Dense Networks",
      "abstract": "The growing popularity of unmanned aerial vehicle (UAV) attracts significant research interests and applications including low-altitude and airborne vehicles. Since there is no declared spectrum allocated to UAV communications, opportunistic transmission has been commonly considered as an important way for supporting UAV communications. When sharing the same spectrum with other users such as satellites and mobile base stations, accurate spectrum sensing and allocation are of critical importance for UAV communications to avoid serious interference. As the UAVs can constantly move to different locations with various spectrum environments, the spectrum decision may be invalid only in a short period, leading to require fast spectrum sensing. Furthermore, an UAV needs to predict possible temporal and spatial vacations of the spectrum. In this case, the spectrum prediction has a high dimensional state space which is notoriously difficult to solve. In this paper, some other issues such as how to determine the spectrum processing time and how to detect the primary signals with high priority to avoid interference, are also discussed. Finally, a fast spectrum sensing algorithm is proposed to improve the energy detection performance by optimizing the error estimation and a constant ratio of missed detection. Our proposed algorithm does not require high computational capability and can achieve relatively accurate sensing in low signal-to-noise ratio scenarios.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "251",
      "title": "Design and Characterization of an IQ Reflection-Type Vector Modulator for Ka-Band Using PIN Diodes",
      "abstract": "Vector modulators (VM) and phase shifters are essential components in phased array antennas with electronic beam steering. This work presents an IQ reflection-type vector modulator using PIN diodes, designed and implemented to operate at 28 GHz. An extensive characterization was carried out, especially concerning bandwidth and input/output return losses. This modulator is capable of producing a 360° phase shifting with a minimum attenuation of 14 dB at 28 GHz, and has a measured bandwidth of 3.6 GHz. A digital control system for the vector modulator was also developed, allowing to obtain pre-selected constellations points, with a measured 0.4 dB of maximum absolute error in amplitude and 2.6° in phase. Additionally, the designed VM was employed in a practical application, where analog beamforming is implemented in a 4 × 4 transmitter phased array allowing to perform a complete electronic control of the radiation pattern of the array.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "252",
      "title": "Angular Features-Based Human Action Recognition System for a Real Application With Subtle Unit Actions",
      "abstract": "Human action recognition (HAR) technology is receiving considerable attention in the field of human-computer interaction. We present a HAR system that works stably in real-world applications. In real-world applications, the HAR system needs to identify detailed actions for specific purposes, and the action data includes many variations. Accordingly, we conducted three experiments. First, we tested our recognition system’s performance on the UTD-MHAD dataset. We compared our system’s accuracy with results from previous research and confirmed that our system achieves a 91% average performance among recognition systems. Furthermore, we hypothesized the use of a HAR system to detect burglary. In the second experiment, we compared the existing benchmark data with our crime detection dataset. We recognized the test scenarios’ data by using the recognition system trained by each dataset. The recognition system trained by our dataset achieved higher accuracy than the past benchmark dataset. The results show that the training data should contain detailed actions for a real application. In the third experiment, we tried to find the motion data type that stably recognizes action regardless of data variation. In a real application, the action data are changed by people. Thus, we introduced variations in the action data using the cross-subject protocol and moving area setting. We trained the recognition system using each position and angle data. In addition, we compared the accuracy of each system. We found that the angle format results in better accuracy because the angle data are beneficial for converting the action variation into a consistent pattern.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "253",
      "title": "A Trainable Monogenic ConvNet Layer Robust in Front of Large Contrast Changes in Image Classification",
      "abstract": "At present, Convolutional Neural Networks (ConvNets) achieve remarkable performance in image classification tasks. However, current ConvNets cannot guarantee the capabilities of mammalian visual systems such as invariance to contrast and illumination changes. Some ideas for overcoming the illumination and contrast variations must usually be tuned manually and tend to fail when tested with other types of data degradation. In this context, a new bio-inspired entry layer is presented in this work, M6, which detects low-level geometric features (lines, edges, and orientations) similar to those patterns detected by the V1 visual cortex. This new trainable layer is capable of dealing with image classification tasks even with large contrast variations. The explanation for this behavior is due to the use of monogenic signal geometry, which represents each pixel value in a 3D space using quaternions, a fact that confers a degree of explainability to the networks. The M6 was compared to conventional convolutional layer (C) and a deterministic quaternion local phase layer (Q9). The experimental setup is designed to evaluate the robustness of this M6 enriched ConvNet model and includes three architectures, four datasets, and three types of contrast degradation (including non-uniform haze degradations). The numerical results reveal that the models with M6 are the most robust in front of any kind of contrast variations. This amounts to a significant enhancement of the C models, which usually have reasonably good performance only when the same training and test degradation are used, except for the case of maximum degradation. Moreover, the Structural Similarity Index Measure (SSIM) and Peak Signal to Noise Ratio (PSNR) are used to analyze and explain the robustness effect of the M6 feature maps under any kind of contrast degradations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "254",
      "title": "An Empirical Study Into the Success of Listed Smart Contracts in Ethereum",
      "abstract": "Since it takes time and effort to put a new product or service on the market, one would like to predict whether it will be a success. In general this is not possible, but it is possible to follow best practices in order to maximize the chance of success. A smart contract is intended to encode business logic and is therefore at the heart of every new business on the Ethereum blockchain. We have investigated how to measure the success of smart contracts, and whether successful smart contracts have characteristics that less successful smart contracts lack. The appearance of a smart contract on a listing website such as Etherscan or StateoftheDapps is such a characteristic. In this paper, we present a three-pronged analysis of the relative success of listed smart contracts. First, we have used statistical analysis on the publicly visible transaction history of the Ethereum blockchain to determine that listed contracts are significantly more successful than their unlisted counterparts. Next, we have conducted a survey among more than 200 developers via an anonymous online survey about their experience with the listing process. A significant majority of respondents do not believe that listing a contract itself contributes to its success, but they believe that the extra attention that is typically paid in tandem with the listing process does contribute. Finally, based on the respondents' answers, we have drafted 10 recommendations for developers and validated them by submitting them to an international panel of experts.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "255",
      "title": "A Comprehensive Study of the IoT Cybersecurity in Smart Cities",
      "abstract": "Smart cities exploit emerging technologies such as Big Data, the Internet of Things (IoT), Cloud Computing, and Artificial Intelligence (AI) to enhance public services management. The use of IoT allows detecting and reporting specific parameters related to different domains of the city, such as health, waste management, agriculture, transportation, and energy. LoRa technologies, for instance, are used to develop IoT solutions for several smart city domains thanks to its available features, but sometimes people (i.e., citizens, information technology administrators, or city managers) might think that these available features involve cybersecurity risks. This study explores the cybersecurity aspects that define an assessment model of cybersecurity maturity of IoT solutions to develop smart city applications. In that sense, we perform a systematic literature review based on a top-down approach of cybersecurity incident response in IoT ecosystems. Besides, we propose and validate a model based on risk levels to evaluate the IoT cybersecurity maturity in a smart city.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "256",
      "title": "p-Power Exponential Mechanisms for Differentially Private Machine Learning",
      "abstract": "Differentially private stochastic gradient descent (DP-SGD) that perturbs the clipped gradients is a popular approach for private machine learning. Gaussian mechanism GM, combined with the moments accountant (MA), has demonstrated a much better privacy-utility tradeoff than using the advanced composition theorem. However, it is unclear whether the tradeoff can be further improved by other mechanisms with different noise distributions. To this end, we extend GM (\n p=2p=2p=2 \n) to the generalized \n ppp \n-power exponential mechanism (\n ppp \nEM with \n p>0p>0p>0 \n) family and show its privacy guarantee. Straightforwardly, we can enhance the privacy-utility tradeoff of GM by searching noise distribution in the wider mechanism space. To implement \n ppp \nEM in practice, we design an effective sampling method and extend MA to \n ppp \nEM for tightly estimating privacy loss. Besides, we formally prove the non-optimality of GM based on the variation method. Numerical experiments validate the properties of \n ppp \nEM and illustrate a comprehensive comparison between \n ppp \nEM and the other two state-of-the-art methods. Experimental results show that \n ppp \nEM is preferred when the noise variance is relatively small to the signal and the dimension is not too high.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "257",
      "title": "Depression Prevalence in Postgraduate Students and Its Association With Gait Abnormality",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "258",
      "title": "A Simple Self-Tuning Resonant Control Approach for Power Converters Connected to Micro-Grids With Distorted Voltage Conditions",
      "abstract": "Over the last few decades, the consolidated goal of reducing greenhouse gasses has increased the relevance of renewable energy research, electromobility, energy storage, and distributed generation, micro-grids, among others. Micro-grids, systems working in islanding mode, are particular cases where some disadvantages are present due to the wide variations which may appear across their electrical quantities. Variations on the voltage amplitude and the frequency are intrinsic in the operation of weak grids, because they have low inertia and therefore the load must be able to cope with these variations, otherwise loads may trip electrical system protection. Particularly, on power electronic drives, these frequency deviations will lead to increased system nonlinearities, entailing a more critical controller design. To overcome these issues, this paper presents an implementation of a resonant controller with self-tuned gains. The strategy imposes a constant sampling time which allows these controllers to be used in variable frequency environments. In addition, the computational capacity required for the digital board is also considered. The simulated and experimental results provided demonstrate the good performance of this proposal.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "259",
      "title": "BERT, XLNet or RoBERTa: The Best Transfer Learning Model to Detect Clickbaits",
      "abstract": "Clickbait can be a spam or an advert which more often provides a link to commercial website and it can also be a headline to news media website which makes money from page views by providing eye-catchy headlines with deceptive news. This paper focuses on the latter definition in order to identify news clickbaits that are published in Twitter. The aim of this work is to use recent Transfer Learning models to detect news clickbaits by adding various configuration changes to the existing models. Based on the author’s knowledge, this is the first attempt to adapt Transfer Learning to classify Clickbaits in social media. In this work we fine-tuned BERT, XLNet and RoBERTa models by integrating novel configuration changes into their default architectures such as model expansion, pruning and data augmentation strategies. Webis Clickbait dataset was used to train these models and the best performed model at the Webit Clickbait competition 2017 was considered as our benchmark. The analyses in this work are mainly focused on eight different scenarios after applying several fine-tuning approaches and model configuration changes to the default Transfer Learning models. The results shown that, our modified Transfer Learning approaches outperformed the considered benchmark. In our experiments, the best performed Transfer Learning model was RoBERTa with the integration of an additional non-linear layer with the hidden output tensor. this configuration has achieved 19.12% more accuracy in compared to the benchmark model for the binary classification. There is no significant performance improvement when each model expanded by adding an extra RNN layer(s). Apart from that, we experimented with another labelled clickbait dataset (Kaggle clickbait challenge) to explore the performance of our fine-tuned models under different scenarios.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "260",
      "title": "An Enhanced Naive Bayes Model for Dissolved Oxygen Forecasting in Shellfish Aquaculture",
      "abstract": "It is difficult to predict dissolved oxygen values because they are disordered and nonlinear. Accurate prediction of dissolved oxygen in shellfish aquaculture plays an important role in improving shellfish production, and a reliable model is needed to accurately predict dissolved oxygen values. Therefore, in this paper, an enhanced naive Bayes (NB) model is proposed. Due to the excessive number of different dissolved oxygen values, their direct use as input samples will result in overly few training set categories for each value, which reduces the prediction accuracy. Therefore, the dissolved oxygen differential series dataset is used as the input data to reduce the number of training set categories and improve the training accuracy. To increase the number of samples in the training set, the sliding window concept from network communication protocols is used to partition the differential sequence dataset and generate the features and labels of the training set. The values were predicted as categories, and the dissolved oxygen data were accurately predicted by selecting the labels that correspond to the posterior probability maxima of all training samples. Finally, the algorithm is used to predict the dissolved oxygen data from February 18, 2016, to January 31, 2020, in Yantai, Shandong Province, China. The dissolved oxygen data of a shellfish farm were trained and predicted, and the best values of the feature lengths were optimized by analyzing their effects on the predicted dissolved oxygen values. The proposed algorithm has significantly improved the mean absolute error (MAE), root mean square error (RMSE), and mean absolute percentage error (MAPE) compared to the advanced algorithms. The results of the Diebold-Mariano test and 10-fold cross-validation also show that the proposed algorithm has a higher prediction accuracy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "261",
      "title": "Interplay Between γ–Ray Irradiation and 3DEG for Dosimeter Applications",
      "abstract": "This work investigates the cumulative dose \n60\nCo gamma (\n γ\\gamma \n) – ray irradiation effects on enhancement mode HEMT devices inheriting 3D – Electron and Hole Gases for dosimeter applications. The devices are irradiated through a \n60\nCo source and demonstrate the enhancement in the drain current metrics. To elucidate, the said devices were irradiated through different mechanisms and the Compton effect was investigated through contour plots via TCAD simulations. The degradation of Schottky Gate contact and insulator charging affects the 2D – Hole Gas at the GaN cap and thereby affects the bottleneck at the 3DEG sheet. This significantly affects the OFF – state leakage components of the said device and can therefore be exploited for potential use in sensing and dosimeter applications. The leakage components can be exploited further to improve the linearity of the dosimeter by considering different grading profiles of the AlGaN layer. In this regard, a workflow for optimizing the sensitivity and linearity of the dosimeter through different graded profiles is also presented. Amongst all, gaussian graded profiles have been identified as the best – case scenario considering the sensitivity and exhibiting a linear operation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "262",
      "title": "Comparing Advanced Control Strategies to Eliminate Stick-Slip Oscillations in Drillstrings",
      "abstract": "In this paper, we present three methods to achieve reliable drillbit angular velocity control for deep drilling operations. We consider a multi-sectional drilling system with the bit off-bottom, which represents the system at the start-up of a drilling operation, e.g., after a connection. The three control procedures are all based on a distributed model for the drilling system. The proposed model has been field validated and considers Coulomb friction between the drillstring and the borehole. The first algorithm we propose combines the industry standard ZTorque controller with a feedforward component. The second procedure is based on a multiplicity-induced-dominancy (MID) design that corresponds to a pole-placement for the downhole state. Finally, the last class of controllers relies on a recursive interconnected dynamics framework. All the controllers are combined with a disturbance rejection procedure whose design is based on a switching-mode approach. These three algorithms are illustrated in simulations with field scenarios on several test-cases. Their complexities, effectiveness and limitations regarding industrial implementation criteria are discussed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "263",
      "title": "On Modeling Link Flooding Attacks and Defenses",
      "abstract": "The emerging link flooding attacks (LFAs) are one type of attacks that attract significant attention in both academia and industry against the routing infrastructure. The attack traffic flows originating from bots (e.g., compromised IoT devices) are deliberately aggregated at upstream critical links and grow intensified, gradually making a network connected to the critical links disconnected. Although LFAs are far more sophisticated than traditional DDoS attacks, whether such sophistication comes without a downside has never been investigated. In this paper, by modeling link flooding attacks and defenses, we tackle a series of questions concerning the practical issues of LFAs. Specifically, from the perspective of attacks, we advance a novel notion of \nstrike precision\n, and reveal that LFAs may exhibit \nattack interference\n (i.e., unexpectedly interfere the connectivity of innocent networks) which might undermine the stealthiness and persistence of LFAs. From the perspective of defenses, we make the first step to study \nattack intention\n, i.e., inversely inferring the target network to disconnect based on the identified links under attack. Furthermore, we consider a strong defender who employs traffic engineering to mitigate LFAs, and formulate the game-theoretic interactions between attackers and defenders. The experiment results show that attack interference is pervasive, and our proposed SPAH flooding strategy can substantially lower attack interference and increase strike precision. Moreover, we demonstrate that LFAs can be effectively mitigated based on traffic engineering from a game-theoretic perspective, wherein the defender can adopt non-cooperative measurement techniques to achieve light-weight and multi-protocol-based robust probe deployment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "264",
      "title": "Exploring the Dynamic Voltage Signature of Renewable Rich Weak Power System",
      "abstract": "Large-scale renewable energy-based power plants are becoming attractive technically and economically for generation mix around the world. Nevertheless, network operation has significantly changed due to the rapid integration of renewable energy in supply side. The integration of more renewable resources, especially inverter-based generation, deteriorates power system resilience to disturbances and substantially affects stable operations. The dynamic voltage stability becomes one of the major concerns for the transmission system operators (TSOs) due to the limited capabilities of inverter-based resources (IBRs). A heavily loaded and stressed renewable rich grid is susceptible to fault-induced delayed voltage recovery. Hence, it is crucial to examine the system response upon disturbances, to understand the voltage signature, to determine the optimal location and sizing of grid-connected IBRs. Moreover, the IBRs fault contribution mechanism investigation is essential in adopting additional grid support devices, control coordination, and the selection of appropriate corrective control schemes. This article utilizes a comprehensive assessment framework to assess power systems' dynamic voltage signature with large-scale PV under different realistic operating conditions. Several indices quantifying load bus voltage recovery have been used to explore the system' s steady-state, transient response, and voltage trajectories. The recovery indices help extricate the signature and influence of IBRs. The proposed framework's applicability is carried out on the New England IEEE - 39 bus test system using the DIgSILENT platform.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "265",
      "title": "Corrections to “Complex Permittivity of NaOH Solutions Used in Liquid-Metal Circuits”",
      "abstract": "In the above article \n[1]\n, \nTable 1\n, Figs. 4 and 5, and Appendices A and B of the associated supplementary materials unfortunately contain minor errors. This article serves to correct those errors.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "266",
      "title": "Adversarial Learning and Interpolation Consistency for Unsupervised Domain Adaptation",
      "abstract": "Unsupervised domain adaptation (UDA) aims to learn a prediction model for the target domain given labeled source data and unlabeled target data. Impressive progress has been made by adversarial learning-based methods that align distributions across domains through deceiving a domain discriminator network. However, these methods only try to align two domains and neglect the boundaries between classes, which may lead to false alignment and poor generalization performance. In contrast, consistency-enforcing methods exploit the target data posterior distribution to make the target features far away from decision boundaries. Despite their efficacy, these approaches require additional intensity augmentation to align distributions when encountering datasets with large domain discrepancy. To solve the above problems, we propose a novel UDA method that unifies the adversarial learning-based method and consistency-enforcing method together to take both domain alignment and boundaries between classes into consideration. In addition to the supervised classification on the source domain and the adversarial domain adaptation, we introduce interpolation consistency into the UDA task. To be specific, we first construct robust and informative pseudo labels for target samples, and then we encourage the prediction at an interpolation of unlabeled target samples to be consistent with the interpolation of the pseudo labels of these samples. The extensive empirical results demonstrate that our method achieves state-of-the-art results on both digit classification and object recognition tasks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "267",
      "title": "SEQ2SEQ++: A Multitasking-Based Seq2seq Model to Generate Meaningful and Relevant Answers",
      "abstract": "Question-answering chatbots have tremendous potential to complement humans in various fields. They are implemented using either rule-based or machine learning-based systems. Unlike the former, machine learning-based chatbots are more scalable. Sequence-to-sequence (Seq2Seq) learning is one of the most popular approaches in machine learning-based chatbots and has shown remarkable progress since its introduction in 2014. However, chatbots based on Seq2Seq learning show a weakness in that it tends to generate answers that can be generic and inconsistent with the questions, thereby becoming meaningless and, therefore, may lower the chatbot adoption rate. This weakness can be attributed to three issues: question encoder overfit, answer generation overfit, and language model influence. Several recent methods utilize multitask learning (MTL) to address this weakness. However, the existing MTL models show very little improvement over single-task learning, wherein they still generate generic and inconsistent answers. This paper presents a novel approach to MTL for the Seq2Seq learning model called SEQ2SEQ++, which comprises a multifunctional encoder, an answer decoder, an answer encoder, and a ternary classifier. Additionally, SEQ2SEQ++ utilizes a dynamic tasks loss weight mechanism for MTL loss calculation and a novel attention mechanism called the comprehensive attention mechanism. Experiments on NarrativeQA and SQuAD datasets were conducted to gauge the performance of the proposed model in comparison with two recently proposed models. The experimental results show that SEQ2SEQ++ yields noteworthy improvements over the two models on bilingual evaluation understudy, word error rate, and Distinct-2 metrics.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "268",
      "title": "Hierarchically Structured Flexible Electrode on Polyimide for Highly Sensitive and Reliable Biosignal Acquisition",
      "abstract": "Numerous wearable biomedical devices are developed for the continuous monitoring of personal health or condition. Biosignals acquisition with high sensitivity is important for designing wearable biomedical devices. A sensing electrode between the human body and wearable electronics significantly affects the sensitivity of the sensors. In this study, we fabricated hierarchically structured flexible electrodes on polyimide substrate (HSFE-PI) using micro-casting technique and gold nanoparticles electrodeposition. Polyimides provides robust and outstanding electrical characteristics, and the reliability of HSFE-PI was verified with a cyclic bending test. The integration of hierarchical structures significantly increased the surface area of the electrode by 2.06 times. We applied the HSFE-PI for electromyogram (EMG) and glucose sensing applications and achieved high sensitivity enhancement in both applications. The signal-to-noise ratio (SNR) of measured EMG signals was increased by 2.48 times, and the sensitivity of the glucose detection was increased by 1.42 times compared to the planar counterpart.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "269",
      "title": "A Case Study on the Monitor Mode Passive Capturing of WLAN Packets in an On-the-Move Setup",
      "abstract": "Monitor mode packet capturing of WLAN is used to derive Access points and devices in the range for localization or occupancy purposes. The general modality of capturing and analysis in almost all available studies is to capture packets by being static (STT) at a location and indoors. In STT mode, the beacon and probe packets extract insights about the localization of devices and occupancy estimation. We propose scanning a predetermined path in an urban locality on the move (OTM) using monitor mode WLAN packet capturing. We also propose that in OTM, devices (STA) and Access Points (APs) can be traced from other packets like CTS, ATS, and ACKs apart from beacons and frames. We performed a case study of monitor mode packet capturing in an on-the-move and outdoor setup. The primary focus of the study was to validate the OTM modality and the methodology of detecting devices and APs. We studied all the packet types that were captured, including Beacons and Probes. The sensed devices and APs counts using probe and beacon packets were compared with the sensed devices, and APs counts using the new methodology. We found that considering other packets helps detect a more significant number of devices and APs. We also found that channel hoping strategy plays an essential role in maximizing the sensed items. The overall exercise revealed that the air is full of WLAN/Wi-Fi traffic, and using OTM can assimilate lots of valuable data and generate relevant information for various purposes. Essentially, on-the-move outdoor capture setups can be used to produce Wi-Fi access points and user devices related heat maps of the scanned locations. This can be useful in many governance and related matters. Briefly, we put forward an application architecture for the same.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "270",
      "title": "An eXtreme Gradient Boosting Algorithm Combining Artificial Bee Colony Parameters Optimized Technique for Single Sand Body Identification",
      "abstract": "Due to the problems of traditional artificial single sand body identification methods such as strong subjectivity, heavy workload and low efficiency, we propose a fast and objective ABC-XGBoost. The algorithm consists of two parts: eXtreme gradient boosting (XGBoost) and artificial bee colony algorithm (ABC). XGBoost introduces a regular term, which can effectively prevent overfitting, and uses the second derivative to make the identification result more accurate. However, a large number of parameters in XGBoost need to be adjusted manually, which affects the efficiency of the algorithm. In this regard, ABC is used to optimize the parameters based on XGBoost, and then the single sand body can be identified quickly and effectively. We take the \nC6\n \n _{1}^{2}21_{1}^{2} \n oil-bearing layer in the second area of Dalugou, Jing’an Oilfield as the research object, and use the ABC-XGBoost to identify the single sand body in the research area. Based on the reasonable selection of physical parameter data and logging data, the partition and interlayer data should be eliminated first to avoid data redundancy. The results indicate that ABC-XGBoost is more efficient and accurate than the existing mainstream machine algorithms, such as support vector machines (SVM), random forests (RF), and XGBoost using trial and error tuning under the same logging data and computer hardware conditions. The accuracy can reach 90.6%, which has certain practical application value in the middle and late development of oil and gas fields.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "271",
      "title": "A Complex Event Processing-Based Online Shopping User Risk Identification System",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "272",
      "title": "Enhanced Model Predictive Control-Based STATCOM Implementation for Mitigation of Unbalance in Line Voltages",
      "abstract": "This paper presents detailed implementation of static synchronous compensator (STATCOM) based on model predictive control (MPC) for mitigating unbalance in line voltages. The main objective is to evaluate the capability of an enhanced MPC state-space model that can be applied in a general form for any power system. The proposed enhanced MPC state-space model presented in this paper is adapted for mitigating unbalanced voltages at nominated buses by injecting suitable unbalanced currents and reactive powers by STATCOM. In addition, a proposed MPC objective function is developed and implemented to predict STATCOM injected output current according to line voltages of adjacent buses. This enables expecting the fluctuations from any part in the network to maintain nominated bus voltage at reference value. The results of MPC technique are compared with the same MPC technique developed for balanced line voltage mode.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "273",
      "title": "Proof of Pseudonym: Blockchain-Based Privacy Preserving Protocol for Intelligent Transport System",
      "abstract": "Intelligent Transportation System is the future for safe and secure transportation. Vehicles in the ITS share basic safety information which can prompt the disclosure of the real identity of the vehicles. Thus, adversaries can misuse these safety messages. Pseudonyms are alias granted to vehicles by trusted authorities to conceal their original identities. To avoid linkability, various pseudonym generation and distribution protocols have been proposed. Such protocols pose overheads in the system as they are performed by Central Authorities. Therefore, re- utilizing the existing pseudonyms through shuffling is the most optimal mechanism for ITS. The Blockchain is a digital ledger and tamper-resistant record of transactions. It eliminates the need for central authority as well as provides anonymity of transactions resulting in more secure and privacy-protected solutions. To handle distribution optimization issues in the pseudonym shuffling process without a central authority, the blockchain is used with its distributed consensus. The shuffling results are logged in blocks as transactions. Pseudonym shuffle randomness is achieved via blockchain and it provides robustness in the structure. When one system fails, the rest would continue to work. The method also provides a fully traceable record in case of certification revocation. The existing blockchain-based pseudonym shuffling mechanism uses traditional consensus algorithms to support the cryptography operation. This leads to overhead in terms of execution time and memory usage. This research proposes Proof of Pseudonym consensus protocol for the shuffling scheme to improve the efficiency of consensus as compared to Proof of Work, Proof of Kernel Work and, Proof of Elapsed Time in terms of time and memory. The execution time of Proof of Pseudonym is shorter than other algorithms. The security and privacy analysis revealed that our scheme achieves identity privacy, unlinkability, and non-repudiation properties. Threat ...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "274",
      "title": "The Datacube Reconstruction Approach for Compressed Sensing Image Mapping Spectrometer (CSIMS)",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "275",
      "title": "Lightweight Secure Message Delivery for E2E S2S Communication in the IoT-Cloud System",
      "abstract": "The continuous increase in the use of smart devices and the need for E2E smart2smart (S2S) services in IoT systems play effective and contemporary roles in the field of communication, and a large amount of resources is required. Thus, IoTs and cloud computing must be integrated. One of the results of this integration is the increase in the number of attacks and vulnerabilities in the E2E S2S message delivery service of such an IoT-cloud system. However, none of the traditional security solutions can be sufficiently regarded as a secure and lightweight mechanism for ensuring that the security requirements for E2E S2S message transmission in the IoT-cloud system are fulfilled. This work aims to provide an efficient and secure, lightweight E2E S2S message delivery function, which includes the E2E S2S secure key and biometric parameter exchange function, a bio-shared parameter and bio-key generation function, secure lightweight E2E S2S communication negotiation and secure E2E S2S lightweight message delivery. The secure, lightweight cryptographic communication procedure is negotiated between a pair of smart devices during each E2E session to minimize the power consumption required of limited-energy devices. Such a negotiation process prevents known attacks by providing responsive mutual authentication. Lightweight message delivery by the two smart devices can satisfy the basic security requirements of E2E communication and ensure that the computational cost required for a real-time system is as low as possible.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "276",
      "title": "Analysis of Connected Arrays and Capacitively Coupled Arrays",
      "abstract": "The concept of connected and capacitively coupled dipoles in a planar array, which improves wideband performance, is investigated. A long wire with multiple feeds acts as an array in connected arrays, whereas a capacitively coupled array uses capacitors between array elements. Both approaches attempt to approximate the current sheet of Wheeler. Using spectral Green’s function, the array active impedance is calculated. The impedance mismatch of a connected/capacitively coupled dipole array is less than that of an array of unconnected dipoles of the same size. Both direct and capacitive connections can be used to design a wideband array antenna with a ground plane, although capacitive coupling performs better than a direct connection. This fact resulted from numerous analytical studies using infinite dipole array scan (active) impedance endorsed by full-wave simulations using CST MWS. The maximum mismatch losses over the frequency band for different source (reference) impedances are used to find the best solution at the broadside. The average reflected power over all scan angles is applied, for the scan performance, and then, the maximum average mismatch loss over the frequency band is investigated.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "277",
      "title": "Dynamic Analysis of User-Role and Topic-Influence for Topic Propagation in Social Networks",
      "abstract": "Hot events spread quickly on social networks. Predicting event diffusion on social networks, also known as topic propagation, is an important task. The two important factors that affect topic propagation are users and topics, and both users’ roles and topics’ influences are time dependent on social networks. However, existing studies have largely overlooked this fact, so topic propagation prediction is still a major challenge. In this paper, a Topic Propagation Prediction method is proposed based on Dynamic Analysis of user-role and topic-influence, named TPP-DA, which predicts the topic propagation on social networks from both users’ and topics’ perspectives. First, we introduce a temporal perspective to improve the static analysis to the dynamic analysis of user-role, which is more adaptable to the changeable user-roles on social networks. Second, we introduce a metric called the topic heat to dynamically analyze the topic-influence on a single user and social group. Third, we combine the dynamic analysis of user-role and topic-influence with a weighted probability model to accurately predict topic propagation trends. The weights are determined by the dynamic analysis of user-role and topic-influence. Finally, several experiments are conducted to evaluate TPP-DA. Compared with TPP, the average error rate of TPP-DA is reduced by approximately 33%, which proves the efficiency of TPP-DA.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "278",
      "title": "A Hybrid Reinforcement Learning-Based Model for the Vehicle Routing Problem in Transportation Logistics",
      "abstract": "Currently, the number of deliveries handled by transportation logistics is rapidly increasing because of the significant growth of the e-commerce industry, resulting in the need for improved functional vehicle routing measures for logistic companies. The effective management of vehicle routing helps companies reduce operational costs and increases its competitiveness. The vehicle routing problem (VRP) seeks to identify optimal routes for a fleet of vehicles to deliver goods to customers while simultaneously considering changing requirements and uncertainties in the transportation environment. Due to its combinatorial nature and complexity, conventional optimization approaches may not be practical to solve VRP. In this paper, a new optimization model based on reinforcement learning (RL) and a complementary tree-based regression method is proposed. In our proposed model, when the RL agent performs vehicle routing optimization, its state and action are fed into the tree-based regression model to assess whether the current route is feasible according to the given environment, and the response received is used by the RL agent to adjust actions for optimizing the vehicle routing task. The procedure repeats iteratively until the maximum iteration is reached, then the optimal vehicle route is returned and can be utilized to assist in decision making. Multiple logistics agency case studies are conducted to demonstrate the application and practicality of the proposed model. The experimental results indicate that the proposed technique significantly improves profit gains up to 37.63% for logistics agencies compared with the conventional approaches.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "279",
      "title": "A Hybrid Approach and Unified Framework for Bibliographic Reference Extraction",
      "abstract": "Publications are an integral part of a scientific community. Bibliographic reference extraction from scientific publication is a challenging task due to diversity in referencing styles and document layout. Existing methods perform sufficiently on one dataset however, applying these solutions to a different dataset proves to be challenging. Therefore, a generic solution was anticipated which could overcome the limitations of the previous approaches. The contribution of this paper is three-fold. First, it presents a novel approach called DeepBiRD which is inspired by human visual perception and exploits layout features to identify individual references in a scientific publication. Second, we release a large dataset for image-based reference detection with 2401 scans containing 38863 references, all manually annotated for individual reference. Third, we present a unified and highly configurable end-to-end automatic bibliographic reference extraction framework called BRExSys which employs DeepBiRD along with state-of-the-art text-based models to detect and visualize references from a bibliographic document. Our proposed approach pre-processes the images in which a hybrid representation is obtained by processing the given image using different computer vision techniques. Then, it performs layout driven reference detection using Mask R-CNN on a given scientific publication. DeepBiRD was evaluated on two different datasets to demonstrate the generalization of this approach. The proposed system achieved an AP50 of 98.56% on our dataset. DeepBiRD significantly outperformed the current state-of-the-art approach on their dataset. Therefore, suggesting that DeepBiRD is significantly superior in performance, generalized, and independent of any domain or referencing style.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "280",
      "title": "A New Algorithm for Displaying Images With High Resolution Using a Directional Volumetric Display With Threads and a Projector",
      "abstract": "Using threads and a projector, a directional volumetric display capable of moving images and full-color representation was developed in our previous work. However, the horizontal resolution of the directional volumetric display could only achieve 20 pixels with 400 threads. Further, the conventional algorithm requires P squared threads per P horizontal pixels of the input image. Because it is difficult to place a large number of threads, thus, a new algorithm for developing projected images to improve the directional volumetric display’s resolution was proposed. It is feasible to display images of P pixels with at least P threads using this technique. However, the higher the resolution, the lower the image quality in the proposed algorithm. Thus, it was verified how many threads can be used to display high-resolution images without degrading the image quality. Further, by representing the horizontal resolution of the input image with 5–6 threads per pixel, it is possible to display high-resolution images while maintaining the image quality. The proposed technique can display 64 pixels per 384 threads, whereas the conventional method can only display 20 pixels input images per 400 threads.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "281",
      "title": "Tactical Decision-Making for Autonomous Driving Using Dueling Double Deep Q Network With Double Attention",
      "abstract": "Decision-making is still a significant challenge to realize fully autonomous driving. Using deep reinforcement learning (DRL) to solve autonomous driving decision-making problems is a recent trend. A common method is to encode surrounding vehicles in a grid to describe the state space to help DRL network extract the scene features. However, in the process of human driving, surrounding vehicles at different positions have different contributions to decision-making. Meanwhile, the network is difficult to fully extract useful features in a sparse state, which can also lead to catastrophic actions. Therefore, this work proposes a spatial attention module to calculate different weights to represent different contributions to decision-making results. And a channel attention module is proposed to fully extract useful features in sparse state features. These two attention modules are integrated into dueling double deep Q network, named D3QN-DA, as a high-level decision-maker of a hierarchical hierarchical control structure based decision-making system. To improve agent performance, an emergency safe checker is introduced in this system. And the agent is trained and test with a designed reward function from safety and efficiency in simulation. The experimental results show that the proposed method increases the safety rate by 54%, and the average explore distance by 30%, which is safer and more intelligent for the decision-making process of automatic driving.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "282",
      "title": "Sparse Graph Learning Under Laplacian-Related Constraints",
      "abstract": "We consider the problem of learning a sparse undirected graph underlying a given set of multivariate data. We focus on graph Laplacian-related constraints on the sparse precision matrix that encodes conditional dependence between the random variables associated with the graph nodes. Under these constraints the off-diagonal elements of the precision matrix are non-positive (total positivity), and the precision matrix may not be full-rank. We investigate modifications to widely used penalized log-likelihood approaches to enforce total positivity but not the Laplacian structure. The graph Laplacian can then be extracted from the off-diagonal precision matrix. An alternating direction method of multipliers (ADMM) algorithm is presented and analyzed for constrained optimization under Laplacian-related constraints and lasso as well as adaptive lasso penalties. Numerical results based on synthetic data show that the proposed constrained adaptive lasso approach significantly outperforms existing Laplacian-based approaches. We also evaluate our approach on real financial data.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "283",
      "title": "Investigation of DNN-HMM and Lattice Free Maximum Mutual Information Approaches for Impaired Speech Recognition",
      "abstract": "Assistive tools that recognize impaired speech due to neurological disorders are emerging and its a fairly complex task. An Intelligent Impaired Speech Recognition system helps persons with speech impairment to improve their interactions with outside world. Impaired speakers have difficulty in pronouncing words which results in partial or incomplete speech contents. Existing Automatic Speech Recognition systems are not effective for Impaired Speech Recognition due to the speaker specific variations which depend on the severity of the neurological disorders. In this work, we have investigated two important approaches namely, Deep Neural Network-Hidden Markov Model and Lattice Free Maximum Mutual Information approach for effective recognition of impaired speech in Tamil language. The training and testing samples are collected from persons with different neurological disorders at varied intelligibility levels such as high, medium, low and very low. The recognition accuracy is evaluated and compared using two datasets namely 20 acoustically similar words and 50 words Impaired Speech Corpus in Tamil.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "284",
      "title": "Optimal Design of Accelerated Life Test Plan for Test Standard of a Manufacturer Making Multi-Series Products",
      "abstract": "To win fierce competition, a manufacturer would produce multi-series products to meet the diverse needs of customers. These products shall comply with the same test standard to estimate reliability before being launched into market. Extensive research has been conducted on the optimal design of accelerated life test (ALT) for a single type of product. However, these methods only utilize the information of a certain type of product and hence might not obtain an optimal plan for other products. This motivates us to study the planning of ALT for a manufacturer making multi-series products. Two criteria, i.e., the minimum sum and the minimum maximum of the asymptotic variance (Avar) of the life at a given percentile, are proposed to design the ALT plan optimally. The analytical solutions are derived for some special cases and numerical methods are provided for more general cases. We further explore the difference between test plans obtained by the two criteria in the cases of small and large number of product categories. Two numerical examples are presented to illustrate the application of the proposed method. The methodology proposed in this paper would be vital for a manufacturer to design its test standard.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "285",
      "title": "Making Connected Cars Untraceable via DSRC Radios",
      "abstract": "This article shows potential of using DSRC radios for vehicle tracking protection. We focus on traffic data collection as our target application where vehicles send their locations to a server while driving. Such vehicles are easily trackable-revealing location history-as the application often requires frequent and accurate location updates. This article presents PathCloak, a method that enables vehicles to report their locations while preventing the server from properly tracking the vehicles. PathCloak leverages vehicles' two network interfaces: in-car Internet (for accessing the server) and car-to-car DSRC (for creating path confusion). PathCloak-enabled vehicles exchange their kinematic information via DSRC radios, and use it to generate plausible path segments for each other, making their paths indistinguishable each other from the server's viewpoint. We demonstrate its feasibility via field experiments on real roads using our DSRC testbeds. Our evaluation shows that PathCloak offers strong privacy (tracking success ratio<; 1%), while maintaining high utility for various traffic statistics.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "286",
      "title": "Robust Fuzzy-Stochastic Programming Model and Meta-Heuristic Algorithms for Dual-Resource Constrained Flexible Job-Shop Scheduling Problem Under Machine Breakdown",
      "abstract": "Resource scheduling, job sequencing, and assigning them to available resources are the most critical issues in manufacturing systems, such as flexible job-shop systems. In addition, scheduling uncertainties have attracted significant attention in this field. This study investigates the dual-resource constrained flexible job-shop scheduling (DRCFJSS) problem under machine breakdown and operational uncertainty. Stochastic scenario-based methods were utilized to study the uncertain nature of the problem. Because process times have inherent uncertainty, they are considered fuzzy numbers and are controlled by a credibility-based measure. Robust scheduling must be developed to address unexpected disruptions, such as machine breakdowns and operational risks, such as uncertain process times. Accordingly, a novel robust fuzzy stochastic programming (RFSP) model is presented for this problem. In the proposed RFSP model, the objective function is formulated using a hybrid measure (i.e., a combined average-case and worst-case performance of the manufacturing system) under probable machine breakdown scenarios. Because the DRCFJSS problem is NP-hard, two types of meta-heuristic algorithms, evolutionary population-based, genetic algorithm (GA), and vibration damping optimization (VDO) algorithm, are used for large-sized problems. Then, the proposed RFSP model was applied to a case study, and numerical experiments with randomly generated test problems were used. In small-sized problems, the proposed model is solved using the CPLEX solver, GA and VDO algorithms. Also, the computational study confirms the proper quality of the results of the GA and VDO algorithms in medium and large-sized problems.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "287",
      "title": "Assessment of Damping Control Using Maximum Power Point Tracking Methods for Heaving Wave Energy Converters",
      "abstract": "There are not many studies conducted in the implementation of maximum power point tracking (MPPT) methods for heaving wave energy converters (WECs). An assessment of damping control using various MPPT methods for heaving WEC was conducted in this study. Damping control was implemented using a DC–DC boost converter. The duty cycle for MPPT was determined using a perturb and observe algorithm. This assessment study determines the following for applying MPPT for heaving WECs: best location for the observing parameters; best performance index for the MPPT; and effect of averaging the performance index. Three locations for the observing parameters (mechanical parameters near the source, electrical parameters at the load, and electrical parameters between the source and load) and three performance indices (maximising power, minimising impedance, and maximising admittance) were assessed and evaluated. Finally, the effects of applying the running mean and conventional instantaneous value on the performance index were compared. Various scenarios using nine MPPT methods were tested using simulated regular and irregular sea states. The test results were validated experimentally using a simple and low-cost hardware-in-the-loop (HIL) scheme. The HIL scheme was developed using off-the-shelf devices that can be used for any topology of WECs. The results showed that the MPPT method has an optimum performance by using the performance index for maximising power, using observing parameters between the source and the load, and deploying conventional instantaneous values for the observing parameters.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "288",
      "title": "A Novel Hierarchical Topic Model for Horizontal Topic Expansion With Observed Label Information",
      "abstract": "Hierarchical topic models, such as hierarchical Latent Dirichlet Allocation (hLDA)and its variations, can organize topics into a hierarchy automatically. On the other hand, there are lots of documents associated with hierarchical label information. Incorporating these information into the topic modeling process can help users to obtain a more reasonable hierarchical structure. However, after analyzing various real-world datasets, we find that these hierarchical labels are ambiguous and conflicting in some levels, which introduces error and restriction to the latent topic and the hierarchical structure exploration process. We call it the horizontal topic expansion problem. To address this problem, in this paper, we propose a novel hierarchical topic model named horizontal and vertical hierarchical topic model (HV-HTM), which aims to incorporate the observed hierarchical label information into the topic generation process, while keeping the flexibility of horizontal and vertical expansion of the hierarchical structure in the modeling process. We conduct experiments on BBC news and Yahoo! Answers datasets and evaluate the effectiveness of HV-HTM on three evaluation metrics. The experimental results show that HV-HTM has a significant improvement on topic modeling, compared to the state-of-the-art models, and it can also obtain a more interpretable hierarchical structure.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "289",
      "title": "LOTR: Face Landmark Localization Using Localization Transformer",
      "abstract": "This paper presents a novel Transformer-based facial landmark localization network named Localization Transformer (LOTR). The proposed framework is a direct coordinate regression approach leveraging a Transformer network to better utilize the spatial information in a feature map. An LOTR model consists of three main modules: 1) a visual backbone that converts an input image into a feature map, 2) a Transformer module that improves the feature representation from the visual backbone, and 3) a landmark prediction head that directly predicts landmark coordinates from the Transformer’s representation. Given cropped-and-aligned face images, the proposed LOTR can be trained end-to-end without requiring any post-processing steps. This paper also introduces a loss function named smooth-Wing loss, which addresses the gradient discontinuity of the Wing loss, leading to better convergence than standard loss functions such as L1, L2, and Wing loss. Experimental results on the JD landmark dataset provided by the First Grand Challenge of 106-Point Facial Landmark Localization indicate the superiority of LOTR over the existing methods on the leaderboard and two recent heatmap-based approaches. On the WFLW dataset, the proposed LOTR framework demonstrates promising results compared with several state-of-the-art methods. Additionally, we report an improvement in the performance of state-of-the-art face recognition systems when using our proposed LOTRs for face alignment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "290",
      "title": "Improved Exact Evaluation of Equal-Gain Diversity Receivers in Rayleigh Fading Channels",
      "abstract": "In this paper, we evaluate the performance of equal-gain-combining (EGC) receivers operating in Rayleigh fading channels in terms of the outage probability (OP) and the average symbol error rate (ASER). For this, we first derive novel, improved, fast, and exact series representations for the probability density function (PDF) and the cumulative distribution function (CDF) of the sum of independent and identically distributed Rayleigh random variables by employing complex analysis as well as the properties of the moment-generating function (MGF). With these results, exact and closed-form-asymptotic expressions to evaluate the OP and the ASER are derived. The efficiency of our expressions, defined in terms of tractability, computational burden, and computation time, overcome the state-of-the-art solutions. Monte-Carlo simulations and a time comparison analysis with the state-of-the-art study support our results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "291",
      "title": "Automatic Segmentation of Human Placenta Images With U-Net",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "292",
      "title": "Dispatchable High-Power Wind Turbine Based on a Multilevel Converter With Modular Structure and Hybrid Energy Storage Integration",
      "abstract": "This paper presents a new multilevel converter solution with modular structure and hybrid energy-storage integration suitable to drive modern/future high-power medium-voltage wind turbines. The hybrid energy-storage integration means that part of the converter submodules are built with batteries and part of them with conventional capacitors. Since traditional wind turbines are non-dispatchable generators, the integration of an energy storage system could be beneficial in multiple ways as the wind power plant could provide stability support to the grid, improvement of the unit commitment and economic dispatch, and the power plant owner could increase his revenues in the electricity market. The capacitors of the proposed converter are responsible to transfer the power produced by the wind turbine to the grid, and the batteries are only charged/discharged with the mismatch between the power produced by the turbine and the power to be injected into the grid, considering a dispatchable operation where the power injected into the grid is different from the power generated by the turbine. The medium-voltage structure could be an interesting option to overcome problems related to high currents in modern/future high-power wind turbines resulting in more efficient, more compact and lighter solutions. Modular multilevel converters are suitable to handle medium-voltage levels and they allow for a straightforward integration of energy storage systems in a decentralized manner.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "293",
      "title": "Performance Evaluation of Green Mine Using a Combined Multi-Criteria Decision Making Method With Picture Fuzzy Information",
      "abstract": "The construction of Green Mine has become an essential policy for the management of mineral resources in China. This study aims to propose a favorable approach to assess the performance of Green Mine. The evaluation criteria are recognized based on the specific characteristics of Green Mine. Considering that some of these criteria could not be mutually compensated, a novel multi-criteria decision making (MCDM) method is presented. It integrates the TODIM (an acronym in Portuguese of interactive and multi-criteria decision-making) method with the elimination and choice translating reality (ELECTRE) method in a picture fuzzy environment. In most existent methods, the evaluation information of Green Mine is described by real numbers. However, in this study, picture fuzzy numbers (PFNs) are first used to express such information to effectively indicate the uncertainty and fuzziness in the evaluation process. Another innovation is that the entropy weights model and the best-worst method (BWM) are combined to determine the comprehensive criteria weights. The practicability and advantages of the proposed method are verified by a case study and a comparative analysis with other methods. In addition, the influences of some parameters are discussed using sensitivity analysis to judge the flexibility and robustness of the proposed method. The results show that the proposed approach is feasible for solving the non-compensatory problems of evaluation criteria and can provide references for the performance evaluation and management of Green Mine.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "294",
      "title": "Automated Non-Intrusive Load Monitoring System Using Stacked Neural Networks and Numerical Integration",
      "abstract": "Population growth and new consumer needs, among other factors, have lead to growing energy demand, without a concomitant increase in energy generation. This way, reduction and rationalization of energy consumption, especially by residential users, have become a global concern generating a need for developing techniques for efficient management and distribution of the available energy. Non-Intrusive Load Monitoring (NILM) techniques have provided valuable information about energy consumption for power generation companies as well as consumers. Such information is important for making decisions related to sustainable use of energy resources. This study proposes an automated system based on Artificial Neural Network for performing some of the NILM tasks. A stacked neural network was developed to extract features of power signals of appliances to identify those in operation during a given period. This information is then used to disaggregate individual appliance loads through the total aggregate signal, and consumption is calculated through numerical integration. The system was tested using real data from two databases about appliances with On/Off, multi-level, and variable consumption patterns collected in low frequency. The performance metrics, resulting from identification and disaggregation tasks, demonstrate the efficiency of the proposed system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "295",
      "title": "Self-Supervised Monocular Depth Estimation With Extensive Pretraining",
      "abstract": "Although depth estimation is a key technology for three-dimensional sensing applications involving motion, active sensors such as LiDAR and depth cameras tend to be expensive and bulky. Here, we explore the potential of monocular depth estimation (MDE) based on a self-supervised approach. MDE is a promising technology, but supervised learning suffers from a need for accurate ground-truth depth data. Recent studies have enabled self-supervised training on an MDE model with only monocular image sequences and image-reconstruction errors. We pretrained networks using multiple datasets, including monocular and stereo image sequences. The main challenges posed by the self-supervised MDE model were occlusions and dynamic objects. We proposed novel loss functions to handle these problems in the form of min-over-all and min-with-flow losses, both based on the per-pixel minimum reprojection error of Monodepth2 and extended to stereo images and optical flow. With extensive pretraining and novel losses, our model outperformed existing unsupervised approaches in quantitative depth estimation and the ability to distinguish small objects against a background, as evaluated by KITTI 2015.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "296",
      "title": "Optimizing Fast Near Collision Attack on Grain Using Linear Programming",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "297",
      "title": "In-situ Measurement Methodology for the Assessment of 5G NR Massive MIMO Base Station Exposure at Sub-6 GHz Frequencies",
      "abstract": "As the roll-out of the fifth generation (5G) of mobile telecommunications is well underway, standardized methods to assess the human exposure to radiofrequency electromagnetic fields from 5G base station radios are needed in addition to existing numerical models and preliminary measurement studies. Challenges following the introduction of 5G New Radio (NR) include the utilization of new spectrum bands and the widespread use of technological advances such as Massive MIMO (Multiple-Input Multiple-Output) and beamforming. We propose a comprehensive and ready-to-use exposure assessment methodology for use with common spectrum analyzer equipment to measure or calculate in-situ the time-averaged instantaneous exposure and the theoretical maximum exposure from 5G NR base stations. Besides providing the correct method and equipment settings to capture the instantaneous exposure, the procedure also comprises a number of steps that involve the identification of the Synchronization Signal Block, which is the only 5G NR component that is transmitted periodically and at constant power, the assessment of the power density carried by its resources, and the subsequent extrapolation to the theoretical maximum exposure level. The procedure was validated on site for a 5G NR base station operating at 3.5 GHz, but it should be generally applicable to any 5G NR signal, i.e., as is for any sub-6 GHz signal and after adjustment of the proposed measurement settings for signals in the millimeter-wave range.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "298",
      "title": "Detection of Wheat Unsound Kernels Based on Improved ResNet",
      "abstract": "In the process of grain acquisition, the unsound kernels of wheat are traditionally detected manually. The determination method based on computer vision typically requires expensive equipment for image acquisition and has disadvantages of low recognition efficiency and difficulties in adhesion segmentation, which strongly limit the application in routine detections. In this paper, six kinds of wheat including sound kernel, broken kernel, sprouted kernel, injured kernel, moldy kernel and spotted kernel are considered as the samples. An image acquisition platform is built with low cost to capture wheat pictures. The designed two-kernels adhesion wheat segmentation algorithm based on concave-mask exhibits high accuracy, with the error rate of 0.93% for total 9988 wheat grains. By comparing the advantages and disadvantages of GoogleNet, DenseNet, IX-ResNet, Res2Net, this paper studies the optimization of depth, width, downsampling mode, convolution order, attention mechanism, receptive field. Finally a wheat unsound kernel detection method is proposed based on Res24_D_CBAM_Atrous. The Macro avg values of Precision, Recall and F1 are respectively 94%, 95% and 94%, which are increased by 3%-4% based on the original Res34. The prediction time is reduced by 220s, which can meet the rapid and accurate evaluation of wheat appearance quality. The method shows important theoretical significance and practical application value for wheat unsound kernel routine detection.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "299",
      "title": "New Overcurrent Relay Coordination Method Through Time Intervals to Enhance Microgrid Protection",
      "abstract": "This paper presents a method to protect microgrids (MGs) through coordination of directional overcurrent relays (DOCRs). The new formulation is subjected to restrictions of pre-established time intervals to guarantee the primary and backup functions of each relay. Traditional DOCR coordination is made according to the time operation sequence for the primary and backup functions, resulting in a functional dependence between the relays. Thus, slow relays affect the neighbor relays, increasing the operating time. The new coordination method has advantages over the conventional coordination because functional independence between the relays is achieved. It is only necessary to update the setting in the relays affected by contingencies, topological changes, or during the formation of islands. The use of non-conventional curves is considered to give the flexibility necessary to meet the time intervals at each required location. Based on the results, the proposed coordination method reduces the operation time of the relays compared with that under the conventional coordination method in the power systems studied. Further simplification in the relay adjustment process under the different contingencies studied was obtained, which improved under the various operating conditions in the test systems.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "300",
      "title": "Using Communication Channel Equalization to Remove Atmospheric Turbulence in Star Signal Detection",
      "abstract": "In this paper, we explore the problem of removing atmospheric turbulence to obtain better images of remote sidereal star systems. The imaging process is remodeled as a transmit–receive wireless communication paradigm in a novel approach for correcting space- and time-varying blur in stellar images. In particular, the effect of starlight passing through atmospheric turbulence is modeled as multipath fading communication channels. The problem is then transformed into channel equalization in space and time domains to produce a sharp stellar image. This approach involves first estimating the center of a blurred stellar image. Next, linear regression obtains an equivalent two-dimensional channel response through decomposition of the blurred image into the weighted sum of the diffraction-limited patterns in the spatial domain. Finally, an alignment algorithm is implemented for synthesis, and a final output is generated. Experiments were performed with real field-captured images; the results revealed that this approach could be used to effectively correct image blur and obtain diffraction-limited stellar images.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "301",
      "title": "Deep Learning-Based Multimodal Abnormal Gait Classification Using a 3D Skeleton and Plantar Foot Pressure",
      "abstract": "Classification of pathological gaits has an important role in finding a weakened body part and diagnosing a disease. Many machine learning-based approaches have been proposed that automatically classify abnormal gait patterns using various sensors, such as inertial sensors, depth cameras and foot pressure plates. In this paper, we present a deep learning-based abnormal gait classification method employing both a 3D skeleton (obtained with a depth camera) and plantar foot pressure. We collected skeleton and foot pressure data simultaneously for 1 normal and 5 pathological (antalgic, lurching, steppage, stiff-legged, and Trendelenburg) gaits and classified them by using a multimodal hybrid model fed both data types together. In the proposed method, we fed the sequential skeleton and average foot pressure data into recurrent neural network (RNN)-based encoding layers and convolutional neural network (CNN)-based encoding layers, respectively, to effectively extract features from different data types. Their output features were concatenated and fed to fully connected layers for classification. The pressure-based and skeleton-based single-modal models achieved classification accuracies of 68.82% and 93.40%, respectively. The proposed multimodal hybrid model showed improved performance with an accuracy of 95.66%. We fine-tuned the hybrid model by applying a 3-step training methodology and ultimately increased the accuracy to 97.60%. This study indicates that the integrated features of the skeleton and foot pressure data represent both the spatiotemporal motion information and weight distribution, so data fusion can generate a positive effect in pathological gait classification.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "302",
      "title": "LEO Mega-Constellations for 6G Global Coverage: Challenges and Opportunities",
      "abstract": "Mega-constellations have the potential for providing 6G Internet owing to the unique advantage of global coverage. However, current satellite technologies are not omnipotent. There are still many challenging problems that need to be solved for mega-constellations to support 6G, e.g., efficient resource allocation, gratifying mobility management, and large-scale full-time TT&C (tracking, telemetry, and command). This paper starts with a novel definition of LEO mega-constellations and a brief review regarding the current typical mega-constellations, discussing the development direction of the mega-constellation air interface. Then, the key technologies development status of satellite networks is illustrated and analyzed from five aspects: network protocol, multiple access, satellite handover, TT&C, and interference mitigation, especially their adaptability in mega-constellations for 6G global coverage. Finally, considering the features and requirements of 6G, future challenges for mega-constellations and some potential solutions are proposed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "303",
      "title": "Wireless Localization Method Using the Distributed Iterative Stochastic-Resonance-Based Signal Spectral Combination",
      "abstract": "In this study, a kind of nonlinear stochastic-resonance (SR) signal enhancement technique combined with the distributed receiving array signal power spectrum combination approach is proposed. By utilizing the signal spectral power improvement technique, the fitness of the distributed SR system with the array structure, and the information combination of the receiving power spectra, the corresponding objective of wireless localization can be realized successfully. An iterative nonlinear SR-based processing structure and corresponding algorithm are also proposed, which guarantee the applicability of the proposed approach. Computer simulations give the better performances of the proposed method compared with the conventional direction of arrival (DoA) estimation approaches and corresponding wireless localization estimation results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "304",
      "title": "Interweaving Network: A Novel Monochromatic Image Synthesis Method for a Photon-Counting Detector CT System",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "305",
      "title": "High Efficiency Mechanism Analysis of Resonant Switched-Capacitor Converter",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "306",
      "title": "LDPC Hardware Acceleration in 5G Open Radio Access Network Platforms",
      "abstract": "The Open Radio Access Network (RAN) concept has been gaining wide acceptance in recent network architectures, including 5G New Radio (NR) network deployments. Current Open RAN radio implementation efforts, aim at integrating several white-box hardware elements and executing digital processing on open-source software. When building such a software-based, 5G Open RAN platform, challenges include achieving real-time execution times for demanding computational blocks of the 5G NR physical layer processing, such as Low Density Parity Check (LDPC) decoding. In this context, having already identified both the capabilities as well as the challenges that Field-programmable Gate Arrays (FPGAs) offer for accelerating LDPC, we present our novel LDPC FPGA accelerator system. In this paper, we contribute the implementation details of our FPGA accelerator design as well as the process of integrating the accelerator with OpenAirInterface (OAI), the basis for our 5G NR platform. For the first time in the literature, we show an FPGA-based LDPC accelerator fully integrated with a complete software platform, that is able to achieve more than \n 1.6Gbps \n decoding throughput and up to 13 times faster execution times compared to single core software implementations. Finally, in our results, we show that LDPC encoding is more challenging to accelerate due to lower computational complexity.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "307",
      "title": "An Embedded Inference Framework for Convolutional Neural Network Applications",
      "abstract": "With the rapid development of deep convolutional neural networks, more and more computer vision tasks have been well resolved. These convolutional neural network solutions rely heavily on the performance of the hardware. However, due to privacy issues or the network instability, we need to run convolutional neural networks on embedded platforms. Critical challenges will be raised by limited hardware resources on the embedded platform. In this paper, we design and implement an embedded inference framework to accelerate the inference of the convolutional neural network on the embedded platform. For this, we first analyzed the time-consuming layers in the inference process of the network, and then we design optimization methods for these layers. Also, we design a memory pool specifically for neural networks. Our experimental results show that our embedded inference framework can run a classification model MobileNet in 80ms and a detection model MobileNet-SSD in 155ms on Firefly-RK3399 development board.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "308",
      "title": "Impact of Geomagnetically Induced Currents on High Voltage Transformers in Malaysian Power Network and Its Mitigation",
      "abstract": "Geomagnetically induced current (GIC) is a ground end manifestation of geomagnetic disturbances (GMDs) and space weather arising from solar activity, which causes half-cycle saturation and represents a potential hazard for a stable and safe operation of earthed high voltage (HV) power transformers. Previous studies have shown that the impact of GIC is not limited to high and mid-latitude regions, but it can also affect power systems located in lower geographic latitudes. This work presents the impact of GIC on HV transformers in the Malaysian power network. A detailed power network was modelled using the Power System Computer-Aided Design for Electromagnetic Transients including Direct Current (PSCAD/EMTDC) software. The entire network was subjected to a geoelectric field strength of 20 V/km at the northward and eastward directions. The GIC analysis has determined the most critical locations in the power network model that are prone to high GICs. The simulation results demonstrated that the most vulnerable substations to GMD events and experience the most severe GICs were those located in the middle of the Malaysian power network. The GIC effects and saturation levels of four transformers’ types in these locations have been investigated over the transmission network. Under the GIC condition, transformers were driven into half-cycle saturation and their reactive power consumption drastically increased. Thus, conventional GIC mitigation systems based on neutral blocking devices (NBDs) were proposed and connected to the power transformers to block the GIC flow in their neutral paths. It was found that the GIC protection modes in the mitigation systems effectively eliminate the injected GICs in the neutral paths and are able to prevent the saturation occurrence of the transformers.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "309",
      "title": "A Socio-Technical Simulation Model for the Design of the Future Single Pilot Cockpit: An Opportunity to Improve Pilot Performance",
      "abstract": "The future deployment of single pilot operations must be supported by new cockpit computer services. Such services require an adaptive context-aware integration of technical functionalities with the concurrent tasks that a pilot must deal with. Advanced artificial intelligence supporting services and improved communication capabilities are the key enabling technologies that will render future cockpits more integrated with the present digitalized air traffic management system. However, an issue in the integration of such technologies is the lack of socio-technical analysis in the design of these teaming mechanisms. A key factor in determining how and when a service support should be provided is the dynamic evolution of pilot workload. This paper investigates how the socio-technical model-based systems engineering approach paves the way for the design of a digital assistant framework by formalizing this workload. The model was validated in an Airbus A-320 cockpit simulator, and the results confirmed the degraded pilot behavioral model and the performance impact according to different contextual flight deck information. This study contributes to practical knowledge for designing human-machine task-sharing systems.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "310",
      "title": "Emergency Pull-Over Algorithm for Level 4 Autonomous Vehicles Based on Model-Free Adaptive Feedback Control With Sensitivity and Learning Approaches",
      "abstract": "This paper presents an emergency pullover algorithm for fail-safe systems designed for level-4 autonomous vehicles. The proposed algorithm utilizes feedback gain adaptation, based on sensitivity estimation, and cost-based learning. Vehicle failure within this paper does not encompass every type of failure and refers only to any situation where the upper controller or communications from the upper controller shuts down. When this type of failure occurs, the algorithm performs an emergency pullover maneuver. This maneuver does not require any form of independent control from the driver to be performed successfully. However, the highest control priority is still given to the driver if the driver intervenes during the maneuver. The feedback gain adaptation is comprised of two sections: Sensitivity Estimation and Gradient Descent (GD) based Adaptation. For Sensitivity Estimation, a relationship function has been designed with feedback gain, from the feedback gain adaptation, and changes in state error. The sensitivity of state error with respect to feedback gain can then be estimated. This estimation is done through the Recursive Least Squares (RLS) method with multiple forgetting factors through the directional forgetting method. For GD based Adaptation, state errors are applied with parameters for the cost-based learning to give Adaptation Gains. These Adaptation Gains are used in tandem with the estimated sensitivity to update the feedback gain. To reduce the number of tuning parameters required in the GD method, an additional distance condition has been proposed. This condition utilizes feedback change rates and state errors, obtained from the multi-dimensional plane of the feedback gain’s change rates. A proportional coefficient is also required as a tuning parameter for this condition. This parameter is tuned by a cost-based learning algorithm, also designed in this study. Resultantly, these methods allow the adaptive feedback controller to forgo any system informa...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "311",
      "title": "Nonlinear Three-Port Representation of PAs for Embedded Self-Calibration of Envelope-Dependent Dynamic Biasing Implementations",
      "abstract": "This paper proposes a three-port power amplifier (PA) representation based on distinct sets of nonlinear complex polynomials that describe a combiner, a nonlinear baseband-to-RF converter and a nonlinear RF amplifying function, for processing the PA's input modulated signal and any envelope-dependent dynamic biasing signal. This novel representation of PA nonlinearities simplifies computation and renders possible analytical formulations to describe a 3-port PA system. It allows accurate prediction of the PA's output distortion components as a function of an input multi-tone excitation and a multi-tone dynamic biasing signal. The representation is intended for a context proposed, to the best of the authors' knowledge for the first time, and envisioned as promising for future mobile communication equipment - the automatic optimization of linearity performance in Radio Frequency Integrated Circuit (RFIC) PAs under any modulated excitation and employing envelope-dependent biasing, through implementation of embedded self-calibration within the transmitter front-ends. In this context, the representation introduced here compares favorably in terms of accuracy with respect to Volterra-based approaches and allows a simpler characterization, while the literature often points to the complexity inherent to Volterra-based approaches. The proposed representation allows the optimization of the PA's dynamic biasing for linearity improvement from one mobile unit to another through embedded self-calibration starting from quasi-static measurements alone of the PA's input/output power. Its applicability is highlighted through benchmarking against experimental results demonstrating accurate PA characterization for multiple PA platforms under different dynamic biasing techniques. In one implementation using an industry-designed GaAs PA, it accurately predicts the dynamic biasing adjustments to achieve more than 4dB reduction in the output intermodulation distortion (IMD3). In another imp...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "312",
      "title": "Ion-Induced Electrical Isolation in GaN-Based Platform for Applications in Integrated Photonics",
      "abstract": "GaN based Photonic Integrated Circuits (PICs) have now become a global contender for their wide range of applications owing their physical characteristics. The GaN material system acts as a promising platform; compatible with silicon and sapphire substrates. Both the carrier transport and carrier removal techniques are vital to develop the efficient platform for the integration of photonic circuits. We demonstrate the carrier removal mechanism in silicon (Si) doped GaN (0001) epitaxially grown on c-plane sapphire wafer using ion engineering of the devices. Ion-engineered regions within the active layers of the device are modelled, fabricated and characterized to assess the isolation created. Helium and Carbon ions with pre-designed doses and energies are used to irradiate the device structures. We have modelled and fabricated ion-engineered regions within the active layers and studied the carrier transport properties on said regions to isolate that particular part with either of active photonic components placed at the common platform. After ion irradiation, detailed analysis in terms of electric field dependent current characteristics, sheet resistance, carrier mobilities, activation energies, dark and photo currents under zero (ground) and multiple biases are examined to see the extent of charge leakage and to map the charge behavior under nominal operation. Device characteristics under wide regime of annealing temperatures ranging from 300°C to 1000°C are mapped to evaluate the thermal stability of implant driven isolated regions. Activation energies of implanted and parent regions has also been studied. The dark and photon driven electric currents at ground and under biased have been measured to investigate the photo-induced transport phenomenon.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "313",
      "title": "A Syntax-Augmented and Headline-Aware Neural Text Summarization Method",
      "abstract": "With the advent of the information age, excessive information collection leads to information overload. Automatic text summarization technology has become an effective way to solve information overload. This paper proposes an automatic text summarization model, which extends traditional sequence-to-sequence (Seq2Seq) neural text summarization model by using a syntax-augmented encoder and a headline-aware decoder. The encoder encodes both syntactic structure and word information of a sentence in the sentence embedding. A hierarchical attention mechanism is proposed to pay attentions to syntactic units. The decoder is improved by a headline attention mechanism and a Dual-memory-cell LSTM network to achieve a higher quality of generated summaries. We designed experiments to compare the proposed method with baseline models on the CNN/DM datasets. The experiment results show that the proposed method is superior to abstractive baseline models in terms of the scores on ROUGE evaluation metrics, and achieve a summary generation performance comparable to the extractive baseline method. Though qualitative analysis, the summary quality of the propose method is more readable and less redundant, which agrees well with our intuition.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "314",
      "title": "Interpretable Global-Local Dynamics for the Prediction of Eye Fixations in Autonomous Driving Scenarios",
      "abstract": "Human eye movements while driving reveal that visual attention largely depends on the context in which it occurs. Furthermore, an autonomous vehicle which performs this function would be more reliable if its outputs were understandable. Capsule Networks have been presented as a great opportunity to explore new horizons in the Computer Vision field, due to their capability to structure and relate latent information. In this article, we present a hierarchical approach for the prediction of eye fixations in autonomous driving scenarios. Context-driven visual attention can be modeled by considering different conditions which, in turn, are represented as combinations of several spatio-temporal features. With the aim of learning these conditions, we have built an encoder-decoder network which merges visual features' information using a global-local definition of capsules. Two types of capsules are distinguished: representational capsules for features and discriminative capsules for conditions. The latter and the use of eye fixations recorded with wearable eye tracking glasses allow the model to learn both to predict contextual conditions and to estimate visual attention, by means of a multi-task loss function. Experiments show how our approach is able to express either frame-level (global) or pixel-wise (local) relationships between features and contextual conditions, allowing for interpretability while maintaining or improving the performance of black-box related systems in the literature. Indeed, our proposal offers an improvement of 29% in terms of information gain with respect to the best performance reported in the literature.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "315",
      "title": "A Boundary Assembling Method for Nested Biomedical Named Entity Recognition",
      "abstract": "Biomedical named entity recognition (BNER) is an important task in biomedical natural language processing, in which neologisms (new terms, words) are coined constantly. Most of the existing work can only identify biomedical named entities with flattened structures and ignore nested biomedical named entities and discontinuous biomedical named entities. Because biomedical domains often use nested structures to represent semantic information of named entities, existing methods fail to utilize abundant information when processing biomedical texts. This paper focuses on identifying nested biomedical named entities using a boundary assembly (BA) model, which is a cascading framework consisting of three steps. First, start and end named entity boundaries are identified and then assembled into named entity candidates. Finally, a classifier is implemented for filtering false named entities. Our approach is effective in handling nesting and discontinuous problems in biomedical named entity recognition tasks. It improves the performance considerably, achieving an F1-score of 81.34% on the GENIA dataset.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "316",
      "title": "Towards a Self-Driving Management System for the Automated Realization of Intents",
      "abstract": "Network management faces the interrelated challenges of increasing network complexity, meeting sophisticated business requirements, and being subject to human oversight. Self-driving networks possess the key properties to overcome such challenges. We present and implement a management system that addresses several elements of a self-driving network. Our system leverages intents, a policy-based paradigm and autonomic control loops. Intent-based networking allows us to formalize how an intent can be provided as input to a control loop, and how the complexities can be abstracted from the user. To realize and assure the intent, autonomic networking enables us to create Monitor-Analyze-Plan-Execute (MAPE) loops. Finally, we execute the control loops using a policy-based approach. We propose a policy abstraction to support requirements at different levels of abstraction, and an Application Programming Interface (API) layer to reduce management complexity from the user perspective. We propose a formal policy information model to model policies across layers of abstractions and to support simplified mapping and strong consistencies among various policy abstraction levels. We have implemented our proposal and present a proof-of-concept use-case to showcase the intent refinement.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "317",
      "title": "Assessment of Transient EMI Impact on LTE Communications Using EVM & PAPR",
      "abstract": "The brief contact losses between the pantograph and the catenary in high-speed trains create transient interferences, which extend to the frequency bands used by telecommunication systems. This article presents a study of the impact of these transient wideband interferences on LTE communications between the train and a base station. In this study, we set up an experimental test bench, which establishes LTE communication between a communication tester and a USB/LTE dongle in the presence of transient interferences. We analysed the impact of these interferences on the error vector magnitude (EVM) of the received LTE signals and we observed that the EVM evolution does not explain certain communication interruptions. Indeed, interruptions can occur for EVM values significantly inferior to the standard limits. To understand the relationship between the interference characteristics and the communication interruption, we studied the peak to average power ratio (PAPR). Indeed, the PAPR is well suited to analyse transient interferences because it evolves with the amplitude but also with the repetition of the transient. Then, the PAPR measurement can provide a diagnostic assistance to analyse whether along certain railway lines, pantograph-catenary interferences are the cause of the LTE interruptions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "318",
      "title": "A Novel Self-Adaptive Affinity Propagation Clustering Algorithm Based on Density Peak Theory and Weighted Similarity",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "319",
      "title": "Indoor Smartphone Localization: A Hybrid WiFi RTT-RSS Ranging Approach",
      "abstract": "Real-time locating and tracking Technology plays a significant role in location-based IoT applications. With the extensive installation of WiFi access points, the WiFi based indoor positioning approach has become one of the most widely used location technologies. However, due to the limitations of wireless signals, the classic WiFi-based method has become labor-intensive. Recently, the WiFi-based two-way ranging approach was introduced into the 802.11-REVmc2 protocol, which is built on a new packet type known as fine timing measurement (FTM) frame. In this work, we introduce the round-trip time measurement with clock skew and analyze the distribution of the round trip time (RTT) ranging error. A calibration method is presented to eliminate the RTT range offset at the transmitter end. We also develop an integrated ranging algorithm based on the WiFi round trip time range and received signal strength to enhance the scalability and robustness of the positioning system. The experimental results demonstrate that the proposed fusion method achieves remarkable improvement in scalability and precision in both static and dynamic tests, including outdoor and indoor environments. Compared with the classic fingerprinting approach, the performance of the system is remarkably improved, and achieves an average positioning accuracy of 1.435 m with an update rate of every 0.19 s.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "320",
      "title": "Design Guidelines for Mammogram-Based Computer-Aided Systems Using Deep Learning Techniques",
      "abstract": "Breast cancer is the second fatal disease among cancers patients both in Canada and across the globe. However, when detected early, a patients’ survival rate can be raised. Thus, researchers and scientists have been practicing to develop Computer-Aided Detection (CADe) and Computer-Aided Diagnosis (CADx) systems. Traditional CAD systems depend on manual feature extraction, which has provided radiologists with poor detection and diagnosis tools. Nevertheless, recently, the powerful application of Convolutional Neural Networks (CNN)s as one of the deep learning-based methods has revolutionized these systems’ accuracy and development. This article proposes categorizing the current deep learning research on mammogram types based on researchers’ techniques for their empirical studies. Also, we provide an overview of different publicly available data resources and available datasets for breast imaging. This critical review of the state-of-the-art techniques is presented, which we believe can serve as a valuable source for research scientists investigating deep learning-based breast mammogram classification.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "321",
      "title": "Event-Triggered State Estimation for Wireless Sensor Network Systems With Packet Losses and Correlated Noises",
      "abstract": "In this article, an event-triggered state estimation problem for wireless sensor network systems affected by random packet losses and correlated noises is considered. A set of independent Bernoulli variables are used to describe the random packet losses in the measurement transmission. An event-triggered transmission strategy is introduced to decrease limited network bandwidth consumption, and the measurement noise is correlated with the process noises of the same moment and the previous moment. Event-triggered estimator of process noises under the linear minimum variance criterion is derived. Then, an event-triggered state estimation algorithm related to the packet loss rate, noise correlation coefficient and triggering threshold is designed. Sufficient conditions are provided to guarantee convergence of the estimation error covariances of the proposed estimator. Finally, comparative simulation verifies the effectiveness of our algorithm.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "322",
      "title": "Design of a High-Gain Single Circular Patch Radiator With a Cavity-Backed Structure Using Multiple SIW Feeders for Monopulse DF-Applications",
      "abstract": "This paper proposes the design of a gain enhanced single circular patch radiator (SCPR) with a cavity-backed structure using multiple substrate integrated waveguide (SIW) feeders for monopulse systems. We derive the equations of a radiation pattern for the multi-feed SCPR and compare it with the full EM simulation results. Based on the theoretical results, the proposed SCPR with multiple feeds is designed by adding the cavity-backed structure to obtain high gain characteristics. In the feeding network, four SIW structures are designed and circularly arranged, which can reduce loss and mutual coupling. Each pair of the SIW feeders can provide sum (\n Σ \n) and difference (\n Δ \n) patterns to achieve the monopulse direction finding (DF) properties in both elevation and azimuth directions. To verify the feasibility, the proposed antenna is fabricated, and the antenna characteristics are measured. The measured reflection coefficient is −14.5 dB at 5.8 GHz, and the maximum gains are 4.9 dBi and 4.8 dBi in \nzy\n-plane. To observe the monopulse DF, the estimated direction of arrival (DOA) results are examined in both elevation and azimuth directions. In the whole estimated angle range, the estimation error is lower than 0.49, and the average error is 0.26.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "323",
      "title": "Demand-Side Power Paradigm-Oriented Analysis of Reactive Electric Spring Stabilization Capabilities",
      "abstract": "Electric Spring (ES) technique is a user-level solution developed to stabilize the supply voltage of a user under variations of the grid voltage. This paper analyzes the stabilization capabilities of a reactive ES that operates according to the demand-side power paradigm. By help of a convenient ES modeling, the extreme values of the active power that a user can draw under the ES action are first determined. Then, it is demonstrated that the demand-side power paradigm is fulfilled only if the distribution line impedance has a resistive component while its reactive component weakens such fulfillment. Lastly, the variations of the grid voltage that ES is able to cope with are worked out. All findings are formulated in terms of normalized quantities and consequently are of general validity. Computer-aided simulation of a case study exemplifies the theoretical findings.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "324",
      "title": "Assessment of Low-Loss Configurations for Efficiency Improvement in Hybrid Modular Multilevel Converters",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "325",
      "title": "A Weighted Chimp Optimization Algorithm",
      "abstract": "These days, a sizable number of meta-heuristic algorithms are utilized to address many problems with numerous variables and huge complexity. One of the most popular swarm intelligence-based meta-heuristic methods is the chimp optimization algorithm inspired by chimps’ individual intelligence and sexual motivation in their group hunting. This paper proposes a weighted chimp optimization algorithm to tackle two main issues in large-scale numerical optimization problems, such as low convergence speed and local optima trapping to solve high-dimensional problems. The main difference between the weighted and standard chimp optimization algorithms is that a position-weighted equation is offered to enhance convergence speed and avoid local optima. Moreover, the balance between exploration and exploitation is carried out in the proposed method that is crucial in the swarm intelligence-based algorithms. The presented weighted chimp optimization algorithm method is evaluated in different conditions to prove that it is the best. For this purpose, a classical set of 30 unimodal, multimodal, and fixed-dimension multimodal benchmark functions is applied to investigate the pros and cons of characteristics of the weighted chimp optimization algorithm. Besides, the proposed algorithm is tested on the IEEE congress of evolutionary computation benchmark test functions. In order to shed more light on probing the performance of the weighted chimp optimization algorithm in large-scale numerical optimization and real-world problems, it is examined by 13 high-dimensional and ten real-world optimization problems. The results show that the suggested algorithm outperforms in terms of convergence speed, the probability of getting stuck in local minimums, exploration, and exploitation compared to state-of-the-art methods in the literature. Source codes are publicly available at \nhttps://se.mathworks.com/matlabcentral/fileexchange/99344-a-weighted-chimp-optimization-algorithm\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "326",
      "title": "Data-Driven Optimal Synchronization for Complex Networks With Unknown Dynamics",
      "abstract": "This paper studies the data-driven optimal synchronization problem for complex networks (CNs) with unknown dynamics. By using pre-compensation technology, a compensator and a controller are proposed. Then, an augmented error system is constructed, which can circumvent the requirement of system dynamics. It is revealed that the the optimal synchronization control of CNs works as the optimal regulation of the augmented system with a performance function. A novel policy iteration (PI) algorithm is given to ensure that the iterative performance function can converge to the optimal value which is the solution of the coupled Hamilton-Jacobi-Bellman equation (HJB), which means that the optimal regulation of the augmented system can be solved and the synchronization can be achieved. Based on this, a novel data-driven control scheme is proposed, which is composed of parts: compensator, controller and critic network. The iterative performance is generated by critic network. The compensator is used to construct the control parameter by using performance and the controller is used to construct control input by using control parameter. Both compensator and critic network are implemented by neural networks (NNs) and only depend on the process sampling data. Finally, we use robot network as an example to verify the effectiveness of proposed control scheme.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "327",
      "title": "Robust Object Tracking Using Affine Transformation and Convolutional Features",
      "abstract": "The state-of-the-art trackers using deep learning technology have no special strategy to capture the geometric deformation of the target. Based on that the affine manifold can better capture the target shape change and that the higher level of Convolutional Neural Network (CNN) can better describe semantic information of objects, we propose a new tracking algorithm combining affine transformation with convolutional features to track targets with dramatic deformation. First, the affine transformation is applied to predict possible locations of a target, then a correlative filter is designed to compute the appearance confidence score for determining the final target location. Furthermore, a standard discriminative correlation filter is used to develop the effect of convolutional features, which is more efficient than other methods used for CNN Networks. Comprehensive experiments demonstrate the outstanding performance of our tracking algorithm compared to the state-of-the-art techniques in the public benchmarks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "328",
      "title": "Seismic Random Noise Removal Based on a Multiscale Convolution and Densely Connected Network for Noise Level Evaluation",
      "abstract": "Traditional denoising methods for seismic exploration data design a corresponding mathematical denoising model batch according to the different properties of different random noises, which is a tedious and time-consuming process. To solve this problem, this paper proposes a deep convolutional neural network denoising model based on noise estimation (MCD-DCNN). This model is primarily composed of two modules, the noise estimation module and the denoising module. The noise estimation module uses a multiscale convolutional neural network to better extract the characteristics of random noise in the seismic data. To make full use of the extracted features, a dense connection method is adopted between the multiscale convolutions in the noise estimation module. In the denoising module, we use multiscale convolutions and dense connections to replace the original convolutional neural network and use the residual structure (ResNet) and batch normalization (BN) to improve the denoising effect and running speed of the model. In this experiment, single trace and simple and complex profile data are used as input to simulate the real data processing environment. Finally, we compare the denoising effects of the MCD-DCNN model proposed in this paper with the current mainstream feed-forward denoising convolutional neural network (DnCNN) and a fast and flexible denoising convolutional neural network (FFDNet) models. The comprehensive results show that under the condition of a given prior noise level, the denoising performance of the FFDNet and MCD-DCNN models are comparable. In the absence of a priori noise level, the denoising performance of the FFDNet model drops sharply, while the denoising performance of MCD-DCNN is not affected; therefore, MCD-DCNN is more in line with actual seismic denoising.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "329",
      "title": "Hierarchical Naming Scheme in Named Data Networking for Internet of Things: A Review and Future Security Challenges",
      "abstract": "The proliferation of connected devices in the Internet of Things (IoT) presents a connectivity challenge. The future internet will require a paradigm shift in which content is evaluated on the basis of “What” it is rather than “Where” it originated. ICN’s goal is to provide the benefits of name-based content addressing in order to facilitate scalable content distribution, security, mobility, and trust. NDN is a new internet architecture that evolved from Content-Centric Networking (CCN). NDN is viewed as a solution to the IoT’s challenges, as well as a way to transcend the IP paradigm. With IoT systems that had a number of challenging characteristics to satisfy, including heterogeneous devices, resource constraints, and energy efficiency. Due to the fact that NDN native features deliver data via hierarchically structured names, it offer promising solutions for current research integrating NDN into IoT. The review discusses the significance of naming, its influence, and security factor. Additionally, research challenges in the areas of naming and security will be discussed. The primary objective of this review is to give a new facelift to a new integrating naming convention for NDN.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "330",
      "title": "Imageability- and Length-Controllable Image Captioning",
      "abstract": "Image captioning can show great performance for generating captions for general purposes, but it remains difficult to adjust the generated captions for different applications. In this paper, we propose an image captioning method which can generate both imageability- and length-controllable captions. The imageability parameter adjusts the level of visual descriptiveness of the caption, making it either more abstract or more concrete. In contrast, the length parameter only adjusts the length of the caption while keeping the visual descriptiveness on a similar degree. Based on a transformer architecture, our model is trained using an augmented dataset with diversified captions across different degrees of descriptiveness. The resulting model can control both imageability and length, making it possible to tailor output towards various applications. Experiments show that we can maintain a captioning performance similar to comparison methods, while being able to control the visual descriptiveness and the length of the generated captions. A subjective evaluation with human participants also shows a significant correlation of the target imageability in terms of human expectations. Thus, we confirmed that the proposed method provides a promising step towards tailoring image captions closer to certain applications.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "331",
      "title": "Research on Optimization of GWO-BP Model for Cloud Server Load Prediction",
      "abstract": "To improve the accuracy of cloud server resource load prediction, particle swarm optimization (PSO) algorithm, gray wolf optimization (GWO) algorithm and BP neural network are studied in-depth and applied. Firstly, the PSO algorithm is introduced to optimize the location update method in the search process of gray wolf. Secondly, the convex function is introduced to improve the linear convergence of the traditional GWO algorithm. Then the optimized GWO algorithm is used to further improve the assignment of weights and thresholds in the traditional BP neural network model, to construct a multi-stage optimized cloud server load prediction model, referred to as PSO- GWO-BP prediction model. Finally, the performance of the PSO- GWO-BP prediction model is verified by comparison experiments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "332",
      "title": "A Hybrid Algorithm for Location-Routing Sustainable Optimization Under Fuzzy Demand",
      "abstract": "With the globalization of the supply chain and the change of demand environment, designing an effective logistic system in the sustainable development of the supply chain becomes more critical. This study proposes a location-routing problem to determine an efficient integration of single factory and multi-distribution centers and multi-customers in uncertain demands. This problem can be regarded as an optimization integrating location, distribution decision, and routing management. The objective function is to minimize the total cost and satisfy all the requirements, which is a highly complex NP-hard problem, so a hybrid algorithm of genetic algorithm (GA) and tabu search (TS) algorithm is proposed. A fuzzy c-means clustering algorithm is used to produce an initial solution. Fuzzy triangular number and confidence interval transformation are used to deal with fuzzy customer demand. The research findings concludes that (i) determine the numbers of facilities with locations that should be opened and (ii) minimize the total cost in supply chain. The experiments prove that the proposed hybrid algorithm of GA and TS algorithm overcomes the defect of local optimum in the literature viewpoint, and the optimization algorithms can effectively solve the location-routing problem.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "333",
      "title": "Multiobjective Ant Lion Optimization for Performance Improvement of Modern Distribution Network",
      "abstract": "Multiobjective ant lion optimization (MALO) is a technique developed to imitate ant foraging behavior. This method has many advantages, including straightforward, scalable, flexible, balanced, and fast response. The MALO technique consists of five stages: ants perform optimization by random walking by updating their position, building traps, inserting ants into traps, capturing prey, and rebuilding traps. MALO has been successfully used to find optimal solutions to power system problems. Computer-assisted operations characterize modern distribution networks to solve complex problems. The complexity of the distribution network problem is owing to the integration of distributed energy resources (DERs). A DER is a renewable energy power plant with a capacity of up to 10 MW that has gained popularity in recent years. In its application, the integration of DERs into the distribution network can cause new problems, namely load imbalances or excessive voltage increases on the buses where the DER is injected. Therefore, good planning is required to place the DER. This study proposes a multiobjective optimization technique based on MALO to determine the optimal DER location and capacity. MALO is a relatively new optimization method that has the potential to improve distribution network performance. Test cases were conducted for an IEEE 33-bus radial power-distribution network. Four scenarios were considered, integrating DER types I, II, III, and IV. In each design, the placement of one DER, two DERs, and three DERs was modeled to optimize the location and capacity. The results of the multiobjective optimization show that the MALO technique can improve the distribution network performance, which is characterized by a significant power loss reduction, an increase in the bus voltage profile, and a balanced load on each feeder.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "334",
      "title": "Towards Sustainability of Manufacturing Processes by Multiobjective Optimization: A Case Study on a Submerged Arc Welding Process",
      "abstract": "Optimization on the basis of sustainability brings important benefits to manufacturing process as sustainable productions constitute a crucial aspect in modern manufacturing. This paper presents a new formalized framework for optimizing the sustainability of manufacturing processes. Unlike previous approaches, the proposed technique combines a methodology for selecting the sustainability indicators and a multi-objective optimization for improving the three sustainability pillars (economy, environment and society). While selecting the significant sustainability indicators in the considered manufacturing process relies on the ABC judgment method, the Saaty's method enables weighting the chosen indicators in order to combine them into suitable economic, environmental and social sustainability indexes. Other technological aspects, usually taken as objectives in previous works, are considered constraints in the proposed approach. The optimization is performed by using nature inspired heuristics, which return the set of non-dominated solutions (also known as Pareto front), from which the most convenient alternative is chosen by the decision maker, depending on the specific conditions of the process. For illustrating the usage of the proposed framework, it is applied to the optimization of a submerged arc welding process. Compared with currently used welding parameters, the computed optimal solution outperforms the economic and environmental sustainability while keeps equal the social impact. The results show not only the effectiveness of the proposed approach, but also its flexibility by giving a set of possible solutions which can be chosen depending on how are ranked the sustainability pillars.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "335",
      "title": "Power System Anomaly Detection Based on OCSVM Optimized by Improved Particle Swarm Optimization",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "336",
      "title": "A Convolutional Neural Network Reaches Optimal Sensitivity for Detecting Some, but Not All, Patterns",
      "abstract": "We investigate the spatial contrast-sensitivity of modern convolutional neural networks (CNNs) and a linear support vector machine (SVM). To measure performance, we compare the CNN contrast sensitivity across a range of patterns with the contrast sensitivity of a Bayesian ideal observer (IO) with the signal-known-exactly and noise-known-statistically. A ResNet-18 reaches optimal performance for harmonic patterns, as well as several classes of real world signals including faces. For these stimuli the CNN substantially outperforms the SVM. We further analyze the case in which the signal might appear in one of multiple locations and found that CNN spatial sensitivity continues to match the IO. However, the CNN sensitivity is far below optimal at detecting certain complex texture patterns. These measurements show that CNNs spatial contrast-sensitivity differs markedly between spatial patterns. The variation in spatial contrast-sensitivity may be a significant factor, influencing the performance level of an imaging system designed to detect low contrast spatial patterns.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "337",
      "title": "Separation Behaviour Difference Between Gelatin and Porcine Liver Under High-Speed Waterjet Impact",
      "abstract": "Different from the rigid separation of biological tissue by scalpel, medical waterjet technology utilizes the impact kinetic energy of high-speed waterjet to instantly destroy the surface of biological tissue to achieve better clinical separation effect. Since the gelatin samples are transparent biomaterials, they were taken as the only substitute for soft tissue in experimental studies and observation in the current studies of medical waterjet separation technology, but the mechanical behavioural difference between the two has not been reported. To verify the adaptability of gelatin as a substitute of soft tissue under the impact of high-speed waterjet. Firstly, the dynamic process of impact was described through the energy balance equation. Then, based on the principle of altering a single variable, the difference of damage depth between 8 wt. %, 10 wt. %, and 12 wt. % gelatin samples and porcine liver tissue under various impact pressure, impact distance, and waterjet speed of motion (as opposed to flow velocity) was compared. The results show that the gelatin sample replicates the damage behaviour of porcine liver samples under the specific waterjet impact conditions, and the direction of the waterjet hydraulic power optimisation of the two materials is also consistent: however, due to the different sampling sites and anisotropy of porcine liver samples, the mechanical response of soft tissue under high-speed waterjet impact cannot be fully expressed by gelatin samples. The experimental results can provide support for the further study of medical waterjet separation technology.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "338",
      "title": "Deep Reinforcement Learning-Based Routing on Software-Defined Networks",
      "abstract": "With an exponential increase in network traffic demands requiring quality of services, the need for routing optimization has become more prominent. Recently, the advent of software-defined networking (SDN) technology enables centralized management and operation, and the networking resources such as switches become flexibly configurable through programmable interfaces. In this paper, we propose a deep reinforcement learning (DRL)-based routing optimization on an SDN. In the proposed method, the DRL agent learns the interdependency between the traffic load of network switches and the network performance, and decides an optimal set of link weights to make a balance between the end-to-end delay and packet losses of the network. The SDN controller determines the routing paths using the set of link weights and installs the flow-rules on the SDN-enabled switches. To overcome an extensively long learning process of DRL in a case of topology change, we develop an M/M/1/K queue-based network model and perform the learning process of DRL using the network model in an offline manner until it is converged. The simulation results demonstrate the proposed routing method outperforms a conventional hop-count routing and a traffic demand-based RL algorithm in several network topologies.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "339",
      "title": "Trend Application of Machine Learning in Test Case Prioritization: A Review on Techniques",
      "abstract": "Software quality can be assured by passing the process of software testing. However, software testing process involve many phases which lead to more resources and time consumption. To reduce these downsides, one of the approaches is to adopt test case prioritization (TCP) where numerous works has indicated that TCP do improve the overall software testing performance. TCP does have several kinds of techniques which have their own strengths and weaknesses. As for this review paper, the main objective of this paper is to examine deeper on machine learning (ML) techniques based on research questions created. The research method for this paper was designed in parallel with the research questions. Consequently, 110 primary studies were selected where, 58 were journal articles, 50 were conference papers and 2 considered as others articles. For overall result, it can be said that ML techniques in TCP has trending in recent years yet some improvements are certainly welcomed. There are multiple ML techniques available, in which each technique has specified potential values, advantages, and limitation. It is notable that ML techniques has been considerably discussed in TCP approach for software testing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "340",
      "title": "Security of Vehicle Platooning: A Game-Theoretic Approach",
      "abstract": "In this paper, we study the security of a vehicle platoon exposed to cyber attacks using a game-theoretic approach. The platoon topologies under investigation are directed (called predecessor following) or undirected (bidirectional) weighted graphs. The edge weights specify the quality of the communication links between the vehicles in both the unidirectional/bidirectional data transfer environments. The attacker-detector game is defined as follows. The attacker targets some vehicles in the platoon to attack and the detector deploys monitoring sensors on the vehicles. The attacker's objective is to be as stealthy to the sensors as possible while the detector tries to place the monitoring sensors to detect the attack impact as much as it can. The existence of Nash Equilibrium (NE) strategies for this game is investigated based on which the detector can choose specific vehicles to put his sensors on and increase the security level of the system. Moreover, we study the effect of adding (or removing) communication weights between vehicles on the game value. The simulation and experimental results conducted on a vehicle platoon setup using Robotic Operating System (ROS) demonstrate the effectiveness of our analyses.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "341",
      "title": "Automatic Detection and Pennation Angle Measurement of Muscle Fascicles in Ultrasound Images Using Belt Linear Summation Transform",
      "abstract": "Ultrasound images of muscle fascicles have been widely used to investigate muscle properties for diagnosis and rehabilitation assessment.The existing automatic fascicle detection and measure methods are based on line detection techniques which do not exactly coincide with the true state of the muscle images. This affects their detection and measure accuracy and depresses their robustness to background interference. In this work, a novel discrete transform namely Belt Linear Summation (BLS) transform is proposed. Unlike the line transform techniques which calculate the sum of pixels on a straight line in images, the BLS transform intends to determine the weighted summation of a belt of pixel values. Based on BLS transform, an automatic fascicle detection and measure method is designed. The performance of the proposed method is compared to the recent automatic fascicle detection and measure methods using both simulated images and clinical images. Experimental results show that the proposed method is robust to background and noise interference, accurate in terms of muscle pennation angle measurement, and feasible for analyzing clinical data.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "342",
      "title": "Trajectory Tracking With Constrained Sensors and Unreliable Communication Networks",
      "abstract": "This work investigates the remote vehicle tracking issue over constrained monitoring sensors and unreliable communication networks. A saturation function is used to describe the bounded time varying acceleration of the vehicle. A set of matrices are introduced to model the sensor monitoring conditions called captured states (CSs), and a Markov chain with time varying and partially unknown transition probability (TVPUTP) is proposed to analyze the conditions of the CSs. Then, a CS dependent nonfragile estimator is designed based on the measured unreliable vehicle information, and the estimation error system (EES) is derived. Two theorems are established to ensure that the EES satisfies the finite-horizon (FH) H\n∞\n performance. Finally, an example is introduced to show the effectiveness of the results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "343",
      "title": "Provably Secure and Fast Color Image Encryption Algorithm Based on S-Boxes and Hyperchaotic Map",
      "abstract": "The World Wide Web is experiencing a daily increase in data transmission because of developments in multimedia technologies. Consequently, each user should prioritize preventing illegal access of this data by encrypting it before moving it over the Internet. Numerous color image encryption schemes have been developed to protect data security and privacy, indifferent to the computation cost. However, most of these schemes have high computational complexities. This research proposes a fast color image scrambling and encryption algorithm depending on different chaotic map types and an S-box that relies on a hyperchaotic map principle. The first step involves converting color image values from decimal representation to binary representation in the scrambling stage by changing the location of the bits according to a proposed swapping algorithm. Next, in the second scrambling stage, the same process occurs after returning color image values from binary representation to decimal representation and generating an S-box with the assistance of two types of chaotic map, namely, a 2D Zaslavsky map and a 3D Hénon map. Thus, this S-box is relied upon to swap the locations of the pixels in the color image. The encryption procedure begins with the production of three key matrices using a hybrid technique that employs two low-complexity types of chaotic map, namely, a 1D Logistic map and a 3D Hénon map, followed by an XORed as a lightweight process between each key generated for the three matrices and the corresponding red, green, and blue image channels. According to the findings, the proposed scheme demonstrates the most efficiency in terms of lowering the computational cost and shows its effectiveness against a wide range of cryptographic attacks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "344",
      "title": "Stator Current Spectral Content of Inverter-Fed Cage Rotor Induction Motor",
      "abstract": "The paper analyzes the influence of the number of rotor bars on the stator current spectral content in a three-phase cage induction motor fed by a pulse-width modulated (PWM) inverter. It is shown that each of the higher-order time harmonics in the supply voltage produces space harmonics in a rotating magnetic flux density wave, which results in induced rotor slot harmonics (RSHs) in the stator current spectrum. The conditions for the existence of these space harmonics are identical to those applying to a mains-fed motor. In other words, the number of rotor bars of a mains-fed motor yielding an RSH-free stator current spectrum produces the same stator current spectrum even in case the motor is inverter-fed. Additionally, to minimize the adverse effects of RSHs in the stator current spectrum, one must consider not only the number of rotor bars, but also its relationship with the frequency modulation ratio of the PWM inverter. Analytical predictions are presented to illustrate these results supported both by numerical simulations of the induction motor modelled through the winding function theory and experimentally taking the case a two-pole cage induction machine as a case study.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "345",
      "title": "LIANet: Layer Interactive Attention Network for RGB-D Salient Object Detection",
      "abstract": "RGB-D salient object detection (SOD) usually describes two modes’ classification or regression problem, namely RGB and depth. The existing RGB-D SOD methods use depth hints to increase the detection performance, meanwhile they focus on the quality of little depth maps. In practical application, the interference of various problems in the acquisition process affects the depth map quality, which dramatically reduces the detection effect. In this paper, to minimize interference in depth mapping and emphasize prominent objects in RGB images, we put forward a layered interactive attention network (LIANet). The whole network model adopts the idea of double branch structure to integrate RGB information and Depth information. The network has three parts: feature coding, layered fusion mechanism, and feature decoding. In the feature coding stage, a simple attention module (SAM) is added, which defines the energy function considering the weights of channel and space dimensions. This module enables the network to learn more discriminating neurons without adding parameters. By refining these neurons, the high-level semantic features of images can be fully mined. The layered interactive fusion module (LIFM) is the most critical part of this paper. This module effectively enhances the cross-modal interaction between RGB features and depth features. The RGB-depth-RGB modulation feedback mechanism successfully eliminates interference in the depth map and accurately highlights the features of salient objects. In addition, we also used mixed losses to optimize further and train our model. Finally, a mass of experiments on six standard datasets demonstrated the importance of the method, and a timely detection speed reaches 30 fps on every dataset.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "346",
      "title": "PersianQuAD: The Native Question Answering Dataset for the Persian Language",
      "abstract": "Developing Question Answering systems (QA) is one of the main goals in Artificial Intelligence. With the advent of Deep Learning (DL) techniques, QA systems have witnessed significant advances. Although DL performs very well on QA, it requires a considerable amount of annotated data for training. Many annotated datasets have been built for the QA task; most of them are exclusively in English. In order to address the need for a high-quality QA dataset in the Persian language, we present PersianQuAD, the native QA dataset for the Persian language. We create PersianQuAD in four steps: 1) Wikipedia article selection, 2) question-answer collection, 3) three-candidates test set preparation, and 4) Data Quality Monitoring. PersianQuAD consists of approximately 20,000 questions and answers made by native annotators on a set of Persian Wikipedia articles. The answer to each question is a segment of the corresponding article text. To better understand PersianQuAD and ensure its representativeness, we analyze PersianQuAD and show it contains questions of varying types and difficulties. We also present three versions of a deep learning-based QA system trained with PersianQuAD. Our best system achieves an F1 score of 82.97% which is comparable to that of QA systems on English SQuAD, made by the Stanford University. This shows that PersianQuAD performs well for training deep-learning-based QA systems. Human performance on PersianQuAD is significantly better (96.49%), demonstrating that PersianQuAD is challenging enough and there is still plenty of room for future improvement. PersianQuAD and all QA models implemented in this paper are freely available.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "347",
      "title": "Detection, Identification, and Direction of Arrival Estimation of Drone FHSS Signals With Uniform Linear Antenna Array",
      "abstract": "Safety, security, and privacy are three critical concerns affiliated with the use of drones in everyday life. Considering their ever-shrinking sizes and capabilities, being aware of drone activities in the vicinity becomes an important surveillance item. Therefore, keeping track of drones and preferably their controllers should be included into the already-existing security measures. In this study, a frequency hopping spread spectrum (FHSS) type drone controller signal detection and emitter direction finding framework is proposed to achieve aforementioned goals. Since drone communications signals generally coexist with other FHSS signals in 2.4 GHz industrial, scientific, and medical (ISM) band, first, a method based on cyclostationarity analysis is proposed to distinguish the drone radio controller signals from other signals utilizing 2.4 GHz ISM band. Then, a variant of short-term Fourier transform is introduced to extract the parameters of detected drone remote controller signals. The correct hopping signals are then aggregated based on the clustered parameters to obtain their combined baseband equivalent signal. Furthermore, the resampling process is applied to reduce the unrelated samples in the spectrum and represent the spectrum with the reconstructed signal, which has a much lower bandwidth than the spread bandwidth. Finally, two different multiple signal classification algorithms are utilized to estimate the direction of the drone controller relative to the receiving system. In order to validate the overall performance of the proposed method, the introduced framework is implemented on hardware platforms and tested under real-world conditions. A uniform linear antenna array is utilized to capture over-the-air signals in hilly terrain suburban environments by considering both line-of-sight and non-line–of-sight cases. Direction estimation performance is presented in a comparative manner and relevant discussions are provided.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "348",
      "title": "Interference and Priority Aware Coexistence (IPC) Algorithm for Link Scheduling in IEEE 802.15.6 Based WBANs",
      "abstract": "This paper presents an Interference and Priority aware Coexistence (IPC) algorithm to ensure coexistence between multiple WBANs communicating within each other transmission range. By intelligently keeping an interfering WBAN silent, the IPC approach aims to maximize simultaneous (interference-free) transmissions from sensor nodes of different WBANs. Coordinators use beacons to exchange interference and priority aware metrics. This information is later used to generate an interference graph of the sensors associated with the coordinator and perform link scheduling. The IPC approach has been evaluated for two different interference scenarios namely, a High interference scenario which considers interference from the highest interfering coordinator or sensor node of all coexisting WBANs, and a Moderate interference scenario (conventionally used in the existing literature) which considers interference from the coordinator only. Considering the mobility of WBANs, the performance of IPC is evaluated in terms of spatial reuse, system throughput, delay, and packet delivery rate. IPC shows significant improvement in all performance metrics over existing schemes.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "349",
      "title": "Systematization of a Multilevel-Topology-Based Linear Amplifier Family for Noiseless DC–AC Power Conversion",
      "abstract": "Electrical power converters use semiconductor switching devices for a larger loss reduction compared with non-switching power linear amplifiers, such as class-B amplifiers. However, it is well known that the switching operation produces harmonics and electromagnetic interference noise; consequently, passive components are usually required for the suppression of these harmful subproducts. The use of recent fast power devices such as silicon carbide and gallium nitride devices produces larger \ndv\n / \ndt\n and \ndi\n / \ndt\n than Si power devices, and, as a result, the above-mentioned problem becomes more tangible. In this study, we propose the concept of a family of multilevel linear amplifiers (MLLA) in which no switching power conversion is possible. MLLAs consist of series-connected switching devices, and only one of them operates as a linear amplifier, and the loss is much less than that of the class-B amplifier. The concept of the family is very useful when a proper MLLA topology is selected for application. In this study, three types of MLLA—diode-clamped, flying-capacitor, and novel modular-cascaded linear amplifiers—with four devices connected in series were investigated, and an efficiency of >82% was demonstrated in the experiments.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "350",
      "title": "Secure Real-Time Chaotic Partial Encryption of Entropy-Coded Multimedia Information for Mobile Devices: Smartphones",
      "abstract": "Smartphones penetration-rate continues expanding, from 44% in 2017 up to 59% expected increase in 2022 as reported by Strategy Analytics. At present, smartphones dominate the global mobile traffic, which in turn is dominated by video communications. For mobile systems with limited power capabilities, the processing of real-time multimedia information with affixed security represents a real challenge. In this work, we propose a high-performance encryption scheme capable of running on low-power smartphones without holding back video coding operation. We are aimed at destroying the meaning of the entropy coded bitstream by inserting random bit errors to induce error propagation and impede natural self-resynchronization process. The scheme consists of three main process: 1) A new integer \nchaos-based Coupled-Map Lattice\n-CML for creating secure pseudo-random trajectories; 2) \nRandom bit flipping\n of the bitstream based on a Dynamic Reference Point (DRP) not exposed to attackers; and 3) \nRandom selection\n of CML byte-trajectories for both \nDRP\n and bit flipping processes for increased security. Implementation of the scheme on smartphones with different CPU-power capabilities shows \nexcellent performance\n to handle high-bandwidth real-time video smoothly (one-to-one and group calls). The scheme provides high scalable security with encrypted data volume fluctuating between 0.7%-3% of the total compressed data (video and still images).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "351",
      "title": "Estimating the Bot Population on Twitter via Random Walk Based Sampling",
      "abstract": "The rise of social bots, which contribute to marketing, political intervention, and the spread of fake news, has been noted. Analysis methods for the characteristics of Twitter bots have been developed for third-party researchers who have access limitations to Twitter data. Here, we propose a method for estimating the bot population on Twitter based on a random walk. The proposed method addresses two major problems in estimating the bot population on Twitter based on a random walk. First, the maximum number of retrievable friends or followers of a user per query is limited. Second, there is a certain percentage of private users who do not publish personal content, e.g., friends, followers, and tweets. We conduct a simulation analysis using directed social graph datasets to validate whether the proposed estimator is effective on the real Twitter follow graph. Then, we present three different estimates of the bot population on Twitter using the proposed estimator based on the three sample sequences of 25,000 users collected in 2.5 weeks each. The three estimates consistently suggest that 8%–18% of Twitter users during April–June 2021 are bots.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "352",
      "title": "Goal Programming Approach for Energy Management of Smart Building",
      "abstract": "In this paper, a collective residential building is considered in which the following points are taken into consideration: (i) a flexibility value of Contract Power (CP) is considered for each consumer; (ii) it is assumed a single CP for the entire building; (iii) an energy resource manager entity is considered to manage the energy resources in the residential building, such as Electric Vehicles (EVs), Photovoltaic (PV) generation system, and the Battery Energy Storage System (BESS). Taking into consideration the previous assumptions, the major goal of this work is to minimize the electricity consumption costs of the residential building by using a Multi-Objective Mixed-Binary Linear Programming (MOMBLP) formulation. The objective function of the MOMBLP model minimizes the electricity cost consumption of each apartment. Then, a Goal Programming (GP) strategy is applied to find the most appropriate solutions for the proposed MOMBLP model. Finally, the performance of the suggested model is evaluated by comparing the obtained results from a Single-Objective Mixed-Binary Linear Programming (SOMBLP) approach in which the whole building consumption cost is minimized. The results show that using the GP strategy a reduction of 7.5% in the total annual energy consumption is verified in comparison with SOMBLP. Moreover, the GP approach leads to fair benefit among building consumers, by finding a solution with less distance from the desired level.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "353",
      "title": "An Accurate Matching Query Method of Natural Language Knowledge Graph Based on Hierarchical Graph Topological Sequence",
      "abstract": "In recent years, although the application of knowledge graph in natural language processing has made some progress, there are still some key problems to be solved, especially the matching query problem in natural language knowledge graph. Since the basic data model of knowledge graph is graph, the matching query problem in natural language knowledge graph is usually transformed into graph matching query problem. However, at present, the traditional graph matching technology applied in knowledge graph consumes too much time and has low query efficiency, which cannot meet the needs of users for large-scale natural language knowledge graph query. Based on the full analysis of the defects of the traditional graph matching technology applied in the knowledge graph, according to the characteristics of the natural language knowledge graph, in order to improve the query efficiency, we propose an accurate matching query method of graph hierarchical topological sequence based on the graph model of knowledge graph. Through experiment analysis, compared with the traditional graph model matching algorithm applied in knowledge graph query, this method can quickly filter the unqualified knowledge graph candidate sets, effectively reduce the number of knowledge graph candidate sets, and make it have more advantages in matching efficiency and time performance. In addition, compared with two algorithms of \nGIndex\n and \nFG-Index\n, this method has better performance in index construction time, average size of candidate set and average running time of online update.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "354",
      "title": "Asymmetric Pulse Frequency Modulation With Constant On-Time for Series Resonant Converter in High-Voltage High-Power Applications",
      "abstract": "The series resonant converter (SRC), controlled by the traditional pulse frequency modulation (PFM) with constant on-time, can operate in discontinuous conduction mode (DCM) and is applicable for high-voltage high-power applications with the requirement of a wide output voltage range. However, in the traditional PFM with constant on-time, the resonant capacitor voltage will be higher than the input voltage during the zero current stage, leading to a higher maximum magnetic flux density (MMFD) case. To avoid this, a novel asymmetric pulse frequency modulation (APFM) with constant on-time is proposed for SRC operating in DCM, where the MMFD of transformer core varies linearly with the operating frequency and output voltage among the whole output voltage range. The high-power transformer can be designed according to highest operating frequency and the transformer turns ratio can be designed to be small. Furthermore, the proposed APFM leads to smaller peak current for all switches and fully zero-current-switching can be achieved. The output power and voltage can be still regulated, meeting the high-voltage high-power applications. For the proposed APFM, there are four different driver combinations with exact the same effects and advantages. The theoretical analysis has been validated by the established simulation model and experimental platform.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "355",
      "title": "RESHAPE: Reverse-Edited Synthetic Hypotheses for Automatic Post-Editing",
      "abstract": "Synthetic training data has been extensively used to train Automatic Post-Editing (APE) models in many recent studies because the quantity of human-created data has been considered insufficient. However, the most widely used synthetic APE dataset, eSCAPE, overlooks respecting the minimal editing property of genuine data, and this defect may have been a limiting factor for the performance of APE models. This article suggests adapting back-translation to APE to constrain edit distance, while using stochastic sampling in decoding to maintain the diversity of outputs, to create a new synthetic APE dataset, \nRESHAPE\n. Our experiments show that (1) RESHAPE contains more samples resembling genuine APE data than eSCAPE does, and (2) using RESHAPE as new training data improves APE models’ performance substantially over using eSCAPE.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "356",
      "title": "On the Throughput Performance of TCP Cubic in Millimeter-Wave Cellular Networks",
      "abstract": "In this paper, we study a cross-layer analysis framework for the performance evaluation of TCP over millimeter-Wave (mmWave) fading channels in the fifth-generation (5G) cellular networks, when the truncated incremental redundancy hybrid automatic repeat request (IR-HARQ) scheme and adaptive modulation and coding (AMC) are employed. Specifically, the throughput performance of TCP Cubic, which is one of the most widely deployed TCP variants in the Internet, is investigated. For this purpose, the mmWave fading channel, approximated by Nakagami-m distribution, is captured by a finite-state Markov chain (FSMC) to develop a transmission loss model. A loss-based TCP model, which is analyzed based on the transmission loss model, is then used to analytically derive the TCP throughput performance. The numerical results quantitatively show the effect of different parameters/settings of AMC, IR-HARQ, blockages and mmWave fading channels on the TCP performance and support the optimal selection of parameters to maximize the system throughput. Monte Carlo simulations are also performed to validate the analytical results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "357",
      "title": "Photonics-Assisted Multi-Band Dual Linear/Nonlinear Chirp Waveform Generation Based on Optical Phase Modulation",
      "abstract": "A novel photonic scheme for generating multi-band dual-chirp waveforms with linear or nonlinear chirp rates is proposed via two cascaded polarization modulators (PolMs) paralleled with a phase modulator (PM). The cascaded PolMs produce a flat optical frequency comb (OFC) as a multi-frequency reference light, while the PM is driven by the power-function-type baseband signals to obtain the lightwave with different order phase chirp. The phase-chirped lightwave and the multi-frequency reference lightwave are orthogonally coupled by a polarization beam combiner (PBC) and then recombined via a polarization beam splitter (PBS) to make them in-phase in one output port of the PBS and anti-phase in the other. The two recombined lightwaves are detected by a balanced photodetector (BPD), and the different order dual-chirp signals, covering six bands, can be generated in their differential photocurrent without interference components. Compared with the single-chirp signal of the knife-edge-type ambiguity function, the dual-chirp signal with the peak-saliency-type ambiguity function significantly suppresses sidelobes and shows better range-Doppler resolution performance. With the 1GHz-bandwidth and 102.4ns-duration quadratic baseband driving signal, six-band linear dual-chirp signal, centered at 10, 30, 50, 70, 90 and 110GHz, are generated by simulation, and each linear dual-chirp signal has a bandwidth of 4.1GHz, the pulse compression ratio of 465.45 and the peak-to-sidelobe ratio (PSLR) of 12.8dB. As baseband driving signal has higher (3rd) order power, the six-band nonlinear dual-chirp signals with the same central frequencies can also be generated but with increased bandwidth (6.3GHz) and improved PSLR (15.51dB). Their autocorrelation functions show that compared with the linear chirp signal, the nonlinear chirp signal has better sidelobe suppression capability, which is improve as the degree of nonlinearity increase.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "358",
      "title": "An Overview of Automotive Service-Oriented Architectures and Implications for Security Countermeasures",
      "abstract": "New requirements from the customers' and manufacturers' point of view such as adding new software functions during the product life cycle require a transformed architecture design for future vehicles. The paradigm of signal-oriented communication established for many years will increasingly be replaced by service-oriented approaches in order to increase the update and upgrade capability. In this article, we provide an overview of current protocols and communication patterns for automotive architectures based on the service-oriented architecture (SOA) paradigm and compare them with signal-oriented approaches. Resulting challenges and opportunities of SOAs with respect to information security are outlined and discussed. For this purpose, we explain different security countermeasures and present a state of the section of automotive approaches in the fields of firewalls, Intrusion Detection Systems (IDSs) and Identity and Access Management (IAM). Our final discussion is based on an exemplary hybrid architecture (signal- and service-oriented) and examines the adaptation of existing security measures as well as their specific security features.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "359",
      "title": "Enhanced Deep Belief Network Based on Ensemble Learning and Tree-Structured of Parzen Estimators: An Optimal Photovoltaic Power Forecasting Method",
      "abstract": "The random fluctuation and non-uniformity of Photovoltaic (PV) power generation greatly affect the power grids’ stability and operation. This paper addresses the high volatility of PV power by proposing a precise and reliable ensemble learning model for short-term PV power generation forecasting. The proposed forecasting tool incorporates a base model and meta-model layers. The first-layer base learner combines extreme learning machines, extremely randomized trees, k-nearest neighbor, and mondrian forest models. The meta-model layer exploits deep belief network to generate the final outputs. The hyper-parameters of the proposed stacking ensemble are carefully tuned using the tree-structured of parzen estimators algorithm to achieve top-notch predictive performance. The proposed model is thoroughly assessed through an empirical study using a real data set from Australia. The simulation results confirm the performance superiority of the proposed model over the existing forecasting models with the lowest average root mean square error and mean absolute percentage error of 3.88kW and 2.30%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "360",
      "title": "4-D SLAM: An Efficient Dynamic Bayes Network-Based Approach for Dynamic Scene Understanding",
      "abstract": "Most of the existing simultaneous localization and mapping (SLAM) methods are based on the static environment assumption. The presence of moving objects in the scene will lead to much uncertainty in SLAM results, which also hinders the loop-closure detection (LCD). Although moving object tracking (MOT) is necessary for planning and decisions, it is often accomplished separately. To jointly solve SLAM and MOT for complex urban driving scenarios, this paper presents a high performance method named 4D-SLAM based on the fusion of LiDAR and IMU. The integration of SLAM and MOT is formulated as a joint posterior probability problem based on a dynamic Bayesian network (DBN) and is implemented with the following four sequential stages: preprocessing, moving object detection and tracking, odometry estimation and mapping. In the preprocessing stage, the motion distortion uncertainty caused by LiDAR scanning is first compensated for, and the initial LiDAR motion is estimated. In the moving object detection and tracking stage, we exploit a CNN-based segmentation network to detect the potential moving objects first, then the states of the potential moving objects are optimized by an unscented Kalman filter (UKF). In the odometry estimation stage, the distinctive planar and edge features extracted from a static background point cloud are used for the odometry estimation, and a two-step Levenberg-Marquardt optimization method is adopted to solve the 6DOF pose across consecutive scans. In the mapping stage, the mapping based on the pose estimation result and LCD are realized, and graph-based global optimization is exploited to further improve the map consistency for large scale environment. The comprehensive experiments with the open source dataset KITTI and the data collected by us show that the presented method not only outperforms the SOTA SLAM methods in terms of trajectory and mapping accuracy but can also detect and track moving objects efficiently.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "361",
      "title": "Intelligent Path Planning for AUVs in Dynamic Environments: An EDA-Based Learning Fixed Height Histogram Approach",
      "abstract": "Autonomous underwater vehicles (AUVs) are robots that require path planning to complete missions in different kinds of underwater environments. The goal of path planning is to find a feasible path from the start-point to the target-point in a given environment. In most practical applications, environments have dynamic factors, such as ocean flows and moving obstacles, which make the AUV path planning more challenging. This paper proposes an estimation of distribution algorithm (EDA) based approach, termed as learning fixed-height histogram (LFHH) to solve path planning problems for AUVs in dynamic environment. The LFHH uses a learning transformation strategy (LTS) to improve its accuracy and convergence speed. Besides, a smooth method is employed to accelerate the speed of finding feasible paths. Moreover, a planning window is adopted to help handle dynamic factors. LFHH is tested in both complex 2-D and 3-D environments with time-variant dynamic factors, and experimental results validate the effectiveness of LFHH.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "362",
      "title": "A Genetic Algorithm-Based Approach for Fluctuating QoS Aware Selection of IoT Services",
      "abstract": "In recent years, the Internet of Things (IoT) has evolved at an exceptional speed, which enables to interconnect a very large number of heterogeneous, distributed, and mobile devices. This number will exceed 70 billion by 2025 according to Statista.\na\n with this huge amount of connected objects, the fulfillment of complex IoT applications, which usually requires a combination of several IoT objects, remains a real challenge. Besides, several requirements of Quality of Service (QoS) must be fulfilled, which makes the problem of selecting the appropriate IoT services NP-hard. In the literature, two main techniques for QoS-driven service selection are proposed: global selection characterized by a poor performance in dynamic and distributed huge environments and local selection which considers pre-defined local QoS constraints. Mainly, the existing works consider static QoS. However, in real life scenarios, QoS of IoT services can be fluctuating. To enhance the reliability of IoT applications, it is of paramount importance to consider the fluctuation dimension. In this context, we propose a QoS fluctuation-aware selection approach of IoT services. To do so, we propose a near-to optimal distributed approach that relies on decomposing the global QoS into distinct local constraints that serve as upper/lower bounds for selection while enhancing the reliability of the resulting composition by considering the QoS fluctuation of the candidate IoT services. The approach, we propose is based on a multi-objective evolutionary algorithm (MOEA) to solve the global QoS decomposition problem. Then a local selection using the obtained local constraints is performed in a parallel and distributed way. The performance of the proposed approach is evaluated and validated via experiment series.\nahttps://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "363",
      "title": "Performance Impact of Simulation-Based Virtual Laboratory on Engineering Students: A Case Study of Australia Virtual System",
      "abstract": "Practitioners of virtual laboratory confront issues on how to fulfill individuals' needs, motivate them to participate and use the tools, and to enhance their performance using virtual tools. Therefore, this study aims at examining the effects of usability and learning objective factors in evaluating students' performance impact from using virtual laboratory. The study proposes a theoretical model based on usability factors of technology acceptance model (perceived ease of use and perceived usefulness) and laboratory learning objectives (instruments, creativity and innovation) to capture the entire patterns of students' perceptions and use outcomes from using the simulation-based virtual laboratory. The study collected survey data from 116 first year Electrical Engineering students from the University of Queensland in Australia, reflecting their personal experience in using virtual laboratory tools. Partial least square approach using structural equation modeling technique (PLS-SEM) was used for statistical analysis and model testing. The results confirm that the proposed model provides a comprehensive understanding of students' perceptions and the understudy factors were truly significant in reflecting their performance impact from using such laboratory tools. More specifically, instrumentation and perceived usefulness of virtual laboratory were found to be the most significant influencing factors that have impacts on students' performance. Also, the findings shed light on the mediation roles of laboratory learning objectives between usability factors and use outcomes. Overall, this study contributes to literature by demonstrating the beneficial use of laboratory learning objectives in creating realistic and credible simulation tool, that can expedite the learning process and foster students' learning outcomes.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "364",
      "title": "Locating Objects in Warehouses Using BLE Beacons & Machine Learning",
      "abstract": "Warehouse management plays a pivotal role to boost the entire supply chain. To increase productivity, enterprises are focusing on different object localization approaches to achieve better accuracy amid high interferences. This helps to reduce the overall time for order taking & perform effective stock management. For this purpose, we propose a cost-effective system to achieve better accuracy for locating objects in indoor spaces with the help of BLE beacons. BLE is the term used for the Bluetooth wireless standard for low power consumption. BLE beacons are used as technology enablers because BLE supports all the major mobile smart devices and tablets. The measurement is performed using Received Signal Strength Indication (RSSI). Also, improved the location accuracy with the help of machine learning algorithms & utilizing neighborhood beacons for real-world use cases of warehouse management. The target object & neighborhood beacons provide the raw data to the system & the mobile device acts as a receiver. Our results show that the proposed work provides high accuracy for finding resources, taking orders & improving the overall stock process in warehouse management.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "365",
      "title": "A Time-Varying Opportunistic Multiple Access for Delay-Sensitive Inference in Wireless Sensor Networks",
      "abstract": "We consider distributed transmission scheduling for inference over multiple access channels (MAC) using a wireless sensor network (WSN). The sensors transmit their data simultaneously using common shaping waveforms through finite-state Markovian fading channels, and the fusion center (FC) receives a superposition of the analog transmitted signals. The inference task is computed by the FC and is based on data received from the sensors. We study the case of delay-sensitive inference, where each sensor must schedule its transmission in one of D consecutive time slots. The essence of the problem is to schedule transmissions by exploiting the channel diversity over time slots to minimize the expected transmission energy consumed during the inference task. We formulate the transmission scheduling problem as a finite-horizon Markov decision process (MDP) with a continuous state space. By judiciously exploiting the inherent structure of the associated dynamic programming (DP) problem, we prove that the optimal solution obeys a time-varying threshold-based policy with low complexity (thus avoiding the general intractable complexity of DP with the problem size). We then establish a novel Time-varying Opportunistic Multiple Access (TOMA) protocol based on the structured DP solution.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "366",
      "title": "Tremor Suppression With Mechanical Vibration Stimulation",
      "abstract": "Tremor, which is one of the most common movement disorders, is a repetitive movement that is caused by periodic muscle contraction and relaxation. To suppress tremors of upper-limb tremor patients, such as essential tremor (ET) patients, many kinds of devices have been developed. On the other hand, when mechanical vibration stimulation is applied to a human muscle, sustained muscle contraction, which is referred to as the tonic vibration reflex (TVR), is induced in the stimulated muscle. In this study, a novel tremor suppression method that utilizes the periodic TVR to induce muscle contraction/relaxation to generate the counterphase motion of the ET is proposed and applied to the forearm pronation-supination ET. In the proposed method, periodic vibration stimulation is applied to generate the periodic TVR in the pronator teres muscle and/or supinator muscle. First, the results confirmed that the TVR can be induced by applying mechanical vibration stimulation to the pronator teres muscle and supinator muscle since the forearm pronation-supination tremor is one of the key features of the ET. Furthermore, the findings also confirmed that the TVR intensity that is induced in these muscles can be adjusted by changing the vibration stimulation frequency. Second, the results show that the counterphase motion of the ET (i.e., periodic pronation-supination motion) can be generated by applying the proposed method. The effectiveness of the proposed method for tremor suppression is evaluated by comparing the generated motion with the ET motion.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "367",
      "title": "Video Shot Boundary Detection Based on Feature Fusion and Clustering Technique",
      "abstract": "For the problems of low accuracy and high complexity in detection of gradual shot boundary and long shot, a new video shot boundary detection algorithm based on feature fusion and clustering technique (FFCT) is proposed. In the algorithm, the interval frames of video sequence are selected, converted to gray images and scaled by sampling. With the frames, the speed-up robust features (SURF) and fingerprint features are extracted from non-compressed domain and compressed domain, and then the extracted features are fused. Next, K-means method is used to cluster the fused features, and linear discriminant analysis (LDA) is introduced to map the clusters to realize cohesion within classes and looseness among classes. Finally, the correlation of the feature classes between frames is calculated, and the features in each class are selected through density calculation and matched to realize the coarse detection and fine detection of video shot boundary. In the experiment, compared with the latest representative algorithms, it has the highest accuracy for the proposed algorithm. In particular, the detection of gradual shot boundary and long shot are also more accurate. Meanwhile, the average time consumption is also reduced. The experimental results show that the proposed algorithm has high accuracy and time efficiency, especially for gradual shot boundary and long shot detection.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "368",
      "title": "A Deep Learning Approach for IoT Traffic Multi-Classification in a Smart-City Scenario",
      "abstract": "As the number of Internet of Things (IoT) devices and applications increases, the capacity of the IoT access networks is considerably stressed. This can create significant performance bottlenecks in various layers of an end-to-end communication path, including the scheduling of the spectrum, the resource requirements for processing the IoT data at the Edge and/or Cloud, and the attainable delay for critical emergency scenarios. Thus, a proper classification or prediction of the time varying traffic characteristics of the IoT devices is required. However, this classification remains at large an open challenge. Most of the existing solutions are based on machine learning techniques, which nonetheless present high computational cost, whereas they are not considering the fine-grained flow characteristics of the traffic. To this end, this paper introduces the following four contributions. Firstly, we provide an extended feature set including, flow, packet and device level features to characterize the IoT devices in the context of a smart environment. Secondly, we propose a custom weighting based preprocessing algorithm to determine the importance of the data values. Thirdly, we present insights into traffic characteristics using feature selection and correlation mechanisms. Finally, we develop a two-stage learning algorithm and we demonstrate its ability to accurately categorize the IoT devices in two different datasets. The evaluation results show that the proposed learning framework achieves 99.9% accuracy for the first dataset and 99.8% accuracy for the second. Additionally, for the first dataset we achieve a precision and recall performance of 99.6% and 99.5%, while for the second dataset the precission and recall attained is of 99.6% and 99.7% respectively. These results show that our approach clearly outperforms other well-known machine learning methods. Hence, this work provides a useful model deployed in a realistic IoT scenario, where IoT traffic and devices’ pr...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "369",
      "title": "Learning-Based Signal Detection for Wireless OAM-MIMO Systems With Uniform Circular Array Antennas",
      "abstract": "This paper presents a neural-like network-based signal detection method for orbital angular momentum multiplexing systems with uniform circular array antennas. The signal detection network is derived by unfolding the alternating direction method of multipliers (ADMM), and in addition, a parallel interference cancellation (PIC) function is integrated, which enhances the tolerance to inter-mode interference while keeping the complexity feasible. The number of parameters to be learned in each layer of the network is a linear order of the number of antenna elements. Simulation results show that the ADMM-PIC detector exhibits excellent error performance, which cannot be achieved by a conventional minimum mean square error-based detector.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "370",
      "title": "Least Squares Generative Adversarial Networks-Based Anomaly Detection",
      "abstract": "Multivariate statistical process control (MSPC) is a technique for detecting anomalies by monitoring several quality characteristics simultaneously. For the MSPC problem, the Hotelling’s \n T2 \n control chart has been widely used as a typical method. Recently, researchers have converted the MSPC problem into a classification problem such as the artificial contrast (AC) and the one-class classification (OCC). Previous studies have shown that these methods outperform the Hotelling’s \n T2 \n chart when the data do not follow a multivariate normal distribution. However, unless the size of the process data is enough for the AC and the OCC, they cannot work properly. To tackle this problem, in this paper, we propose a novel anomaly detection (AD) approach. The proposed method adopts the least square generative adversarial network (LS-GAN) to estimate the probability distribution of the training data. It generates new training samples from the learned probability distribution. The classifiers such as the random forests (RF) and the one-class support vector machines (OC-SVM) are considered for tackling the AC and the OCC respectively. The numerical experiments demonstrate that the proposed approach outperforms the existing methods in terms of the area under the receiver operating characteristic (ROC) curve (AUC).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "371",
      "title": "Subjective Answers Evaluation Using Machine Learning and Natural Language Processing",
      "abstract": "Subjective paper evaluation is a tricky and tiresome task to do by manual labor. Insufficient understanding and acceptance of data are crucial challenges while analyzing subjective papers using Artificial Intelligence (AI). Several attempts have been made to score students’ answers using computer science. However, most of the work uses traditional counts or specific words to achieve this task. Furthermore, there is a lack of curated data sets as well. This paper proposes a novel approach that utilizes various machine learning, natural language processing techniques, and tools such as Wordnet, Word2vec, word mover’s distance (WMD), cosine similarity, multinomial naive bayes (MNB), and term frequency-inverse document frequency (TF-IDF) to evaluate descriptive answers automatically. Solution statements and keywords are used to evaluate answers, and a machine learning model is trained to predict the grades of answers. Results show that WMD performs better than cosine similarity overall. With enough training, the machine learning model could be used as a standalone as well. Experimentation produces an accuracy of 88% without the MNB model. The error rate is further reduced by 1.3% using MNB.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "372",
      "title": "IEEE Access Special Section: Radio Frequency Identification and Security Techniques",
      "abstract": "Radio Frequency Identification (RFID) systems have been receiving much attention in the last few decades due to their effective role in our everyday life. They propose different solutions to many vital applications. Moreover, RFID systems are the backbone of modern Internet-of-Things (IoT) and Near-Field Communication (NFC) systems. Extending the capacity of such systems and making them more secure is the desired objective of the research community.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "373",
      "title": "Data-Driven Network Simulation for Performance Analysis of Anticipatory Vehicular Communication Systems",
      "abstract": "The provision of reliable connectivity is envisioned as a key enabler for future autonomous driving. Anticipatory communication techniques have been proposed for proactively considering the properties of the highly dynamic radio channel within the communication systems themselves. Since real world experiments are highly time-consuming and lack a controllable environment, performance evaluations and parameter studies for novel anticipatory vehicular communication systems are typically carried out based on network simulations. However, due to the required simplifications and the wide range of unknown parameters (e.g., Mobile Network Operator (MNO)-specific configurations of the network infrastructure), the achieved results often differ significantly from the behavior in real world evaluations. In this paper, we present Data-driven Network Simulation (DDNS) as a novel data-driven approach for analyzing and optimizing anticipatory vehicular communication systems. Different machine learning models are combined for achieving a close to reality representation of the analyzed system's behavior. In a proof of concept evaluation focusing on opportunistic vehicular data transfer, the proposed method is validated against field measurements and system-level network simulation. In contrast to the latter, DDNS does not only provide massively faster result generation, it also achieves a significantly better representation of the real world behavior due to implicit consideration of cross-layer dependencies by the machine learning approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "374",
      "title": "An Integrative User-Level Customized Modeling and Simulation Environment for Smart Manufacturing",
      "abstract": "As smart factories are emerging, the importance of modeling and simulation (M&S) continues to increase in the production system. As a result, various commercial tools and environments are provided for production simulation, and manufacturing companies are also applying them to establish a smart manufacturing system. This is used in various ways, such as optimal layout design, scheduling, and fault diagnosis using the acquired smart manufacturing model. However, these model constructions are generally done through a stand-alone environment in which the work type or user level is not considered. It is necessary to use different environments depending on the user level or to rely on M&S experts. Therefore, this paper eliminates this inefficiency and proposes an integrative user-level customized smart manufacturing M&S environment for all users in the production system. It provides three-phase modeling environments appropriate for the user level, including an automatic model synthesis interface and a production line generator. Using this environment, anyone can easily make capacity and logistic models, and simulate them.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "375",
      "title": "Research and Embedded Implementation of Let-Off and Take-Up Dynamic Control Based on Fuzzy Neural Network and Vector Control Optimization",
      "abstract": "This paper investigates the warp let-off and take-up mechanism of rapier looms to solve the problem that the warp tension of rapier looms fluctuates greatly and the warp let-off is difficult to maintain constant. The design and hardware implementation of a let-off and take-up control system based on fuzzy neural network (FNN) and vector control (VC) are presented to improve the control level of warp tension and drive performance of the let-off and take-up system. Firstly, the spring-damper dynamic model of the warp is established according to the mechanical properties. The parametric expression of warp tension and the control strategy of fixed angle interval based on let-off and take-up motions are constructed according to the generation mechanism and fluctuation law of warp tension. Then, based on fuzzy reasoning mechanism and neural network model, the fusion theory of fuzzy neural network is introduced, and a tension controller based on T-S fuzzy neural network (FNN) is designed. FNN is trained by introducing genetic optimization and the backpropagation fusion algorithm (GA-BP). In addition, a specialized let-off and take-up hardware circuit is constructed through embedded technology, and the SVPWM algorithm is used as the driving scheme of the hardware circuit. Finally, simulation and actual weaving experiments test the proposed let-off and take-up control system and hardware circuit. The results show that, compared to PID and fuzzy PID, the proposed fuzzy neural network algorithm has higher tension control accuracy and can effectively restrain the rapier loom’s warp tension undulation. The designed hardware circuit and SVPWM algorithm have a fast and stable driving ability, which ensures the constant let-off amount.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "376",
      "title": "An Approach to Detect Anomaly in Video Using Deep Generative Network",
      "abstract": "Anomaly detection in the video has recently gained attention due to its importance in the intelligent surveillance system. Even though the performance of the state-of-art methods has been competitive in the benchmark dataset, the trade-off between the computational resource and the accuracy of the anomaly detection should be considered. In this paper, we present a framework to detect anomalies in video. We proposed a “multi-scale U-Net” network architecture, the unsupervised learning for anomaly detection in video based on generative adversarial network (GAN) structure. Shortcut Inception Modules (SIMs) and residual skip connection are employed to the generator network to increase the ability of the training and testing of the neural network. An asymmetric convolution has been applied instead of traditional convolution layers to decrease the number of training parameters without performance penalty in terms of detection accuracy. In the training phase, the generator network was trained to generate the normal events and attempt to make the generated image and the ground truth to be similar. A multi-scale U-Net kept useful features of an image that were lost during training caused by the convolution operator. The generator network is trained by minimizing the reconstruction error on the normal data and then using the reconstruction error as an indicator of anomalies in the testing phase. Our proposed framework has been evaluated on three benchmark datasets, including UCSD pedestrian, CHUK Avenue, and ShanghaiTech. As a result, the proposed framework surpasses the state-of-the-art learning-based methods on all these datasets, which achieved 95.7%, 86.9%, and 73.0% in terms of AUC. Moreover, the numbers of training and testing parameters in our framework are reduced compared to the baseline network architecture, while the detection accuracy is still improved.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "377",
      "title": "Adaptive Transceiver Architecture With QoS Provision for OCDMA Network Based on Logic Gates",
      "abstract": "Utilization of an adaptable transceiver with quality of service (QoS) features is a promising notion to build next generation optical network. This paper proposes an adaptive transceiver design by adopting logic gates in the optical domain. The proposed design offers multiple scenarios to support QoS diversity with a slight modification of conventional optical code division multiple access (OCDMA) transceiver architecture through Sigma Shift Matrix (SSM) signature code. In particular, the proposed transceiver design categorizes the users into two classes of service, one having a higher quality level and the other having a lower quality level. Users of high class transmit at low interference versus high interference power for low classes’ users. To switch between the multiple scenarios, an optical Mux performs digital operation is developed and integrated to the transceiver design. This type of MUX is built by using a semiconductor optical amplifier (SOA). In addition, a comprehensive algorithm is developed to control the function of the adaptable transceiver. Five scenarios were formed and investigated to offer a platform for a different type of applications. A proof concept using Optisystem software demonstrates ability of the proposed architecture to efficiently switch between different levels of QoS as per user requirement and provide desired transmission capacity",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "378",
      "title": "State of the Art Sub-Terahertz Switching Solutions",
      "abstract": "In this paper the state of the art in RF switches for mm-wave frequency range is summarized and evaluated. Several leading technologies is presented from typical semiconductor devices based on transistors and diodes on Si, SiGe or III-V semiconductor substrates to more unconventional solutions such as microelectromechanical or phase-change material switches. The most important parameters and characteristics for those technologies are gathered and compiled for comparison. Besides different technologies, also various switch topologies of mm-wave switches are presented, assessed and compared. Furthermore, new emerging technological solutions approaching mm-wave range involving two-dimensional materials are also presented. Their evaluation is focused on proposed designs and current results for experimentally evaluated prototypes. Although the performance of these devices are currently not competitive with more traditional approaches, some reported results near the mm-wave range makes them a promising solution for future mm-wave switches and an interesting topic for further research and development.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "379",
      "title": "Systematic and Critical Review of RSA Based Public Key Cryptographic Schemes: Past and Present Status",
      "abstract": "The interconnected digital world is generating enormous data that must be secured from unauthorized access. Advancement in technologies and new innovative methods applied by attackers play an instrumental role in breaching data security. Public key Cryptography provides a set of cryptographic algorithms in achieving data security through confidentiality, integrity and authentication. Among all cryptographic algorithms in general and public key cryptography in particular, RSA is one of the most widely used and applied algorithms. Since its inception, it is commonly being adopted in securing data across different domains such as cloud, image and others. Despite its importance and wide applications, no such systematic and extensive survey exists in the literature. A systematic and thorough study of RSA based cryptography is presented in this work covering several domains. All the available works in this direction are divided into 11 different categories, viz, Hybrid, Parallel, Cloud, Image, Multiple-Keys, Chinese-Remainder-Theorem-based, Digital-Signatures, K-Nearest-Theorem-based, Batch, Wireless, and Core-Modifications. This study methodically explores RSA-based cryptosystems, either modifications in core RSA or applications of enhanced RSA across different domains, systematically categorizing in various categories and eventually providing findings and indications. The current study compares RSA methods based on parameters such as key generation, encryption schemes, decryption schemes, key features and enhancements, and also finds the leading areas where modified RSA has been applied in the recent past. As a result, this study will guide researchers and practitioners in understanding the past and present status of RSA cryptography along with the possibility of its applications in other domains.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "380",
      "title": "Tumor Depth and Size Perception Using a Pneumatic Tactile Display in Laparoscopic Surgery",
      "abstract": "Tumor location, depth, and size are essential information for tumor resection surgery. In open surgery, surgeons can obtain information by palpating the tissue with their fingers. In minimally invasive surgery, where the natural sense of touch is restricted, surgeons can rely on haptic information provided by haptic devices to determine the tumor characteristics. Tactile feedback is a promising representation modality for providing haptic information intuitively to surgeons during tissue palpation. In this paper, we propose a palpation strategy using tactile feedback to determine the tumor depth and size. For the palpation strategy, the tumor depth was determined by detecting the presence of the tumor at a given indentation depth of the sensor. Tumor size may be obtained by localizing the tumor edges. Fundamental experiments were conducted to investigate the use of contact force components in determining tumor features using the proposed strategy. The results indicated that the normal force is more useful in estimating the indentation depth, and the shear force is highly effective in detecting tumor regions and edges. Users’ ability to characterize the tumor using tactile feedback from our developed tactile display was demonstrated through tissue palpation tasks. Participants who received both normal force and shear force feedback could identify the depth and size of the embedded tumor with 66 % and 65 % accuracy, respectively. These results suggest that tactile displays that provide normal and shear force feedback can be successfully used for tumor characterization.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "381",
      "title": "Analysis and Prediction of Students’ Academic Performance Based on Educational Data Mining",
      "abstract": "The development of intelligent technologies gains popularity in the education field. The rapid growth of educational data indicates traditional processing methods may have limitations and distortion. Therefore, reconstructing the research technology of data mining in the education field has become increasingly prominent. In order to avoid unreasonable evaluation results and monitor the students’ future performance in advance, this paper comprehensively uses the relevant theories of clustering, discrimination and convolution neural network to analyze and predict students’ academic performance. Firstly, this paper proposes that the clustering-number determination is optimized by using a statistic which has never been used in the algorithm of K-means. Then, the clustering effect of K-means algorithm is tested by discriminant analysis. The convolutional neural network is introduced for training and testing data that are labeled with categories. The generated model can be used to predict prospective performance. Finally, in order to validate the prediction results, the effectiveness of the generated model is evaluated by using two metrics in two cross-validation methods. The experimental result demonstrates that the statistic not only solves the difficulty to determine the clustering number in K-means algorithm from an objective and quantitative point of view, but also improves the reliability of prediction results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "382",
      "title": "Resolving Energy Consumption Issues and Spectrum Allocation for Future Broadband Networks",
      "abstract": "With the fast and rapid pace of developments in wireless technology, energy consumption has become a problem of great significance for future networks. Over the past few years, several energy monitoring policies have been initiated to promote energy efficiency emphasizing the active and important role of consumers to realize this goal. This study resolves the energy consumption issues of broadband networks and determines the energy usage associated with high spectrum allocation in future broadband networks by leveraging clustering from the data mining domain. For analyzing the overall patterns of energy consumption in broadband networks, this study segments the broadband networks based on the similarities of their electrical load profiles and the proportion of energy usage per hour (%) as a common framework and divides the users into different groups. The prime objective for the segmentation is to provide personalized recommendations to each group to reduce the energy consumption and associated costs thereby fostering energy efficiency measures and improving consumer engagement. The segmentation is obtained by an iterative process based on computational clusters calculation which is finalized by a post clustering analysis. Post clustering analysis involves visualization and statistical data mining techniques to analyze the energy consumption patterns and reallocating to a more appropriate group. The K-Means clustering technique is utilized for this purpose which provides the best prediction accuracy of 98.46% for energy load profiles at the spectrum of 100GHz. The energy consumption segmentation of the consumers provides knowledge and a better understanding of the consumer for optimizing energy consumption for future broadband.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "383",
      "title": "Image Super-Resolution Reconstruction Based on a Generative Adversarial Network",
      "abstract": "In the field of computer vision, super-resolution reconstruction techniques based on deep learning have undergone considerable advancement; however, certain limitations remain, such as insufficient feature extraction and blurred image generation. To address these problems, we propose an image super-resolution reconstruction model based on a generative adversarial network. First, we employ a dual network structure in the generator network to solve the problem of insufficient feature extraction. The dual network structure is divided into an upsample subnetwork and a refinement subnetwork, which upsample and optimize a low-resolution image, respectively. In a scene with large upscaling factors, this structure can reduce the negative effect of noise and enhance the utilization of high-frequency details, thereby generating high-quality reconstruction results. Second, to generate sharper super-resolution images, we use the perceptual loss, which exhibits a fast convergence and excellent visual effect, to guide the generator network training. We apply the ResNeXt-50-32×4d network, which has few parameters and a large depth, to calculate the loss to obtain a reconstructed super-resolution image that is highly realistic. Finally, we introduce the Wasserstein distance into the discriminator network to enhance the discrimination ability and stability of the model. Specifically, this distance is employed to eliminate the activation function in the last layer of the network and avoid the use of the logarithm in calculating the loss function. Extensive experiments on the DIV2K, Set5, Set14, and BSD100 datasets demonstrate the effectiveness of the proposed model.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "384",
      "title": "How Does Proximity Affect the Dual Innovation of Alliance Partner? The Role of Knowledge Coupling",
      "abstract": "Recent work on alliance partner selection focuses on the relationship between partner features and alliance performance, while ignoring the influence mechanism of alliance partner features on different innovation types of firms. In this paper, based on proximity perspective, the influence mechanism model of alliance partner features on firms’ dual innovation is constructed. Analyzing questionnaires and patent data of high-tech firms, it is found that (1) Technological proximity (TP) has a positive impact on focal firms’ exploratory innovation (EXR) and exploitative innovation (EXI); (2) Knowledge coupling (KC) mediates the relationship between TP and dual innovation; (3) Social proximity (SP) positively moderates the relationship between TP and dual innovation, and positively moderates the relationship between TP and KC; Meanwhile, (4) there is a moderating effect of different levels of SP on the magnitude of the mediating effect of KC. By constructing a theoretical framework based on “proximity – knowledge coupling – dual innovation”, this paper is helpful to draw scholars’ attention to the relationship between proximity and dual innovation, and provide theoretical reference for firms to select alliance partners reasonably and efficiently.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "385",
      "title": "A Nonlinear Subspace Approach for Parametric Estimation of PDFs From Short Data Records With Application to Rayleigh Fading",
      "abstract": "This paper tackles the issue of real-time parametric estimation of a wide class of probability density functions from limited datasets. This type of estimation addresses recent applications that require joint sensing and actuation. The suggested estimator operates in the nonlinear subspace that the parameter space of the distribution creates in the measurement sample space. This enables the estimator to embed \n a \n \npriori\n available information about the distribution in the computations to produce parameter estimates that are induced by signal components belonging only to the correct class of density functions being considered. It also enables it to nullify the effect of those components that do not belong to this class on the estimation process. The estimator can, with high accuracy, compute quickly the parameters of a wide class of probability density functions from short data records. The approach is developed and basic proofs of correctness are carried-out for the Rayleigh distribution, which is used to characterize wireless communication channels experiencing fast fading in heavily cluttered environments. Simulation results demonstrate the capabilities of the suggested procedure and the clear advantages it has over conventional norm-based estimation techniques. The results also show the ability of the suggested approach to estimate other density functions including the two-parameter lognormal distribution used to characterize shadowing in wireless communication.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "386",
      "title": "Path Planning Algorithm Using the Hybridization of the Rapidly-Exploring Random Tree and Ant Colony Systems",
      "abstract": "This paper proposes a path planning algorithm using the hybridization of the rapidly-exploring random tree (RRT) and ant colony system (ACS) algorithms. The RRT algorithm can quickly generate paths. However, the resulting path is suboptimal. Meanwhile, the ACS algorithm can generate the optimal path from the suboptimal previous path information. Then, the proposed algorithm will combine the advantages of RRT with the ACS algorithm. Therefore, it can reach the optimal value with a good convergence speed. We call this proposed algorithm the RRT-ACS algorithm. This study developed a new method for hybridizing the RRT and ACS algorithms for path planning problems. This hybridization process is carried out using one of the ACS principles: the pseudorandom proportional rule. The performance of the proposed algorithm with the RRT*, informed RRT*, RRT*-connect, and informed RRT*-connect algorithms is tested with several benchmark cases. The test results from benchmark case tests with known optimal values indicate that the proposed algorithm has succeeded in achieving those optimal values. Furthermore, statistical tests have also been carried out to verify whether there is a significant difference in performance between the RRT-ACS algorithm and the existing algorithms. The test and statistical analysis results show that the RRT-ACS algorithm has good performance and convergence speed. We also discuss the stability, robustness, convergence, and rapidity of the RRT-ACS algorithm. The results indicates that the RRT-ACS algorithm may be used in applications that require fast and optimal path planning algorithms such as robots and autonomous vehicles.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "387",
      "title": "Kernel Parameter Optimization for Support Vector Machine Based on Sliding Mode Control",
      "abstract": "Support Vector Machine (SVM) is a supervised machine learning algorithm, which is used for robust and accurate classification. Despite its advantages, its classification speed deteriorates due to its large number of support vectors when dealing with large scale problems and dependency of its performance on its kernel parameter. This paper presents a kernel parameter optimization algorithm for Support Vector Machine (SVM) based on Sliding Mode Control algorithm in a closed-loop manner. The proposed method defines an error equation and a sliding surface, iteratively updates the Radial Basis Function (RBF) kernel parameter or the 2-degree polynomial kernel parameters, forcing SVM training error to converge below a threshold value. Due to the closed-loop nature of the proposed algorithm, key features such as robustness to uncertainty and fast convergence can be obtained. To assess the performance of the proposed technique, ten standard benchmark databases covering a range of applications were used. The proposed method and the state-of-the-art techniques were then used to classify the data. Experimental results show the proposed method is significantly faster and more accurate than the anchor SVM technique and some of the most recent methods. These achievements are due to the closed-loop nature of the proposed algorithm, which significantly has reduced the data dependency of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "388",
      "title": "Proof-of-Search: Combining Blockchain Consensus Formation With Solving Optimization Problems",
      "abstract": "To address the large amount of energy wasted by blockchains, we propose a decentralized consensus protocol for blockchains in which the computation can be used to search for good approximate solutions to any optimization problem. Our protocol allows the wasted energy to be used for finding approximate solutions to problems submitted by any nodes (called clients). Our protocol works in a similar way to proof-of-work, and it makes nodes evaluate a large number of solution candidates to add a new block to the chain. A client provides a search program that implements any search algorithm that finds a good solution by evaluating a large number of solution candidates. The node that finds the best approximate solution is rewarded by the client. Our analysis shows that the probability of a fork and the variance in the block time with our protocol are lower than those in proof-of-work.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "389",
      "title": "Genetic-Algorithm-Optimization-Based Predictive Functional Control for Chemical Industry Processes Against Partial Actuator Faults",
      "abstract": "Actuator faults, which are common in industrial processes, can make the controller fail to achieve the desired control objectives, which may lead to the degradation of control performance. In order to solve this problem, this paper proposes a predictive functional control based on genetic algorithm optimization. Firstly, an extended dimension discrete switched model is constructed, which consists of a state difference variable, tracking error and a new state variable including tracking error. In this model, the performance index function based on a genetic optimization algorithm is selected, and its parameters are adjusted and the controller is designed. Then, under the obtained control law, the switching signal is designed and the range of uncertainty caused by the actuator fault is given to realize the robustness of the system. At the same time, the corresponding robustly sufficient conditions are presented. The advantage of this design is to avoid the disadvantages of manually adjusting the performance parameters, and the system has good tracking performance. Finally, taking the typical injection molding process of chemical production process as an example, the speed and pressure parameters are controlled, and compared with the traditional control method, the effectiveness and feasibility of the proposed method are verified.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "390",
      "title": "Super Resolution Reconstruction of Images Based on Interpolation and Full Convolutional Neural Network and Application in Medical Fields",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "391",
      "title": "xCorrection to “Classification of Poetry Text Into the Emotional States Using Deep Learning Technique”",
      "abstract": "In the above article \n[1]\n, the affiliation of Fahad Mazaed Alotaibi was incorrectly listed, whereas the authors Shakeel Ahmad and Fahad Mazaed Alotaibi have the same affiliation as mentioned above.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "392",
      "title": "Aggregate Message Authentication Code Capable of Non-Adaptive Group-Testing",
      "abstract": "We introduce group-testing aggregate message authentication code (GTA MAC) and provide its formal study. We first specify its syntax and security requirements. Then, we present a scheme of generic construction which applies non-adaptive group-testing to aggregate MAC. We also confirm the security of the generic construction based on that of underlying aggregate MAC and a useful property of matrices representing non-adaptive group-testing. In addition, we instantiate the generic construction using the aggregate MAC scheme proposed by Katz and Lindell or a scheme using a cryptographic hash function for aggregating tags. Finally, we present some implementation results to show the effectiveness of our proposed GTA MAC.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "393",
      "title": "Achieving Privacy-Preserving Subset Aggregation in Fog-Enhanced IoT",
      "abstract": "Fog-enhanced IoT (Internet of Things) is a fast-growing technology in which many firms and industries are currently investing to develop their own real-time and low latency scenarios. Compared with the traditional IoT, fog-enhanced IoT can offer a higher level of efficiency and stronger security by providing local data pre-processing, filtering, and forwarding mechanisms. However, fog-enhanced IoT faces some security and privacy challenges, since fog nodes are deployed at the network edge and may not be fully trustable. In this paper, we present a new privacy-preserving subset aggregation scheme, called PPSA, in fog-enhanced IoT scenarios, that enables a query user to gain the sum of data from a subset of IoT devices. To identify the subset, inner product similarity of the normalized vectors in the query user side and each IoT device is securely computed. If the inner product is greater than the user's specified threshold, IoT device's data will be privately aggregated to form the final response. To successfully launch privacy-preserving subset aggregation in the proposed scheme, we employ the Paillier homomorphic encryption to encrypt user's attribute vector, similarity threshold, IoT end-devices' data, as well as the intermediate results. To the best of our knowledge, this work is the first one to address the privacy-preserving subset aggregation in fog-enhanced IoT. We analyze and extensively evaluate the efficiency and security of the proposed PPSA scheme, and the detailed analysis and results indicate that our proposed PPSA scheme can practically achieve privacy-preserving subset aggregation with significant communication and computational cost saving.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "394",
      "title": "Adaptive Event-Triggered H∞ Control for Networked Control Systems With Actuator Saturation and Random Nonlinearities",
      "abstract": "This paper investigates the problem of the adaptive event-triggered control for networked nonlinear systems with actuator saturation using dynamic output feedback controller (DOFC). In view of adaptive event-triggered mechanism (AETM), a model of networked control systems (NCSs) with actuator saturation and random nonlinearities is first established. Then, by constructing the Lyapunov-Krasovskii functional (LKF), sufficient condition for asymptotically stable with an H\n∞\n performance index is derived in terms of linear matrix inequalities (LMIs). In the process, through combining the Wirtinger-based integral inequality and the extended reciprocally convex matrix inequality (ERCMI), the delay-dependent integral terms obtained by the derivative of the constructed LKF are estimated. Based on the above results, the DOFC gains and corresponding AETM parameter are co-designed. Finally, two numerical examples are demonstrated to illustrate the effectiveness of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "395",
      "title": "Joint Power and Gain Allocation in MDM-WDM Optical Communication Networks Based on Enhanced Gaussian Noise Model",
      "abstract": "Achieving reliable communication over different wavelength channels and modes is one of the main goals of Mode Division Multiplexing-Wavelength Division Multiplexing (MDM-WDM) transmission. The reliability can be described by the minimum Signal to Noise Ratio (SNR) margin which depends on launch power, the gain of Few-Mode Erbium-Doped Fiber Amplifiers (FM-EDFA), and the nonlinear impairments of Few-Mode Fiber (FMF). In this paper, we develop the Enhanced Gaussian Noise (EGN) nonlinear model for FMF, which can be used in both weak and strong coupling regimes. We validate the model by comparing simulation results with those obtained through the Split-Step Fourier Method. Based on our proposed EGN model, we address the problem of joint optimized power and gain allocation based on minimum SNR margin maximization when accounting for practical FM-EDFA constraints such as saturation power and maximum gain. The problem is solved using a convex optimization approach and considering different scenarios such as the best equal power, optimized power, and joint optimized power and gain. Results demonstrate that the minimum SNR margin improvement for the joint optimized power and gain allocation compared to the best equal power allocation is \n 1.4 dB \n and \n 1.7 dB \n for MDM-single channel and single-mode fiber-WDM systems, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "396",
      "title": "Standing, Walking, and Sitting Support Robot Based on User State Estimation Using a Small Number of Sensors",
      "abstract": "With the aging of the population and the consequent severe shortage of caregivers, the demand for care robots to assist the elderly is increasing. However, care robots have yet to be widely adopted owing to cost constraints and anxiety issues due to several factors. For instance, care robots are required to have higher functionality than general care devices. It is important to provide both massive power and the appropriate support for the user’s state. However, this requires more sensors to obtain detailed information for user-state estimation and more actuators for physical support, increasing the cost and risk of failure. In a system that has many sensors and operates based on detailed data, the problem of user privacy also emerges. The risk of personal information leakage and the feeling of being monitored increase user discomfort. To support standing up and prevent falling during walking, care robots are required to apply power to the user according to the user state. The position of the center of gravity (CoG) has been used for such state estimation; however, many sensors are required to determine the accurate CoG position. To reduce the number of sensors required for user state estimation, we proposed a method for calculating CoG candidates, and validated the proposed method via experiments. Previous studies have focused solely on normal standing-up motion. However, in daily activities, standing up, walking, and sitting down are a set of motions. In addition, it is not always true that the care robot user can move normally; hence, anomaly detection is beneficial in care robots. Therefore, it is important to estimate the user state considering not only standing-up motion, but also walking and sitting down, as well as any anomaly that may occur during these motions. In this study, we develop an elderly support system that can assist in standing, walking, and sitting based on user state estimation. The CoG candidate calculation method is improved for walking and...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "397",
      "title": "Replay Attack Detection Using Linear Prediction Analysis-Based Relative Phase Features",
      "abstract": "Recent studies have reported the success of linear prediction analysis (LPA)-related features, which are extracted as a short-term spectral feature for replay attack detection due to the advantage of the imperfection in the LPA-based signal produced by recording and playback devices. However, exploiting LPA-based signals is focused on only magnitude-based features and ignores phase-based features. In this paper, we propose two novel LPA-based relative phase features, namely, linear prediction residual-based relative phase (LPR-RP) and linear prediction analysis estimated speech-based relative phase (LPAES-RP). The key idea of both LPR-RP and LPAES-RP is to extract the phase information based on LPA-based signals. In the LPR-RP feature, we modify the relative phase (RP) feature extraction using a linear prediction residual (LPR) derived from the difference between the original/raw speech and LPA estimated speech signal (LPAES) instead of the original/raw speech signal. LPES-RP feature exploits the LPAES signal to replace the original/raw speech signal. Because the trace of the recording and playback device artifacts is the primary evidence for detecting the replayed signal, the advantages of the imperfection of LPR and LPAES are expected to provide efficient phase information for the replay attack detection task. In addition, using the individual LPR-RP/LPAES-RP feature, our proposed features are combined with two standard features, mel-frequency cepstral coefficients (MFCC), constant Q transform cepstral coefficients (CQCC) and the original RP feature, at score level to further improve the detection decision. The performance of the proposed LPR-RP/LPAES-RP feature and combination are evaluated using the ASVspoof 2017 version 2 database. On the evaluation subset, our proposed LPR-RP and LPAES-RP feature achieves a promising improvement over baseline features (MFCC/CQCC). Moreover, the combined systems of LPR-RP, RP, and CQCC obtains an equal error rate of 9.26%.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "398",
      "title": "Transient Atomization Modeling and Optimal Design of a Medical Air-Compressing Nebulizer",
      "abstract": "This paper studies three-dimensional transient flow characteristics of a medical air-compressing nebulizer which is widely used to treat respiratory diseases in the medical field. The transient atomization process of air and water was numerically simulated and reproduced by solving Navier-Stokes equations, turbulent transport equations, the volume of fluid (VOF) model, and discrete phase model (DPM). The water volume fraction inside the nebulizer was simulated and demonstrated under different time. Besides, to better the working performance of the nebulizer, the effects of different working parameters such as different orifice diameters, length of the outflow pipe, and air velocity on the secondary atomization were also studied and discussed. It was found that the most suitable diameter of the orifice for this air-compressing nebulizer is 1.0 mm. Most suitable length of the outflow pipe and the air velocity for producing small air-water bubbles are 10 mm and 4 m/s, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "399",
      "title": "Deep Learning-Based Engraving Segmentation of 3-D Inscriptions Extracted From the Rough Surface of Ancient Stelae",
      "abstract": "Ancient stelae are considered important historical sources. However, it is a challenge to recognize the inscriptions carved on stelae that have rough surfaces due to prolonged weathering. In this paper, we propose a deep learning-based method to extract engraved regions from the 3D scanned mesh of a stela. First, the uneven distribution of vertices in the mesh is transformed using a mesh subdivision method such that the vertices in the mesh are uniformly distributed. Then, surface features (depth, concave features, and local surface features) are extracted from the subdivided mesh. The depth represents the basic shape of the mesh and is obtained from the aligned mesh. The concave features effectively represent concave regions by using a Frangi filter, and the local surface features have the spin image technique applied to describe the fine shapes of neighboring vertices relative to a vertex. The mesh and the surface features are rasterized into feature images, and engraved regions are segmented from the feature images by using a FC-DenseNet. Our experiments confirm that the proposed method effectively extracts engraved regions of the inscriptions from the rough surface of a stela and it shows robustness to noisy and extremely abraded characters. The proposed method outperformed the second-best method, obtaining an F1 score, IoU, and SIRI of approximately 2.95%, 3.65%, and 7.53%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "400",
      "title": "Robust Model-Dependent Poisson Multi Bernoulli Mixture Trackers for Multistatic Sonar Networks",
      "abstract": "This work proposes a robust tracker based on the Poisson Multi Bernoulli Mixture (PMBM) filter for multistatic sonar networks (MSNs) systems. The PMBM based trackers estimate the number of targets and provide the target information via Bernoulli and Poisson Point Processes. The PMBM based trackers handle existing tracks, undetected targets, and new births separately at each computation step by using these two processes together. In practice, the PMBM tracker aims to initiate the track as soon as possible and maintain the track continuity. Initiating track and maintaining track continuity are hard in challenging underwater environments without adapting the algorithm to changing environmental conditions. This paper uses the adaptive measurement-driven birth process and multistatic acoustic model-dependent probability of detection specifications. The adaptive measurement-driven birth process improves the robustness of the track initiation, and the multistatic acoustic model-dependent probability of detection advances the track continuity through the transition regions. These contributions to the PMBM tracker make it robust in terms of tracker performance in challenging underwater environments and acoustic transition regions where it is hard to get an accurate measurement.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "401",
      "title": "Design of a Fixed-Wing UAV Controller Based on Adaptive Backstepping Sliding Mode Control Method",
      "abstract": "In this paper, an advanced control method is proposed for a fixed-wing unmanned aerial vehicle (UAV) to maintain the stabilization of its altitude, attitude, and velocity. The mathematical model of a fixed-wing UAV is very complicated because of its characteristics of nonlinearity and large extent of multi-variable coupling. Thus, to design the relevant controller is also difficult. In addition, during the operation of a fixed-wing UAV, the concomitant various uncertainties and disturbances will make the control process harder to accomplish. To solve these problems, this study designs a variable-structure controller with multiple algorithm fusion. The design mainly adopts the backstepping sliding mode control method to simplify the complex nonlinear mathematical model, and an adaptive law is introduced to estimate the uncertainty and disturbance of the system. Subsequently, the tracking error of the controller is proved to converge to zero using Lyapunov’s second method. Finally, it is verified that the controller has the ability to stably control a fixed-wing UAV by numerical simulation and can overcome the disturbance and uncertainty. The buffeting also can be eliminated by the adaptive law.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "402",
      "title": "Local Fractional Strong Metric Dimension of Certain Rotationally Symmetric Planer Networks",
      "abstract": "Fractional versions of metric based networks invariants widen the scope of application in fields of intelligent systems, computer science and chemistry including, robot navigation, sensor networking, linear optimization problems, scheduling, assignment, operation research problems, image processing and drug discovery. It plays vital role in the study to check structural properties of the networks such as complexity, modularity and accessibility. Rotationally symmetric and planer networks have key importance in the fields of robot navigation, networking, telecommunication and chemistry due the structure of these networks which help in optimal rate of data transfer and minimize the time taken and resources used. In this paper we introduce a combinatorial technique to compute local fractional strong metric dimension (LFSMD) of networks. The technique is further used to compute LFSMD of certain rotationally symmetric planer networks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "403",
      "title": "Randomly Pre-Coded Packets Based Random Access Scheme for IoT-Oriented Satellite Networks",
      "abstract": "In this article, a novel random pre-coding (RPC) based random access (RA) scheme is proposed to improve the system performance in the Internet of Things-oriented satellite networks. In this scheme, each device randomly selects a non-orthogonal multi-level complex sequence from a pre-defined pre-coding sequence set to pre-code the transmitted packets in a sub-frame, by which multiple superimposed packets in the sub-frame can be successfully decoded by using the minimum mean squared error (MMSE) based successive interference cancellation (SIC) detection algorithm. Besides, by combining the proposed RPC with the existing contention resolution diversity slotted ALOHA (CRDSA) scheme, which the RPC-CRDSA scheme is generated. The SIC processing should be carried out across sub-frames to remove the received signals that are already recovered, which can further significantly improve the system throughput. The performance of the RPC-RA scheme is evaluated via both theoretical analysis and computer simulation. The collision probabilities of both preamble and pre-coding sequences and an upper bound of throughput are derived, respectively. Simulation results show that the peak normalized throughput of RPC-CRDSA with the pre-coding sequence length L = 8 can reach 1.87 bits/symbol, which largely outperforms traditional schemes.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "404",
      "title": "Data Dissemination in VANETs Using Clustering and Probabilistic Forwarding Based on Adaptive Jumping Multi-Objective Firefly Optimization",
      "abstract": "Data dissemination in a VANETs network requires a meticulous process to ensure a high quality of service and eliminate hazardous conditions due to congestion or a broadcast storm. Considering multi-metric approaches and their implicit conflicting nature, it is necessary to handle this through effective multi-objective optimization algorithms. An effective optimization can be handled using a meta-heuristic approach with a high level of solution interactions. For this purpose, firefly was selected, which is a type of meta-heuristic search algorithm. Several developments of the firefly optimization were added to increase its capability to find more dominating solutions, namely, objective decomposition, archive management, and controlled mutation for exploration and exploitation balance. This developed multi-objective optimization was designated as adaptive jumping multi-objective firefly algorithm (AJ-MOFA). Afterwards, AJ-MOFA was integrated with a clustering and forwarding mechanism (CFM). This mechanism includes three main components. The first is clustering, which uses arbitration based on the cluster head score; the second is a forwarding mechanism that uses probabilistic forwarding and the third is AJ-MOFA. The solution space design in CFM combined two variables: the first is the probability of forwarding and the second is the maximum number of nodes within one cluster. The metrics to be incorporated in the multi-objective optimizations are the packet delivery ratio (PDR), the end-to-end delay (E2E-delay) and the number of dropped packets. Comparing both AJ-MOFA and CFM with benchmarks using multi-objective optimization and networking metrics reveals the superiority in most evaluation measures, which makes them promising algorithms for data dissemination in VANETs. The results showed an accomplished PDR of 60% and an E2E delay of 6.6 seconds, while the number of dropped packets was almost nine for the entire running time of the experiment, comparing a similar or ...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "405",
      "title": "Impact of Surfactants on the Electrical and Rheological Aspects of Silica Based Synthetic Ester Nanofluids",
      "abstract": "This study reports experimental investigations of the effects of different surfactants (CTAB, Oleic acid and Span 80) on silica based synthetic ester nanofluids. The positive and negative potential observed for the ionic (CTAB) and non-ionic surfactant (Span 80) from zeta potential analysis indicates an improved stability. The optimization of nanofillers and surfactants is performed considering the corona inception voltage measured using ultra high frequency (UHF) technique and fluorescent fiber. Rheological analysis shows no significant variation of properties with shear rate, implying Newtonian behavior even with the addition of surfactant. In addition, the permittivity of the nanofluid is not much affected by adding surfactant but a marginal variation is noticed in the loss tangent with the effect of temperature. The fluorescence spectroscopy shows no change in the emission wavelength with the addition of silica nanofiller and surfactants. Flow electrification studies indicate an increase in the streaming current with the rotation speed and temperature, with a higher current magnitude observed in the case of nanofluids.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "406",
      "title": "Effect of Additional Transmitting Coils on Transfer Distance in Multiple-Transmitter Wireless Power Transfer System",
      "abstract": "Wireless power transfer (WPT) technology has been widely introduced and developed over the past few years. Nevertheless, the basic WPT configuration using one transmitting (Tx) coil and one receiving (Rx) coil still achieves very limited performance in terms of power transfer distance. To overcome this limitation, various multi-coil WPT systems using three or more coils have been studied. Among them, a multiple-input single-output (MISO) structure can provide the Rx with advanced freedom in an extensive lateral area. However, few studies have investigated how far multi-Tx coils can increase the transfer distance. In this paper, we analyze the transfer distance and lateral coverage based on the generalized critical coupling condition and system energy efficiency according to the number of additional Tx coils in the MISO WPT system. The results demonstrate that the MISO WPT system using planarly arranged Tx coils improves by barely 1% in the optimal transfer distance, which achieves the maximum output power condition in a single-Tx WPT system. To validate our analysis, the MISO WPT system with seven Tx coils and seven LCC inverters was implemented and its performance was assessed. The measured results agreed well with the theoretically calculated results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "407",
      "title": "3D Large-Scale Point Cloud Semantic Segmentation Using Optimal Feature Description Vector Network: OFDV-Net",
      "abstract": "Efficient semantic segmentation of large-scale 3D point clouds is a fundamental and essential capability for real-time intelligent systems, such as autonomous driving and augmented reality. The high dimension feature vector and the complex network structure are two major constraints to utilize the large-scale point cloud. This paper proposes an optimal feature description vector network (OFDV-Net) for 3D point cloud semantic segmentation. First, a multiscale point cloud feature extraction structure is constructed to generate an initial feature description vector (IFDV). Then, IFDV is selected by a feature selection unit to obtain the optimal feature description vector (OFDV). The OFDV encapsulates the best 3D features set of the points and can be used as the input of the deep neural network for training and testing. Finally, the OFDV-Net was applied to the standard public outdoor large-scale point cloud datasets Semantic3D and NPM3D, and the overall segmentation accuracy of 88.3% and 87.7% were obtained, respectively; moreover, the OFDV-Net requires less training time, which indicates that the algorithm can obtain high-precision semantic segmentation results on an outdoor large-scale point cloud while reducing model training time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "408",
      "title": "CN-Motifs Perceptive Graph Neural Networks",
      "abstract": "Graph neural networks (GNNs) have been the dominant approaches for graph representation learning. However, most GNNs are applied to homophily graphs and perform poorly on heterophily graphs. Meanwhile, these GNNs fail to directly capture long-range dependencies and complex interactions between 1-hop neighbors when generating node representations by iteratively aggregating directly connected neighbors. In addition, structural patterns, such as motifs which have been established as building blocks for graph structure, contain rich topological and semantical information and are worth studying further. In this paper, we introduce the common-neighbors based motifs, which we called CN-motifs, to generalize and enrich the definition of structural patterns. We group the 1-hop neighbors and construct a high-order graph according to CN-motifs, and propose CN-motifs Perceptive Graph Neural Networks (CNMPGNN), a novel framework which can effectively resolve problems mentioned above. Notably, by making full use of structural patterns, our model achieves the state-of-the-art results on several homophily and heterophily datasets.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "409",
      "title": "Design and FPGA Implementation of a Pseudorandom Number Generator Based on a Four-Wing Memristive Hyperchaotic System and Bernoulli Map",
      "abstract": "Random numbers are widely used in the fields of computer, digital signature, secure communication and information security. Especially in recent years, with the large-scale application of smart card and the demand of information security, the demand for high-quality random number generator is increasingly urgent. With the development of the theory of non-linear systems, the design of pseudorandom number generator (PRNG) for chaotic behavior of non-linear systems provides a new theoretical basis and implementation method. This paper presents a PRNG based on a no-equilibrium four-wing memristive hyperchaotic system (FWMHS) and its implementation on Field Programmable Gate Array (FPGA) board. In order to increase the output throughput and the statistical quality of the generated bit sequences, we propose the PRNG design which uses a dual entropy sources architecture with FWMHS and Bernoulli map. Simulation and experimental results verifying the feasibility of the FWMHS are also given. Then, the proposed PRNG system is modeled and simulated on the Vivado 2018.3 platform, and implemented on the Xilinx ZYNQ-XC7Z020 FPGA evaluation board. The maximum operating frequency has been achieved as 135.04 MHz with a speed of 62.5 Mbit/s. Finally, we have experimentally verified that the binary data obtained by this dual entropy sources architecture pass the tests of NIST 800.22, ENT and AIS.31 statistical test suites with XOR function post-processing for a high throughput speed. The security analysis is carried out by means of dynamical degradation, key space, key sensitivity, correlation and information entropy. Statistical tests and security analysis show that it has good pseudorandom characteristics and can be used in chaos-based cryptographic applications at hardware or software implementation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "410",
      "title": "Low Gain Ripple and DC-Grounded Slant-Polarized Formulation With 360° Broadbeam Coverage",
      "abstract": "In this paper, a new slant-polarized slot antenna configuration is presented for direction finding and base station applications. The proposed antenna comprises enhanced size coaxial cables, slots, and feeding assemblies. The slant polarization is achieved by four angled slots etched around the outer cylinder of the oversized coaxial cable. An internal compact axis-symmetric feeding network connects primary apertures to form the omnidirectional antenna. Simulations and measurements demonstrate that the antenna maintains an omnidirectional pattern from 2.5 GHz to 2.8 GHz, having 11.3% bandwidth (measured return loss <; -10 dB) and gain ripple of ±0.2 dB in the azimuth plane, which leads to the stable operational coverage. Another benefit of this structure is its polarization purity. The cross-polarization levels are below -14dB over the whole bandwidth. Move over; it is ruggedized DC short, self-supporting, and surface-mountable structure. Furthermore, compact and conformal shape reduces aerodynamic drag and makes this antenna a potential candidate for mounting vehicle systems too.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "411",
      "title": "Two Novel Blockchain-Based Market Settlement Mechanisms Embedded Into Smart Contracts for Securely Trading Renewable Energy",
      "abstract": "The progress of ICT technologies, day-ahead forecast, home energy management systems, implementation of smart meters, and Distributed Energy Sources (DER) enables new business opportunities for prosumers to locally trade the surplus via blockchain platforms leading to considerable advantages at the community level. The current research handles settlement similar to a centralized market that it is not necessarily the best solution for blockchain. Nonetheless, the settlement is essential as sellers and buyers perceive the attractiveness of the local trading through the market results. In this paper, we propose two novel and efficient settlement mechanisms (Global Balancing Settlement GBS and Splitting Settlement SS) for Peer-to-Peer (P2P) electricity exchange enhancing the performance of the classic Pairwise Settlement PS. These will be written as stored procedures embedded into the smart contracts along with auctioning procedures. The simulations are performed using a small residential community with 30% of the electricity that can be locally traded to lower the bills and unstress the public grid. The performance of the two proposed settlement methods is proved by the 14 scenarios that thoroughly indicate that GBS and SS provide better results for both sellers and buyers than PS. In the reference scenario, with GBS, sellers have the highest encashments with almost 4% more, whereas buyers encounter the lowest payments with almost 5% less than in case of the classic settlement. Starting from reference scenario, alternative scenarios are envisioned to extend the analyses and assess the performance of the settlement mechanisms. The highest gain is recorded with GBS mechanism: almost 8.8% for sellers and 6.5% for buyers. Another interesting outcome is that GBS is providing better results than SS. When deviations are small, SS provides almost 6% gain for both sellers and buyers, but when they increase, the gain is exceedingly small or none.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "412",
      "title": "Autonomous Convoying: A Survey on Current Research and Development",
      "abstract": "Convoying or platooning with a fleet of autonomous vehicles, which is denoted as autonomous convoying in this paper, has attracted increasing attention from the research communities, governments, and private sectors in recent years. Autonomous convoying offers immense opportunities due to its potential in enhancing logistical efficiency as well as reducing road incidents/accidents by eliminating human errors due to stress and fatigue. While humans can make complex decisions, involving humans in decision-making processes often causes delays as compared with those of automated machines. Indeed, human errors cause approximately 90% of road accidents and fatalities. Efficient platooning techniques can also reduce fuel consumption and carbon footprints. This paper presents a concise survey on current research and development initiatives in autonomous convoying while critically discussing the underlying techniques and technologies developed in this domain. Implications of autonomous convoying toward different industries are also analyzed and discussed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "413",
      "title": "A Deep Learning Model Based on BERT and Sentence Transformer for Semantic Keyphrase Extraction on Big Social Data",
      "abstract": "In the evolution of the Internet, social media platform like Twitter has permitted the public user to share information such as famous current affairs, events, opinions, news, and experiences. Extracting and analyzing keyphrases in Twitter content is an essential and challenging task. Keyphrases can become precise the main contribution of Twitter content as well as it is a vital issue in vast Natural Language Processing (NLP) application. Extracting keyphrases is not only a time-consuming process but also requires much effort. The current works are on graph-based models or machine learning models. The performance of these models relies on feature extraction or statistical measures. In recent year, the application of deep learning algorithms to Twitter data have more insight due to automatic feature extraction can improve the performance of several tasks. This work aims to extract the keyphrase from Big social data using a sentence transformer with Bidirectional Encoder Representation Transformers (BERT) deep learning model. This BERT representation retains semantic and syntactic connectivity between tweets, enhancing performance in every NLP task on large data sets. It can automatically extract the most typical phrases in the Tweets. The proposed Semkey-BERT model shows that BERT with sentence transformer accuracy of 86% is higher than the other existing models.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "414",
      "title": "A Novel Trust Evaluation Process for Secure Localization Using a Decentralized Blockchain in Wireless Sensor Networks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "415",
      "title": "A Miniaturized Triple-Band and Dual-Polarized Monopole Antenna Based on a CSRR Perturbed Ground Plane",
      "abstract": "This paper proposes a new triple-band monopole antenna based on Complementary Split Ring Resonators (CSRR) perturbing the ground plane (GND). The antenna consists of an inverted-L-shaped monopole fed by a modified microstrip line with two CSRRs cut out of the ground plane. The operational bands are independently controlled by the CSRR unit cell parameters. In addition, the antenna presents a dual-polarization performance (vertical polarization at 2.4 GHz band and horizontal polarization at both 3.6 and 5.9 GHz bands). The designed antenna is fully planar and low profile avoiding the vias with the ground plane and covering the WLAN, WiMAX, and IEEE 801.11p bands at 2.45, 3.6, and 5.8 GHz. A compact prototype (\n 0.32λ0×0.32λ0 \n being \n λ0 \n is the wavelength corresponding to the lowest resonance frequency) has been fabricated and measured showing good agreement between simulations and measurements. The measured impedance bandwidths are 10% (2.38-2.63 GHz), 2.5% (3.54-3.63 GHz), and 20% (5.83-7.12 GHz) whereas the measured gains are 1.34, 0.68, and 2.65 dBi at 2.4, 3.6, and 5.9 GHz respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "416",
      "title": "Transmittance Multispectral Imaging for Reheated Coconut Oil Differentiation",
      "abstract": "Oil reheating has a significant impact on global health due to its extensive consumption, especially in South Asia, and severe health risks. Nevertheless, food image analysis using multispectral imaging systems(MISs) has not been applied to oil reheating analysis despite their vast application in rapid food quality screening. To that end, the paper discusses the application of a low-cost MSI to estimate the ‘reheat cycle count classes’ (number of times an oil sample is recursively heated) and identify ‘critical classes’ at which substantial changes in the oil sample have materialized. Firstly, the reheat cycle count class is estimated with Bhattacharyya distance between the reheated and a pure oil sample as the input. The classification was performed using a support vector machine classifier that resulted in an accuracy of 83.34% for reheat cycle count identification. Subsequently, an unsupervised clustering procedure was introduced using a modified spectral clustering (SC) algorithm to distinguish critical classes under reheating. In addition, laboratory experiments were performed to ascertain the ramifications of the reheating process with a chemical analysis. The chemical analysis of the coconut oil samples used in the experiment coincided with the image analysis results and was statistically significant (\n p<0.05 \n). Accordingly, the proposed work closes the gap for using multispectral imaging for oil reheating and proposes a novel algorithm for unsupervised detection of critical property changes in the oil. Hence, the proposed research work is significant in its practical implications, contribution to food image analysis, and unsupervised classification mechanisms.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "417",
      "title": "Joint Channel and Power Allocation Based on Generalized Nash Bargaining Solution in Device-to-Device Communication",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "418",
      "title": "A Wideband, Circularly Polarized, Directive Antenna With a Circular Reflector",
      "abstract": "A two-element, patch antenna with a single feed is presented to achieve wideband, circular polarization, and uni-directional radiation. The driven element of the antenna has a rotated, corner-truncated radiating patch to achieve circularly polarized radiation with an offset microstrip feedline in the front side. The back side of the driven element comprises a wide hexagonal slot, eight meander tips, and a parasitic patch in the center. A circular reflector is added behind the driven element to increase realized gain toward the front side direction of the driven element. A prototype of the antenna is fabricated for validation. In both simulation and measurement, the 3-dB axial ratio bandwidth is fully included in the -10-dB impedance bandwidth. In measurement, the proposed antenna has a -10-dB impedance bandwidth of 83% (1.58 GHz - 3.83 GHz), and a 3-dB axial ratio bandwidth of 49% (1.99 GHz - 3.27 GHz). Within the common band, the average realized gain is 6.1 dBic, and the peak realized gain is 8.6 dBic toward the front side direction of the antenna. The electrical size of the antenna is a kr of 1.69.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "419",
      "title": "High-Fidelity Audio Generation and Representation Learning With Guided Adversarial Autoencoder",
      "abstract": "Generating high-fidelity conditional audio samples and learning representation from unlabelled audio data are two challenging problems in machine learning research. Recent advances in the Generative Adversarial Neural Networks (GAN) architectures show great promise in addressing these challenges. To learn powerful representation using GAN architecture, it requires superior sample generation quality, which requires an enormous amount of labelled data. In this paper, we address this issue by proposing Guided Adversarial Autoencoder (GAAE), which can generate superior conditional audio samples from unlabelled audio data using a small percentage of labelled data as guidance. Representation learned from unlabelled data without any supervision does not guarantee its' usability for any downstream task. On the other hand, during the representation learning, if the model is highly biased towards the downstream task, it losses its generalisation capability. This makes the learned representation hardly useful for any other tasks that are not related to that downstream task. The proposed GAAE model also address these issues. Using this superior conditional generation, GAAE can learn representation specific to the downstream task. Furthermore, GAAE learns another type of representation capturing the general attributes of the data, which is independent of the downstream task at hand. Experimental results involving the S09 and the NSynth dataset attest the superior performance of GAAE compared to the state-of-the-art alternatives.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "420",
      "title": "CU-Net: A New Improved Multi-Input Color U-Net Model for Skin Lesion Semantic Segmentation",
      "abstract": "Melanoma is considered one of the most dangerous skin cancer diseases that threaten human health and life. Early diagnosis of melanoma is a big challenge, especially with the presence of color variations across similar lesion types. Automatic skin lesion segmentation is an essential step to build a successful skin disease classification system. Recent deep learning architectures significantly improve the skin lesion segmentation results. Especially, U-Net deep convolutional neural network (CNN) is considered one of the state-of-the-art models with promising performance. Most deep CNNs and particularly U-Net model utilize a single input RGB color image for skin lesion semantic segmentation. However, RGB color space is not usually the best choice to represent the invariant characteristics of skin lesion chromatic information. The selection of the optimal color space significantly affects the performance of segmentation results. In this paper, three novel variants of U-Net model with single, dual, and triple inputs, namely, Single Input Color U-Net (SICU-Net), Dual Input Color U-Net (DICU-Net) and Triple Input Color U-Net (TICU-Net) are proposed. The structure of SICU-Net, DICU-Net, and TICU-Net contains single, dual, and triple encoder sub-networks connected with only a single decoder path. Each encoder sub-network is fed with different color space of the input image. A channel-wise attention module is utilized to fuse the contribution of the learned feature maps from each encoder sub-network which is fed to the decoder sub-network to generate segmented image map. Moreover, a composite loss function is designed to improve the performance of the proposed CU-Net models. Three public benchmark datasets, namely, International Skin Imaging Collaboration (ISIC 2017, ISIC 2018) and PH2 datasets, are utilized to evaluate the performance of the proposed models. Experimental results reveal that the proposed models significantly improve the performance of the original U-Net mode...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "421",
      "title": "Identity-Based Blind Multisignature From Lattices",
      "abstract": "Blind multisignature (BMS), first introduced by Horster et al, constitutes a crucial primitive that allows a user to generate a signature of a message from multiple signers, while the signers cannot obtain any information about the message. With these useful properties, blind multisignature is suitable for electronic payments and electronic voting. However, most of the current BMS schemes may be attacked by quantum computers in the future because they are based on traditional number theories, such as discrete logarithm assumption and large integer factor assumption. In this work, we first formalize the notion and the sound security models of the identity-based blind multisignature scheme (IDBMS). Then we present an instantiation based on lattices, along with rigorous proofs of the blindness and unforgeability under the lattice hard assumption (short integer solution, SIS), which is considered to remain secure under quantum computer attacks. To the best of our knowledge, it is the first identity-based quantum-resistant scheme that has the advantages of blind signature and multisignature.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "422",
      "title": "SPMSMs HFI Based Self-Sensing Using Intentional Magnetic Saturation",
      "abstract": "High-frequency injection (HFI) is widely used for zero-to-low speed self-sensing in machines with saliency. HFI algorithms use inductive saliency in the d- and q-axes to estimate the rotor position in permanent magnet synchronous machines (PMSMs). Generally speaking, surface PMSMs (SPMSMs), which are designed without inductive saliency, are not suitable for HFI inductive based self-sensing. In this article, a method to enhance HFI algorithms at zero-to-low speed for classically designed SPMSMs with low inductive saliency is presented. The proposed method is based on using intentional magnetic saturation under flux-intensifying (FI) operation, which will temporarily enable robust self-sensing operation in the zero-to-low speed region in machines that are not suitable for traditional HFI self-sensing.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "423",
      "title": "Multi-Level High Precision LBS Architecture Based on GNSS CORS Network, A Case Study of HNCORS",
      "abstract": "With the rapid development of the ground infrastructure as CORS and mobile communication stations, the high precision LBS expand from the limited fields to the public. The comprehensive LBS platforms which meet the demands such as multi-precision level, massive user and desirable scalability, become critical for the public applications. In this paper, a new high precision LBS architecture based on GNSS CORS network is presented. The platform is deployed in the cloud computational environment. It is divided into two parts: data processing and allocation system individually. The virtual grids differential corrections are involved to optimize the real-time CORS stations data processing. Besides, the API/SDK module is introduced as a new service mode, which integrates the meter, decimeter, centimeter level LBS applications, respectively realized by the coordinates, pseudo range and carrier phase differential. With the daily needs of HNCORS network, the platform “SoBDS” is established. The experiments for decimeter level example shows that, the platform could support one million users, and it is compatible and scalable. The real-time positioning accuracy is ±0.425m and ±0.436m in east and north. The total accuracy is ±0.612m and ±0.773m in horizontal and vertical direction.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "424",
      "title": "The Effects of Visual Stimuli on Attention in Children With Autism Spectrum Disorder: An Eye-Tracking Study",
      "abstract": "Attention is one of the fundamental elements of effective learning. The design of learning environments often consists of a blend of visual stimuli. Investigating the effect of visual stimuli types on the attention of children with autism spectrum disorder (ASD) is important for the theoretical understanding of attention. This study explores the effect of social and nonsocial visual stimuli on the attention of children with ASD and typically developing (TD) children in a simulated virtual classroom. Forty-six participants (ASD = 20, TD = 26) took part in a series of attention tests, in which social and nonsocial visual stimuli were used as target stimuli. We examined four eye-gaze measures: time to first fixate, first fixation duration, average fixation duration, and the sum of fixation count. The results show that social and nonsocial stimuli do not affect the attention of ASD and TD children. However, TD children pay significantly greater attention to target stimuli than children with ASD. These findings emphasize the strengths of children with ASD during attention tasks and the potential for the use of eye-gaze measures to identify attention impairment in children with ASD. This study thus recommends an investigation methodology for on-task attention assessment in a learning environment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "425",
      "title": "Quantitative Analysis of AC/DC Side Harmonic Transfer Characteristics for Modular Multilevel Converter and Suppression Measures",
      "abstract": "MMC (Modular Multilevel Converter) is the preferred topology for renewable energy delivery, but renewable energy resources, such as wind farms, contains much harmonic components. Compared with two-level VSC (Voltage Source Converter), the internal dynamic characteristics of MMC have great impact on the harmonic transmission. This paper quantitatively analyzes the harmonic transferring mechanism from one side to the other side of MMC, and deduces the time-domain analytical expression of the harmonic response on the MMC's other side. Firstly, the influence of background harmonic on MMC's control system and electrical system are quantitatively analyzed. On this basis, the equivalent circuit of MMC's electrical system considering its internal dynamics is established to accurately calculate the effect of background harmonic on the MMC's other side. In addition, the harmonic transferring impedance in frequency-domain is also defined in this paper, based on that the influence of background harmonic on the MMC's other side can be calculated quickly. According to the harmonic transferring characteristics analyzed above, a zero-sequence virtual damping strategy is proposed for the first time to suppress the background harmonic transferring. Finally, a 232-level 500kV MMC simulated model is built in MATLAB/Simulink to verify the accuracy of the harmonic transferring calculation method and the effectiveness of the virtual damping suppression strategy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "426",
      "title": "Permanent Magnet Vernier Machines for Direct-Drive Offshore Wind Power: Benefits and Challenges",
      "abstract": "Permanent magnet Vernier (PM-V) machines, at low power levels (few kWs), have shown a great potential to improve the torque density of existing direct-drive PM machines without much compromising on efficiency or making the machine structure more complicated. An improved torque density is very desirable for offshore wind power applications where the size of the direct-drive machine is an increasing concern. However, the relatively poor power factors of the PM-V machines will increase the power converter rating and hence cost. The objective of this paper is to review the benefits and challenges of PM-V machines for direct-drive offshore wind power applications. The review has been presented considering the system-level (direct-drive generator + converter) performance comparison between the surface-mounted permanent magnet Vernier (SPM-V) machines and the conventional SPM machines. It includes the indepth discussion on the challenges facing the PM-V machines when they are scaled up for multi-MW offshore wind power application. Other PM-V topologies discussed in literature have also been reviewed to asses their suitability for offshore wind power application.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "427",
      "title": "Systematic Transistor Sizing of a CNFET-Based Ternary Inverter for High Performance and Noise Margin Enlargement",
      "abstract": "Noise and variation are the two major challenges for the reliability of digital circuits, especially multiple-valued logic (MVL) circuits where the entire voltage range is divided into some narrow zones. In spite of few correct examples, many ternary inverters with reduced noise margins have been presented in the literature. The defect is mainly because of their improperly shaped voltage transfer characteristic (VTC). With proper transistor sizing, we can rectify the problem and provide uniformly wide noise margin values while maintaining power-delay product (PDP) low. As far as we know, none of the previous ternary inverters has been given based on a methodical transistor sizing procedure. In this paper, a systematic transistor sizing through physical equations is suggested for an existing standard ternary inverter (STI), whose original sizes for the carbon nanotube FETs (CNFETs) are inappropriate. This paper includes a comprehensive investigation to determine appropriate values for the physical parameters of the CNFET-based STI. Compared with the original design, with a negligible increase in circuit delay and area, simulation results show that the proposed ternary inverter can increase noise margin and static noise margin by up to 47.7% and 83.3%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "428",
      "title": "A Novel Parallel Architecture for Template Matching based on Zero-Mean Normalized Cross-Correlation",
      "abstract": "Template matching based on zero-mean normalized cross-correlation measure (ZNCC) has been widely used in a broad range of image processing applications. To meet the requirements for high processing speed, small size, and variable image size in automatic target recognition systems, a novel field-programmable gate array (FPGA)-based parallel architecture is presented in this paper for the ZNCC computation. The proposed architecture employs two groups of RAM blocks, one of which is used for the multiply-accumulate operations of the real and the reference images and the other for data rearrangement of the reference image, and their functions are switched through 2-input multiplexers when searching at the next row. Moreover, the sum of the pixels in the searching area of the real image is computed through serially accumulating the differences between the new column in the current searching area and the old column in the last searching area using one dual-port RAM. Simultaneously, the sum of the squares of the pixels is calculated in the same way. Using the Altera Stratix II FPGA chip (EP2S90F780I4) as the target device, the compilation results with Quartus II show that compared with the traditional architecture, the synthesis logic utilization decreases from 63% to 35% and the usage of DSP blocks decreases from 59% to 39%, while the memory bits only increase by 8% and the usage of other resources is nearly the same. The simulation and practical experimental results show that the proposed architecture can effectively improve the performance of the practical automatic target recognition system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "429",
      "title": "Policy Distillation for Real-Time Inference in Fronthaul Congestion Control",
      "abstract": "Centralized Radio Access Networks (C-RANs) are improving their cost-efficiency through packetized fronthaul networks. Such a vision requires network congestion control algorithms to deal with sub-millisecond delay budgets while optimizing link utilization and fairness. Classic congestion control algorithms have struggled to optimize these goals simultaneously in such scenarios. Therefore, many Reinforcement Learning (RL) approaches have recently been proposed to deal with such limitations. However, when considering RL policies’ deployment in the real world, many challenges exist. This paper deals with the real-time inference challenge, where a deployed policy has to output actions in microseconds. The experiments here evaluate the tradeoff of inference time and performance regarding a TD3 (Twin-delayed Deep Deterministic Policy Gradient) policy baseline and simpler Decision Tree (DT) policies extracted from TD3 via a process of policy distillation. The results indicate that DTs with a suitable depth can maintain performances similar to those of the TD3 baseline. Additionally, we show that by converting the distilled DTs to rules in C++, we can make inference-time nearly negligible, i.e., sub-microsecond time scale. The proposed method enables the use of state-of-the-art RL techniques to congestion control scenarios with tight inference-time and computational constraints.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "430",
      "title": "Dispatch for Urban Integrated Heat and Power System Considering Secondary PM2.5 Under Smart Environmental Sensing",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "431",
      "title": "IEEE Access Special Section Editorial: Secure Modulations for Future Wireless Communications and Mobile Networks",
      "abstract": "Security has become an extremely important research topic in wireless networks over the last decade, as it is intimately related to both individual privacy and national security. Directional modulation, as a conventional type of secure modulations, transmits confidential information along the desired directions of legitimate receivers, and artificial noise in other directions, to deliberately confuse eavesdroppers in line-of-sight channels. Recently, artificial noise is also introduced into spatial modulation, leading to a secure spatial modulation strategy. In this Special Section in IEEE A CCESS, secure modulation is defined broadly as any secure modulation method, which includes, but is not limited to, secure directional modulation, secure spatial modulation, and secure index modulation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "432",
      "title": "Consensus-Based Multi-Person Decision Making Using Consistency Fuzzy Preference Graphs",
      "abstract": "This paper presents consensus based multi-person decision making (MPDM) using consistency graphs (additive consistent and order consistent) in a fuzzy environment. At the first level, consistency analysis is put forward after defining consistent fuzzy preference graph (CFPG) with the help of additive transitivity. This analysis further leads us to determine priority weights vector of the decision-makers (DMRs) after evaluation consistency weights. At the second level, the consensus analysis helps us to determine whether the selection process should be initiated or not. If the consensus degree amongst DMRs does not reach a minimum acceptable level, then the enhancement mechanism plays a central role to improve the consensus level by giving suitable suggestions to DMRs. In the end, the weighted sum operator (WSO) is used to get aggregated consistency fuzzy preference graph (AgCFPG) and the order consistency property provides us sufficient information to rank the alternatives.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "433",
      "title": "Analysis of Data Management in Blockchain-Based Systems: From Architecture to Governance",
      "abstract": "In a blockchain-based system, data and the consensus-based process of recording and updating them over distributed nodes are central to enabling the trustless multi-party transactions. Thus, properly understanding what and how the data are stored and manipulated ultimately determines the degree of utility, performance, and cost of a blockchain-based application. While blockchains enhance the quality of the data by providing a transparent, immutable, and consistent data store, the technology also brings new challenges from a data management perspective. In this paper, we analyse blockchains from the viewpoint of a developer to highlight important concepts and considerations when incorporating a blockchain into a larger software system as a data store. The work aims to increase the level of understanding of blockchain technology as a data store and to promote a methodical approach in applying it to large software systems. First, we identify the common architectural layers of a typical software system with data stores and conceptualise each layer in blockchain terms. Second, we examine the placement and flow of data in blockchain-based applications. Third, we explore data administration aspects for blockchains, especially as a distributed data store. Fourth, we discuss the analytics of blockchain data and trustable data analytics enabled by blockchain. Lastly, we examine the data governance issues in blockchains in terms of privacy and quality assurance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "434",
      "title": "Finite Time Annular Domain Robust Stability Analysis and Controller Design for T-S Fuzzy Interval Positive Systems",
      "abstract": "This paper is concerned with the finite time annular domain robust stability (FTADRS) analysis and controller design for T-S fuzzy positive systems with interval uncertainties. The concept of finite time annular domain stability is first introduced for positive systems. Based on this and using the copositive Lyapunov function approach, some sufficient conditions for FTADRS are derived. Subsequently, the finite time annular domain robust controller is designed via the linear programming technique. Finally, two numerical examples and an application example are employed to show the effectiveness of our results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "435",
      "title": "An Active and Reactive Power Controller for Battery Energy Storage System in Microgrids",
      "abstract": "Battery energy storage systems (BESS) are widely used for renewable energy applications, especially in stabilizing the power system with ancillary services. The objective of this paper is to propose an active and reactive power controller for a BESS in microgrids. The proposed controller can operate the BESS with active and reactive power conditions and realize power smoothing and voltage regulation. The demanded active power flow generated through a low pass filter (LPF) is used to control the power smoothing for microgrids. LPF design is presented based on the BESS sizing and genetic algorithm (GA). The demanded reactive power flow generated according to the reactive current calculation is used to compensate the microgrid voltage to fulfill the voltage regulation. The analysis of the vector diagram is adopted to validate the proposed controller and to explain the applicability and functionality of the voltage regulation for microgrids. To verify the validity of the proposed controller, a 1-kW grid-connected inverter is built to demonstrate the ability of power smoothing and voltage regulation. Both simulations and hardware experimental results agree well with the theoretical analysis.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "436",
      "title": "FlexDRAN: Flexible Centralization in Disaggregated Radio Access Networks",
      "abstract": "Radio Access Network (RAN) disaggregation allows operators to mix-and-match multivendor components and bring RAN services from one end to the other. Despite this goal, issues of resource misuse or performance undershoot may arise because of inflexible RAN function deployment and uncoordinated decision-making across different network segments. To address these issues, this paper considers full flexibility in the synthesis of end-to-end RAN services from a set of disaggregated and uncoordinated components. In particular, five design factors are jointly considered to maximize the overall network spectral efficiency: (1) User association, (2) Remote radio unit clustering, (3) RAN functional split, (4) Fronthaul network routing, and (5) Baseband unit placement. To efficiently deal with the formulated problem, we propose a two-level turbo-based solution and compare its performance with several related works. The simulation results show that our proposed solution can not only achieve a 1.33-times spectral efficiency gain compared with state-of-the-art methods, but also provides 1.27 and 1.74 multiplexing benefits for computing and networking resources, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "437",
      "title": "A Four-Phase Passive Mixer-First Receiver With a Low-Power Complementary Common-Gate TIA",
      "abstract": "This paper presents a four-phase passive mixer-first receiver using a common-gate (CG) trans-impedance amplifier (TIA), instead of a conventional shunt-feedback amplifier. The four-transistor TIA used in this work combines current-reuse with cross-coupled g\nm\n-boosting to achieve a reduced noise figure (NF) at low power levels. Moreover, complementary derivative-superposition (CDS) linearization within the TIA helps to improve the linearity with no additional power overhead. A prototype receiver is implemented in a 180 nm CMOS technology. The receiver operates from 0.3 to 1.3 GHz with a conversion gain of 21.9 dB. In measurements, the receiver achieved a noise figure of 5.8 dB and an in-band (IB) IIP3 of +7.2 dBm while consuming 0.34 mW power per TIA at 1 GHz. The measured spurious-free dynamic range (SFDR) at 1 GHz is 76.9 dB.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "438",
      "title": "Who Speaks Like a Style of Vitamin: Towards Syntax-Aware Dialogue Summarization Using Multi-Task Learning",
      "abstract": "Abstractive dialogue summarization is a challenging task for several reasons. First, most of the key information in a conversation is scattered across utterances through multi-party interactions with different textual styles. Second, dialogues are often informal structures, wherein different individuals express personal perspectives, unlike text summarization, tasks that usually target formal documents such as news articles. To address these issues, we focused on the association between utterances from individual speakers and unique syntactic structures. Speakers have unique textual styles that can contain linguistic information, such as voiceprint. To do this, we used ad-hoc analysis to explore speakers’ text styles and constructed a syntax-aware model by leveraging linguistic information (i.e., POS tagging), which alleviates the above issues by inherently distinguishing utterances from individual speakers. Our approach allows for both data and model-centric investigation. Also, we employed multi-task learning of both syntax-aware information and dialogue summarization. To the best of our knowledge, our approach is the first method to apply multi-task learning to the dialogue summarization task. Experiments on a SAMSum corpus (a large-scale dialogue summarization corpus) demonstrated that our method improved upon the vanilla model. Consequently, we found that our efforts of syntax-aware approach have been reflected by the model.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "439",
      "title": "Ankle Joint Torque Prediction Based on Surface Electromyographic and Angular Velocity Signals",
      "abstract": "Joint torque prediction plays an important role in quantitative limb rehabilitation assessment and exoskeleton robot, and it is essential to acquire feedback or feedforward signal for adaptive functional electrical stimulation (FES) control. The Surface electromyography (sEMG) signal is one of the basic processing techniques to detect muscle activity, and also one favorable technique to estimate joint torque. In order to predict joint torque in a wide range of real time convenient applications, it is necessary to fuse sEMG signals with other convenient physical sensors such as accelerometers and gyroscopes, herein, we use a time delay artificial neural network to predict human joint force of ankle eversion and inversion based on sEMG and angular velocity signals. We testify our method on the data recorded from 8 subjects (5 healthy subjects and 3 patients) who are on isokinetic ankle eversion and inversion. The results show that the mean Cross-correlation coefficients (ρ) and the mean normalized root-mean-square deviation (NRMSE %) calculated between the prediction and the real value for isokinetic contraction is 0.966±0.019 and 7.9% ±0.026. Compared with artificial neural network (ANN) and support vector regression (SVR), the proposed method can predict the joint torque effectively. For the future application, the method has the potential to be employed to predict the ankle moments in real-time application for quantitative lower limb rehabilitation assessment and exoskeleton robot control.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "440",
      "title": "Deep Code-Comment Understanding and Assessment",
      "abstract": "Code comments are a key software component for program comprehension and software maintainability. High-quality code and comments are urgently needed by data-driven models widely used in tasks like code summarization. Many existing approaches for assessing the quality of comments are machine learning based classification algorithms or rely on heuristic rules. These approaches are difficult to capture the complicated features of text data and are often limited in accuracy, efficiency, and generalization ability. In this paper, we convert the quality assessment of code comments into a classification problem based on the multi-input neural network. We summarize the input, the code and comments, into vectors using the attention-based Bi-LSTM model and the weighted GloVe model, respectively, and concatenate the code vectors and the comment vectors as the input of the Multiple-Layer Perceptron classifier for the comment quality assessment. Experimental results show that our approach, in general, outperforms the previous technique, on both our labeled dataset and the public dataset, with the F1-score of 96.91% and 91.90%, respectively. Using the training set and the testing set from distinct sources, our approach can still achieve reasonable performance, which demonstrates its generalization ability.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "441",
      "title": "Cross-Lingual Passage Re-Ranking With Alignment Augmented Multilingual BERT",
      "abstract": "The task of Cross-lingual Passage Re-ranking (XPR) aims to rank a list of candidate passages in multiple languages given a query, which is generally challenged by two main issues: (1) the query and passages to be ranked are often in different languages, which requires strong cross-lingual alignment, and (2) the lack of annotated data for model training and evaluation. In this article, we propose a two-stage approach to address these issues. At the first stage, we introduce the task of Cross-lingual Paraphrase Identification (XPI) as an extra pre-training to augment the alignment by leveraging a large unsupervised parallel corpus. This task aims to identify whether two sentences, which may be from different languages, have the same meaning. At the second stage, we introduce and compare three effective strategies for cross-lingual training. To verify the effectiveness of our method, we construct an XPR dataset by assembling and modifying two monolingual datasets. Experimental results show that our augmented pre-training contributes significantly to the XPR task. Besides, we directly transfer the trained model to test on out-domain data which are constructed by modifying three multi-lingual Question Answering (QA) datasets. The results demonstrate the cross-domain robustness of the proposed approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "442",
      "title": "Feedback Module Based Convolution Neural Networks for Sound Event Classification",
      "abstract": "Sound event classification is starting to receive a lot of attention over the recent years in the field of audio processing because of open datasets, which are recorded in various conditions, and the introduction of challenges. To use the sound event classification model in the wild, it is needed to be independent of recording conditions. Therefore, a more generalized model, that can be trained and tested in various recording conditions, must be researched. This paper presents a deep neural network with a dual-path frequency residual network and feedback modules for sound event classification. Most deep neural network based approaches for sound event classification use feed-forward models and train with a single classification result. Although these methods are simple to implement and deliver reasonable results, the integration of recurrent inference based methods has shown potential for classification and generalization performance improvements. We propose a weighted recurrent inference based model by employing cascading feedback modules for sound event classification. In our experiments, it is shown that the proposed method outperforms traditional approaches in indoor and outdoor conditions by 1.94% and 3.26%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "443",
      "title": "Medium Voltage Large-Scale Grid-Connected Photovoltaic Systems Using Cascaded H-Bridge and Modular Multilevel Converters: A Review",
      "abstract": "Medium-voltage (MV) multilevel converters are considered a promising solution for large scale photovoltaic (PV) systems to meet the rapid energy demand. This article focuses on reviewing the different structures and the technical challenges of modular multilevel topologies and their submodule circuit design for PV applications. The unique structure of the converter's submodule provides modularity, independent control of maximum power point tracking (MPPT), galvanic isolation, etc. Different submodule circuits and MPPT methods to efficiently extract the PV power are reviewed. The integration of the multilevel converters to PV systems suffers unbalanced power generation during partial PV shading conditions. Several balancing strategies to solve this problem are presented and compared to give a better understanding of the balancing ranges and capabilities of each strategy. In addition, the paper discusses recent research advancements, and possible future directions of MV converters-based large-scale PV systems for grid integration.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "444",
      "title": "Finite-Time Trajectory Tracking Control of Output-Constrained Uncertain Quadrotor",
      "abstract": "In this article, a finite-time robust tracking control of output constrained multirotor unmanned aerial vehicle (UAV) is proposed. A finite-time sliding mode control (SMC) technique with barrier Lyapunov function (BLF) is used to assure robustness of the derived control laws while maintaining the output in specified constraints. A comparison of the proposed controller is carried out with conventional SMC to manifest the effectiveness of the output-constrained tracking control. Numerical simulations of quadrotor UAV with exogenous disturbances and time-invariant output constraints demonstrate the efficacy of the proposed controller regarding robustness, finite-time convergence, and chattering reduction.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "445",
      "title": "Color Edge Detection Using the Normalization Anisotropic Gaussian Kernel and Multichannel Fusion",
      "abstract": "Color edge detection is a key technique in image processing for vision engineering. In this paper, a new edge detector based on normalized Anisotropic Gaussian Directional Derivative and Multi-channel Gradient Matrix Fusion is proposed. Firstly, the color image is decomposed into six components in the RGB model and the HSV model, respectively. The gradient amplitude of the image edge is emphasized by Contrast Limited Adaptive Histogram Equalization (CLAHE). A normalized Anisotropic Gaussian Derivative is constructed by Multi-direction ANGK to extract the edge strength map of original color image. Finally, Singular Value Decomposition (SVD) was adopted to fuse each channel component in combination with a Multi-channel Morphological Gradient Derivative Matrix to improve the accuracy of edge detection. The proposed detector is compared with three state-of-art edge detectors with the Berkeley dataset (BSDS500) as the database. The results show that the proposed algorithm is more prominent in the performance of noise robustness and edge detection resolution.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "446",
      "title": "Clustering and Classification for Time Series Data in Visual Analytics: A Survey",
      "abstract": "Visual analytics for time series data has received a considerable amount of attention. Different approaches have been developed to understand the characteristics of the data and obtain meaningful statistics in order to explore the underlying processes, identify and estimate trends, make decisions and predict the future. The machine learning and visualization areas share a focus on extracting information from data. In this paper, we consider not only automatic methods but also interactive exploration. The ability to embed efficient machine learning techniques (clustering and classification) in interactive visualization systems is highly desirable in order to gain the most from both humans and computers. We present a literature review of some of the most important publications in the field and classify over 60 published papers from six different perspectives. This review intends to clarify the major concepts with which clustering or classification algorithms are used in visual analytics for time series data and provide a valuable guide for both new researchers and experts in the emerging field of integrating machine learning techniques into visual analytics.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "447",
      "title": "Experimental Investigation of the Effects of Reactor Neutron-Gamma Pulse Irradiation on SiGe HBTs Under Different Bias Conditions",
      "abstract": "The degradation characteristics of silicon-germanium heterojunction bipolar transistors (SiGe HBTs) under different bias modes (forward, cutoff and saturation) during irradiation were reported after multiple pulsed neutron-gamma irradiation at room temperature. The radiation-sensitive parameters of the test samples, including base current I\nB\n, collector current I\nC\n and DC current gain \n β \n, were measured and compared before and after every reactor n-\n γ \n pulse irradiation. The test results show that I\nB\n increased with increasing fluence, and I\nC\n slightly increased in the low base-emitter voltage V\nBE\n region (approximately from 0.4 V to 0.5 V) and decreased in the high-V\nBE\n region (approximately V\nBE\n >0.5 V). Moreover, the degradation degree of the test samples was different under different bias conditions. The performance of the test samples under cutoff bias mode displayed the most serious degradation, while those under forward bias mode suffered minimum damage. Meanwhile, the time-dependent annealing characteristics of the DC current gain for SiGe HBTs at various bias conditions were compared and analyzed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "448",
      "title": "Resilience Analysis of Discrete-Time Networked System in the Presence of Information Disclosure",
      "abstract": "Nowadays, security attacks on cyber physical systems have been reported frequently, wherein the eavesdropping attack is an usual hidden type of passive attack. In this paper, we consider the resilience of a discrete-time networked system in the presence of eavesdropping attacks. First, we analyze the convergence properties of the networked system. Then we provide necessary and sufficient conditions under which the eavesdropper can infer the states of the networked system by observing the states of partial of nodes, and also provide necessary conditions when the network has some nodes with zero out-degree. Finally, we verify all the derived theoretical results by numerical simulations, and show the relation of the node role in the network and the eavesdropping performance in some typical networks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "449",
      "title": "D-Band Perfect Anomalous Reflectors for 6G Applications",
      "abstract": "We demonstrate anomalous reflectors at 140 GHz for the application of 6G communication coverage expansion. The reflectors are designed on cyclo-olefin polymer (COP) substrates on the basis of measured complex permittivity and conductivity at millimeter frequencies obtained with the balanced-type circular disk resonator method. From full-wave simulations, we confirm that nearly perfect anomalous reflection characteristics are realized with suppressed parasitic reflections in undesired directions. The simulated efficiencies excluding the material losses of the reflectors designed with the reflection angle \n θR=30∘ \n, 45°, 60°, and 75° are 99.5%, 98.9%, 99.7%, and 99.8%, respectively. In addition, we fabricate the designed reflectors on the COP substrates and experimentally evaluate their anomalous reflection performances. The measured overall efficiencies of the reflectors with \n θR=45∘ \n, 60°, and 75° are 88.0%, 83.6%, and 81.6%, respectively. This is the first demonstration of highly efficient anomalous reflectors in the D-band.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "450",
      "title": "Signal Denoising Method Combined With Variational Mode Decomposition, Machine Learning Online Optimization and the Interval Thresholding Technique",
      "abstract": "The signal-to-noise ratio of lidar signals decreases rapidly with an increase in distance, which seriously affects the application of lidar detection technology. Variational mode decomposition (VMD) has performed optimality in dealing with noise, but the number of modes, \n K \n, and the penalty parameter, \n α \n, must be preset. Therefore, a novel lidar signal denoising method that combines VMD with machine learning online optimization (MLOO) and the interval thresholding (IT) technique, named VMD-MLOO-IT, is proposed in this article. The proposed method defines new fitness functions to evaluate the result of VMD-based denoising, and selects the optimal parameters by the model which development by MLOO. In addition, IT is used to deal with the recovered signal. The experimental results demonstrate the superiority of the presented method over the other empirical mode decomposition-based and VMD-based denoising methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "451",
      "title": "Dynamic Computation Offloading Based on Graph Partitioning in Mobile Edge Computing",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "452",
      "title": "Lip Reading Sentences Using Deep Learning With Only Visual Cues",
      "abstract": "In this paper, a neural network-based lip reading system is proposed. The system is lexicon-free and uses purely visual cues. With only a limited number of visemes as classes to recognise, the system is designed to lip read sentences covering a wide range of vocabulary and to recognise words that may not be included in system training. The system has been testified on the challenging BBC Lip Reading Sentences 2 (LRS2) benchmark dataset. Compared with the state-of-the-art works in lip reading sentences, the system has achieved a significantly improved performance with 15% lower word error rate. In addition, experiments with videos of varying illumination have shown that the proposed model has a good robustness to varying levels of lighting. The main contributions of this paper are: 1) The classification of visemes in continuous speech using a specially designed transformer with a unique topology; 2) The use of visemes as a classification schema for lip reading sentences; and 3) The conversion of visemes to words using perplexity analysis. All the contributions serve to enhance the accuracy of lip reading sentences. The paper also provides an essential survey of the research area.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "453",
      "title": "Towards InAs/InP Quantum-Dash Laser-Based Ultra-High Capacity Heterogeneous Optical Networks: A Review",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "454",
      "title": "Novel Method for Magnetic Flux Density Estimation in the Vicinity of Multi-Circuit Overhead Transmission Lines",
      "abstract": "In this paper, a novel method for the magnetic flux density estimation in the vicinity of multi-circuit overhead transmission lines is proposed. The proposed method is based on a fully connected feed-forward artificial neural network model that is trained to estimate the magnetic flux density vector components for a range of single-circuit overhead transmission lines. The proposed algorithm is able to simplify estimation process in instances when there are two or more geometrically identical circuits present in the multi-circuit overhead transmission line. In such instances, artificial neural network model is employed to estimate the magnetic flux density distribution over a considered lateral profile for only one of such circuits. The magnetic flux density estimates of the other geometrically identical circuits are derived from these results. The proposed methodology defines the resultant magnetic flux density for the multi-circuit overhead transmission line in terms of the contributions made by individual circuits. The application of the proposed magnetic flux density estimation method is demonstrated on several multi-circuit configurations of overhead transmission lines. The performance of the proposed method is compared with the Biot-Savart law based method calculation results as well as with field measurement results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "455",
      "title": "Generalizing the Split Factor of the Minimizing Delta Debugging Algorithm",
      "abstract": "One of the first attempts at the automation of test case reduction was the minimizing delta debugging algorithm, widely known as ddmin. Despite its age, it is still an unavoidable cornerstone of this field of research. One criticism against ddmin is that it can take too long to reach the granularity where it can perform actual reduction. Therefore, in this paper, ddmin is generalized with respect to the granularity by introducing a new split factor parameter, leading to the formalization of a parametric algorithm variant. The complexity analysis of this parametric variant reveals that the theoretical worst and best-case behavior of ddmin can be improved. Moreover, the results of experiments with the generalized algorithm show that the reduction can be sped up significantly by choosing the right split factor: up to 84% of the test steps can be eliminated in practice.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "456",
      "title": "Robust Estimators for Faster-Than-Nyquist Signaling",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "457",
      "title": "Wireless Information and Power Transfer Using Full-Duplex Self-Energy Recycling Relays",
      "abstract": "This paper proposes a Polarization-Enabled Digital Self-Interference Cancellation (PDC)-based Full-Duplex (FD) network with an energy-harvesting-enabled source and a Self-Energy Recycling (SER)-enabled relay. The fixed power supply at the relay is only used in the first phase to broadcast energy signals to the source. During this process, the receive antenna of the relay also receives the energy signals, allowing the relay to recycle its own energy. In the remaining phase, the recycled power is used at the relay to forward signals from the source to the destination, using the PDC-based full-duplex technique. An in-depth analysis and comparison of the throughput of the proposed system with that of the non-recycling counterpart are presented. The power saving and throughput improvement capabilities of the SER enabled system is researched. In particular, the consumed power in the proposed system can be reduced by up to 80% to achieve the same throughput compared to the non-recycling system for a small-to-medium distance range between the relay and the destination. Alternatively, the proposed FD-SER system can boost the system throughput by 1.61 times the non-recycling counterpart with the same power consumption.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "458",
      "title": "Design of Drain-Extended MOS Devices Using RESURF Techniques for High Switching Performance and Avalanche Reliability",
      "abstract": "The drift region of conventional drain extended NMOS (DeNMOS_C) is engineered to reduce gate charge for high performance and to enhance avalanche ruggedness for reliability in switching applications. Reduced-surface-field (RESURF) techniques, including surface implant (P-Top), split-gate (SG), and shallow trench isolation (STI), with an optimum doping implant of the drift region, are presented to improve the on-state safe operating area (SOA) and hot carrier stress (HCS) reliability of DeNMOS after the gate charge reduction. It is shown that under unclamped inductive switching (UIS) conditions, the avalanche ruggedness of optimized devices is improved, whereas DeNMOS_C shows high susceptibility towards thermal runaway and device failure due to electrothermal effects. Switching performance shows a reduction of up to 46% in total gate charge (\n Qg \n) and more than 65% in gate-to-drain coupling charge (\n Qgd \n). Moreover, the highest improvement achieved in switching delay is 34%. The high-frequency figure of merits such as FoM1 (\n RON×Qgd \n) and FoM2 (\n RON×Qg \n) show significant improvement of up to 65% and 35%, respectively. The tradeoff in the DC figure of merits FoM3 (\n VBD/RON) \n and Baliga-FoM (\n V2BD/RON) \n are also analyzed. Comparative analysis of optimized DeNMOS structures indicates that split gate DeNMOS without STI shows a minimum degradation of DC performance and the most significant improvement in high-frequency performance and switching reliability.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "459",
      "title": "Train Impedance Reshaping Method for Suppressing Harmonic Resonance Caused by Various Harmonic Sources in Trains-Network Systems With Auxiliary Converter of Electrical Locomotive",
      "abstract": "With the development of electrified railway, harmonic resonance accidents occur from time to time. Based on the mechanism of resonance, a harmonic resonance suppression radical method by impedance reshaping is proposed. Thus, the equivalent impedance of the train position is significantly reduced. Compared with the traditional method of improving harmonic current, this method of impedance reshaping can not only suppress the resonance caused by its own harmonic, but also suppress the resonance caused by other trains or other unknown harmonic sources. Harmonic impedance of the train in the resonant frequency is reshaped by detecting the resonance voltage and controlling the auxiliary converter harmonic current. The resonance identification and parameter settings of the impedance reshaping control are also discussed. The proposed harmonic resonance suppression strategy is fully tested with an auxiliary converter control in a simulation trains-network system model. The performance of the proposed strategy is further evaluated on the experimental platform. Both the results verify the effectiveness and feasibility of the proposed strategy. The application of SiC devices makes it effective to suppress the resonance of thousands of hertz. The experiment was validated in two cases. One is the resonance caused by the harmonic current of the train itself. The second is the resonance caused by the harmonic current of trains in other locations. In both cases, the train using impedance reshaping method can ensure that the resonance of its position is effectively suppressed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "460",
      "title": "The Performance Analysis of Virtual Queues for Space-Ground Integrated Networks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "461",
      "title": "Alicante-Murcia Freeway Scenario: A High-Accuracy and Large-Scale Traffic Simulation Scenario Generated Using a Novel Traffic Demand Calibration Method in SUMO",
      "abstract": "The design, testing and optimization of Vehicle to Everything (V2X), connected and automated driving and Intelligent Transportation Systems (ITS) and technologies requires mobility traces and traffic simulation scenarios that can faithfully characterize the vehicular mobility at the macroscopic and microscopic levels under large-scale and complex scenarios. The generation of accurate scenarios and synthetic traces requires a precise modelling approach, and the possibility to validate them against real-world measurements that are generally not available for large-scale scenarios. This limits the open availability of realistic and large-scale traffic simulation scenarios. The purpose of this paper is to present a large-scale and high-accuracy traffic simulation scenario. The scenario has been implemented over the open-source SUMO traffic simulator and is openly released to the community. The scenario accurately models the traffic flow, the traffic speed and the road’s occupancy for 9 full days of traffic over a 97 km freeway section. The scenario models mixed traffic with light and heavy vehicles. The simulation scenario has been calibrated using a unique dataset provided by the Spanish road authority and a novel learning-based and iterative traffic demand calibration technique for SUMO. This technique, referred to as Clone Feedback, is proposed for the first time in this paper and does not require a pre-calibration to generate realistic traffic demand. Clone Feedback can generate calibrated mixed traffic (light and heavy vehicles) using as input only traffic flow measurements. The results obtained show that Clone Feedback outperforms two reference techniques for calibrating the traffic demand in SUMO.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "462",
      "title": "A Low-Profile Dual-Polarized Magneto-Electric Dipole Antenna",
      "abstract": "A novel low-profile dual-polarized magneto-electric dipole antenna with two choices of feeding probes are proposed and investigated. The antenna utilizes a radiating structure which adopts equilateral triangular cavities with small gaps as the magnetic dipole while maintaining the original rectangular planar patches as the electric dipole, reducing the thickness to 0.15λ\n0\n (where λ\n0\n is the free-space wavelength at the center frequency). Each type of the feeding probe has its own merit and demerit in terms of mechanical robustness, performance and assembly tolerance. Measurement results show that the prototypes achieve wide impedance bandwidth of 48% (SWR <; 2), high gain (7.7 to 11 dBi) and unidirectional radiation patterns with low cross-polarizations (<; -22dB) and back-radiation level.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "463",
      "title": "Analysis of Sub-Synchronous Band Oscillation in a DFIG System With Non-Smooth Bifurcation",
      "abstract": "With the interconnection of large-scale wind power, the sub-synchronous oscillation (SSO) which is mainly analyzed by the local small-signal method occurs in many power grids. This paper presents the phenomenon of the sub-synchronous band oscillation (SSBO) of the doubly-fed induction generator (DFIG) system due to limits, which belongs to global dynamics, and analyzes its relationship with certain limits from the viewpoint of non-smooth bifurcation, which can serve as one of the mathematical foundations of the SSBO. Specifically, the concept of non-smooth bifurcation, a power system interconnected with the DFIG and the related current limit (CL) of d-axis and q-axis in the outer power control loop (OPCL) of the DFIG's rotor side converter (RSC) are introduced first. Secondly, the SSBO phenomenon induced by the CL of d-axis and q-axis is presented. And then, the influence of one parameter on the SSBO is analyzed, such as the short circuit capacity, the fault grounding resistance and the PI parameters of the OPCL, which reveals the non-smooth bifurcation with respect to relative one parameter. Finally, on the plane, the non-smooth bifurcation characteristics of PI controller parameters in the OPCL are given, showing that the non-smooth bifurcation/SSBO may be associated with saturation of different limits.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "464",
      "title": "LDPC Coded Multi-User Massive MIMO Systems With Low-Complexity Detection",
      "abstract": "We design a low-density parity-check (LDPC) coded multi-user (MU) massive multiple-input multiple-output (MIMO) system with an iterative joint detection and decoding (JDD) algorithm. As a low-complexity MU detection scheme, we consider a factor graph based belief propagation detection with Gaussian approximation of interference, called a FG-GAI BP detection. We introduce a factor graph representation of LDPC coded MU massive MIMO system and define the message updating rule in the JDD process. We devise a design tool for analyzing extrinsic information transfer (EXIT) characteristics of messages exchanged in JDD, based on which degree distribution of LDPC codes and a JDD strategy are efficiently designed for coded MU massive MIMO systems. A JDD strategy and LDPC codes are designed such that a fast convergence of JDD and a low bit error probability are attained. It is observed that the coded MU massive MIMO system equipped with LDPC codes and the JDD strategy designed by the proposed method shows a lower bit error rate than conventional ones with a given number of iterations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "465",
      "title": "Estimating Road Traffic Capacity",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "466",
      "title": "Damping Low-Frequency Oscillations in Power Systems Using Grid-Forming Converters",
      "abstract": "The increasing incorporation of renewable energy in power systems is causing growing concern about system stability. Renewable energy sources are connected to the grid through power electronic converters, reducing system inertia as they displace synchronous generators. New grid-forming converters can emulate the behavior of synchronous generators in terms of inertia provision and other grid services, like power-frequency and voltage-reactive regulation. Nevertheless, as a consequence of synchronous generator emulation, grid-forming converters also present angle oscillations following a grid disturbance. This paper proposes two novel power stabilizers for damping low-frequency oscillations (LFOs) in the power system. The first power stabilizer provides power oscillation damping through active power (POD-P), and it is implemented in a grid-forming converter, using the active power synchronization loop to damp system oscillations by acting on the converter angle. The second one provides power oscillation damping through reactive power (POD-Q), and it is implemented in a STATCOM, using the voltage control loop to damp system oscillations. Both proposals are first assessed in a small-signal stability study and then in a comprehensive simulation. Moreover, two cases are considered: damping the oscillations of a single machine connected to an infinite bus through a tie-line, and damping the inter-area oscillations in a two-area system. Simulation results, as well as the stability study, demonstrate the ability of both stabilizers to damp power system oscillations, being the POD-P more effective than the POD-Q, but at the cost of requiring some kind of energy provision at the DC bus.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "467",
      "title": "Opportunistic Networks Link Prediction Method Based on Bayesian Recurrent Neural Network",
      "abstract": "The goal of link prediction is to estimate the possibility of future links among nodes using known network information and the attributes of the nodes. According to the time-varying characteristics and the node's mobility of opportunistic networks, this paper proposes a novel link prediction method based on the Bayesian recurrent neural network (BRNN-LP) framework. The time series data of a dynamic opportunistic networks is sliced into snapshots in which there exist the correlation information and spatial location information. A vector of a snapshot is constructed based on such information, which represents the link information. Then, the vectors of multiple network snapshots constitute a spatiotemporal vector sequence. Benefiting from the BRNN's ability of extracting the features of time series data, the correlation between spatiotemporal vector sequence and node connection states is learned, and the law of the link evolution is captured to predict future links. The results on the MIT Reality dataset show that compared with methods such as the similarity-based indices, the support vector classifier, linear discriminant analysis and recurrent neural network, the proposed prediction method is more accurate and stable.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "468",
      "title": "Linear Arrhenius-Weibull Model for Power Transformer Thermal Stress Assessment",
      "abstract": "Arrhenius equations with Weibull distribution have been broadly deployed to quantify the loss of life and probability of failure of power transformers. This model is highly nonlinear, and this non-linearity makes it challenging to use this model for grid management and optimization. In this study, equations are linearized using Taylor series expansion to provide a linear formulation for transformer loss of life and probability of failure as a function of ambient temperature and transformer loading. The proposed formulation allows transformer constraints to be incorporated in grid management applications within conventional optimization approaches, such as linear programming, and decreases the calculation burden caused by nonlinearity.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "469",
      "title": "An Efficient Hardware Implementation of Reinforcement Learning: The Q-Learning Algorithm",
      "abstract": "In this paper we propose an efficient hardware architecture that implements the Q-Learning algorithm, suitable for real-time applications. Its main features are low-power, high throughput and limited hardware resources. We also propose a technique based on approximated multipliers to reduce the hardware complexity of the algorithm. We implemented the design on a Xilinx Zynq Ultrascale+ MPSoC ZCU106 Evaluation Kit. The implementation results are evaluated in terms of hardware resources, throughput and power consumption. The architecture is compared to the state of the art of Q-Learning hardware accelerators presented in the literature obtaining better results in speed, power and hardware resources. Experiments using different sizes for the Q-Matrix and different wordlengths for the fixed point arithmetic are presented. With a Q-Matrix of size 8 × 4 (8 bit data) we achieved a throughput of 222 MSPS (Mega Samples Per Second) and a dynamic power consumption of 37 mW, while with a Q-Matrix of size 256 × 16 (32 bit data) we achieved a throughput of 93 MSPS and a power consumption 611 mW. Due to the small amount of hardware resources required by the accelerator, our system is suitable for multi-agent IoT applications. Moreover, the architecture can be used to implement the SARSA (State-Action-Reward-StateAction) Reinforcement Learning algorithm with minor modifications.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "470",
      "title": "A New Approach to Bicarbonate Addition During Hemodialysis: Testing Model Predictions in a Patient Cohort",
      "abstract": "In this study, we present a new protocol for kidney replacement therapy (hemodialysis), based on an explicitly solvable mathematical model. With current protocols, the high and constant level of bath bicarbonate (HCO\n3\n−\n) used to prevent metabolic acidosis leads to very rapid delivery of HCO\n3\n−\n into the patient during the first part of the therapy. This rapid alkalinization elicits a robust buffer response that, paradoxically, consumes more HCO\n3\n−\n than is added during the remainder of the treatment. In previous studies, we developed an analytical model that allows one to quantify these events and tested alternative protocols manipulating the rate of rise in blood bicarbonate concentration (HCO\n3\n−\n). The protocol tested in this paper enforces a more gradual increase in blood HCO\n3\n−\n, by means of a model-based staircase adjustment of bath HCO\n3\n−\n. Model equations predict a reduction of buffer response and rate of organic acid production. These predictions are tested in 20 stable outpatients receiving hemodialysis. We find that the proposed protocol achieves the desired profile of blood HCO\n3\n−\n with good accuracy and reduces the total buffer response by 1/3 and the rate of lactic acid production by at least 1/4, as compared to conventional therapy. Although more studies are needed, we believe that our work will pave the way for a more rational approach to correction of acidosis during hemodialysis. Article Highlights \n•Our study tests an analytic model designed to enforce a more gradual rate of bicarbonate delivery during hemodialysis.•Using our model, we show that we can reduce the excessive buffer response and lactic acid production that occur with the conventional approach.•We demonstrate that our model can provide a rational approach to bicarbonate addition during treatment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "471",
      "title": "Improving Failure Prediction by Ensembling the Decisions of Machine Learning Models: A Case Study",
      "abstract": "The complexity of software has grown considerably in recent years, making it nearly impossible to detect all faults before pushing to production. Such faults can ultimately lead to failures at runtime. Recent works have shown that using Machine Learning (ML) algorithms it is possible to create models that can accurately predict such failures. At the same time, methods that combine several independent learners (i.e., ensembles) have proved to outperform individual models in various problems. While some well-known ensemble algorithms (e.g Bagging) use the same base learners (i.e., homogeneous), using different algorithms (i.e., heterogeneous) may exploit the different biases of each algorithm. However, this is not a trivial task, as it requires finding and choosing the most adequate base learners and methods to combine their outputs. This paper presents a case study on using several ML techniques to create heterogeneous ensembles for Online Failure Prediction (OFP). More precisely, it attempts to assess the viability of combining different learners to improve performance and to understand how different combination techniques influence the results. The paper also explores whether the interactions between learners can be studied and leveraged. The results suggest that the combination of certain learners and techniques, not necessarily individually the best, can improve the overall ability to predict failures. Additionally, studying the synergies in the best ensembles provides interesting insights into why some are able to perform better.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "472",
      "title": "Network Solutions for CoMP Coordinated Scheduling",
      "abstract": "Demanding throughput, latency and scalability requirements of 5G networks may be addressed by relying on dense deployments of small cells. Coordinated Multipoint (CoMP) Coordinated Scheduling (CS) techniques are introduced to reduce inter-cell interference in case of dense deployment, given that local CoMP-CS information from the evolved NodeBs (eNodeBs) in the cluster are timely collected at the scheduling decision entity. This work studies how the distribution of CoMP-CS cell information is affected by the backhaul infrastructure in terms of both physical and logical topology. The differentiation between physical and logical infrastructure is justified in the context of new approaches like Software Defined Networking and Network Function Virtualization that enable the dynamic configuration of the network. We consider either a Packet Switched Network with three possible topologies (namely, ring, mesh and star) or a Time Division Multiplexing Passive Optical Network (TDM-PON), both carrying heterogeneous traffic. To improve the convergence time in the TDM-PON, we propose a novel bandwidth allocation scheme to prioritize the signaling traffic with respect to data traffic. Performance of both distributed and centralized CoMP-CS are compared in terms of convergence delay and traffic overhead. Finally, we analyze the impact of the periodicity of CS operations on mobile performance, in terms of average UEs throughput, in the presence of different cell loads.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "473",
      "title": "IEEE Access Special Section Editorial: Big Data Learning and Discovery",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "474",
      "title": "ST-BFL: A Structured Transparency Empowered Cross-Silo Federated Learning on the Blockchain Framework",
      "abstract": "Federated Learning (FL) relies on on-device training to avoid the migration of devices’ data to a centralized server to address privacy leakage. Moreover, FL is feasible for scenarios (e.g., autonomous cars) where an enormous amount of data is generated every day. Transferring only local model updates in the case of FL is highly communication-efficient compared to transferring all data in the case of centralized machine learning (ML). Although FL offers many advantages, it also has some challenges. A malicious aggregation server can infer device information via local model updates. Another downside of FL is the centralized aggregation server that can malfunction due to an attack or physical damage. To address these issues, we propose a novel Structured Transparency empowered cross-silo Federated Learning on the Blockchain (ST-BFL) framework. In ST-BFL, homomorphic encryption, FL-aggregators, FL-verifiers, and smart contract are employed, which satisfy various structured transparency components, such as input privacy, output privacy, output verification, and flow governance. We present the framework architecture, algorithms, and sequence diagram of our ST-BFL framework to show how different entities interact in ST-BFL for the FL process. We also present a simplified class diagram of ST-BFL’s smart contract for an FL task. Finally, we perform a simulation to analyze our framework from the perspective of aggregation time, accuracy, and storage size. The qualitative and quantitative evaluation shows that ST-BFL has the same accuracy as traditional FL. However, ST-BFL provides input privacy, output privacy, input verification, output verification, and flow governance at the expense of relatively higher computation and communication costs than traditional FL.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "475",
      "title": "Tm3+-Doped Harmonic Dissipative Soliton Mode-Locked Fiber Laser at 1.93  $\\mu$ m Based on Tungsten Disulfide in Anomalous Dispersion Regime",
      "abstract": "We report a harmonic dissipative soliton 1.93 μm thulium fiber laser based on a tungsten disulfide (WS\n2\n) saturable absorber (SA) in the anomalous dispersion regime. The multilayer WS\n2\n nanosheets were prepared by liquid phase exfoliation method and the SA was fabricated by dropping WS\n2\n solution onto a gold mirror. The transferred WS\n2\n SA had a modulation depth of 2.5% and a saturation intensity of 0.82 MW/cm\n2\n. By incorporating the SA into a linear Tm\n3+\n fiber laser cavity, harmonic mode-locked dissipative soliton laser was achieved at 1930 nm with the spectral width of 8 nm, the pulse energy of 3 nJ, the pulse width of 3.6 ns, and the repetition rate of 56.3 MHz. Based on the experimental results, it is shown that with the presence of harmonic mode-locking in 2 μm wavelength region, the multilayer WS\n2\n serving as a SA was verified to be a good candidate for broadband high-energy mode-locking. The order of the harmonic dissipative soliton mode-locked pulses remains the same along with the increasing pump power.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "476",
      "title": "Quad Swipe Pattern: A New Point-of-Entry Security Measure for Smartphone Users",
      "abstract": "In this paper, we develop a new point-of-entry security measure for smartphone users. We devise a concept, the “Quad Swipe Pattern”, which includes four swipes from a user in four directions and utilizes the user’s swipe behavior for authentication. The Quad Swipe Pattern overcomes several shortcomings present in current point-of-entry security measures. We performed several experiments to demonstrate the effectiveness of the Quad Swipe Pattern in smartphone user authentication. We evaluated the Quad Swipe Pattern using five machine learning classifiers, three datasets of different sizes, and five different fingers. In addition, we studied how fusion of information from multiple fingers and multiple classifiers can improve the performance of Quad Swipe Pattern. All of our experimental results show significant promise of the Quad Swipe Pattern as a new point-of-entry security measure for smartphones. With a Neural Network model, the Quad Swipe Pattern achieves the Accuracy of 99.7%, False Acceptance Rate of 0.4%, and False Rejection Rate of 0%. With Support Vector Machine, the Quad Swipe Pattern achieves the Accuracy of 99.5%, False Acceptance Rate of 0.4%, and False Rejection Rate of 1.7%. With fusion of two best fingers, the Quad Swipe Pattern demonstrates an excellent performance of a zero Equal Error Rate.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "477",
      "title": "Multimodal Patient Satisfaction Recognition for Smart Healthcare",
      "abstract": "The inclusion of multimodal inputs improves the accuracy and dependability of smart healthcare systems. A user satisfaction monitoring system that uses multimodal inputs composed of users' facial images and speech is proposed in this paper. This smart healthcare system then sends multimodal inputs to the cloud. The inputs are processed and classified as fully satisfied, partly satisfied, or unsatisfied, and the results are sent to various stakeholders in the smart healthcare environment. Multiple image and speech features are extracted during cloud processing. Moreover, directional derivatives and a weber local descriptor is used for speech and image features, respectively. The features are then combined to form a multimodal signal, which is supplied to a classifier by support vector machine. Our proposed system achieves 93% accuracy for satisfaction detection.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "478",
      "title": "Improving the Cryptocurrency Price Prediction Performance Based on Reinforcement Learning",
      "abstract": "During recent developments, cryptocurrency has become a famous key factor in financial and business opportunities. However, the cryptocurrency investment is not visible regarding the market’s inconsistent aspect and volatility of high prices. Due to the real-time prediction of prices, the previous approaches in price prediction doesn’t contain enough information and solution for forecasting the price changes. Based on the mentioned problems in cryptocurrency price prediction, we proposed a machine learning-based approach to price prediction for a financial institution. The proposed system contains the blockchain framework for secure transaction environment and Reinforcement Learning algorithm for analysis and prediction of price. The main focus of this system is on Litecoin and Monero cryptocurrencies. The results show the presented system accurate the performance of price prediction higher than another state-of-art algorithm.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "479",
      "title": "Super-Energy-Resolution Material Decomposition for Spectral Photon-Counting CT Using Pixel-Wise Learning",
      "abstract": "Spectral photon-counting CT offers novel potentialities to achieve quantitative decomposition of material components, in comparison with traditional energy-integrating CT or dual-energy CT. Nonetheless, achieving accurate material decomposition, especially for low-concentration materials, is still extremely challenging for current sCT, due to restricted energy resolution stemming from the trade-off between the number of energy bins and undesired factors such as quantum noise. We propose to improve material decomposition by introducing the notion of super-energy-resolution in sCT. The super-energy-resolution material decomposition consists in learning the relationship between simulation and physical phantoms in image domain. To this end, a coupled dictionary learning method is utilized to learn such relationship in a pixel-wise way. The results on both physical phantoms and in vivo data showed that for the same decomposition method using lasso regularization, the proposed super-energy-resolution method achieves much higher decomposition accuracy and detection ability in contrast to traditional image-domain decomposition method using L1-norm regularization.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "480",
      "title": "Anomalous Radio Frequency Conductivity and Sheet Resistance of 2D Ti3C2Tx MXene",
      "abstract": "In this paper, we demonstrate the anomalous radio frequency (RF) performance of a 2D nanomaterial, Ti\n3\nC\n2\nT\nx\n MXene, by extracting conductivity and sheet resistance at both direct current (DC) and RF. Two-port microstrip transmission lines with detachable top layers, copper ground layer, and end launch connectors were fabricated. MXene transmission lines were manufactured through the deposition of layers with thicknesses of of \n 2 μm \n, \n 1 μm \n, and \n 0.2 μm \n onto polyethylene terephthalate (PET) substrates. Copper transmission lines were fabricated to serve as a benchmark. Two-port \n S \n-parameters were measured using a network analyzer from 0.9 GHz to 1.4 GHz and Telegrapher’s equation \nRLGC\n parameters (per unit length resistance \n R \n, inductance \n L \n, conductance \n G \n, and capacitance \n C \n) were extracted. The RF sheet resistance values of MXene films, as well as copper, were extracted from the \n R \n-values. \n S \n-parameters were simulated with the extracted RF sheet resistance values and a good match was found with the measured values. \n S \n-parameters were also simulated using the 4-point conductivity and thickness of the MXene films. The RF conductivity of the MXene coating was found to be 35,000 S/cm, higher than the DC conductivity of the material (10,000-15,000 S/cm). This work gives a guideline on designing MXene-based communication devices which are different from those fabricated with conventional metals.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "481",
      "title": "A Comparative Analysis of the Impact of Barrage and Comments on Video Popularity",
      "abstract": "In recent years, watching online videos has gradually become an indispensable part of netizens’ daily lives. Almost all video sites have added the barrage function. Both barrage and comments are two important ways for users to participate and play an important role in online video viewing. Based on the barrage and comments of videos uploaded by users of the bilibili website, our research explores the impact of barrage and comments with different emotional tendencies on video popularity and their differences, and explores the moderating effect of comments on the impact of the barrage. We also propose a method for calculating the emotional intensity of barrage that considers the herd effect and the emotional attenuation. The study finds that barrage has a positive impact on video popularity, while the emotional intensity of positive comments has a negative impact on video popularity, and comments play a negative role in the impact of the barrage. It explains that barrage and comments have their advantages and disadvantages. Our research has expanded the research in related fields such as user-generated content and video popularity, and the research conclusions have important management significance for video websites. In future research, we can further refine the emotional classification and consider the impact of video characteristics (video content and subtitles) on video popularity.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "482",
      "title": "Design of a Small NEMP Simulator for the Immunity Test of Core Electronic Components in HEMP Environments",
      "abstract": "We design a small nuclear electromagnetic pulse (NEMP) simulator to study the immunity of core electronic components in high-altitude electro-magnetic pulse (HEMP) environments. The NEMP simulator comprises of a power device, a high-voltage charging part, a pulse-shaping part, and the input taper. The performance of the proposed simulator is verified by the actual experimental results. The positive and negative polarities for the mono pulse output of a transient pulse generator are checked against the standard. The field uniformity of the proposed NEMP simulator is 1.6 dB and fully meets the standard.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "483",
      "title": "On Entanglement Assisted Classical Optical Communication With Transmitter Side Optical Phase-Conjugation",
      "abstract": "Entanglement assisted (EA) communication has been advocated by numerous authors as a potential alternative to classical communications, in particular in noisy and low-brightness regime. In this paper, I propose an EA scheme employing the optical phase-conjugation (OPC) on transmitter side. I show that the proposed EA communication system, with the transmitter side OPC, significantly outperforms its classical counterpart in low-brightness and highly noisy regime, while employing a classical coherent detection scheme for two-dimensional demodulation. Moreover, the capacity of the proposed EA scheme is significantly higher than EA repetition-BPSK, homodyne, heterodyne, and Holevo capacities. Finally, the proposed EA scheme outperforms the corresponding EA scheme with OPC placed on a receiver side.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "484",
      "title": "A Study on the Elimination of Thermal Reflections",
      "abstract": "Recently, thermal cameras have been used in various surveillance and monitoring systems. In particular, in camera-based surveillance systems, algorithms are being developed for detecting and recognizing objects from images acquired in dark environments. However, it is difficult to detect and recognize an object due to the thermal reflections generated in the image obtained from a thermal camera. For example, thermal reflection often occurs on a structure or the floor near an object, similar to shadows or mirror reflections. In this case, the object and the areas of thermal reflection overlap or are connected to each other and are difficult to separate. Thermal reflection also occurs on nearby walls, which can be detected as artifacts when an object is not associated with this phenomenon. In addition, the size and pixel value of the thermal reflection area vary greatly depending on the material of the area and the environmental temperature. In this case, the patterns and pixel values of the thermal reflection and the object are similar to each other and difficult to differentiate. These problems reduce the accuracy of object detection and recognition methods. In addition, no studies have been conducted on the elimination of thermal reflection of objects under different environmental conditions. Therefore, to address these challenges, we propose a method of detecting reflections in thermal images based on deep learning and their elimination via post-processing. Experiments using a self-collected database (Dongguk thermal image database (DTh-DB), Dongguk items and vehicles database (DI&V-DB)) and an open database showed that the performance of the proposed method is superior compared to that of other state-of-the-art approaches.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "485",
      "title": "Design and Implementation of Secure Cryptographic System on Chip for Internet of Things",
      "abstract": "Due to the 4th industrial revolution and the strength of the 5\nth\n Generation (5G) era, the Internet of Things (IoT) industry is growing significantly. As a result, the number of IoT devices in various industries, such as smart cars, smart homes, and smart healthcare, and the importance of security for these devices are increasing. This study proposes a design method for a secure cryptographic system on a chip (SecSoC) that can be used in the IoT industry and presents the results of the performance and security evaluations of the implemented chipset. The experimental results demonstrated that the SecSoC is a low-power high-performance cryptographic chip that is safe from external attacks. Compared to conventional smart card integrated circuits, the proposed design includes intrusion detection circuits that can respond to external attacks. At the same time, it supports a physical unclonable function for hiding secret data and cryptographic logic for maintaining integrity and confidentiality. The SecSoC ensured a fast transfer rate up to 110 Mbps and consumed only 95.8 mW when operating at maximum frequency.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "486",
      "title": "vMobiDesk: Desktop Virtualization for Mobile Operating Systems",
      "abstract": "Smart mobile devices have significantly increased the popularity of Bring-Your-Own-Device (BYOD) at work, as they benefit people's daily lives. However, BYOD comes with several challenging issues such as limited hardware capacity, frequent upgrades of applications, and security and privacy concerns. Virtual Mobile Infrastructure (VMI), a general framework that provides more reliable and secure solution for BYOD, has therefore been proposed. The key of VMI is to host a mobile Operating System (OS) on a remote cloud data center, and run mobile applications on it. However, VMI faces performance challenge as it needs to display the entire virtualized desktop on a mobile device while the real content of the desktop is on a remote server. To address the performance challenge, we design and implement a VMI named vMobiDesk on top of Android with optimized network transfer mechanisms and display virtualization. In particular, vMobiDesk focuses on virtualizing the display of Android desktops, redirecting users' input events, providing audio support and remote camera. The experimental results show that vMobiDesk has low virtualization overhead, as well as enables mobile users to obtain good experiences with BYOD applications.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "487",
      "title": "Correction to Reducing Signal Overload by Disconnection Tolerant Voice Service in Heterogeneous Networks",
      "abstract": "In the above paper \n[3]\n, two references \n[1]\n, \n[2]\nweremissing. The first sentence of Section III should read “This section proposes an analytical model for DHM, which is based on the mathematical analysis in \n[1]\n and \n[2]\n. Compared to \n[1]\n and \n[2]\n, DHM has different trafc model and different execution condition (DHM only applies in silent period).”",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "488",
      "title": "A Novel Multi-Attribute Group Decision-Making Method and Its Application in Solving the Downward Referral Problem in the Hierarchical Medical Treatment System in China",
      "abstract": "China has made many achievements in health care industry since the establishment of hierarchical medical treatment system, but also exposed a lot of problems, such as the problem of “easy to upward-referral, hard to downward-referral”, which occurred in the implementation process of two-way referral. Recently, the appearance of “hard to downward-referral” have gotten more and more attention from scholars. The key step in solving the problem of “downward-referral” is to classify hospitals at different levels evaluated by the professional doctors. This paper proposes a framework to solve the problem where evaluation values of the hospital are given as q-rung orthopair fuzzy uncertain linguistic variables (q-ROFULVs). Considering Schweizer-Sklar t-conorm and t-norm (SSTT) can make the information aggregation process more flexible, and Hamy Mean operator can consider the correlation between hospital indicators. In order to take full advantage of these two kinds of operators, firstly, we extend SSTT to q-ROFULVs and define Schweizer-Sklar operational rules of q-ROFULVs. Secondly, we combine the Hamy Mean operator with Schweizer-Sklar t-conorm and t-norm, and propose the q-rung orthopair fuzzy uncertain linguistic Schweizer-Sklar Hamy mean aggregation operators and q-Rung orthopair fuzzy uncertain linguistic Schweizer-Sklar weighted Hamy Mean respectively. Afterwards, q-rung orthopair fuzzy uncertain linguistic Schweizer-Sklar dual Hamy mean operator and its weighted form are also developed. Then, we have studied in detail some of the ideal properties of these operators. Furthermore, a novel multi-attribute group decision-making approach based on proposed operators is introduced. Finally, we apply the new approach to solve the problem about the downward conversion in the hierarchical medical treatment system. This is of great significance for integrating the medical resources of the whole society and improving the service efficiency of the medical service system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "489",
      "title": "A Genetic Algorithm-Based Metaheuristic Approach for Test Cost Optimization of 3D SIC",
      "abstract": "Demand for small, multi-functional, high performance electronic product with less power consumption is increasing rapidly. To meet the demand, IC design has been shifted from two dimensional integrated circuit (2D-IC) to three dimensional integrated circuit (3D-IC), where multiple device layers are stacked together to create stacked integrated circuit (SIC). This results the complexity in 3D SIC architecture and increase in the number of fault-sites. Therefore, testing of SIC has become complicated. Consequently, the test data volume also grows in proportion to the number of cores in the SIC, since each core is associated with one or more tests, which leads to longer test times. Test cost of IC which depends on test time, associated hardware to test the cores and the power dissipated at the time of test, can be represented as a weighted sum of test time and the associated hardware to test the core with power considered as the test constraint. As a result an efficient test plan is required to co-optimize test time and hardware under certain power constraint. The objective of our work is to design an efficient test plan both for non-stacked IC (i.e. SIC with single chip) and 3D stacked IC (i.e. SIC with multiple chips) under a power constraint, where each chip is provided with IEEE 1149.1 architecture. An existing cost model is used for calculating the test cost. Initially we propose First fit based two dimensional (2D) Bin Packing optimization algorithm for minimizing the test cost of non-stacked IC. However, the method produces sub-optimal result in comparison to earlier reported work. Knowing the complexity of 3D SIC, Genetic algorithm based metaheuristic approach is next proposed in this paper. It is applied on several ITC02 benchmark circuits and the experimental result shows the efficacy of the proposed algorithm in comparison to earlier works.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "490",
      "title": "Off-Person ECG Biometrics Using Spatial Representations and Convolutional Neural Networks",
      "abstract": "Targeting off-person ECG-based biometrics, we report a comparative analysis of identification accuracy and verification Equal Error Rate (EER) performances of four distinct types of spatial representations of ECG signals applied as inputs to Convolutional Neural Networks. The actual algorithms used to transform the original time series into 2D/3D images are based on a modified version of the Continuous Wavelet Transform (the S-Transform), the Gramian Angular Field, the recurrence plot, and state-space representations. Extensive experiments have been conducted using UofT and CYBHI datasets including recordings acquired on fingers and hand palm under various activity scenarios. The wavelet-based approach yielded best results, while all analyzed solutions compare favorably with previously reported performances.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "491",
      "title": "Medium Voltage Power Switch in Silicon Carbide—A Comparative Study",
      "abstract": "This paper discusses various solutions of energy conversion in medium voltage using power switches in Silicon Carbide (SiC) technology. In particular, a comparative study is focused on four different variants of an inverter phase leg operating at 1.5 kV DC, which has not been presented in the literature yet. The first one is based on a standard two-level half-bridge built from a 3.3 kV SiC MOSFET power module rated at 450 A. Then, the two-level solution with series-connected devices inside 1.2 kV/450 A power modules is taken into account. Finally, a flying-capacitor phase leg also based on the same 1.2 kV devices is investigated in two different modes: a standard three-level operation and quasi-two-level mode with a significantly reduced capacitor. The presented study is founded on in-depth experiments: all four phase legs were designed, built, and tested in the laboratory. All versions were connected in a half-bridge configuration with an inductive load. Tests were conducted under identical conditions to test the overall performance and switching behavior for various gate resistances. In addition, different aspects are analyzed and compared in this paper, including parasitics, cooling performance, gate drivers and layout considerations, providing selection guidelines for power switches with SiC power devices in medium voltage power electronics applications.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "492",
      "title": "Energy Management Framework for 5G Ultra-Dense Networks Using Graph Theory",
      "abstract": "The next-generation 5G networks are being developed with high promised capabilities. Beyond just multitudes faster data speed, 5G is expected to serve billions of connected devices and the Internet of Things (IoT), with the right trade-offs between speed, latency, and energy at an affordable cost. 5G radio networks will strongly depend on using ultra-dense integrated Small Cells (SCs) beside the Macro Cells (MCs). This kind of Ultra-Dense Networks (UDN) consisting of a large number of MCs and SCs will significantly increase network energy demands. A practical method to control energy consumption is by dynamically controlling power-saving modes in radio networks. In this paper, we propose a novel cooperative energy management framework for 5G UDN using graph theory. The 5G network is first modeled as a graph, then graph theory methods are exploited to determine the order of nodes at which power-off/on procedure is applied. We also show that significant power savings are achievable by considering only a subset of network nodes and thus reduce traffic migration and control plane signaling. We evaluated the proposed algorithm at different network densification levels and several load factors including two real-life networks. We also present the convergence of the proposed algorithm and the robustness of networks optimized using it. We also show that power savings up to 25% at full load and 65% during off-peak can be achieved using the proposed algorithm. These power savings increase further if no constraints are imposed on traffic migration and control signaling.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "493",
      "title": "Codebook Designs for Millimeter-Wave Communication Systems in Both Low- and High-Mobility: Achievements and Challenges",
      "abstract": "More connectivity, higher data rates, more reliability, massive network capacity, higher performance and fewer delays are required in the fifth generation (5G) of cellular networks. The last ten years have contained explosive growth in mobile data traffic due to the rapid proliferation of Internet-connected smart devices. For 5G mobile and wireless networks, one of the challenges is to discover how to solve the dilemma between capacity requirements and spectrum shortage. Millimeter-wave communication is therefore a key enabler for 5G technologies. Due to the high path and penetration losses at millimeter wavelengths, antenna beamforming assumes a pivotal role in establishing and maintaining a robust communication link. Recently, codebook-based beamforming has been proposed to achieve a fair balance between complexity and performance and to eliminate the overheads. In this paper, we track the techniques of codebook-based beamforming for millimeter-wave communications in the context of the distinct requirements for low-mobility channel and high-mobility channel scenarios. Subsequently, we will provide a comparison of existing codebook-based beamforming techniques in terms of their respective benefits and shortcomings. Finally, some open directions of research are discussed, and challenges that need to be met are pointed out.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "494",
      "title": "Integrated Network and Security Operation Center: A Systematic Analysis",
      "abstract": "Traditionally, network and security operation center teams have worked in silos despite commonalities. The network operating center (NOC) team is to provide operationality and availability of information technology (IT) assets, while the security operation center (SOC) team is to ensure IT assets security and protect them from cyber-security attacks. The convergence in IT assets and exponential growth in cyber-security threats in the present digital-online scenario have created many challenges in maintaining network and IT assets effectively and protecting them. It is vital to break these silos and bring them under one integrated unit to effectively counter cyber-security attacks, threats, and vandalism at a reduced operational cost. Despite its necessity, the relevant literature lacks an opinion. It focuses mainly on conceptual segments instead of a holistic view of an integrated NOC and SOC architecture, limiting further innovations in the field. A systematic literature review and analysis is conducted to collate and understand current research ideas in this paper. The mapped relevant literature and our expertise have been then used to propose the implementable state-of-the-art architecture of an integrated NOC and SOC, its definition, the main building blocks and its usefulness for the organizations. Only explicit knowledge of people is considered while neglecting the tacit knowledge in automating and integrating the processes of NOC and SOC, which is the major limitation of the relevant literature. Taping people tacit knowledge is necessary for utilizing the entire caliber of the NOC and SOC integration in the future.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "495",
      "title": "Authenticated Encryption Schemes: A Systematic Review",
      "abstract": "Authenticated encryption (AE) is a cryptographic construction that simultaneously protects confidentiality and integrity. A considerable amount of research has been devoted to the area since its formal inception in 2000. Different lines of research have been proposed to enhance the available schemes in terms of security, efficiency, and design and to implement new ideas. However, a comprehensive systematic literature review (SLR) of the topic has not been provided to the best of the authors’ knowledge. This study fills this gap in the literature by proposing a framework for classifying AE schemes and highlighting past contributions to help researchers familiarize themselves with the current state and directions for future research in the area. This SLR covered AE schemes proposed from 2000 to 2020. A total of 217 articles, selected from eight sources, were categorized into independent schemes, CAESAR competition schemes, and NIST lightweight competition schemes. These schemes were then classified according to their design approaches, security-related properties, and functional features. Our analysis reveals that a significant outstanding challenge in AE is to balance security, efficiency, and the provision of desirable features.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "496",
      "title": "FPGA Based Real-Time Implementation of Online EMD With Fixed Point Architecture",
      "abstract": "Empirical mode decomposition (EMD) is a data driven method for nonstationary data analysis which has proven to be extremely useful in diverse applications in biomedical engineering. In its original formulation, the EMD method works collectively on a batch of data and hence is not suitable for online applications that demand continuous data processing capability in real-time. To cater for such applications, few complete field-programmable gate array (FPGA) based designs for EMD computations have emerged in recent years, yet they have found limited practical applications. The main reason could be that existing complete FPGA based architectures invariably work on integer data sets thus ignoring the sensitivity EMD to truncation errors. Moreover, these architectures mostly implement simplistic linear interpolation technique for sifting process within EMD, thereby compromising its accuracy. To that end, we develop a complete FPGA-based architecture for EMD which works on fixed point data formats thereby alleviating the main source of error in existing EMD based architectures. We also implement well established and accurate cubic spline interpolation technique in addition to giving provision to linear interpolation within the sifting process in EMD, which further improves its accuracy. Our proposed pipeline design ensures that despite implementing computationally expensive EMD related tasks, the proposed architecture exhibits lowest execution time among all existing EMD architectures. We provide examples of computation of EMD decomposition through proposed architecture for both synthetic and real world biomedical signals to demonstrate the prowess of our work.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "497",
      "title": "A Novel Hybrid Optimization-Based Algorithm for the Single and Multi-Objective Achievement With Optimal DG Allocations in Distribution Networks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "498",
      "title": "A Novel Hybrid Multi-Objective Particle Swarm Optimization Algorithm With an Adaptive Resource Allocation Strategy",
      "abstract": "Recently, there are a number of particle swarm optimization algorithms (PSOs) proposed for tackling multi-objective optimization problems (MOPs). Most of multi-objective PSOs (MOPSOs) were designed to speed up their convergence, which have been validated when tackling various kinds of MOPs. However, they may face some challenges for tackling some complicated MOPs, such as the UF test problems with complicated Pareto-optimal sets, mainly due to their neglect on the diversity. To solve the above problem, a novel hybrid MOPSO (called HMOPSO-ARA) is suggested in this paper with an adaptive resource allocation strategy, which shows a superior performance over most MOPSOs. Using the decomposition approach in HMOPSO-ARA, MOPs are transferred into a set of subproblems, each of which is accordingly optimized by one particle using a novel velocity update approach with the strengthened search capability. Then, an adaptive resource allocation strategy is employed based on the relevant improvement on the aggregated function, which can reasonably assign the computational resource to the particles according to their performance, so as to accelerate the convergence speed to the true Pareto-optimal front. Moreover, a decomposition-based clonal selection strategy is further used to enhance our performance, where the cloning process is run on the external archive based on the relevant fitness improvement. The experiments validate the superiority of HMOPSO-ARA over four competitive MOPSOs (SMPSO, CMPSO, dMOPSO and AgMOPSO) and four competitive multi-objective evolutionary algorithms (MOEA/D-ARA, MOEA/D-DE MOEA/D-GRA and EF_PD) when tackling thirty-five test problems (DTLZ1-DTLZ9, WFG1-WFG9, UF1-UF10 and F1-F9), in terms of two widely used performance indicators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "499",
      "title": "Comparative Assessment of Multi-Port MMCs for High-Power Applications",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "500",
      "title": "Neural Image Compression and Explanation",
      "abstract": "Explaining the prediction of deep neural networks (DNNs) and semantic image compression are two active research areas of deep learning with a numerous of applications in decision-critical systems, such as surveillance cameras, drones and self-driving cars, where interpretable decision is critical and storage/network bandwidth is limited. In this article, we propose a novel end-to-end Neural Image Compression and Explanation (NICE) framework that learns to (1) explain the predictions of convolutional neural networks (CNNs), and (2) subsequently compress the input images for efficient storage or transmission. Specifically, NICE generates a sparse mask over an input image by attaching a stochastic binary gate to each pixel of the image, whose parameters are learned through the interaction with the CNN classifier to be explained. The generated mask is able to capture the saliency of each pixel measured by its influence to the final prediction of CNN; it can also be used to produce a mixed-resolution image, where important pixels maintain their original high resolution and insignificant background pixels are subsampled to a low resolution. The produced images achieve a high compression rate (e.g., about 0.6x of original image file size), while retaining a similar classification accuracy. Extensive experiments across multiple image classification benchmarks demonstrate the superior performance of NICE compared to the state-of-the-art methods in terms of explanation quality and semantic image compression rate. Our code is available at: https://github.com/lxuniverse/NICE.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "501",
      "title": "Detection and Localization of Multiple Image Splicing Using MobileNet V1",
      "abstract": "In modern society, digital images have become a prominent source of information and medium of communication. The easy availability of image-altering softwares have greatly reduced the expenses and expertise required to exploit visual tampering. Images can, however, be simply altered using these freely available image editing softwares. Two or more images are combined to generate a new image that can transmit information across social media platforms to influence the people in the society. This information may have both positive and negative consequences. Hence there is a need to develop a technique that will detect and locate a multiple image splicing forgery in an image. This research work proposes multiple image splicing forgery detection using Mask R-CNN, with a backbone as a MobileNet V1. It also calculates the percentage score of a forged region of multiple spliced images. The comparative analysis of the proposed work with the variants of ResNet is performed. The proposed model is trained and tested using the MISD (Multiple Image Splicing dataset), and it is observed that the proposed model outperforms the variants of ResNet models (ResNet 51,101 and 151). The proposed model achieves an average precision of 82% on Multiple Image Splicing Dataset, 74% on CASIA 1.0, 81% on WildWeb, and 86% on Columbia Gray. The F1-Score of the proposed method on MISD was 67%, 64% on CASIA 1.0 68% on WildWeb, and 61% on Columbia Gray, outperforming ResNet variants.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "502",
      "title": "Adaptive Multi-Channels Allocation in LoRa Networks",
      "abstract": "In this paper, we consider an IoT dedicated network corresponding to a non licensed LoRa Low Power Wide Area Network. The LoRa network operates in the unlicensed 868 MHz band within a total bandwidth of 1 MHz divided into 8 orthogonal channels of 125 kHz each. Despite the high level of interference, this network offers long range communications in the order of 2 to 5 km in urban areas and 10 to 30 km in rural areas. To efficiently mitigate this high level of interference, LoRa network essentially relies on a Chirp Spread Spectrum (CSS) modulation and on repetition diversity mechanisms. The LoRa CSS modulation spreads the signal within a band of 125 kHz using 6 possible spreading factors (from 7 to 12) to target data rates (starting from 5 kbps for the closest node to 300 bps for the furthest ones). The repetition diversity mechanisms enable the data recovery when the transmission is subject to bad channel conditions or/and high interference levels. Although the CSS modulation protects edge-cell's devices from the high level of interference induced by nodes in the proximity of the gateway, it fails to protect nodes at the edge of a given SF region and several trials are required to recover the packet. In this paper, we propose an adaptive multi-channels allocation policy that attributes multiple adjacent channels of 125 kHz for nodes situated at the edge of SF zones. We study the impact of this adaptive sub-band allocation on the gateways' intensities, the rate distribution and the power consumption. Our results are based on a statistical characterization of the interference in the network as well as the outage probability in a typical cell.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "503",
      "title": "An SDN/ML-Based Adaptive Cell Selection Approach for HetNets: A Real-World Case Study in London, UK",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "504",
      "title": "Impedance-Sliding Mode Control With Force Constraints for Space Robots Capturing Non-Cooperative Objects",
      "abstract": "The safe realization of on-orbit capture remains a challenging task because of uncontrolled service objects, big impact forces, post-impact control, and so on. In this study, based on the relationships between the kinematics and forces established by impedance control, a force constraint function is developed to reduce the contact force during the collision process of capture. Additionally, to realize flexible contact and improve motion performance during the capture process, a control method combining impedance and a sliding mode is designed to make the end-effector exhibit mass-spring-damping behavior after contact with the target, decreasing movement overshoot and stabilization time. Finally, numerical simulations are carried out in a scenario where a planar two-link space robot is utilized to capture a non-cooperative target, and the effectiveness of the proposed method is demonstrated.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "505",
      "title": "A Logistic Chaotic Barnacles Mating Optimizer With Masi Entropy for Color Image Multilevel Thresholding Segmentation",
      "abstract": "Barnacles mating optimizer (BMO) is an evolutionary algorithm that simulates the mating and reproductive behavior of barnacle population. In this article, an improved Barnacles mating optimizer based on logistic model and chaotic map (LCBMO) was proposed to produce the high-quality optimal result. Firstly, the logistic model is introduced into the native BMO to realize the automatic conversion parameters. This strategy maintains a proper relationship between exploitation and exploration. Then, the chaotic map is integrated to enhance the exploitation capability of the algorithm. After that, six variants based on LCBMO are compared to find the best algorithm on benchmark functions. Moreover, to the knowledge of the authors, there is no previous study on this algorithm for multilevel color image segmentation. LCBMO takes Masi entropy as the objective function to find the optimal threshold. By comparing different thresholds, different types of images, different optimization algorithms, and different objective functions, our proposed technique is reliable and promising in solving color image multilevel thresholding segmentation. Wilcoxon rank-sum test and Friedman test also prove that the simulation results are statistically significant.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "506",
      "title": "User Behavior Clustering Scheme With Automatic Tagging Over Encrypted Data",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "507",
      "title": "Facial Expression Rendering in Medical Training Simulators: Current Status and Future Directions",
      "abstract": "Recent technological advances in robotic sensing and actuation methods have prompted development of a range of new medical training simulators with multiple feedback modalities. Learning to interpret facial expressions of a patient during medical examinations or procedures has been one of the key focus areas in medical training. This article reviews facial expression rendering systems in medical training simulators that have been reported to date. Facial expression rendering approaches in other domains are also summarized to incorporate the knowledge from those works into developing systems for medical training simulators. Classifications and comparisons of medical training simulators with facial expression rendering are presented, and important design features, merits and limitations are outlined. Medical educators, students and developers are identified as the three key stakeholders involved with these systems and their considerations and needs are presented. Physical-virtual (hybrid) approaches provide multimodal feedback, present accurate facial expression rendering, and can simulate patients of different age, gender and ethnicity group; makes it more versatile than virtual and physical systems. The overall findings of this review and proposed future directions are beneficial to researchers interested in initiating or developing such facial expression rendering systems in medical training simulators.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "508",
      "title": "SATSal: A Multi-Level Self-Attention Based Architecture for Visual Saliency Prediction",
      "abstract": "Human visual Attention modelling is a persistent interdisciplinary research challenge, gaining new interest in recent years mainly due to the latest developments in deep learning. That is particularly evident in saliency benchmarks. Novel deep learning-based visual saliency models show promising results in capturing high-level (top-down) human visual attention processes. Therefore, they strongly differ from the earlier approaches, mainly characterised by low-level (bottom-up) visual features. These developments account for innate human selectivity mechanisms that are reliant on both high- and low-level factors. Moreover, the two factors interact with each other. Motivated by the importance of these interactions, in this project, we tackle visual saliency modelling holistically, examining if we could consider both high- and low-level features that govern human attention. Specifically, we propose a novel method SAtSal (Self-Attention Saliency). SAtSal leverages both high and low-level features using a multilevel merging of skip connections during the decoding stage. Consequently, we incorporate convolutional self-attention modules on skip connection from the encoder to the decoder network to properly integrate the valuable signals from multilevel spatial features. Thus, the self-attention modules learn to filter out the latent representation of the salient regions from the other irrelevant information in an embedded and joint manner with the main encoder-decoder model backbone. Finally, we evaluate SAtSal against various existing solutions to validate our approach, using the well-known standard saliency benchmark MIT300. To further examine SAtSal’s robustness on other image types, we also evaluate it on the Le-Meur saliency painting benchmark.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "509",
      "title": "Feedback Control for QoS-Aware Radio Resource Allocation in Adaptive RAN",
      "abstract": "In order to meet the quality requirements of various communication services in the advanced 5G era around 2025, the authors have proposed an Adaptive radio access network (RAN) that changes the placement of virtualized base station functions according to the services. In Adaptive RAN, each base station function has its own scheduler, and multiple schedulers share common radio resources. Therefore, in order to guarantee communication quality for more users, it is necessary to control the allocation of the radio resources required for scheduling to each base station function with neither excess nor deficiency. This allocation control is performed based on the information collected from the base station functions by the RAN intelligent controller (RIC). If a large amount of information is used for control, allocation can be performed with higher accuracy, but the collection of information overuses the limited bandwidth of the network. Therefore, it is necessary to reduce the information volume required for control while at the same time guaranteeing communication quality. In this paper, we propose a method that guarantees communication quality while reducing the information volume required for control by combining a required resource estimation control in a long cycle and a resource allocation modification control based on feedback information related to communication quality in a short cycle. We evaluated the impact of the proposed method on communication quality compared to conventional methods through simulation, and verified that the proposed method can guarantee better communication quality than conventional methods while suppressing the increase in information volume.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "510",
      "title": "ConvFusion: A Model for Layer Fusion in Convolutional Neural Networks",
      "abstract": "The superior accuracy and appealing universality of convolutional neural networks (CNNs) as a generic algorithm for many classification tasks have made the design of energy efficient CNN accelerators an important topic in both academia and industry. Of particular interest in the design and use of CNN accelerators is the scheduling of the computational workload, which can have a major impact on the quality of the final design. The many inherently independent operations in CNNs result in a vast scheduling space however, rendering the selection of the optimal schedule(s) non-trivial. To aid in this complex task, this work introduces a generic mathematical cost model of the external memory accesses, internal memory footprint, and compute load for CNN execution schedules. The model enables fast exploration of the scheduling space, including loop tiling, loop reordering, explicit data transfer scheduling, recomputation, and, crucially, layer fusion, which recently has attracted interest as a method to reduce external memory accesses. An accompanying open source tool is released to perform schedule space exploration for CNNs using the introduced cost model. Leveraging the code generation capabilities of this tool the proposed model is validated on six real world networks, demonstrating that layer fusion can reduce the external memory accesses by more than two orders of magnitude compared to the best non-fused schedules. Confusing at first glance however, a high-level energy analysis shows that the practical benefits of layer fusion may be overestimated if other parts of the system are not tuned accordingly.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "511",
      "title": "Improvements to the Construction of Bubble Inception Formulae for Use With Transformer Insulation",
      "abstract": "Moisture in transformer insulation is a topic of major interest to power system equipment operators. Moisture plays a large role in the degradation of insulation within the transformer, impacting on the longevity and the failure rate of this crucial asset. Therefore, understanding of how moisture behaves in the transformer insulation has been the focus of many studies. One particular matter that can occur during high-temperature events is the formation of bubbles of water vapor which are released from the cellulosic paper wrapped on the transformer windings. During such events, the presence of these bubbles could lead to an electrical failure of the transformer, and so it is desirable to be able to set operational criteria which prevent such occurrences. A formula which can predict the temperature at which bubbles will form from the paper insulation can allow operators to restrict transformer operation in order to avoid such situations. However, it has proven difficult to generate a formula with global applicability that is simplistic enough for generic use. This paper assesses the current formula against existing data in literature and compares a suggested alternative, drawing on fundamental science to assist in development of both formulae. The alternative formula is based on a better representation of bubbling activity and requires fewer input variables. Finally, adjustments are suggested to the formulae which allow them to be used more generally throughout the transformer fleet, including on service-aged transformers and with alternative insulation materials.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "512",
      "title": "ADSM: Adaptive Data Scheduling Method for Hybrid Memories in Distributed System",
      "abstract": "With the deployment of innovative memories such as non-volatile memory and 3D-stacked memory in distributed systems, how to improve the application performance by utilizing the unique characteristics of these hybrid memories remains an active research direction. For instance, the Intel Knight Landing (KNL) processor incorporates a High Bandwidth Memory (HBM) using 3D-stacked technology with traditional DRAM onto the same chip. HBM achieves much higher bandwidth than traditional DRAM when the application exhibits high parallelism and sequential access. In this paper, we propose a new metric SP-factor to guide the data scheduling in distributed system using hybrid memories such as HBM and DRAM. The SP-factor incorporates the data access patterns including data block size and data access parallelism, which leads to better data scheduling decision for higher performance. We apply SP-factor to several data eviction policies on the hybrid memory system, which achieves better performance. Moreover, an adaptive data scheduling method (ADSM) is proposed for such hybrid memory system with HBM and DRAM. ADSM can dynamically adjust scheduling decisions based on runtime performance metrics so that it can adapt to workloads with different data access patterns. Our experimental results show that ADSM can significantly improve the performance of the representative workloads. For SQL query application with mixed access pattern, the cache hit ratio increases by 10.4% and the execution time reduces by 14.6% using ADSM compared to ARC policy.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "513",
      "title": "Analysis of 0–9 kHz Current Harmonics in a Three-Phase Power Converter Under Unbalanced-Load Conditions",
      "abstract": "The unbalanced condition of typical loads in industrial networks could affect the current harmonics across the dc-link in Adjustable Speed Drives (ASDs). These current harmonics could pass through the dc-link and create new current harmonics at the grid side. Thus, the effect of unbalanced-load condition on the current harmonics across the dc-link needs to be considered in the design process. Moreover, new compatibility levels and emission limits will be developed for the 2–9 kHz current harmonics, so drives need to meet these new requirements in future. These current harmonics could also be significantly affected by the load power factor at the unbalanced-load condition. Due to these reasons, analysing the effect of unbalanced-load and load power factor on the current harmonics between 0 to 9 kHz across the dc-link is vital. Thus, this paper presents an analytical approach for estimating the current harmonics of the inverter at the dc side considering unbalanced-load currents. The proposed mathematical equations are then validated with experimental results. These analyses reveal that the negative-sequence current generates new harmonics across the dc-link. Additionally, the relationship between unbalanced currents at the load side and dc-link are found as a function of positive- and negative-sequence currents.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "514",
      "title": "Abnormal Condition Monitoring and Diagnosis for Coal Mills Based on Support Vector Regression",
      "abstract": "Abnormal condition monitoring is an essential part in ensuring the reliability and safety and guaranteeing the efficiency for industrial processes. This paper proposes a monitoring and diagnosis framework applied to coal mills in thermal power plants. The support vector regression (SVR) method with optimized parameters is utilized to detect the abnormal condition that the operating performances deviate from the normal levels expected. The support vectors in the trained models are considered as the representative operating conditions; then are used for responsible variables diagnosis, measuring how far each performance related variable deviates from its expected value when abnormal events occur. This approach is validated by three real cases from a thermal power plant, and the application results indicate that the proposed approach can detect abnormal conditions in time and accurately. Furthermore, effective diagnosis can be achieved and is validated by the case analysis conclusions from experts, which shows the effectiveness and potential value of the proposed approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "515",
      "title": "Gamma and Proton Irradiation Tests on a Piezoelectric Actuator",
      "abstract": "Piezoelectric actuators are candidates for use in radioactive environments but specific radiation tests are necessary to understand the radiation effects on the whole actuator assembly. The results of three irradiation tests on a piezoelectric actuator used for Crystal Collimation are presented. The total ionising dose effects are studied with two Gamma (\n60\nCo) Tests up to 10 MGy and 1 MGy, whereas the displacement damage effects are studied in a Proton Test up to 2 MGy and 1.14 × 10\n16\n p/cm\n2\n fluence. The main results are summarised for each test, presenting a maximum impedance increase of less than 25% (Proton Test), a maximum free stroke reduction of less than 25% (Proton Test) and a variation in the shape of the hysteresis response of the actuator.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "516",
      "title": "Flexible Pricing Strategies in Electric Free-Floating Bicycle Sharing",
      "abstract": "Bike sharing is an important tool to reduce congestion and pollution in urban areas. Electrically Power Assisted Bicycles (EPAC’s) make cycling possible also for sedentary people. Standard EPAC’s are difficultly integrable into a free-floating sharing system because the battery pack requires frequent recharging. This paper studies the challenges, opportunities and solutions of implementing a free-floating bike sharing system based on electric bicycles. The analysis revolves around the charge sustaining paradigm. The idea of charge sustaining leverages the metabolic efficiency gaps to reduce the overall physical effort required without determining a net discharge of the battery. Already validated in private bicycles, the idea needs to be modified and adapted to the challenges of a shared fleet. The paper analyzes two approaches to the fleet level energy management and assistance control of a fleet of charge sustaining bicycles. Specifically, we compare a fixed price approach against a flexible pricing approach where the user can select the cost based on the pedaling effort they are willing to exercise. A simulation framework (calibrated on data collected during a large trial in Milan, Italy) assesses the operational costs and revenues of the two approaches quantifying how they depend on the design and environmental parameters. We provide and validate a lower bound in terms of usage rate that guarantees economic sustainability, additionally showing that a flexible pricing strategy can lower this bound and grant more degrees of freedom to the users.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "517",
      "title": "Neuron Circuits for Low-Power Spiking Neural Networks Using Time-To-First-Spike Encoding",
      "abstract": "Hardware-based Spiking Neural Networks (SNNs) are regarded as promising candidates for the cognitive computing system due to its low power consumption and highly parallel operation. In this paper, we train the SNN in which the firing time carries information using temporal backpropagation. The temporally encoded SNN with 512 hidden neurons achieved an accuracy of 96.90% for the MNIST test set. Furthermore, the effect of the device variation on the accuracy in temporally encoded SNN is investigated and compared with that of the rate-encoded network. In a hardware configuration of our SNN, NOR-type analog memory having an asymmetric floating gate is used as a synaptic device. In addition, we propose a neuron circuit including a refractory period generator for temporally encoded SNN. The performance of the 2-layer neural network composed of synapses and proposed neurons is evaluated through circuit simulation using SPICE based on the BSIM3v3 model with \n 0.35 μm \n technology. The network with 128 hidden neurons achieved an accuracy of 94.9%, a 0.1% reduction compared to that of the system simulation of the MNIST dataset. Finally, each block’s latency and power consumption constituting the temporal network is analyzed and compared with those of the rate-encoded network depending on the total time step. Assuming that the network has 256 total time steps, the temporal network consumes 15.12 times less power than the rate-encoded network and makes decisions 5.68 times faster.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "518",
      "title": "A Simple Structure Constrained Attitude Control for Rigid Bodies: A PD-Type Control",
      "abstract": "This study investigates the challenging and complicated issue of full-state constraint attitude control for rigid bodies under actuators physical limitation. Using the concept of prescribed performance control (PPC), a novel proportional-derivative (PD)-type control is introduced by which both the attitude quaternion and the rotation velocity of the rigid body are enforced to possess specific behaviors in transient and steady state. To this end, a prescribed performance function (PPF) with finite-time convergence is first defined as the predefined boundaries for the quaternion and rotation velocity. Subsequently, a constrained PD-type attitude control for rigid body attitude system is developed. The significant difference between the proposed methodology and the PPC is the simple structure of the controller making it more applicable from practical implementation point of view. Indeed, due to the use of error transformation in the PPC, the controller contains partial derivative terms and complicated functions even for only constraining the attitude quaternion. When it comes to angular velocity constraint as well, the complexity of the control design procedure is doubled. It is rigorously proved that the suggested control framework can successfully satisfy constraints not only on the quaternion but also on the angular velocity, simultaneously. These interesting results are obtained even when the actuator saturation is considered. The simulation results conducted on a rigid spacecraft verify the efficacy and applicability of the suggested constrained attitude control approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "519",
      "title": "Efficient AoA-Based Rigid Body Localization via Single Base Station for Internet of Things Applications",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "520",
      "title": "Mobile Edge Computing Based Task Offloading and Resource Allocation in 5G Ultra-Dense Networks",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "521",
      "title": "Performance-Issues-Mitigation-Techniques for On-Chip-Antennas – Recent Developments in RF, MM-Wave, and Thz Bands With Future Directions",
      "abstract": "The need for a compact, economical, and low-power wireless system has given birth to the System-on-Chip (SoC) concept viable of a multitude of innovative applications. On-Chip-Antennas (AoCs) are an integral part of the SoC based wireless system and have got a remarkable attention since last one decade. In contrary to off-chip-antennas, AoCs are fabricated and integrated on the same substrate where the other components of the wireless system are fabricated. This integration results in several challenges besides highly desired benefits. The most serious challenge is the degradation in AoC's key performance metrics, i.e. gain and radiation efficiency because of low-resistivity and high-permittivity of the Silicon substrate which is the optimized choice for the AoC design. This triggers a need for the use of novel methods for the mitigation of these performance issues. Consequently, a variety of such innovative methods have been proposed in the literature. However, a critical description on the recent developments in these methods at one place to facilitate a wide range of researchers is missing. Therefore, this article presents a well-organized and systematic survey on the recent advancements of the AoC's performance-issues-mitigation-methods for wireless applications in Radio Frequency (RF), Millimeter-Wave (MM-Wave), and Terahertz (THz) bands for the first time. A concise description of future directions with respect to AoCs performance enhancement methods is also part of this article. It is anticipated that the critical presentation of these methods will make this article a valuable guide for a wide spectrum of researchers, who want to adventure with the tough task of high performance AoC design. In addition, it is envisioned that this article will pave a promising path for a further dominance of the AoCs in RF, MM-Wave, and THz regions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "522",
      "title": "New q-Rung Orthopair Hesitant Fuzzy Decision Making Based on Linear Programming and TOPSIS",
      "abstract": "A new multiple attribute decision making method based on the q-rung orthopair hesitant fuzzy sets has been developed. The evaluation values are given as q-rung orthopair hesitant fuzzy values. Then some weighted similarity functions are defined. A linear programming model is proposed to derive attribute weights based on the similarity functions for the case of partly known attribute weight information and a formula is given to determine attribute weight based on similarity function and the Lagrange function for completely unknown attribute weights. Finally, TOPSIS method is used to rank alternatives. The application of the proposed approach is explored by the application of purchase self-service book sterilizer problem. Some comparisons are also conducted to demonstrate advantages of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "523",
      "title": "Joint Framework for Image Fusion and Super-Resolution via Multicomponent Analysis and Residual Compensation",
      "abstract": "To solve the problems in two-step processing of image fusion and Super-Resolution Reconstruction (SRR), we propose a joint framework of image Fusion and Super-Resolution (FSR) based on multicomponent analysis and residual compensation. Inspired by the idea of multicomponent analysis, we design a new structure-texture decomposition model to realize multicomponent dictionary learning for the above task. To depict the relationship between low-resolution image and its corresponding high-resolution image, the correlation of their sparse coding coefficients is introduced in the model. To compensate the information loss during the SRR, we propose a reconstruction residue compensation mechanism, in which the reconstruction residual error is compensated into the initial result of FSR to improve the quality of the final processing result. In addition, we propose different fusion algorithms for structure and texture components. For structure components, the fusion rule with the maximum absolute value is adopted, and for texture components, we design a new saliency measure to construct fusion results. Experiment results show that the proposed method can well retain the brightness and detail information in the original image, and is superior to other methods in subjective and objective evaluation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "524",
      "title": "Large-Scale Text Classification Using Scope-Based Convolutional Neural Network: A Deep Learning Approach",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "525",
      "title": "In-FPGA Instrumentation Framework for OpenCL-Based Designs",
      "abstract": "The productivity achieved when developing applications on high-performance reconfigurable heterogeneous computing (HPRHC) systems is increased by using the Open Computing Language (OpenCL). However, the hardware produced by OpenCL compilers in field-programmable gate arrays (FPGAs) can result in severe performance bottlenecks that are challenging to solve. The problem is compounded by the fact that the generated netlist details are disorganized, making them mostly unreadable and only partially visible to designers. This paper proposes an in-FPGA instrumentation method and a new framework for extracting the FPGA-cycle-accurate timing performances of OpenCL-based designs. The results clearly show that the chosen execution model for OpenCL-based designs strongly affects the timing performance when it is not properly implemented. Our framework is implemented on an HPRHC platform that contains a CPU and two Arria10 FPGAs, and it is evaluated with a wide variety of benchmarks with different complexities. After testing on the reported benchmarks, the average logic overhead for one inserted instrument is 0.2 % of the total amount of adaptive look-up tables (ALUTs) and 0.1 % of the total registers in an FPGA. This resource utilization is between 1.5 and six times lower than those reported in the best previously published works. The scalability of the framework is also evaluated by inserting up to 50 instruments. The experimental results show that the average logic utilization per instrument is 0.19 % of the ALUTs and 0.17 % of the registers in the FPGA when 50 instruments are inserted.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "526",
      "title": "Aerodynamic Characteristics of a Hex-Rotor MAV With Three Coaxial Rotors in Hover",
      "abstract": "In order to study the aerodynamic characteristics of a Hex-rotor micro aerial vehicle (MAV) with different rotor spacing, both experiments and numerical simulations are performed in this paper. First of all, a series of aerodynamic parameters to characterize the hover performance of the Hex-rotor MAV are analyzed theoretically. Secondly, tests on the Hex-rotor MAV with different rotor spacing ratios (i=0.5 , 0.56, 0.63, 0.71, 0.83, 1.00) is presented in detail. The thrust and power of the Hex-rotor MAV are obtained from the self-designed test platform. In the meanwhile, pressure and velocity distribution of the Hex-rotor MAV are obtained by Computational Fluid Dynamics (CFD) simulation. The results show that the aerodynamic performance of the Hex-rotor MAV is varied with the rotor spacing. Specifically, the rotor interference is inclined to improve the aerodynamic performance of the Hex-rotor MAV with the proper rotor spacing. Owing to the increase of rotor spacing, the interactions between rotors are weakening gradually. In addition, the uniformity of velocity distribution, the stability of downwash distribution and the integrity of vortex are the necessary conditions for a larger thrust of the Hex-rotor MAV. Finally, combined with the test and simulation results, it is also found that there is larger thrust characterized with better aerodynamic performance at i=0.63 , which is assumed as the best rotor arrangement of the Hex-rotor MAV. Especially for Re =1.16 × 10\n5\n, the thrust increases by 6.09%, and the hover efficiency increases by about 9.17% in general.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "527",
      "title": "Dual-Band Direct Conversion Receiver With Additive Mixing Architecture",
      "abstract": "A dual-band direct conversion receiver based on additive mixing architecture for low-cost and multi-mode wireless communication systems is proposed. The proposed receiver consists of two active four-port junctions for additive mixing and one-stage dual-band polyphase filter for quadrature LO signal generation. Each four-port junction is fabricated with \n 0.18 μm \n CMOS technology and configured by an active balun, two buffer amplifiers, two active combiners and two power detectors. The proposed polyphase filter is implemented using type-I architecture adopting one-stage and R-LC resonance type for low power and dual-band operation. The phase and amplitude calibration schemes are also integrated to effectively correct I/Q mismatch within the proposed architecture. The calibration ranges for the phase and amplitude mismatches show 8° and 14 dB, respectively. The validity of the proposed receiver based on additive mixing method is successfully demonstrated by demodulating 16-QAM signals with 40 Mbps at the dual band of 900 MHz and 2.4 GHz.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "528",
      "title": "Quadrature Index Modulation With Three-Dimension Constellation",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "529",
      "title": "Privacy-Protection Path Finding Supporting the Ranked Order on Encrypted Graph in Big Data Environment",
      "abstract": "Since data outsourcing in big data environment become popular and become a trend, large quantities of graph data are outsourced to the big data server for saving cost. As the big data server can not be fully reliable, people usually encrypt the graph data before they are outsourced to the big data platform for the privacy protection. The path finding is a frequently-used action and can be useful for production and living. The path finding supporting the ranked order is a more useful operation, and a user can obtain a ranked search result set. Because of the outsourced graph data being encrypted on the big data server, the path finding supporting the ranked order becomes a task with enough challenge. In this paper, we propose a solution to perform privacy-protection path finding supporting the ranked order on encrypted graph in big data environment (PPFR). Our research uses an encryption mechanism and a ranking strategy to achieve path finding supporting the ranked order. We formally analyze the security of our scheme. We demonstrate the efficiency of our proposed scheme on a real graph data set by experiment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "530",
      "title": "PD-Like H∞ Control for Large-Scale Stochastic Nonlinear Systems Under Denial-of-Service Attacks",
      "abstract": "This paper focuses on the observer-based H\n∞\n control issue for large-scale systems under denial-of-service attacks. Due to the security vulnerability of communication networks, adversaries have the capability to hamper the system normal operation by blocking the signal exchange in both sensor-to-observer channels and the observer-to-observer channels. Under this scenario, a decentralized proportional-derivative-like controller is employed to realize the predetermined H\n∞\n performance while considering the improvement of dynamic response of closed-loop systems. By using the Lyapunov stability theory, a sufficient condition dependent on the attack occurring probability is established to realize the desired control performance. Furthermore, in light of the established condition, the desired controller and observer gains are formalized by resorting to the orthogonal decomposition of control matrix. Finally, the effectiveness and practicability of the control scheme are illustrated by resorting to the numerical simulation of a four area power system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "531",
      "title": "Promotion Pathways of Financial Performance: A Configuration Analysis of Corporate Social Responsibility Based on a Fuzzy Set Qualitative Comparative Analysis Approach",
      "abstract": "To explore the mechanism of multiple conjunctural causation underlying differences in financial performance, this study selects 39 Chinese companies from the Fortune Global 500 as samples and applies configurational thinking and the qualitative comparative analysis (QCA) approach to integrate five variable conditions concerning corporate social responsibility (CSR). The results show that 3 path configurations achieve high financial performance. Specifically, the first configuration includes highly responsible governance, superior employee rights and interests, and effective environmental protection. The second configuration includes highly responsible governance, superior employee rights, and active public charity. The third configuration includes highly responsible governance, active public charity, and effective environmental protection. The four dimensions involved in the above three path configurations have alternative effects in interpreting financial performance. When the level of responsible governance ability is high, as long as any two conditions among employee rights and interests, environmental protection and public charity also attain a high level, this situation can drive the corporation to achieve high financial performance. Based on the conclusions of this paper, management implications from the perspectives of firms are also proposed.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "532",
      "title": "An End-to-End Stochastic Action and Visual Estimation System Towards Autonomous Teleoperation",
      "abstract": "Teleoperation systems have been getting significant attention from many application areas for decades. However, classical teleoperation systems suffer from problems such as lack of natural feedback, latency, and inefficient operator throughput. Researchers attempted to address these issues by performing some of the teleoperation sub-tasks autonomously whenever requested by the operator. Nevertheless, these systems still need the operator to see the need for autonomous actions and initiate these actions manually, which is demanding for the operators. This paper proposes a novel end-to-end Stochastic Assistive Teleoperation System (SATS) that always stays in the loop, automatically detects applicable actions with probabilities, and produces visual scene estimations for each of these actions, which results in increased operator efficiency and throughput. We introduce several methods that combine ideas from Markov processes and recurrent neural networks to stochastically predict future action sequences and scene configurations with tractable algorithms. Experiments performed with a group of operators on real and simulative teleoperation environments show that operators issue a considerably smaller number of commands compared to alternative methods. We also showed that the operators can manipulate multiple robots simultaneously using our technique, which boosts the operator throughput even further. We provide supplementary video material that demonstrates SATS in action.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "533",
      "title": "A Google Glass Based Real-Time Scene Analysis for the Visually Impaired",
      "abstract": "Blind and Visually Impaired People (BVIP) are likely to experience difficulties with tasks that involve scene recognition. Wearable technology has played a significant role in researching and evaluating systems developed for and with the BVIP community. This paper presents a system based on Google Glass designed to assist BVIP with scene recognition tasks, thereby using it as a visual assistant. The camera embedded in the smart glasses is used to capture the image of the surroundings, which is analyzed using the Custom Vision Application Programming Interface (Vision API) from Azure Cognitive Services by Microsoft. The output of the Vision API is converted to speech, which is heard by the BVIP user wearing the Google Glass. A dataset of 5000 newly annotated images is created to improve the performance of the scene description task in Indian scenarios. The Vision API is trained and tested on this dataset, increasing the mean Average Precision (mAP) score from 63% to 84%, with an IoU > 0.5. The overall response time of the proposed application was measured to be less than 1 second, thereby providing accurate results in real-time. A Likert scale analysis was performed with the help of the BVIP teachers and students at the “Roman & Catherine Lobo School for the Visually Impaired” at Mangalore, Karnataka, India. From their response, it can be concluded that the application helps the BVIP better recognize their surrounding environment in real-time, proving the device effective as a potential assistant for the BVIP.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "534",
      "title": "A Novel HF Broadband Frequency-Reconfigurable Whip Antenna With Radiation Blades Loading",
      "abstract": "Aiming at the problems of low gain, low efficiency in low frequency band and warping pattern in high frequency band of the existing HF broadband whip antenna, this paper introduces frequency reconfigurable antenna technology and radiation blades loading technology to redesign whip structure, loading and matching network in different bands, and designs a kind of frequency-reconfigurable whip antenna with improved gain and efficiency. The whip body structure, loading and matching network structure of the antenna in each band are optimized, and the on-off control is carried out through the radio frequency switch according to the actual needs. The results show that the standing wave ratio of the proposed antenna is all less than 3, the average value is 2.32; the gain is all greater than -2dB, the average value is 3.63dB; the total efficiency is all over 20%, the average value is 72.77%, and the pattern keeps horizontal omnidirectional in the whole short wave band without upward warping phenomenon.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "535",
      "title": "A Robust License Plate Recognition Model Based on Bi-LSTM",
      "abstract": "License plate detection and recognition are still important and challenging tasks in natural scenes. At present, most methods have favorable effect on license plate recognition under restrictive conditions, and most of such license plates are shot under good angle and light conditions. However, for license plates under non-restrictive conditions, such as dark, bright, rotated conditions etc. from the Chinese City Parking Dataset (CCPD), the performance of some methods of license plate recognition will be significantly reduced. In order to improve the accuracy of license plate recognition under unrestricted conditions, a robust license plate recognition model is proposed in this paper, which mainly includes license plate feature extraction, license plate character localization, and feature extraction of characters. First of all, the model can activate the regional features of characters and fully extract the character features of license plates. Then locate each license plate character through Bi-LSTM combined with the context location information of license plates. Finally, 1D-Attention is adopted to enhance useful character features after Bi-LSTM positioning, and reduce useless character features to realize effective acquisition of character features of license plates. A large number of experimental results demonstrate that the proposed algorithm has good performance under unrestricted conditions, which proves the effectiveness and robustness of the model. In CCPD-Base, CCPD-DB, CCPD-FN, CCPD-Tilt, CCPD-Weather, CCPD-Challenge and other sub-datasets, the recognition rates reach 99.3%, 98.5%, 98.6%, 96.4%, 99.3% and 86.6% respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "536",
      "title": "SCA-Net: A Spatial and Channel Attention Network for Medical Image Segmentation",
      "abstract": "Automatic medical image segmentation is a critical tool for medical image analysis and disease treatment. In recent years, convolutional neural networks (CNNs) have played an important role in this field, and U-Net is one of the most famous fully convolutional network architectures among many kinds of CNNs for medical segmentation tasks. However, the CNNs based on U-Net used for medical image segmentation rely only on simple concatenation operation of multiscale features. The spatial and channel context information is easily missed. To capture the spatial and channel context information and improve the segmentation performance, in this paper, a spatial and channel attention network (SCA-Net) is proposed. SCA-Net presents two novel blocks: a spatial attention block and a channel attention block. The spatial attention block (SAB) combines the multiscale information from high-level and low-level stages to learn more representative spatial features, and the channel attention block (CAB) redistributes the channel feature responses to strengthen the most critical channel information while restraining the irrelevant channels. Compared with other state-of-the-art networks, our proposed framework obtained better segmentation performance in each of the three public datasets. The average Dice score improved from 88.79% to 92.92% for skin lesion segmentation, 94.02% to 98.25% for thyroid gland segmentation and 87.98% to 91.37% for pancreas segmentation compared with U-Net. Additionally, the Bland–Altman analysis showed that our network had better agreement between automatic and manually calculated areas in each task.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "537",
      "title": "Optimal Strong Solution of the Minimax Problem With Two-Sided Fuzzy Relation Inequality Constraints",
      "abstract": "To avoid unoccupied base stations, we introduce the concept of a strong solution to max-product fuzzy relation inequalities in this paper. Such a strong solution enables all base stations take part in wireless communication activities. The structure of the set of all strong solutions is discussed. The strong solution set is composed of a finite number of closed intervals. To decrease the damage caused by electromagnetic radiation, one always aims to find an optimal strong solution, in which each component reaches its minimum value. However, this is generally impossible. Hence, finding an optimal strong solution with a specific objective function is more feasible. In this work, we investigate the optimization, minimizing the largest component of a strong solution. A detailed algorithm is developed to find an optimal strong solution. The experimental results show that our proposed algorithm is efficient. In addition, we further discuss the structure of the complete optimal strong solution set.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "538",
      "title": "Mobile Apps Meet the Smart Energy Grid: A Survey on Consumer Engagement and Machine Learning Applications",
      "abstract": "Consumers lie at the epicenter of smart grids, since their activities account for a large portion of the total energy demand. Therefore, utility companies, governmental agencies, and various other entities with environmental concerns aim at lowering and shaping energy consumption patterns to achieve peak load reduction, load smoothing, and hence carbon emission curtailment. In this survey paper, we present an overview of approaches for engaging smart grid consumers and for providing them with information, motivation, and recommendations for energy efficiency through mobile apps. Our focus is to bring machine learning approaches closer to smart grid mobile apps so as to optimally manage consumer flexibility and enhance energy savings through detailed consumer profiling and modeling, since an increasing amount of energy consumer data is becoming available. A novel survey and analysis of prior work in the area is conducted in order to identify gaps from this perspective. We consider both recent research project outputs and commercial products and we discuss various aspects of the designs, such as state-of-the-art technologies, extrinsic and intrinsic motivation techniques, gamification, consumer profiling, and the role of machine learning and recommender systems in this context. Furthermore, different mobile apps are presented and compared based on the most important features that affect consumer energy efficiency and sustainability, such as data visualization, gamification, flexibility, consumer profiling methods, feedback mechanisms, recommendations, social media, and machine learning integration. The main goal of this work is to identify how mobile apps incorporate these features to engage energy consumers in energy-efficient behavior, assess the current state-of-the-art in the area, and highlight future research directions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "539",
      "title": "Nowhere to Hide Methodology: Application of Clustering Fault Diagnosis in the Nuclear Power Industry",
      "abstract": "When a system crashes, fast and accurate log-based fault diagnosis can remarkably reduce the recovery time of the system and avoid further economic losses. Especially for the nuclear power industry, recovery time will lead not only to economic losses but also to international repercussions. Nevertheless, the massive quantity of obscure log information and the existence of hidden nodes pose major challenges to fault diagnosis and root cause determination. To overcome these obstacles, we propose the nowhere to hide (NTH) methodology, an efficient method to diagnose faults and locate root causes. We implement log-node and node-log mapping to avoid vital data loss in collecting fault logs and hidden nodes; furthermore, we utilize the logic of the nuclear power unit process system to reveal the crucial information in fault logs and hidden nodes and their causality to determine the root cause. We evaluate the methodology in a real nuclear industrial environment. The results show that system administrators can efficiently determine the root cause with the proposed methodology. Finally, we discuss the enhancements that are underway to improve the methodology.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "540",
      "title": "Cavity-Backed Patch Filtenna for Harmonic Suppression",
      "abstract": "A co-design consisting of a filtering antenna integrating a cavity-backed patch antenna and a low-pass coaxial filter is proposed for size reduction of the RF front-end. The cavity-backed patch antenna is developed to exhibit a broad impedance bandwidth and a unidirectional radiation pattern. The low-pass coaxial filter is implemented to suppress harmonic resonances and gain in the stop-band of the antenna and is embedded directly inside the antenna cavity to realize a compact small-footprint co-designed filtering antenna structure. Two prototypes of the proposed filtering antennas, which integrate cavity-backed patch antennas with 4\nth\n and 5\nth\n order low-pass coaxial filters and with the overall dimensions of 0.697λ\n0\n × 0.585λ\n0\n × 0.236λ\n0\n and 0.697λ\n0\n × 0.585λ\n0\n × 0.320λ\n0\n (where λ\n0\n is the free space wavelength at 3.15 GHz), respectively, are fabricated and measured. The experimental results show fractional bandwidths of 25% and 23.8% and gain suppression levels exceeding 11 dB and 22 dB in the stop-bands for the filtering antennas with the 4\nth\n and 5\nth\n order filters, respectively. The measured gain is more than 6.5 dBi in the pass-band for both filtering antennas. In addition, excellent agreement is obtained between the simulated and measured results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "541",
      "title": "Challenges in Building an End-to-End System for Acquisition, Management, and Integration of Diverse Data From Sensor Networks in Watersheds: Lessons From a Mountainous Community Observatory in East River, Colorado",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "542",
      "title": "MRC4: A Modified RC4 Algorithm Using Symmetric Random Function Generator for Improved Cryptographic Features",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "543",
      "title": "Bearing Fault Detection in ASD-Powered Induction Machine Using MODWT and Image Edge Detection",
      "abstract": "Today the industry depends on various types of three-phase induction machines, requiring operating at variable speeds to perform more complex processes. Therefore, it is vital to monitor their operation conditions to maintain the optimal efficiency of the processes they perform and avoid significant economic losses. The proposed work presents the design and development of a method for bearing damage detection based on Maximal Overlap Discrete Wavelet Transform and image processing for edge detection. Accuracies achieved with three types of damage exceed 90%. The signals for the test are acquired from seven different operating conditions for each type of damage. Supply comes from a power grid source and an adjustable speed drive. The Maximal Overlap Discrete Wavelet Transform is applied with different filtering levels to the three phases of the stator current, the magnitude of the filtered signals is acquired, a periodic two-dimensional array is generated and further smoothed by a Gaussian filter allowing the observation of patterns at the edges. Finally, the obtained images are scanned with a 2-D mask aiming to detect and count patterns associated to the fault detection process. Statistical analysis is performed over characteristic signatures obtained from the current magnitude of the three phases at different classes of damage and several mechanical load conditions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "544",
      "title": "Misclassification Bias in Computational Social Science: A Simulation Approach for Assessing the Impact of Classification Errors on Social Indicators Research",
      "abstract": "A growing body of literature has examined the potential of machine learning algorithms in constructing social indicators based on the automatic classification of digital traces. However, as long as the classification algorithms’ predictions are not completely error-free, the estimate of the relative occurrence of a particular class may be affected by misclassification bias, thereby affecting the value of the calculated social indicator. Although a significant amount of studies have investigated misclassification bias correction techniques, they commonly rely on a set of assumptions that are likely to be violated in practice, which calls into question the effectiveness of these methods. Thus, there is a knowledge gap with respect to the assessment of misclassification bias’s impact on a specific social indicator formula without strict reference to the number of classes. Moreover, given the erroneous nature of automatic classification algorithms, the quality of a predicted indicator can be assessed not only using regression quality metrics, as was done in existing literature, but also using correlation metrics. In this paper, we propose a simulation approach for assessing the impact of misclassification bias on the calculated social indicators in terms of regression and correlation metrics. The proposed approach focuses on indicators calculated based on the distribution of classes and can process any number of classes. The proposed approach allows selecting the most appropriate classification model for a particular social indicator, and vice versa. Moreover, it allows for assessment of the optimistic level of correlation between the indicator calculated based on the results of the classification algorithm and the true underlying indicator.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "545",
      "title": "Research on Motion Mode Switching Method Based on CPG Network Reconstruction",
      "abstract": "Traditional underwater robots have many shortcomings in terms of resistance to sea currents, stability and functionality. In order to improve the efficiency and quality of underwater operations, this paper proposes and designs a new underwater robot, the navigation and crawl underwater unmanned vehicle (NCUUV), it has two motion modes: swimming and crawling. In order to enable the robot to have the ability to switch motion modes, this paper designed a motion mode switching mechanism, and verified the effectiveness of the mechanism through experiments, which proved that the mechanism has good motion reliability and accuracy. In order to control NCUUV to smoothly switch the motion mode, a controller based on the central pattern generator (CPG) was developed. The upper controller reconstructs the CPG network in the middle controller according to the feedback information of the acoustic rangefinder. The CPG network in the middle controller has two configurations: a triangular fully symmetrical network and a hexagonal fully symmetrical network, and the CPG network can be freely changed between the two configurations according to the instructions of the upper controller. These two configurations control NCUUV's swimming and crawling respectively, so as to realize the smooth switching between swimming and crawling. The experimental result shows that this control mechanism of motion mode switching can enable NCUUV to stably realize motion mode switching and the switching process is smooth and reliable.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "546",
      "title": "An Ultralight High-Directivity Ceramic Composite Lens Antenna for 220–330 GHz",
      "abstract": "This work presents the characterization of Lithium molybdenum oxide (Li\n2\nMoO\n4\n, LMO) hollow glass microspheres (HGMS) ceramic composite from 0.1 to 1 THz and an associated bullet shaped lens used with WR3.4 for 220-330 GHz band. LMO-HGMS had permittivity of 1.18 and loss tangent of 0.003 at 300 GHz. The calculated reflectivity for the LMO-HGMS-air interface was 0.2 %. The fabricated bullet lens weighed 5 grams and was characterized using an experimental measurement system. The lens was measured to have a focus spot of diameter 1.5 mm. Simulated results showed the lens to operate with a WR3.4 waveguide having a gain of 27.5 dBi with a narrow beam width of 1-degree, 18 dB sidelobe level (SLL), 40% Fractional Beam Width (FBW), and −13 dB S\n11\n over the broadband 220-330 GHz.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "547",
      "title": "A Single-Layer Broadband Reflectarray in K-Band Using Cross-Loop Slotted Patch Elements",
      "abstract": "A broadband linearly polarized reflectarray antenna is designed by modifying a typically narrowband square patch unit element with cross-loop slot (CLS). Due to the introduction of the CLS, the unit patch element becomes multi-resonant and miniaturized. Besides, the outer length and width of the CLS are one-to-one related to the length of the patch. As a result, more than 480° phase range with quite good linearity is achieved. In addition, the phase ranges are almost parallel to each other from 22.5–26.5 GHz, which signifies its broadband property. Using such \n 36×36 \n CLS patches in a square aperture of 180 mm \n ×180 \n mm size, an offset-fed reflectarray is constructed for an off-broadside radiation pattern. A prototype has been fabricated to experimentally validate the numerical results obtained using CST full-wave simulations. The measurement results exhibit a broad 1-dB gain bandwidth of 17.6% (22.44–26.78 GHz) and a peak gain of 32.2 dBi with an aperture efficiency of 60.6%. Moreover, both the cross-pol and side-lobe levels (SLLs) remain more than 40 dB and 21 dB, respectively, below the peak co-pol level throughout the 1-dB gain bandwidth. The proposed reflectarray can be used as a CubeSat antenna for K-band inter-satellite links (ISL).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "548",
      "title": "Iterative Electrical–Thermal Coupled Simulation Method of Automotive Power Module Used in Electric Power Steering System",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "549",
      "title": "An Unsupervised Hyperspectral Band Selection Method Based on Shared Nearest Neighbor and Correlation Analysis",
      "abstract": "Band selection is an important dimensionality reduction (DR) methodology for hyperspectral images (HSI). In recent years, many ranking-based clustering band selection methods have been developed. However, these methods do not consider the combination of bands in different clusters but only select the desired number of clustering centers based on band ranking to construct the reduced band subset, which may lead to obtaining a set of bands with low redundancy but little information or a set of bands with a large amount of information but high redundancy, thus falling into the local optimal solution set. To solve this problem, an unsupervised hyperspectral band selection method based on shared nearest neighbor and correlation analysis (SNNCA) is proposed in this paper. The proposed SNNCA method considers the interaction of bands in different clusters, and can obtain a set of bands with a large amount of information and low redundancy. First, this method uses the shared nearest neighbor to describe the local density of each band and takes the product of local density and distance factor as the weight to rank each band to select the required number of clustering centers, which ensures low redundancy among the clustering centers. Then, all bands are grouped into several clusters based on the Euclidean distance matrix and the clustering centers. Finally, the correlation among intra-cluster and inter-cluster bands and the information entropy are further analyzed, and the most representative band is selected from each cluster. The experimental results on two HSI datasets demonstrate that the proposed SNNCA method achieves better classification performance than that of other state-of-the-art comparison methods and possesses competitive running time.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "550",
      "title": "Human Heart-Related Indexes Behavior Study for Aircraft Pilots Allowable Workload Level Assessment",
      "abstract": "This study aimed to evaluate workload by detecting Heart Rate Variability (HRV) indexes in a sample of 34 pilots (with a mean age of 33 years) while performing simulated flight exercises. A one-way ANOVA with repeated measures was performed to assess the changes of the physiological measures in five standard maneuvers associated with different workload levels. The results show that all the indexes, but the Low Frequency to High Frequency ratio index (LF/HF), have a well-defined trend between the baseline and the en-route phase and with the three phases takeoff, steady turn, and landing. This study, as main findings, provides evidence of a differentiation among low, medium, and high workload levels using the time, frequencies, and non-linear HRV domains of analysis. These findings support the relevance of HRV indexes for workload evaluation, suggesting the development of non-invasive instruments capable of assessing workload in real-time. Further studies may be conducted to investigate whether the same findings could also be applied to more challenging maneuvers in real working conditions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "551",
      "title": "FAMN: Feature Aggregation Multipath Network for Small Traffic Sign Detection",
      "abstract": "Traffic sign detection has achieved promising results in recent years. Nevertheless, there are still two problems remain to be overcome. One problem is the detection of small traffic signs, which usually occupy less than 2% of the image area. The other problem is fine-grained classification, with difficulties arising from similar appearances between traffic signs. For example, different speed-limit traffic signs have differences solely from the speed numbers. In this paper, we propose a Feature Aggregation MultiPath Network (FAMN) to tackle the problems simultaneously. First, we propose a Feature Aggregation (FA) structure to aggregate regional features from different feature maps by using element-wise Max, then convolution layers are used to extract rich semantic features. Accordingly, objects of different scales can choose the best features to improve performance of small object detection. Second, we propose a Multipath Network (MN) structure to obtain fine-grained features. The MN structure consists of three paths, extracting instance-level, part-level, and context-level features, respectively. The three types of features are then concatenated to form fine-grained features of the proposals. Experimental results demonstrate the effectiveness of our proposed FAMN. Specifically, FAMN is able to obtain an average F1-measure of 93.1% in TT100K dataset, 2.9% higher than the state-of-the-art.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "552",
      "title": "Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap",
      "abstract": "Methodologies that utilize Deep Learning offer great potential for applications that automatically attempt to generate captions or descriptions about images and video frames. Image and video captioning are considered to be intellectually challenging problems in imaging science. The application domains include automatic caption (or description) generation for images and videos for people who suffer from various degrees of visual impairment; the automatic creation of metadata for images and videos (indexing) for use by search engines; general-purpose robot vision systems; and many others. Each of these application domains can positively and significantly impact many other task-specific applications. This article is not meant to be a comprehensive review of image captioning; rather, it is a concise review of both image captioning and video captioning methodologies based on deep learning. This study treats both image and video captioning by emphasizing the algorithmic overlap between the two.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "553",
      "title": "Degradation Observations of Protective Coatings: An Improved Version of Coating Impedance Detector",
      "abstract": "This study proposes coating impedance detector 3.0 (CID 3.0), an improved version of our previously developed CID 2.0. The new circuit design in CID 3.0 has lower power consumption because it has fewer components, and it affords better accuracy through the modification of the analog part of CID 2.0 and the use of oversampling. This approach successfully afforded CID 3.0 with higher measurement stability for evaluating a high-performance coating with impedance values exceeding \n 109 Ω \n. Furthermore, CID 3.0 could detect impedance decreases associated with coating delamination when the coating suffers an attack.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "554",
      "title": "Reviewer Recommendations Using Document Vector Embeddings and a Publisher Database: Implementation and Evaluation",
      "abstract": "We develop and evaluate an automated data-driven framework for providing reviewer recommendations for submitted manuscripts. Given inputs comprising a set of manuscripts for review and a listing of a pool of prospective reviewers, our system uses a publisher database to extract papers authored by the reviewers from which a \nParagraph Vector\n (\ndoc2vec\n) neural network model is learned and used to obtain vector space embeddings of documents. Similarities between embeddings of an individual reviewer’s papers and a manuscript are then used to compute manuscript-reviewer match scores and to generate a ranked list of recommended reviewers for each manuscript. Our mainline proposed system uses full text versions of the reviewers’ papers, which we demonstrate performs significantly better than models developed based on abstracts alone, which has been the predominant paradigm in prior work. Direct retrieval of reviewer’s manuscripts from a publisher database reduces reviewer burden, ensures up-to-date data, and eliminates the potential for misuse through data manipulation. We also propose a useful evaluation methodology that addresses hyperparameter selection and enables indirect comparisons with alternative approaches and on prior datasets. Finally, the work also contributes a large scale retrospective reviewer matching dataset and evaluation that we hope will be useful for further research in this field. Our system is quite effective; for the mainline approach, expert judges rated 38% of the recommendations as \nVery Relevant\n; 33% as \nRelevant\n; 24% as \nSlightly Relevant\n; and only 5% as \nIrrelevant\n.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "555",
      "title": "A High-Isolation Building Block Using Stable Current Nulls for 5G Smartphone Applications",
      "abstract": "In this paper, a new design method to enhance the isolation of a two-antenna building block is introduced. Here, a two-antenna building block (Ant 1 and Ant 2) that is composed of a gap-coupled loop antenna (Ant 1) and a loop antenna (Ant 2) is meticulously designed to allow Ant 1 to excite a standing-wave region that can be formed on the structure of Ant 2. To exhibit high isolation (26 dB) between the two antennas, the stable current null point existed in the standing wave region is exploited and designed to fall at the feed point of Ant 2 during the excitation of Ant 1. By employing this proposed building block, a four-port multiple-input multiple-output (MIMO) system and an eight-port MIMO system operating in the long term evolution (LTE) band 42 (3.4-3.6 GHz) are implemented. The proposed four-antenna and eight-antenna MIMO arrays can yield desirable measured isolation of better than 23 dB and 17.9 dB, respectively, over the band of interest, and their respective measured ECCs (envelope correlation coefficients) were lower than 0.032 and 0.075. To further evaluate the MIMO performances of the presented MIMO arrays, their ergodic channel capacities are also investigated.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "556",
      "title": "Analyzing Response Efficiency to COVID-19 and Underlying Factors of the Outbreak With Deep Assessment Methodology and Fractional Calculus",
      "abstract": "This study focuses on modeling the daily deaths per new case of COVID-19 by using the Fractional Calculus and the Least Squares Method. Based on our prior work, we proposed a new modeling approach, assessed the strength of outbreak response, and analyzed possible underlying factors of the outbreak for 8 countries including China, France, Germany, Italy, Russia, Spain, the UK, and the US. First, we modeled weekly deaths per new case of COVID-19 using our new modeling method Deep Assessment Methodology - Second Derivative (DAM-SD). Later, we defined a performance indicator to understand how well each country copes with the pandemic. Lastly, Pearson correlations between the performance indicator and several economic, social, and environmental indices, such as Human Development Index, Human Freedom, Democracy, Competitiveness, and Trust Index are computed, and \n p \n-values are reported. Results showed that DAM-SD successfully models the daily new cases of COVID-19 with 3.7390% Mean Average Precision Error and outperforms the DAM by 1.5678% MAPE. China is the best-modeled country with 4.0975e-08% MAPE whereas the model produced the highest error rate for France as 8.8317% MAPE. According to the analysis with the performance indicators, China is the most successful country against the pandemic while the United States and France fail to confine COVID-19 outbreak compared to the others. Indicators such as Human Development Index, Human Freedom, Human Democracy, GINI Index, Workers Rights, the Trust Index, and Air Pollution are found significant for COVID-19 response according to the p-values. In the correlation analysis, Average Class Size, Government’s Long Term Vision, Responsiveness to Change, Better Life Index, and Population Density were the least significant indicators. Long Term Care Beds, Social Capital, and Global Social Mobility indicators are found correlated with the COVID-19 response. Household Spending and Student Skills are found insignificant.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "557",
      "title": "Integrated Single Shot Multi-Box Detector and Efficient Pre-Trained Deep Convolutional Neural Network for Partially Occluded Face Recognition System",
      "abstract": "Partial occlusion is a key issue in face recognition as it decreases the recognition accuracy. As a result, current face recognition systems are limited to operate under constrained environments. To resolve the partial occlusion problem, we propose a system that adopts the convolutional neural network but with a pre-trained model for robust face recognition and facial feature extraction. The model improves the accuracy of partially occluded face recognition. Moreover, the face detection network utilizes the feature pyramids to reduce the number of network parameters and achieve scale invariance. The image context module is also incorporated to increase the receptive field, as it effectively improves the detection accuracy and reduces memory usage. Experiment results show that the proposed method performs better than existing state-of-the-art methods for the detection and recognition of occluded faces.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "558",
      "title": "Soft Label With Channel Encoding for Dependent Facial Image Classification",
      "abstract": "In classification tasks, training labels are usually specified as one-hot targets which represent each class equally and exclusively. However, this labeling rule is not suitable in some situations. For the dependent classes, one-hot targets are not capable to represent the relation among them. The existing label smoothing methods just split the target response into neighboring classes, but it is only applied for ordinal classification, but not for the dependent but non-ordered classes. In this paper, we propose a novel labeling rule that decomposes the one-hot target into several bases to reflect relationships among classes while maintaining a balanced target space, which adopts channel encoding from communication systems, in particular, Bose–Chaudhuri–Hocquenghem (BCH) encoding. Besides, BCH encoder has an error-correcting mechanism that is expected to lift the accuracy. In theory, training with BCH targets ensures improved classification performance given the original accuracy is not less than 50%. To verify the proposed method on dependent classification, we conduct experiments with two facial tasks: age recognition and face anti-spoofing. The former is an ordinal classification task, and the latter is also regarded as a specific dependent classification problem due to the varying attack types being classified as one class finally and real for the other. Experimental results show that the proposed method improves accuracy by 6.33% on age recognition and reduces HTER by 3.63% for face anti-spoofing. In addition, as BCH targets divide the original response into a higher dimensional space, that is, the model is made to be heeded on learning the delicate sub-features. Hence, BCH targets also enhance model generalizability, thus guaranteeing improved performance on cross-domain evaluations. We further perform an assessment on the PACS dataset for evaluating domain generalizability. The results show that the domain generalizability is enhanced by increasing average acc...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "559",
      "title": "Directed Model Checking for Fast Abstract Reachability Analysis",
      "abstract": "We propose a novel technique (TOUR) to improve both bug detection ability and verification speed of ARMC by detecting a target path quickly. The key idea of TOUR is an \nerror location directed search\n that utilizes \nthe distance to an error location\n and \nfunction call context\n at runtime. TOUR applies four different distance metrics and a distance metric selection heuristic using static features of a target program. We have extensively evaluated TOUR on 3,042 real-world C programs in a software verification competition benchmark. The experiment results show that TOUR, due to its error location directed search, finds bugs in 20% more programs in 11% less model checking time than the state-of-the-art ARMC technique (i.e., block-abstraction memoization) for 354 buggy programs. Also, TOUR verifies 15% more programs within 15% less model checking time than the block-abstraction memoization for 652 \ncomplex\n clean programs.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "560",
      "title": "Security and Privacy for the Internet of Medical Things Enabled Healthcare Systems: A Survey",
      "abstract": "With the increasing demands on quality healthcare and the raising cost of care, pervasive healthcare is considered as a technological solutions to address the global health issues. In particular, the recent advances in Internet of Things have led to the development of Internet of Medical Things (IoMT). Although such low cost and pervasive sensing devices could potentially transform the current reactive care to preventative care, the security and privacy issues of such sensing system are often overlooked. As the medical devices capture and process very sensitive personal health data, the devices and their associated communications have to be very secured to protect the user's privacy. However, the miniaturized IoMT devices have very limited computation power and fairly limited security schemes can be implemented in such devices. In addition, with the widespread use of IoMT devices, managing and ensuring the security of IoMT systems are very challenging and which are the major issues hindering the adoption of IoMT for clinical applications. In this paper, the security and privacy challenges, requirements, threats, and future research directions in the domain of IoMT are reviewed providing a general overview of the state-of-the-art approaches.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "561",
      "title": "Joint State Estimation Under Attack of Discrete Event Systems",
      "abstract": "The problem of state estimation in the setting of partially-observed discrete event systems subject to cyber attacks is considered. An operator observes a plant through a natural projection that hides the occurrence of certain events. The objective of the operator is that of estimating the current state of the system. The observation is corrupted by an attacker which can tamper with the readings of a set of sensors thus inserting some fake events or erasing some observations. The aim of the attacker is that of altering the state estimation of the operator. An automaton, called joint estimator, is defined to describe the set of all possible attacks. In more details, an unbounded joint estimator is obtained by concurrent composition of two state observers, the attacker observer and the operator observer. The joint estimator shows, for each possible corrupted observation, the joint state estimation, i.e., the set of states consistent with the uncorrupted observation and the set of states consistent with the corrupted observation. Such a structure can be used to establish if an attack function is harmful w.r.t. a misleading relation. Our approach is also extended to the case in which the attacker may insert at most \n n \n events between two consecutive observations.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "562",
      "title": "Fuzzy Distributed Hybrid Flow Shop Scheduling Problem With Heterogeneous Factory and Unrelated Parallel Machine: A Shuffled Frog Leaping Algorithm With Collaboration of Multiple Search Strategies",
      "abstract": "The single factory production is shifting to multi-factory production which brings new challenges. Hybrid flow shop problem (HFSP) as a common problem in production-manufacturing has been studied extensively, however distributed hybrid flow shop problem (DHFSP) has not been paying sufficient attention. Fuzzy distributed hybrid flow shop problem (FDHFSP) is studied and a shuffled frog leaping algorithm with collaboration of multiple search strategies (SFLA-CMSS) is proposed to optimize multiple objectives simultaneously. In SFLA-CMSS, multiple search-mode collaboration strategy in memeplex search consists of multiple search strategies. A search strategy is selected according to the historical search status of the solution. Dynamic memeplex number adjustment strategy is used to provide more search opportunity to the memeplex which has better search capability. Experiments are conducted and the computational results reveal that SFLA-CMSS has promising advantages on FDHFSP.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "563",
      "title": "Unsupervised Segmentation of Fire and Smoke From Infra-Red Videos",
      "abstract": "This paper proposes a vision-based fire and smoke segmentation system which uses spatial, temporal and motion information to extract the desired regions from the video frames. The fusion of information is done using multiple features such as optical flow, divergence and intensity values. These features extracted from the images are used to segment the pixels into different classes in an unsupervised way. A comparative analysis is done by using multiple clustering algorithms for segmentation. Here the Markov Random Field performs more accurately than other segmentation algorithms since it characterizes the spatial interactions of pixels using a finite number of parameters. It builds a probabilistic image model that selects the most likely labeling using the maximum a posteriori (MAP) estimation. This unsupervised approach is tested on various images and achieves a frame-wise fire detection rate of 95.39%. Hence this method can be used for early detection of fire in real-time and it can be incorporated into an indoor or outdoor surveillance system.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "564",
      "title": "Self-Induced Localized Electric-Field-Enhanced Electrostatic Electron Emission in Polypropylene Surface-Based Roll-to-Roll Manufacturing",
      "abstract": "The roll-to-roll (RtR) Manufacturing can produce a large amount of electrostatic charges. In terms of industrial safety, a large amount of energy can be released via electrostatic discharge (ESD) that can cause severe shocks, which can be a risk to automated machines, operators, and merchandise. In this study, the ESD associated with the existing nonwoven Polypropylene (PP) manufacturing is minimized by designing and introducing a sharp-edge metal bar with a radius of curvature of 100 μm as a passive electrostatic charge dissipation system next to the PP winding stock roll. The coulombic force from the deposited charges on PP can induce a highly localized electric field (up to ~10\n6\n V/cm) between the grounded metal edge and the nanoscale surface of the nonwoven PP fabric that reduces the potential barrier, causing electrostatic electron/ion emission or discharge from the insulating PP winding surface to the ambient air, especially along the metal edge. Further, the level of static charge associated with the RtR process is characterized using a noncontact electrostatic field (E-field) meter without contaminating and interrupting the production lines. Furthermore, the three-dimensional finite element method (FEM) is used to obtain an accurate electrostatic charge distribution based on the actual size of the winding stock roll, providing a comprehensive understanding of the self-induced E-field-assisted ESD during operation. The experiment and simulation indicate that 75% of the effective stored charge density is transferred through the air. Therefore, the induced field emission structure is cost effective for dissipating the electrostatic charges and minimizing the ESD hazards.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "565",
      "title": "Physics-Driven Mask R-CNN for Physical Needle Localization in MRI-Guided Percutaneous Interventions",
      "abstract": "Discrepancies between the needle feature position on magnetic resonance imaging (MRI) and the underlying physical needle position could increase localization errors during needle-based targeting procedures in MRI-guided percutaneous interventions. This work aimed to develop a deep learning-based framework to automatically localize the physical needle position using only the needle features on MR images. Physics-based simulations were performed to generate single-slice and 3-slice images with needle features from a range of underlying needle positions and MRI parameters to form datasets for training single-slice and 3-slice Mask Region-Based Convolutional Neural Network (R-CNN) models for physical needle localization. \nEx vivo\n tissue images were combined with simulated needle features for fine-tuning. Next, the physics-driven Mask R-CNN models were combined with a previously developed Mask R-CNN model for needle feature localization to form an automated framework to localize the physical needle. To test the accuracy of the proposed framework, both single-slice and 3-slice MRI data were acquired from needle insertion experiments in \nex vivo\n tissue phantoms. Using the single-slice model, the proposed framework achieved sub-millimeter physical needle localization accuracy on single-slice images aligned with the needle. The fine-tuning step reduced in-plane physical needle tip localization error (mean±standard deviation) to 0.96±0.69 mm in \nex vivo\n tissue data. The 3-slice model further reduced the through-plane physical needle tip localization error to 2.3±1.1 mm in situations where the imaging plane may be misaligned with the needle. The processing time of the framework using both models was 200 ms per frame. The proposed framework can achieve physical needle localization in real time to support MRI-guided interventions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "566",
      "title": "Incremental Attribute Reduction Under Variations of the Attribute Set Based on Conflict Region",
      "abstract": "In real application, the attribute set of decision systems may vary with time. How to efficiently update the reduct becomes one of important tasks in the knowledge discovery. The static methods for updating knowledge need to recalculate when the attribute set varies every time, which makes it potentially very time-consuming to update knowledge, especially if the data sets are growled rapidly. Incremental learning method is an efficient technique for knowledge discovery in the dynamic system. In the dynamic system of the attribute set variations, there exist three kinds of attribute set changes: addition of the attribute set, deletion of the attributes and simultaneous variation of adding and deleting the attribute sets. The objective of this paper is to study the incremental reduction algorithm based on conflict region in the dynamic decision system. For three variations of the attribute set, we firstly introduce incremental mechanisms of updating conflict region; and then we research acceleration strategies for calculating significance measures of candidate attributes and eliminating redundant attributes. Consequently, a unified incremental reduction algorithm based on conflict region is presented for three variations of the attribute set. Finally, we design a series of experiments which are performed on 12 UCI data sets. The experimental results indicate that the proposed incremental methods can effectively to update the reduct with variations of the attribute set, and its efficiency is much better than that of static algorithms.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "567",
      "title": "Lighting-and Personal Characteristic-Aware Markov Random Field Model for Facial Image Relighting System",
      "abstract": "A learning-based image relighting framework is proposed for automatically changing the lighting conditions of facial images from one lighting source to another. Given only a 2D unseen facial testing image, the framework automatically infers the highlight or shadow areas in the relighted image in accordance with the specific facial characteristics of the input image using a learned non-parametric Markov random field model of the facial appearance correlation between the source and target lighting conditions. The proposed framework first decomposes the input image into its global and local components, where these components relate mainly to the lighting and detailed facial appearance characteristics of the image, respectively. The two components are then processed independently to ease the problem of insufficient training samples and to properly analyze the local contrast, overall lighting direction effects, and personal feature characteristics of the unseen subject. Specifically, the global and local components are processed by a lighting–aware classifier and a personal characteristic–aware classifier, respectively, in order to determine the semantic factors of the facial region. The semantic factors of the facial region are then used to update the Markov random field model of the facial appearance correlation between the source and target lighting conditions and to produce lighting enhancement matrices for the lighting components and facial characteristic components, respectively. Finally, the lighting enhancement matrices are applied to the original decomposition images, which are then integrated to obtain the final relighted result. The experimental results show that the proposed image relighting framework generates vivid and recognizable results despite the scarcity of training samples. Furthermore, the relighted results successfully simulate the individual lighting effects produced by the specific personal characteristics of the input image, such as the nose and...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "568",
      "title": "Using HW/SW Codesign for Deep Neural Network Hardware Accelerator Targeting Low-Resources Embedded Processors",
      "abstract": "The usage of RISC-based embedded processors, aimed at low cost and low power, is becoming an increasingly popular ecosystem for both hardware and software development. High performance yet low power embedded processors may be attained via the use of hardware acceleration and Instruction Set Architecture (ISA) extension. Efficient mapping of the computational load onto hardware and software resources is a key challenge for performance improvement while still keeping low power and area. Furthermore, exploring performance at an early stage of the design makes this challenge more difficult. Potential hardware accelerators can be identified and extracted from the high-level source code by graph analysis to enumerate common patterns. A scheduling algorithm is used to select an optimized sub-set of accelerators to meet real-time constraints. This paper proposes an efficient hardware/software codesign partitioning methodology applied to high-level programming language at an early stage of the design. The proposed methodology is based on graph analysis. The applied algorithms are presented by a synchronous directed acyclic graph. A constraint-driven method and unique scheduling algorithm are used for graph partitioning to obtain overall speedup and area requirements. The proposed hardware/software partitioning methodology has been evaluated for MLPerf Tiny benchmark. Experimental results demonstrate a speedup of up to 3 orders of magnitude compared to software-only implementation. For example, the resulting runtime for the KWS (Keyword Spotting) software implementation is reduced from 206 sec to only 181ms using the proposed hardware-acceleration approach.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "569",
      "title": "A Two-Tier Service Filtering Model for Web Service QoS Prediction",
      "abstract": "Service recommendation technology is the key to realize the personalization of intelligent services. The recommended services need to meet functional requirements as well as non-functional requirements. Therefore, QoS-based service recommendation came into being. To perform intelligent service recommendations, matching users with convenient services based on QoS becomes an inevitable task. However, most of the service recommendation models are based on user interaction records to predict and recommend, ignoring the service-user correlation and unstable QoS values. In this article, we propose a new service recommendation model. We have performed two-tier filtering calculation on a large number of Web Services, filtering the contextual information of users and services and the instability of services. In the first filtering layer, we take the instability of QoS as an indicator to eliminate invalid services, which significantly reduces the service scale and eliminates the interference of invalid services on the recommendation to a certain extent. Further, we process the contextual information of both users and services in the second filtering layer. Considering the impact of the correlation between the service and the user, we use the geographic location information of the user and the service, and solve the combined features generated by the similarity between the user and the service to filter. Considering the sparsity of the service recommendation environment and the influence of noise generated by useless features, we use a model of factorization machine combined with the attention mechanism for computational processing. It effectively distinguishes the interactive importance of different features. We have conducted many experiments on real dataset, and the results show that our model is better than most baseline model in terms of recommendation performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "570",
      "title": "Robust Distributed Fault Diagnosis for Large-Scale Interconnected Multi-Motor Web-Winding Systems",
      "abstract": "Web-winding systems are generally large-scale interconnected systems with many motor-driven subsystems. If the centralized fault diagnosis methods are adopted, the information exchanges among the motor driven subsystems will be required. However, the information exchanges are not always available due to the communication restriction, high system cost and so on. Moreover, it will lead to the high computational cost. To solve this problem well, the web-winding system is considered as a synthetic system with several dynamic subsystems subjected to multiple disturbances and actuator faults. Then, the methods of disturbance attenuation based distributed fault diagnosis method and disturbance compensation based distributed fault diagnosis method are developed to estimate the actuator faults. The objective of fault detection, fault isolation and fault estimation can also be realized via these methods. Meanwhile, sufficient conditions of asymptotic stability of the estimation error system are derived based on the Lyapunov theory. Observer gain matrices are obtained by solving the linear matrix inequalities (LMIs). Finally, simulations and analysis are performed on the three-motor web-winding system to verify the effectiveness of the proposed two fault diagnosis methods.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "571",
      "title": "Deliberate Clipping and Iterative Distortion Recovery for UCA-Based OAM Multiplexing Systems",
      "abstract": "Deliberate amplitude clipping is a simple and well-known technique to reduce the peak-to-average power ratio of orthogonal frequency division multiplexing (OFDM) systems. In this paper, we propose a clipping technique for peak power reduction in orbital angular momentum (OAM) multiplexing systems with uniform circular array (UCA) antennas. In the proposed technique, clipping is performed on digital baseband signals prior to OAM beamforming and pulse-shaping filtering, which helps to avoid out-of-band radiation and affecting the orthogonality of the OAM modes. In addition, an iterative distortion recovery algorithm is proposed in order to mitigate performance degradation in bit error rate (BER) due to the clipping. The algorithm is derived by unfolding the clipping noise cancellation (CNC) algorithm for OFDM systems into layers and by introducing layer-wise learnable parameters. Simulation results show that for a realistic OAM multiplexing system with 256QAM signaling, the unfolded CNC exhibits excellent BER performance even when the conventional CNC suffers from a high error-floor. The combination of the proposed clipping and distortion recovery schemes provides a significant reduction in the peak power of the OAM signals at the cost of only a slight degradation in BER performance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "572",
      "title": "Lightweight Bridge Crack Detection Method Based on SegNet and Bottleneck Depth-Separable Convolution With Residuals",
      "abstract": "Regular crack inspection of concrete facilities is an important means to ensure the safe operation of the bridge. Currently, some methods based on the computer visualization have been applied for the surface of concrete crack detection. However, thin and narrow, poor light and complicated noise are the main characteristics of the concrete cracks at the bottom of the bridge, resulting in low accuracy of the current network model applied. Therefore, the improvement of detection accuracy and algorithm efficiency is a challenging task. This article proposes a high-precision lightweight bridge concrete crack detection method based on the SegNet and bottleneck depth-separable convolution with residuals. The cross-entropy loss function is determined as the evaluation function and the root mean square prop (RMSProp) algorithm is used for optimization in the training progress. From the results, the trained model can achieve higher efficiency and robustness, so as to identify the crack position of the original image under different conditions (such as various illumination, messy back-ground, different crack widths, etc.). In addition, a comparative experiment is performed between the proposed method and the state of the art methods. Due to the addition of the feature extraction front-end on the basis of SegNet, our model is more elegant, robust and efficient than SegNet and U-Net. And our model compared with the latest methods DeepCrack and CrackU-net, the accuracy is increased to 97.95%, and the MIoU index is increased to 77.76%. In addition, we developed a crack detection system to better demonstrate our approach. To confirm the superiority of this method, we extracted the skeleton of the crack for analysis, and calculated the length, width and area of the crack. Obviously, using our recommendations, the average relative errors of predicted crack length and width are 9.65% and 8.95%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "573",
      "title": "Robust Optimal Formation Control of Heterogeneous Multi-Agent System via Reinforcement Learning",
      "abstract": "In this paper, a distributed robust optimal formation control problem is studied based on reinforcement learning for the heterogeneous multi-agent system with partial unknown system parameters. The formation system is subjected to equivalent disturbances containing parameter uncertainties and external disturbances. The proposed robust optimal controller consists of a nominal controller and a robust compensator. For the nominal controller, the reinforcement learning algorithm is proposed to obtain the optimal control input. For the robust compensator, the reinforcement learning algorithm is firstly used to identify the unknown dynamic parameters and then the robust compensator is designed to restrain the equivalent disturbances in the formation system. The robustness properties of the global multi-agent system are proven. A simulation of heterogeneous rotorcrafts is provided to verify the effectiveness of the proposed method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "574",
      "title": "SAO 1-Resilient Functions With Lower Absolute Indicator in Even Variables",
      "abstract": "In 2018, Tang and Maitra presented a class of balanced Boolean functions in n variables with the absolute indicator Δ\nf\n <; 2\nn/2\n and the nonlinearity NL( f) > 2\nn-1\n - 2\nn/2\n, that is, f is SAO (strictly almost optimal), for n = 2k ≡ 2 (mod 4) and n > 46 in [IEEE Ttans. Inf. Theory 64(1):393-402, 2018]. However, there is no evidence to show that the absolute indicator of any 1-resilient function in n variables can be strictly less than 2\n⌊(n+1)/2⌋\n, and the previously best known upper bound of which is 5 · 2\nn/2\n - 2\nn/4+2\n + 4. In this paper, we concentrate on two directions. Firstly, to complete Tang and Maitra's work for k being even, we present another class of balanced functions in n variables with the absolute indicator Δ\nf\n <; 2\nn/2\n and the nonlinearity NL( f) > 2\nn-1\n - 2\nn/2\n for n ≡ 0 (mod 4) and n ≥ 48. Secondly, we obtain two new classes of 1-resilient functions possessing very high nonlinearity and very low absolute indicator, from bent functions and plateaued functions, respectively. Moreover, one class of them achieves the currently known highest nonlinearity 2\nn-1\n - 2\nn/2-1\n - 2\nn/4\n, and the absolute indicator of which is upper bounded by 2\nn/2\n + 2\nn/4+1\n that is a new upper bound of the minimum of absolute indicator of 1-resilient functions, as it is clearly optimal than the previously best known upper bound 5 · 2\nn/2\n - 2\nn/4+2\n + 4.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "575",
      "title": "Ground Truth Force Distribution for Learning-Based Tactile Sensing: A Finite Element Approach",
      "abstract": "Skin-like tactile sensors provide robots with rich feedback related to the force distribution applied to their soft surface. The complexity of interpreting raw tactile information has driven the use of machine learning algorithms to convert the sensory feedback to the quantities of interest. However, the lack of ground truth sources for the entire contact force distribution has mainly limited these techniques to the sole estimation of the total contact force and the contact center on the sensor's surface. The method presented in this article uses a finite element model to obtain ground truth data for the three-dimensional force distribution. The model is obtained with state-of-the-art material characterization methods and is evaluated in an indentation setup, where it shows high agreement with the measurements retrieved from a commercial force-torque sensor. The proposed technique is applied to a vision-based tactile sensor, which aims to reconstruct the contact force distribution purely from images. Thousands of images are matched to ground truth data and are used to train a neural network architecture, which is suitable for real-time predictions.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "576",
      "title": "Application of Non-Negative Tensor Factorization for Airport Flight Delay Pattern Recognition",
      "abstract": "With the rapid development of civil aviation transportation in China, huge demand growth has broken the balance between supply and demand, resulting in airspace congestion and increasing flight delays. The delays of large airports have been increasing year by year, which has seriously affected the air travel experience of passengers. Obtaining their flight delay patterns can help identify defects in flight scheduling and airspace utilization. The investigation based on the actual flight operation data of Tianjin Binhai International Airport (TSN) is conducted, in order to capture the relationship and impact between the factors such as traffic flow direction, airline attributes and hourly average delay distribution. Furthermore, Non-negative Tensor Factorization (NTF) is applied to pattern recognition by introducing CP (CANDECOMP/PARAFAC) decomposition and Block Coordinate Descent (BCD) algorithm for selected data set. Numerical experiments show that the designed method has good performance in terms of computation speed and solution quality. Recognition results indicate the significant pattern characteristics of the Tianjin airport delay are extracted, which can provide some new perspectives for air traffic management unit to alleviate airspace congestion and improve service quality.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "577",
      "title": "Physics-Informed Neural Network Method for Space Charge Effect in Particle Accelerators",
      "abstract": "The electromagnetic coupling of a charged particle beam with vacuum chambers is of great interest for beam dynamics studies in the design of a particle accelerator. A deep learning-based method is proposed as a mesh-free numerical approach for solving the field of space charges of a particle beam in a vacuum chamber. Deep neural networks based on the physical model of a relativistic particle beam with transversally nonuniform charge density moving in a vacuum chamber are constructed using this method. A partial differential equation with the Lorentz factor, transverse charge density, and boundary condition is embedded in its loss function. The proposed physics-informed neural network method is applied to round, rectangular, and elliptical vacuum chambers. This is verified in comparison with analytical solutions for coupling impedances of a round Gaussian beam and an elliptical bi-Gaussian beam. The effects of chamber geometries, charge density, beam offset, and energy on the beam coupling impedance are demonstrated.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "578",
      "title": "A Dynamic Virtual Datacenter Selection Strategy for Integrated Cloud Service Platform Construction With Multiclouds",
      "abstract": "The pay-as-you-go model and network virtualization of cloud computing allow micro and small content businesses (MSCBs) who construct their integrated cloud service platforms (ICSPs) with virtual datacenters (VDCs) to serve their end users with low service latency and construction cost. However, designing a flexible VDC selection strategy to meet the demands of MSCBs is a challenging task. To address this problem, a dynamic VDC selection strategy is designed for MSCBs to construct their ICSPs flexibly with the VDCs from different clouds. To this end, three dynamic landmark selection metrics are proposed and applied to construct the network coordinates. Then, a dynamic VDC selection algorithm is presented to determine the locations and service resources of VDCs, which are purchased from different clouds by MSCBs to construct their ICSPs. Based on our VDC selection strategy, a simulator is developed based on our designed experimental framework to evaluate our VDC selection strategy. The experimental results show that compared with previous server placement strategies, our strategy can actively and effectively determine VDCs' locations and allocate service resources for each VDC with less computing consumption and is a practical VDC selection strategy for cloud construction in a multicloud environment.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "579",
      "title": "A Multi-Floor Location Method Based on Multi-Sensor and WiFi Fingerprint Fusion",
      "abstract": "Aiming at the problems of high time overhead, low positioning accuracy, and inability to meet the requirements of indoor positioning applications in WiFi and Pedestrian Dead Rockoning (PDR) positioning technologies, a cross-layer positioning method based on multi-sensor and WiFi fingerprint fusion is proposed. Firstly, Multi-dimensional scaling technology (MDS) is used in WiFi location, which reduces the overhead of offline stage of large area WiFi fingerprint location and improves the responsiveness of online location. Without limiting the holding mode, the high and low threshold detection method is used to reduce the error in gait detection of the PDR method. Unscented Kalman Filter (UKF) is used to fusion WiFi and PDR positioning results, output the optimal two-dimensional estimation, and finally use WiFi signal and multi-sensor information to determine the height of pedestrian position and output three-dimensional coordinates. The experiment results show that the proposed method have higher accuracy and better stability compared with WiFi and PDR positioning method.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "580",
      "title": "New Quantum Codes Constructed by Quantum Caps in PG(3,9) and PG(4,9)",
      "abstract": "In this paper, we present a computer-supported method of searching for quantum caps. By means of this method and relevant knowledge of combinatorics, many quantum caps in PG(3, 9) and PG(4, 9) are constructively proven to exist. Then, according to the theorem that each quantum cap corresponds to a quantum error-correcting code with d = 4, we obtain 278 quantum error-correcting codes. Most of these results break the GV bound, and a number of them are optimal quantum codes or have improved parameters.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "581",
      "title": "Enabling Identity for the IoT-as-a-Service Business Model",
      "abstract": "The IoT-as-a-Service (IoTaaS) business model has already been identified by some people from both industry and academia, but has not been formally defined. IoTaaS offers IoT devices on demand, with considerable cost savings and resource optimization. In addition, it enables different applications to reuse the existing devices. However, this business model is associated with different technological challenges that need to be addressed, one of which is the identity problem. Focusing on this, self-sovereign identity (SSI) schemes have proven to provide better privacy and scalability than traditional identity paradigms, which is especially important in the IoT owing to its characteristics. In this paper, we formally analyze an IoTaaS business model, identifying and detailing its main technological challenges. In addition, we tackle the identity problem of this business model and propose an SSI-based identity management system, which is compliant with the existing standards from the W3C, and include a performance evaluation.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "582",
      "title": "Ebola Optimization Search Algorithm: A New Nature-Inspired Metaheuristic Optimization Algorithm",
      "abstract": "Nature computing has evolved with exciting performance to solve complex real-world combinatorial optimization problems. These problems span across engineering, medical sciences, and sciences generally. The Ebola virus has a propagation strategy that allows individuals in a population to move among susceptible, infected, quarantined, hospitalized, recovered, and dead sub-population groups. Motivated by the effectiveness of this strategy of propagation of the disease, a new bio-inspired and population-based optimization algorithm is proposed. This study presents a novel metaheuristic algorithm named Ebola Optimization Search Algorithm (EOSA) based on the propagation mechanism of the Ebola virus disease. First, we designed an improved SIR model of the disease, namely SEIR-HVQD: Susceptible (S), Exposed (E), Infected (I), Recovered (R), Hospitalized (H), Vaccinated (V), Quarantine (Q), and Death or Dead (D). Secondly, we represented the new model using a mathematical model based on a system of first-order differential equations. A combination of the propagation and mathematical models was adapted for developing the new metaheuristic algorithm. To evaluate the performance and capability of the proposed method in comparison with other optimization methods, two sets of benchmark functions consisting of forty-seven (47) classical and thirty (30) constrained IEEE-CEC benchmark functions were investigated. The results indicate that the performance of the proposed algorithm is competitive with other state-of-the-art optimization methods based on scalability, convergence, and sensitivity analyses. Extensive simulation results show that the EOSA outperforms popular metaheuristic algorithms such as the Particle Swarm Optimization Algorithm (PSO), Genetic Algorithm (GA), and Artificial Bee Colony Algorithm (ABC). Also, the algorithm was applied to address the complex problem of selecting the best combination of convolutional neural network (CNN) hyperparameters in the image classi...",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "583",
      "title": "Neuro-Symbolic Speech Understanding in Aircraft Maintenance Metaverse",
      "abstract": "In the emerging world of metaverses, it is essential for speech communication systems to be aware of context to interact with virtual assets in the 3D world. This paper proposes the metaverse for aircraft maintenance training and education of Boeing-737, supplied with legacy manuals, 3D models, 3D simulators, and aircraft maintenance knowledge. Furthermore, to navigate and control operational flow in the metaverse, which is strictly followed by maintenance manuals, the context-aware speech understanding module Neuro-Symbolic Speech Executor (NSSE) is presented. Unlike conventional speech recognition methods, NSSE applies Neuro-Symbolic AI, which combines neural networks and traditional symbolic reasoning, to understand users’ requests and reply based on context and aircraft-specific knowledge. NSSE is developed with an industrially flexible approach by applying only synthetic data for training. Nevertheless, the evaluation process performed with various automatic speech recognition metrics on real users’ data showed sustainable results with an average accuracy of 94.7%, Word Error Rate (WER) of 7.5%, and the generalization ability to handle speech requests of users with the non-native pronunciation. The proposed Aircraft Maintenance Metaverse is a cheap and scalable solution for aviation colleges since it replaces expensive physical aircraft with virtual one that can be easily modified and updated. Moreover, the Neuro-Symbolic Speech Executor, playing the role of field expert, provides technical guidance and all the resources to facilitate effective training and education of aircraft maintenance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "584",
      "title": "An FPGA Compliant Single-Rail Encoded Asynchronous Pipeline",
      "abstract": "Asynchronous systems are native to a full custom domain. Their implementation using auto place-and-route tools requires dynamic calibration of interconnects delays in addition to the placement of predefined static delay elements. This paper presents a completion detector for a single-rail bit encoded datapath that, as an adaptive-delay element, eliminates the need to insert any predefined delay element and caters to routing delays dynamically. A programmable pulse-generator is also proposed that empowers the designers to generate clock signals based on the timing report obtained from the CAD tool to drive various synchronous subsystems and embedded resources like BRAMs in FPGAs. Employing these components, we present an asynchronous pipeline model with implicit control to expedite migration from the traditional synchronous pipelines to their asynchronous counterparts. A single-rail bit encoded datapath has been used to utilize chip area effectively instead of a delay-insensitive dual-rail datapath, and a two-phase handshake protocol has been adopted as opposed to a four-phase handshake protocol to lower handshaking overhead. A RISC processor validates the proposed asynchronous pipeline model, exhibiting a smooth functionality and power-delay parameter comparable to that of a synchronous pipeline, in addition to ease of routing and avoiding clock skews in a complex system-on-chip.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "585",
      "title": "Automated Prescreening of Mild Cognitive Impairment Using Shank-Mounted Inertial Sensors Based Gait Biomarkers",
      "abstract": "The mild symptoms in Mild Cognitive Impairment (MCI), a precursor of dementia, often go unnoticed and are assumed as normal aging signs. Such negligence result in late visits which consequently, lead to the diagnosis and progression of dementia. An instrumented gait assessment in home settings may facilitate the detection of subtle MCI-related motor deficits thus, allowing early diagnosis and intervention. This paper investigates potential gait biomarkers derived from shank mounted inertial sensors signals under normal and dual-task walking conditions using data collected from thirty MCI and thirty cognitively normal (CN) subjects. To identify potential gait biomarkers for MCI screening, we assess the variance and predictive power of each feature. Moreover, multiple classification models using different machine learning and feature selection techniques are built to automate MCI detection by leveraging the gait biomarkers. Statistical analysis reveal multiple gait parameters that are significantly different under both single and dual-task settings. However, we show that dual-task walking provides better distinction between MCI and CN subjects. The machine learning model employed for MCI pre-screening based on the inertial sensor-derived gait biomarkers achieves accuracy and sensitivity of 71.67% and 83.33%, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "586",
      "title": "Anti-Periodic Synchronization of Clifford-Valued Neutral-Type Recurrent Neural Networks With D Operator",
      "abstract": "In this paper, a class of Clifford-valued neutral-type recurrent neural networks with \n D \n operator is explored. By using non-decomposition method and the Banach fixed point theorem, we obtain several sufficient conditions for the existence of anti-periodic solutions for Clifford-valued neutral-type recurrent neural networks with \n D \n operator. By using the proof by contradiction and inequality techniques, we obtain the global exponential synchronization of anti-periodic solutions for Clifford-valued neutral-type recurrent neural networks with \n D \n operator. Finally, we give one example to illustrate the feasibility and effectiveness of main results.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "587",
      "title": "Electron Radiation Effects on the 4H-SiC PiN Diodes Characteristics: An Insight From Point Defects to Electrical Degradation",
      "abstract": "Silicon carbide (SiC) devices have shown substantial promise in realizing ultrahigh-voltage and high power, and have been usually considered as a potential candidate for high radiation levels applications. However, in this work it is found that the SiC P-intrinsic-N (PiN) diodes are sensitive to the electron irradiation, which exerts significant influence on the device characteristics. The physical mechanisms behind these behaviors are studied by probing the production of point defects and the evolution of carrier lifetime in the SiC epilayers after irradiation. It is found that the forward current is significantly reduced by irradiation and the specific on-resistance monotonously increases with the increasing electron fluences, which is resulted from the deteriorated conductivity modulation effects in the epilayer due to the enhanced carrier recombination from the radiation induced deep-level defects, such as the carbon vacancy (VC), silicon vacancy (VSi) and VC+VSi complexes. Inversely, no significant change is observed in the reverse leakage current of 4H-SiC PiN diodes, and the breakdown voltage even slightly increases after electron irradiation, which are ascribed to the suppressed carrier generation arising from the point defects in 4H-SiC with a wide bandgap and the carrier-removal effects caused by the acceptor like point defects generated during irradiation, respectively.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "588",
      "title": "MIMO Cross-Layer Secure Communication Algorithm for Cyber Physical Systems Based on Interference Strategies",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "589",
      "title": "A Visual Residual Perception Optimized Network for Blind Image Quality Assessment",
      "abstract": "Blind image quality assessment (BIQA) is a fundamental yet challenging problem in the image processing system. Existing BIQA models have the following problems: 1) Due to the lack of available quality-label images, most of the methods have poor generalization ability in different distortion categories; 2) The impact of human visual characteristics on the content of images is not taken into account. In this paper, we proposed a visual residual perception optimized network (VRPON) that can effectively solve these problems. The proposed method separates the training of BIQA into two stages: 1) a distortion degree identification network and 2) an image quality prediction network. In the first stage, the spatial and temporal features of image sequences are extracted by CNN and LSTM respectively, which are used to evaluate the degree of image distortion. And then the proposed model is learned to predict image patches' scores in the second stage with the outputs of the first stage. Finally, a pooling strategy that follows the human visual saliency is designed to evaluate the quality score of the whole image. Experimental results show that the proposed VRPON not only has better performance than state-of-the-art methods on synthetic distorted images (LIVE, TID2013, CSIQ), but also has better robustness for different authentic distortions (LIVE challenge).",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "590",
      "title": "NASCENT: A Non-Invasive Solution for Detecting Utilization of Servers in Bare-Metal Cloud",
      "abstract": "Physical servers are available as-a-service in bare-metal public and private cloud platforms, and their demand has been proliferating because of the high levels of privacy and security guarantees they provide to the tenants. This raises the need for efficient management of bare-metal clouds to keep operational costs low such as by reducing energy consumption. For efficiently managing the cloud infrastructure, bare-metal cloud operators need to monitor the utilization of servers. However, the privacy and security concerns prohibit the installation of third-party monitoring agents on the servers; thus, finding the server-utilization becomes a challenge. In this work, we present NASCENT, a scalable machine-learning (ML) based non-invasive solution for finding the utilization of servers without compromising the privacy and security of bare-metal cloud tenants. Our key idea is to infer utilization from various sensor readings accessible via a server’s baseboard management controller (BMC) hardware. We evaluate the proposed solution with three regression based supervised ML algorithms in a Bare-metal-as-a-service (BMaaS) cloud. Our experimental evaluation shows that one of the ML algorithms employed in NASCENT infers the utilization with a root-mean-square error (RMSE) between 2.9 to 9.3 for different workloads. Also, the proposed solution uses minimal memory resources (19 KB) and can even run on BMC hardware which has very limited memory. We also propose a BMaaS cloud architecture that seamlessly integrates automated training and deployment of the ML algorithm in our solution into the life-cycle of bare-metal servers. NASCENT’s codebase can be found at \nhttps://github.com/iithcandle/dhi-ojas",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "591",
      "title": "A Novel Hybrid Fuzzy-JAYA Optimization Algorithm for Efficient ORPD Solution",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "592",
      "title": "Influence of Sheath Radial Crack on Flashover Arc and Leakage Current of Roof Silicon Rubber Insulator for High-Speed Train",
      "abstract": "In this paper, three types of insulators with no crack, short crack, and long crack are taken as the research objects to evaluate the influence of the penetrating cracks on the 1\nst\n sheath of the roof silicone rubber composite insulator of high-speed train on the flashover characteristics. The continuous voltage rising method is used to obtain the influence characteristics of the crack on the development process of the flashover arc. The constant voltage withstand method is adopted to compare the leakage current when the contamination degree is 0.1 mg/cm\n2\n. The test results demonstrate that the crack has no significant effect on the flashover voltage and flashover path, and the flashover arc can burn the edge of the crack. The peak leakage current of the three different tests ranges from 24 mA to 30 mA. Additionally, the development of leakage current can be divided into four stages: rising, continuous violence, falling, and oscillating. Moreover, the sequence of the apparent leakage current of the insulator is long crack insulator, short crack insulator, and the one with no crack. The acceleration of the rising stage of the leakage current increases with the increase in the crack length. Meanwhile, the sum of the time of the rising stage, continuous stage, and falling stage of the insulator with long crack is the smallest. The crack will distort the distribution of current density and the electric field intensity in the vicinity. The results can provide references for evaluating the influence of radial cracks at the edge of the sheath on the flashover characteristics and optimizing the design of the roof insulator sheath structure.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "593",
      "title": "Named-Entity Recognition Using Automatic Construction of Training Data From Social Media Messaging Apps",
      "abstract": "In recent years, social media messaging app data has served as a precious resource to extract useful information, such as critical clues and evidence in legal trials and criminal investigations. Although these data can be of various types, they are mostly in the form of natural language text. Therefore, to extract information from them efficiently, it is essential to research practical natural language processing approaches. This study proposes applying a deep-learning-based named-entity recognition (NER) system as a natural language processing approach for information extraction to these messaging data. In addition, a system for automatically constructing NER training data is presented using the distant supervision method for the training data of deep-learning models. Because social media messaging app data generally include a significant amount of noise, such as typographical and word-spacing errors, a NER system with robustness against these types of noisy data is required to extract information from the messaging data effectively. The results demonstrate that the proposed approach outperforms that of a NER system with manually labeled training data.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "594",
      "title": "Gated-Dilated Networks for Lung Nodule Classification in CT Scans",
      "abstract": "Different types of Convolutional Neural Networks (CNNs) have been applied to detect cancerous lung nodules from computed tomography (CT) scans. However, the size of a nodule is very diverse and can range anywhere between 3 and 30 millimeters. The high variation of nodule sizes makes classifying them a difficult and challenging task. In this study, we propose a novel CNN architecture called Gated-Dilated (GD) networks to classify nodules as malignant or benign. Unlike previous studies, the GD network uses multiple dilated convolutions instead of max-poolings to capture the scale variations. Moreover, the GD network has a Context-Aware sub-network that analyzes the input features and guides the features to a suitable dilated convolution. We evaluated the proposed network on more than 1,000 CT scans from the LIDC-LDRI dataset. Our proposed network outperforms state-of-the-art baseline models including Multi-Crop, Resnet, and Densenet, with an AUC of >0.95. Compared to the baseline models, the GD network improves the classification accuracies of mid-range sized nodules. Furthermore, we observe a relationship between the size of the nodule and the attention signal generated by the Context-Aware sub-network, which validates our new network architecture.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "595",
      "title": "Flattenet: A Simple and Versatile Framework for Dense Pixelwise Prediction",
      "abstract": "In this paper, we focus on devising a versatile framework for dense pixelwise prediction whose goal is to assign a discrete or continuous label to each pixel for an image. It is well-known that the reduced feature resolution due to repeated subsampling operations poses a serious challenge to Fully Convolutional Network (FCN) based models. In contrast to the commonly-used strategies, such as dilated convolution and encoder-decoder structure, we introduce a novel Flattening Module to produce high-resolution predictions without either removing any subsampling operations or building a complicated decoder module. In addition, the Flattening Module is lightweight and can be easily combined with any existing FCNs, allowing the model builder to trade off among model size, computational cost and accuracy by simply choosing different backbone networks. We empirically demonstrate the effectiveness of the proposed Flattening Module through competitive results in human pose estimation on MPII, semantic segmentation on PASCAL-Context and object detection on PASCAL VOC. We hope that the proposed approach can serve as a simple and strong alternative of current dominant dense pixelwise prediction frameworks.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "596",
      "title": "Design of 94GHz Dual-Polarization Antenna Fed by Diagonal Horn for Cloud Radars",
      "abstract": "In this paper, a 94 GHz dual-polarization high-isolation cassegrain antenna feed by a diagonal horn antenna is designed. The antenna consists of a D = 540 mm main reflector, sub-reflector, and dual-port dual-polarization diagonal horn feed antenna. To obtain similar feed horn E-H radiation patterns, gain, high polarization, and port isolation, a dual-port diagonal horn was designed in the feed. The measured antenna gains are 50.85 dBi and the side-lobe levels are −24.5 dB at E-H radiation patterns of two ports at 94 GHz, respectively. The VSWRs of port 1 and port 2 are less than 1.5:1 in the range 93.2–95.3 GHz, which meets the working requirements of frequency modulated continuous wave and pulse cloud radars. And the isolation between the two ports is above −50 dB, whereas the polarization isolation of each port is above 40 dB. The proposed W-band antenna is a suitable candidate for the dual-polarization cloud radars.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "597",
      "title": "Memory Storage Systems Utilizing Chaotic Attractor-Merging Bifurcation",
      "abstract": "In nonlinear dynamical systems with barriers/thresholds, the signal response against a weak external input signal is enhanced by an appropriate additive noise (stochastic resonance). In recent years, progress in the application of stochastic resonance shows that the existence of additive noise heightens the memory storage functions in memory elements using bistable oscillations even with extremely low power consumption. By not restricting the additive noise, the deterministic chaos (an internal fluctuation) induces a similar phenomenon known as chaotic resonance. Chaotic resonance appears in nonlinear dynamical systems and is accompanied by chaos–chaos intermittency, where the chaotic orbit intermittently transitions among separated attractor regions through attractor-merging bifurcation. Previously, a higher chaotic resonance sensitivity than that of stochastic resonance was reported in various types of systems. In this study, we hypothesize that chaotic-resonance-based memory devices can store information with lower power consumption than that of stochastic-resonance-based devices. To prove this hypothesis, we induced attractor-merging bifurcation in a cubic map system, which is the simplest model for the emergence of chaotic resonance. Thereafter, we adjusted the internal system parameter under a noise-free system as the chaotic resonance and applied stochastic noise similar to the condition for inducing stochastic resonance. The results of this study reveal that, even with weaker memory storage input signals, the former exhibits a higher memory storage capability than the latter. The approach using chaotic resonance could facilitate the development of memory devices that were hitherto restricted to the application of stochastic resonance.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "598",
      "title": "NADS-RA: Network Anomaly Detection Scheme Based on Feature Representation and Data Augmentation",
      "abstract": "Network anomaly detection aims to identify network anomalies, and it has obtained many achievements using the supervised classification technique. Since the supervised classifier depends on the prior data, it is difficult to accurately classify the rare anomalies when they account less in the training set. Data augmentation can tackle the imbalanced training set problem through creating artificial rare anomaly samples. However, the existing data augmentation methods either ignore the data distribution or ignore the spatial knowledge between features. Therefore, this article addresses this issue by proposing a Network Anomaly Detection Scheme based on feature Representation and data Augmentation (NADS-RA). Re-circulation Pixel Permutation strategy is first designed as feature representation strategy to construct images, and it rotates each feature left by the times of feature number to maintain the spatial knowledge between original network traffic features. An image-based augmentation strategy is thus designed to produce augmented images according to the distribution characteristics of rare network anomaly images with the help of Least Squares Generative Adversarial Network, which alleviates the effect of imbalanced training set and avoids over-fitting. After that, NADS-RA is implemented on the Convolutional Neural Network classification model. We conduct experiments on five public benchmark datasets, including NSL-KDD and UNSW-NB15, and so on, and compare against 12 detection methods and 17 data generation methods. The experimental results demonstrate the superior effectiveness of our work to state-of-the-art methods and the general applicability in different scenarios.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "599",
      "title": "Quality Aware Features for Performance Prediction and Time Reduction in Video Object Tracking",
      "abstract": "The existing body of work on video object tracking (VOT) algorithms has studied various image conditions such as occlusion, clutter, and object shape, which influence video quality and affect tracking performance. Nonetheless, there is no clear distinction between the performance reduction caused by scene-dependent challenges such as occlusion and clutter, and the effect of authentic in-capture and post-capture distortions. Despite the plethora of VOT methods in the literature, there is a lack of detailed studies analyzing the performance of videos with authentic in-capture and post-capture distortions. We introduced a new dataset of authentically distorted videos (AD-SVD) to address this issue. This dataset contains 4476 videos with different authentic distortions and surveillance activities. Furthermore, it provides benchmarking results for evaluating ten state-of-the-art visual object trackers (from VOT 2017–2018 challenges) based on the proposed dataset. In addition, this study develops an approach for performance prediction and quality-aware feature selection for single-object tracking in authentically distorted surveillance videos. The method predicts the performance of a VOT algorithm with high accuracy. Then, the probability of obtaining the reference output is maximized without executing the tracking algorithms. We also propose a framework to reduce video tracker computation resources (time and video storage space). We achieve this by balancing processing time and tracking accuracy by predicting the performance in a range of spatial resolutions. This approach can reduce the execution time by up to 34% with a slight decrease in performance of 3%.",
      "subjects": []
    },
    {
      "source": "IEEE",
      "identifier": "600",
      "title": "Conceptualizing the Role of Gamification in Contemporary Enterprises",
      "abstract": "",
      "subjects": []
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Un module inversible associ\\'e au ruban de M\\\"obius, et quelques autres",
      "abstract": "  After attaching explicitly to the M\\\"obius strip an invertible module over\nthe ring of real polynomial functions on the real circle, we expound as\ndirectly as possible the many faces and the main algebraic properties of\ninvertible modules. The goal is to make this algebraic concept accessible to a\nwide mathematical audience.\n",
      "subjects": [
        "math.AC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Forward-Backward Charge Asymmetry in Z Production at the LHC",
      "abstract": "  We present here a study on the determination of the effective weak mixing\nangle, $\\sin^{2}\\theta^{lept}_{eff}$ from the measurement of the\nForward-Backward Asymmetry with a high a statistical precision, 10$^{-4}$. To\nreach such a precision it is necessary to identify the electrons in the forward\nregions of the ATLAS detector. It is demonstrated that one can reach an\nelectron-jet rejection of more than 100 with an efficiency on electron\nreconstruction better than 50%, by using a multivariate analysis.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1006/spmi.2000.0928",
      "title": "GaAs delta-doped quantum wire superlattice characterization by quantum\n  Hall effect and Shubnikov de Haas oscillations",
      "abstract": "  Quantum wire superlattices (1D) realized by controlled dislocation slipping\nin quantum well superlattices (2D) (atomic saw method) have already shown\nmagnetophonon oscillations. This effect has been used to investigate the\nelectronic properties of such systems and prove the quantum character of the\nphysical properties of the wires. By cooling the temperature and using pulsed\nmagnetic field up to 35 T, we have observed both quantum Hall effect (QHE) and\nShubnikov de Haas (SdH) oscillations for various configurations of the magnetic\nfield. The effective masses deduced from the values of the fundamental fields\nare coherent with those obtained with magnetophonon effect. The field rotation\ninduces a change in the resonance frequencies due to the modification of the\nmass tensor as in a (3D) electron gas. In view the QHE, the plateaus observed\nin rho_yz are dephased relatively to rho_zz minima which seems to be linked to\nthe dephasing of the minima of the density of states of the broadened Landau\nlevels.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.dis-nn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1751-8113/40/50/N01",
      "title": "Remarks on \"Resolving isospectral `drums' by counting nodal domains\"",
      "abstract": "  In [3] the authors studied the 4-parameter family of isospectral flat 4-tori\nT^\\pm(a,b,c,d) discovered by Conway and Sloane. With a particular method of\ncounting nodal domains they were able to distinguish these tori (numerically)\nby computing the corresponding nodal sequences relative to a few explicit\ntuples (a,b,c,d). In this note we confirm the expectation expressed in [3] by\nproving analytically that their nodal count distinguishes any 4-tuple of\ndistinct positive real numbers.\n",
      "subjects": [
        "math.SP",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1098/rspa.2007.0294",
      "title": "Numerical removal of water-vapor effects from THz-TDS measurements",
      "abstract": "  One source of disturbance in a pulsed T-ray signal is attributed to ambient\nwater vapor. Water molecules in the gas phase selectively absorb T-rays at\ndiscrete frequencies corresponding to their molecular rotational transitions.\nThis results in prominent resonances spread over the T-ray spectrum, and in the\ntime domain the T-ray signal is observed as fluctuations after the main pulse.\nThese effects are generally undesired, since they may mask critical\nspectroscopic data. So, ambient water vapor is commonly removed from the T-ray\npath by using a closed chamber during the measurement. Yet, in some\napplications a closed chamber is not applicable. This situation, therefore,\nmotivates the need for another method to reduce these unwanted artifacts. This\npaper presents a study on a computational means to address the problem.\nInitially, a complex frequency response of water vapor is modeled from a\nspectroscopic catalog. Using a deconvolution technique, together with fine\ntuning of the strength of each resonance, parts of the water-vapor response are\nremoved from a measured T-ray signal, with minimal signal distortion.\n",
      "subjects": [
        "cs.CE",
        "physics.comp-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.81.224403",
      "title": "Critical behavior of diluted magnetic semiconductors: the apparent\n  violation and the eventual restoration of the Harris criterion for all\n  regimes of disorder",
      "abstract": "  Using large-scale Monte Carlo calculations, we consider strongly disordered\nHeisenberg models on a cubic lattice with missing sites (as in diluted magnetic\nsemiconductors such as Ga_{1-x}Mn_{x}As). For disorder ranging from weak to\nstrong levels of dilution, we identify Curie temperatures and calculate the\ncritical exponents nu, gamma, eta, and beta finding, per the Harris criterion,\ngood agreement with critical indices for the pure Heisenberg model where there\nis no disorder component. Moreover, we find that thermodynamic quantities (e.g.\nthe second moment of the magnetization per spin) self average at the\nferromagnetic transition temperature with relative fluctuations tending to zero\nwith increasing system size. We directly calculate effective critical exponents\nfor T > T_{c}, yielding values which may differ significantly from the critical\nindices for the pure system, especially in the presence of strong disorder.\nUltimately, the difference is only apparent, and eventually disappears when T\nis very close to T_{c}.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "cond-mat.dis-nn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.2168/LMCS-3(4:8)2007",
      "title": "Coinductive Proof Principles for Stochastic Processes",
      "abstract": "  We give an explicit coinduction principle for recursively-defined stochastic\nprocesses. The principle applies to any closed property, not just equality, and\nworks even when solutions are not unique. The rule encapsulates low-level\nanalytic arguments, allowing reasoning about such processes at a higher\nalgebraic level. We illustrate the use of the rule in deriving properties of a\nsimple coin-flip process.\n",
      "subjects": [
        "cs.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1748-0221/3/02/P02006",
      "title": "Detector of alpha particles and x-rays operating in ambient air in pulse\n  counting mode or/and with gas amplification",
      "abstract": "  Ionization chambers working in ambient air in current detection mode are\nwidely used in several applications such as smoke detection, dosimetry,\ntherapeutic beam monitoring and cetera. The aim of this work was to investigate\nif gaseous detectors can operate in ambient air in pulse counting mode as well\nas with gas amplification. . To investigate the feasibility of this method two\ntypes of open- end gaseous detectors were build and successfully tested. The\nfirst one was a single wire or multiwire cylindrical geometry detector\noperating in pulse mode at a gas gain of 1. The second type alpha detector was\nan innovative GEM-like detector with resistive electrodes operating in air in\navalanche mode at high gas gains (up to 10E4). A detailed comparison between\nthese two detectors is given as well as comparison with the commercially\navailable alpha detectors. The main advantages of gaseous detectors operating\nin air in a pulse detection mode are their simplicity, low cost and high\nsensitivity. One of the possible applications of these new detectors is alpha\nparticle background monitors which, due to their low cost can find wide\napplication not only in houses, but in public areas: airports, railway station\nand so on.\n",
      "subjects": [
        "physics.ins-det"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0953-8984/20/02/023201",
      "title": "Semiclassical theories of the anomalous Hall effect",
      "abstract": "  Recently, the semiclassical theory of the anomalous Hall effect induced by\nthe Berry curvature in Bloch bands has been introduced. The theory operates\nonly with gauge invariant concepts, that have a simple semiclassical\ninterpretation and provides a clear distinction among various contributions to\nthe Hall current. While the construction of such an approach to the anomalous\nHall effect problem has been long sought, only the new semiclassical theory\ndemonstrated the agreement with quantitative results of rigorous approaches\nbased on the Green function techniques. The purpose of this work is to review\nthe semiclassical approach including the early ideas and the recent\nachievements.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/OE.16.002176",
      "title": "A high-accuracy algorithm for designing arbitrary holographic atom traps",
      "abstract": "  We report the realization of a new iterative Fourier-transform algorithm for\ncreating holograms that can diffract light into an arbitrary two-dimensional\nintensity profile. We show that the predicted intensity distributions are\nsmooth with a fractional error from the target distribution at the percent\nlevel. We demonstrate that this new algorithm outperforms the most frequently\nused alternatives typically by one and two orders of magnitude in accuracy and\nroughness, respectively. The techniques described in this paper outline a path\nto creating arbitrary holographic atom traps in which the only remaining hurdle\nis physical implementation.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Ternary cyclotomic polynomials having a large coefficient",
      "abstract": "  Let $\\Phi_n(x)$ denote the $n$th cyclotomic polynomial. In 1968 Sister Marion\nBeiter conjectured that $a_n(k)$, the coefficient of $x^k$ in $\\Phi_n(x)$,\nsatisfies $|a_n(k)|\\le (p+1)/2$ in case $n=pqr$ with $p<q<r$ primes (in this\ncase $\\Phi_n(x)$ is said to be ternary). Since then several results towards\nestablishing her conjecture have been proved (for example $|a_n(k)|\\le 3p/4$).\nHere we show that, nevertheless, Beiter's conjecture is false for every $p\\ge\n11$. We also prove that given any $\\epsilon>0$ there exist infinitely many\ntriples $(p_j,q_j,r_j)$ with $p_1<p_2<... $ consecutive primes such that\n$|a_{p_jq_jr_j}(n_j)|>(2/3-\\epsilon)p_j$ for $j\\ge 1$.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Capacity of the Bosonic Wiretap Channel and the Entropy Photon-Number\n  Inequality",
      "abstract": "  Determining the ultimate classical information carrying capacity of\nelectromagnetic waves requires quantum-mechanical analysis to properly account\nfor the bosonic nature of these waves. Recent work has established capacity\ntheorems for bosonic single-user and broadcast channels, under the presumption\nof two minimum output entropy conjectures. Despite considerable accumulated\nevidence that supports the validity of these conjectures, they have yet to be\nproven. In this paper, it is shown that the second conjecture suffices to prove\nthe classical capacity of the bosonic wiretap channel, which in turn would also\nprove the quantum capacity of the lossy bosonic channel. The preceding minimum\noutput entropy conjectures are then shown to be simple consequences of an\nEntropy Photon-Number Inequality (EPnI), which is a conjectured\nquantum-mechanical analog of the Entropy Power Inequality (EPI) form classical\ninformation theory.\n",
      "subjects": [
        "quant-ph",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.77.193311",
      "title": "Multiscale theory of valley splitting",
      "abstract": "  The coupling between $z$ valleys in the conduction band of a Si quantum well\narises from phenomena occurring within several atoms from the interface, thus\nruling out a theoretical description based on pure effective mass theory.\nHowever, the complexity and size of a realistic device precludes an analytical\natomistic description. Here, we develop a fully analytical multiscale theory of\nvalley coupling, by combining effective mass and tight binding approaches. The\nresults are of particular interest for silicon qubits and quantum devices, but\nalso provide insight for GaAs quantum wells.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s11207-008-9158-z",
      "title": "High-resolution mapping of flows in the solar interior: Fully consistent\n  OLA inversion of helioseismic travel times",
      "abstract": "  To recover the flow information encoded in travel-time data of time-distance\nhelioseismology, accurate forward modeling and a robust inversion of the travel\ntimes are required. We accomplish this using three-dimensional finite-frequency\ntravel-time sensitivity kernels for flows along with a 2+1 dimensional (2+1D)\noptimally localized averaging (OLA) inversion scheme. Travel times are measured\nby ridge filtering MDI full-disk Doppler data and the corresponding Born\nsensitivity kernels are computed for these particular travel times. We also\nutilize the full noise covariance properties of the travel times which allow us\nto accurately estimate the errors for all inversions. The whole procedure is\nthus fully consistent. Due to ridge filtering, the kernel functions separate in\nthe horizontal and vertical directions, motivating our choice of a 2+1D\ninversion implementation. The inversion procedure also minimizes cross-talk\neffects among the three flow components, and the averaging kernels resulting\nfrom the inversion show very small amounts of cross-talk. We obtain\nthree-dimensional maps of vector solar flows in the quiet Sun at spatial\nresolutions of 7-10 Mm using generally 24 h of data. For all of the flow maps\nwe provide averaging kernels and the noise estimates. We present examples to\ntest the inferred flows, such as a comparison with Doppler data, in which we\nfind a correlation of 0.9. We also present results for quiet-Sun supergranular\nflows at different depths in the upper convection zone.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s11232-009-0006-6",
      "title": "Geometric torsions and invariants of manifolds with triangulated\n  boundary",
      "abstract": "  Geometric torsions are torsions of acyclic complexes of vector spaces which\nconsist of differentials of geometric quantities assigned to the elements of a\nmanifold triangulation. We use geometric torsions to construct invariants for a\nmanifold with a triangulated boundary. These invariants can be naturally united\nin a vector, and a change of the boundary triangulation corresponds to a linear\ntransformation of this vector. Moreover, when two manifolds are glued by their\ncommon boundary, these vectors undergo scalar multiplication, i.e., they work\naccording to M. Atiyah's axioms for a topological quantum field theory.\n",
      "subjects": [
        "math.GT",
        "math.AT",
        "math.QA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10994-008-5069-3",
      "title": "Rollout Sampling Approximate Policy Iteration",
      "abstract": "  Several researchers have recently investigated the connection between\nreinforcement learning and classification. We are motivated by proposals of\napproximate policy iteration schemes without value functions which focus on\npolicy representation using classifiers and address policy learning as a\nsupervised learning problem. This paper proposes variants of an improved policy\niteration scheme which addresses the core sampling problem in evaluating a\npolicy through simulation as a multi-armed bandit machine. The resulting\nalgorithm offers comparable performance to the previous algorithm achieved,\nhowever, with significantly less computational effort. An order of magnitude\nimprovement is demonstrated experimentally in two standard reinforcement\nlearning domains: inverted pendulum and mountain-car.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Schr\\\"oder Paths and Pattern Avoiding Partitions",
      "abstract": "  In this paper, we show that both 12312-avoiding partitions and 12321-avoiding\npartitions of the set $[n+1]$ are in one-to-one correspondence with Schr\\\"oder\npaths of semilength $n$ without peaks at even level. As a consequence, the\nrefined enumeration of 12312-avoiding (resp. 12321-avoiding) partitions\naccording to the number of blocks can be reduced to the enumeration of certain\nSchr\\\"oder paths according to the number of peaks. Furthermore, we get the\nenumeration of irreducible 12312-avoiding (resp. 12321-avoiding) partitions,\nwhich are closely related to skew Dyck paths.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1215/00127094-1507272",
      "title": "Differentiable Rigidity under Ricci curvature lower bound",
      "abstract": "  In this article we prove a differentiable rigidity result. Let $(Y, g)$ and\n$(X, g_0)$ be two closed $n$-dimensional Riemannian manifolds ($n\\geqslant 3$)\nand $f:Y\\to X$ be a continuous map of degree $1$. We furthermore assume that\nthe metric $g_0$ is real hyperbolic and denote by $d$ the diameter of\n$(X,g_0)$. We show that there exists a number $\\varepsilon:=\\varepsilon (n,\nd)>0$ such that if the Ricci curvature of the metric $g$ is bounded below by\n$-n(n-1)$ and its volume satisfies $\\vol_g (Y)\\leqslant (1+\\varepsilon)\n\\vol_{g_0} (X)$ then the manifolds are diffeomorphic. The proof relies on\nCheeger-Colding's theory of limits of Riemannian manifolds under lower Ricci\ncurvature bound.\n",
      "subjects": [
        "math.DG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1137/080727361",
      "title": "Deflated and restarted symmetric Lanczos methods for eigenvalues and\n  linear equations with multiple right-hand sides",
      "abstract": "  A deflated restarted Lanczos algorithm is given for both solving symmetric\nlinear equations and computing eigenvalues and eigenvectors. The restarting\nlimits the storage so that finding eigenvectors is practical. Meanwhile, the\ndeflating from the presence of the eigenvectors allows the linear equations to\ngenerally have good convergence in spite of the restarting. Some\nreorthogonalization is necessary to control roundoff error, and several\napproaches are discussed. The eigenvectors generated while solving the linear\nequations can be used to help solve systems with multiple right-hand sides.\nExperiments are given with large matrices from quantum chromodynamics that have\nmany right-hand sides.\n",
      "subjects": [
        "math-ph",
        "hep-lat",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2008.13679.x",
      "title": "Gravitational fragmentation and the formation of brown dwarfs in stellar\n  clusters",
      "abstract": "  We investigate the formation of brown dwarfs and very low-mass stars through\nthe gravitational fragmentation of infalling gas into stellar clusters. The\ngravitational potential of a forming stellar cluster provides the focus that\nattracts gas from the surrounding molecular cloud. Structures present in the\ngas grow, forming filaments flowing into the cluster centre. These filaments\nattain high gas densities due to the combination of the cluster potential and\nlocal self-gravity. The resultant Jeans masses are low, allowing the formation\nof very low-mass fragments. The tidal shear and high velocity dispersion\npresent in the cluster preclude any subsequent accretion thus resulting in the\nformation of brown dwarfs or very low-mass stars. Ejections are not required as\nthe brown dwarfs enter the cluster with high relative velocities, suggesting\nthat their disc and binary properties should be similar to that of low-mass\nstars. This mechanism requires the presence of a strong gravitational potential\ndue to the stellar cluster implying that brown dwarf formation should be more\nfrequent in stellar clusters than in distributed populations of young stars.\nBrown dwarfs formed in isolation would require another formation mechanism such\nas due to turbulent fragmentation.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2008.13722.x",
      "title": "Helioseismic analysis of the solar flare-induced sunquake of 2005\n  January 15. II: A magneto-seismic study",
      "abstract": "  On 2005 January 15, the active region AR10720 produced an X1.2 solar flare\nthat induced high levels of seismicity into the photospheric layers. The\nseismic source was detected using helioseismic holography and analysed in\ndetail in Paper I. Egression power maps at 6 mHz with a 2 mHz bandwidth\nrevealed a compact acoustic source strongly correlated with the footpoints of\nthe coronal loop that hosted the flare. We present a magneto-seismic study of\nthis active region in order to understand, for the first time, the magnetic\ntopological structure of a coronal field that hosts an acoustically active\nsolar flare. The accompanying analysis attempts to answer questions such as:\nCan the magnetic field act as a barrier and prevent seismic waves from\nspreading away from the focus of the sunquake? And, what is the most efficient\nmagnetic structure that would facilitate the development of a strong seismic\nsource in the photosphere?\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0264-9381/25/18/184015",
      "title": "Detection of periodic gravitational wave sources by Hough transform in\n  the frequency and spin down plane",
      "abstract": "  In the hierarchical search for periodic sources of gravitational waves, the\ncandidate selection, in the incoherent step, can be performed with Hough\ntransform procedures. In this paper we analyze the problem of sensitivity loss\ndue to discretization of the parameters space vs computing cost, comparing the\nproperties of the sky Hough procedure with those of a new frequency Hough,\nwhich is based on a transformation from the time - observed frequency plane to\nthe source frequency - spin down plane. Results on simulated peak maps suggest\nvarious advantages in favor of the use of the frequency Hough. The ones which\nshow up to really make the difference are 1) the possibility to enhance the\nfrequency resolution without relevantly affecting the computing cost. This\nreduces the digitization effects; 2) the excess of candidates due to local\ndisturbances in some places of the sky map. They do not affect the new analysis\nbecause each map is constructed for only one position in the sky. Pacs.\nnumbers: 04.80Nn,07.05Kf,97.60Jd 1.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The dealternating number and the alternation number of a closed 3-braid",
      "abstract": "  We give an upper bound for the dealternating number of a closed 3-braid. As\napplications, we determine the dealternating numbers, the alternation numbers\nand the Turaev genera of some closed positive 3-braids. We also show that there\nexist infinitely many positive knots with any dealternating number (or any\nalternation number) and any braid index.\n",
      "subjects": [
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Impurity suppression of the critical temperature in the iron-based\n  superconductors",
      "abstract": "  We study the impurity suppression of the critical temperature $T_c$ of the\nFeAs superconductors theoretically based on the the $\\pm$s-wave pairing state\nof a two band model. The effects of non-magnetic and magnetic impurities are\nstudied with the $\\mathcal{T}$-matrix approximation, which can continuously\ntreat impurity scattering from weak to strong coupling limit. We found that\nboth magnetic and non-magnetic impurities suppress $T_c$ with a rate that is\npractically indistinguishable from the standard d-wave case despite a possibly\nlarge difference of the positive and negative s-wave order parameter (OP)\nmagnitudes. This is because the density of states enters together with the OP\nmagnitude for the scattering process.\n",
      "subjects": [
        "cond-mat.supr-con",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Logarithmic Sobolev inequalities: regularizing effect of L\\'evy\n  operators and asymptotic convergence in the L\\'evy-Fokker-Planck equation",
      "abstract": "  In this paper we study some applications of the L\\'evy logarithmic Sobolev\ninequality to the study of the regularity of the solution of the fractal heat\nequation, i. e. the heat equation where the Laplacian is replaced with the\nfractional Laplacian. It is also used to the study of the asymptotic behaviour\nof the L\\'evy-Ornstein-Uhlenbeck process.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Finite time blow-up for radially symmetric solutions to a critical\n  quasilinear Smoluchowski-Poisson system",
      "abstract": "  Finite time blow-up is shown to occur for radially symmetric solutions to a\ncritical quasilinear Smoluchowski-Poisson system provided that the mass of the\ninitial condition exceeds an explicit threshold. In the supercritical case,\nblow-up is shown to take place for any positive mass. The proof relies on a\nnovel identity of virial type.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fermionic correlation functions from the staggered Schr\\\"odinger\n  functional",
      "abstract": "  We consider the Schr\\\"odinger functional with staggered one-component\nfermions on a fine lattice of size $(L/a)^3 \\times (T/a)$ where $T/a$ must be\nan odd number. In order to reconstruct the four-component spinors, two\ndifferent set-ups are proposed, corresponding to the coarse lattice having size\n$(L/2a)^3 \\times (T'/2a)$, with $T' = T \\pm a$. The continuum limit is then\ndefined at fixed $T'/L$. Both cases have previously been investigated in the\npure gauge theory. Here we define fermionic correlation functions and study\ntheir approach to the continuum limit at tree-level of perturbation theory.\n",
      "subjects": [
        "hep-lat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1745-3933.2008.00590.x",
      "title": "Planet formation in the habitable zone of alpha Centauri B",
      "abstract": "  Recent studies have shown that alpha Centauri B might be, from an\nobservational point of view, an ideal candidate for the detection of an\nEarth-like planet in or near its habitable zone (0.5-0.9AU). We study here if\nsuch habitable planets can form, by numerically investigating the\nplanet-formation stage which is probably the most sensitive to binarity\neffects: the mutual accretion of km-sized planetesimals. Using a\nstate-of-the-art algorithm for computing the impact velocities within a test\nplanetesimal population, we find that planetesimal growth is only possible,\nalthough marginally, in the innermost part of the HZ around 0.5AU. Beyond this\npoint, the combination of secular perturbations by the binary companion and gas\ndrag drive the mutual velocities beyond the erosion limit. Impact velocities\nmight later decrease during the gas removal phase, but this probably happens\ntoo late for preventing most km-sized objects to be removed by inward drift,\nthus preventing accretion from starting anew. A more promising hypothesis is\nthat the binary formed in a crowded cluster, where it might have been wider in\nits initial stages, when planetary formation was ongoing. We explore this\nscenario and find that a starting separation roughly 15 AU wider, or an\neccentricity 2.5 times lower than the present ones are required to have an\naccretion-friendly environment in the whole HZ.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.4064/aa145-2-7",
      "title": "On a Diophantine problem with two primes and s powers of two",
      "abstract": "  We refine a recent result of Parsell on the values of the form $\\lambda_1p_1\n+ \\lambda_2p_2 + \\mu_1 2^{m_1} + ...m + \\mu_s 2^{m_s}, $ where $p_1,p_2$ are\nprime numbers, $m_1,...c, m_s$ are positive integers, $\\lambda_1 / \\lambda_2$\nis negative and irrational and $\\lambda_1 / \\mu_1$, $\\lambda_2/\\mu_2 \\in \\Q$.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A solution to the little hierarchy problem in a partly N=2 extension of\n  the MSSM",
      "abstract": "  We extend a model of the Dirac gauginos, which originate from N=2\nsupersymmetry (SUSY) for the gauge sector, such that the N=2 SUSY is imposed\nalso to the sfermion sector but only for the 3rd generation squarks and\nsleptons. In addition to the N=2 supersymmetry, our model is constructed based\non the SU(3)c times SU(3)L times U(1)' gauge symmetry. By this extension, the\ndominant source of radiative correction to the Higgs mass squared coming from\nthe stop loop becomes controllable based on the enhanced symmetry. Then it\nbecomes a viable model which provides a solution to the little hierarchy\nproblem in SUSY models. Even in the original scenario, the Dirac gauginos can\nbe superheavy, of order 10 TeV or so, while keeping the scalar masses at the\nweak scale. This possibility is phenomenologically interesting because it can\nsuppress the unwanted flavor changing processes. And in scope of the LHC, this\nscenario can have a very distinct signature related to the exotic sfermions\nwhich are accompanied as the N=2 superpartners as well as the Dirac gauginos.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.80.041502",
      "title": "Hidden scale invariance in molecular van der Waals liquids: A simulation\n  study",
      "abstract": "  Results from molecular dynamics simulations of two viscous molecular model\nliquids -- the Lewis-Wahnstrom model of ortho-terphenyl and an asymmetric\ndumbbell model -- are reported. We demonstrate that the liquids have a\n``hidden'' approximate scale invariance: Equilibrium potential energy\nfluctuations are accurately described by inverse power law (IPL) potentials,\nthe radial distribution functions are accurately reproduced by the IPL's, and\nthe radial distribution functions obey the IPL predicted scaling properties to\na good approximation. IPL scaling of the dynamics also applies -- with the\nscaling exponent predicted by the equilibrium fluctuations. In contrast, the\nequation of state does not obey the IPL scaling. We argue that our results are\ngeneral for van der Waals liquids, but do not apply, e.g., for hydrogen-bonded\nliquids.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On a new method for controlling exponential processes",
      "abstract": "  Unlike the classical polynomial case there has not been invented up to very\nrecently a tool similar to the Bernstein-Bezier representation which would\nallow us to control the behavior of the exponential polynomials. The\nexponential analog to the classical Bernstein polynomials has been introduced\nin a recent authors' paper which appeared in Constructive Approximations, and\nthis analog retains all basic properties of the classical Bernstein\npolynomials. The main purpose of the present paper is to contribute in this\ndirection, by proving some important properties of the \"Bernstein exponential\noperator\" which has been introduced. We also fix our attention upon some\nspecial type of exponential polynomials which are particularly important for\nthe further development of theory of representation of Multivariate data.\n",
      "subjects": [
        "math.NA",
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Collins diffraction formula and the Wigner function in entangled state\n  representation",
      "abstract": "  Based on the correspondence between Collins diffraction formula (optical\nFresnel transform) and the transformation matrix element of a three-parameters\ntwo-mode squeezing operator in the entangled state representation (Opt. Lett.\n31 (2006) 2622) we further explore the relationship between output field\nintensity determined by the Collins formula and the input field's probability\ndistribution along an infinitely thin phase space strip both in spacial domain\nand frequency domain. The entangled Wigner function is introduced for\nrecapitulating the result.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2009.15161.x",
      "title": "Galaxy shear estimation from stacked images",
      "abstract": "  Statistics of the weak lensing of galaxies can be used to constrain cosmology\nif the galaxy shear can be estimated accurately. In general this requires\naccurate modelling of unlensed galaxy shapes and the point spread function\n(PSF). I discuss suboptimal but potentially robust methods for estimating\ngalaxy shear by stacking images such that the stacked image distribution is\nclosely Gaussian by the central limit theorem. The shear can then be determined\nby radial fitting, requiring only an accurate model of the PSF rather than also\nneeding to model each galaxy accurately. When noise is significant asymmetric\nerrors in the centroid must be corrected, but the method may ultimately be able\nto give accurate un-biased results when there is a high galaxy density with\nconstant shear. It provides a useful baseline for more optimal methods, and a\ntest-case for estimating biases, though the method is not directly applicable\nto realistic data. I test stacking methods on the simple toy simulations with\nconstant PSF and shear provided by the GREAT08 project, on which most other\nexisting methods perform significantly more poorly, and briefly discuss\ngeneralizations to more realistic cases. In the appendix I discuss a simple\nanalytic galaxy population model where stacking gives optimal errors in a\nperfect ideal case.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1751-8113/42/23/235202",
      "title": "Dromion solutions of noncommutative Davey-Stewartson equations",
      "abstract": "  We consider a noncommutative version of the Davey-Stewartson equations and\nderive two families of quasideterminant solution via Darboux and binary Darboux\ntransformations. These solutions can be verified by direct substitution. We\nthen calculate the dromion solutions of the equations and obtain computer plots\nin a noncommutative setting.\n",
      "subjects": [
        "nlin.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.79.134519",
      "title": "Optimal effective current operator for flux qubit accounting for\n  inductive effects",
      "abstract": "  An optimal effective current operator for flux qubit has been investigated by\ntaking account of the inductive effects of the circuit loop. The whole system\nis treated as two interacting subsystems: one is the inductance-free flux qubit\nconsisting of three Josephson junctions and the other a high frequency\nLC-oscillator. As the composite system hardly affords one excessively high\nenergy LC photon, an effective theory for the inductive flux qubit providing\nits physical variable operators has been achieved, which can take account of\nthe inductive effects but does not include the additional degree of freedom for\nthe LC-oscillator. Considering the trade-off between simplicity and accuracy,\nit has been revealed that the optimal effective current operator resulting in\nan error only on the order of $L^{3/2}$ provides an approximation of high\naccuracy, which is also verified numerically.\n",
      "subjects": [
        "cond-mat.supr-con",
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Extension of representations in quasi *-algebras",
      "abstract": "  Let $(A, A_o)$ be a topological quasi *-algebra, which means in particular\nthat $A_o$ is a topological *-algebra, dense in $A$. Let $\\pi^o$ be a\n*-representation of $A_o$ in some pre-Hilbert space ${\\cal D} \\subset {\\cal\nH}$. Then we present several ways of extending\n  $\\pi^o$, by closure, to some larger quasi *-algebra contained in $A$, either\nby Hilbert space operators, or by sesquilinear forms on ${\\cal D}$. Explicit\nexamples are discussed, both abelian and nonabelian, including the CCR algebra.\n",
      "subjects": [
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.80.024030",
      "title": "Fermion Mass Hierarchy from the Soft Wall",
      "abstract": "  We develop a 5d model for ElectroWeak physics based on a non compact warped\nextra dimension of finite length, known as the soft wall scenario, where all\nthe dynamical degrees of freedom propagate in the 5d bulk. We solve the\nequations of motion and find the allowed spectra, showing that the mass of the\nlightest fermionic mode behaves as a power law of the effective 4d Yukawa\ncoupling constant, with the exponent being the corresponding fermionic 5d bulk\nmass. Precisely this non universal behavior allows us to reproduce the\nhierarchy between the Standard Model (SM) fermion masses (from neutrinos to the\ntop quark) with non-hierarchical fermionic bulk masses.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Time to fixation in the presence of recombination",
      "abstract": "  We study the evolutionary dynamics of a haploid population of infinite size\nrecombining with a probability $r$ in a two locus model. Starting from a low\nfitness locus, the population is evolved under mutation, selection and\nrecombination until a finite fraction of the population reaches the fittest\nlocus. An analytical method is developed to calculate the fixation time $T$ to\nthe fittest locus for various choices of epistasis. We find that (1) for\nnegative epistasis, $T$ decreases slowly for small $r$ but decays fast at\nlarger $r$ (2) for positive epistasis, $T$ increases linearly for small $r$ and\nmildly for large $r$ (3) for compensatory mutation, $T$ diverges as a power law\nwith logarithmic corrections as the recombination fraction approaches a\ncritical value. Our calculations are seen to be in good agreement with the\nexact numerical results.\n",
      "subjects": [
        "q-bio.PE",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On Node Density -- Outage Probability Tradeoff in Wireless Networks",
      "abstract": "  A statistical model of interference in wireless networks is considered, which\nis based on the traditional propagation channel model and a Poisson model of\nrandom spatial distribution of nodes in 1-D, 2-D and 3-D spaces with both\nuniform and non-uniform densities. The power of nearest interferer is used as a\nmajor performance indicator, instead of a traditionally-used total interference\npower, since at the low outage region, they have the same statistics so that\nthe former is an accurate approximation of the latter. This simplifies the\nproblem significantly and allows one to develop a unified framework for the\noutage probability analysis, including the impacts of complete/partial\ninterference cancelation, of different types of fading and of linear filtering,\neither alone or in combination with each other. When a given number of nearest\ninterferers are completely canceled, the outage probability is shown to scale\ndown exponentially in this number. Three different models of partial\ncancelation are considered and compared via their outage probabilities. The\npartial cancelation level required to eliminate the impact of an interferer is\nquantified. The effect of a broad class of fading processes (including all\npopular fading models) is included in the analysis in a straightforward way,\nwhich can be positive or negative depending on a particular model and\npropagation/system parameters. The positive effect of linear filtering (e.g. by\ndirectional antennas) is quantified via a new statistical selectivity\nparameter. The analysis results in formulation of a tradeoff relationship\nbetween the network density and the outage probability, which is a result of\nthe interplay between random geometry of node locations, the propagation path\nloss and the distortion effects at the victim receiver.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/pasj/61.4.L29",
      "title": "Effects of Mutual Transits by Extrasolar Planet-Companion Systems on\n  Light Curves",
      "abstract": "  We consider the effects of mutual transits by extrasolar planet-companion\nsystems (in a true binary or a planet-satellite system) on light curves. We\nshow that induced changes in light curves depend strongly on a ratio between a\nplanet-companion's orbital velocity around their host star and a\nplanet-companion's spin speed around their common center of mass. In both the\nslow and fast spin cases (corresponding to long and short distances between\nthem, respectively), a certain asymmetry appears in light curves. We show that,\nespecially in the case of short distances, occultation of one faint object by\nthe other, while the transit of the planet-companion system occurs in front of\nits parent star, causes an apparent increase in light curves and characteristic\nfluctuations appear as important evidence of mutual transits. We show also that\nextrasolar mutual transits provide a complementary method of measuring the\nradii of two transiting objects, their separation and mass, and consequently\nidentifying them as a true binary, planet-satellite system or others.\nMonitoring $10^5$ stars for three years with Kepler may lead to a discovery of\na second Earth-Moon-like system if the fraction of such systems for an averaged\nstar is larger than 0.05, or it may put upper limits on the fraction as f <\n0.05.\n",
      "subjects": [
        "astro-ph.EP",
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Threshold Verification Technique for Network Intrusion Detection System",
      "abstract": "  Internet has played a vital role in this modern world, the possibilities and\nopportunities offered are limitless. Despite all the hype, Internet services\nare liable to intrusion attack that could tamper the confidentiality and\nintegrity of important information. An attack started with gathering the\ninformation of the attack target, this gathering of information activity can be\ndone as either fast or slow attack. The defensive measure network administrator\ncan take to overcome this liability is by introducing Intrusion Detection\nSystems (IDSs) in their network. IDS have the capabilities to analyze the\nnetwork traffic and recognize incoming and on-going intrusion. Unfortunately\nthe combination of both modules in real time network traffic slowed down the\ndetection process. In real time network, early detection of fast attack can\nprevent any further attack and reduce the unauthorized access on the targeted\nmachine. The suitable set of feature selection and the correct threshold value,\nadd an extra advantage for IDS to detect anomalies in the network. Therefore\nthis paper discusses a new technique for selecting static threshold value from\na minimum standard features in detecting fast attack from the victim\nperspective. In order to increase the confidence of the threshold value the\nresult is verified using Statistical Process Control (SPC). The implementation\nof this approach shows that the threshold selected is suitable for identifying\nthe fast attack in real time.\n",
      "subjects": [
        "cs.CR",
        "cs.NI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1367-2630/12/2/025018",
      "title": "Topological Color Codes and Two-Body Quantum Lattice Hamiltonians",
      "abstract": "  Topological color codes are among the stabilizer codes with remarkable\nproperties from quantum information perspective. In this paper we construct a\nfour-valent lattice, the so called ruby lattice, governed by a 2-body\nHamiltonian. In a particular regime of coupling constants, degenerate\nperturbation theory implies that the low energy spectrum of the model can be\ndescribed by a many-body effective Hamiltonian, which encodes the color code as\nits ground state subspace. The gauge symmetry\n$\\mathbf{Z}_{2}\\times\\mathbf{Z}_{2}$ of color code could already be realized by\nidentifying three distinct plaquette operators on the lattice. Plaquettes are\nextended to closed strings or string-net structures. Non-contractible closed\nstrings winding the space commute with Hamiltonian but not always with each\nother giving rise to exact topological degeneracy of the model. Connection to\n2-colexes can be established at the non-perturbative level. The particular\nstructure of the 2-body Hamiltonian provides a fruitful interpretation in terms\nof mapping to bosons coupled to effective spins. We show that high energy\nexcitations of the model have fermionic statistics. They form three families of\nhigh energy excitations each of one color. Furthermore, we show that they\nbelong to a particular family of topological charges. Also, we use\nJordan-Wigner transformation in order to test the integrability of the model\nvia introducing of Majorana fermions. The four-valent structure of the lattice\nprevents to reduce the fermionized Hamiltonian into a quadratic form due to\ninteracting gauge fields. We also propose another construction for 2-body\nHamiltonian based on the connection between color codes and cluster states. We\ndiscuss this latter approach along the construction based on the ruby lattice.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Icequakes as precursors of ice avalanches",
      "abstract": "  A hanging glacier at the east face of Weisshorn broke off in 2005. We were\nable to monitor and measure surface motion and icequake activity for 21 days up\nto three days prior to the break-off. Results are presented from the analysis\nof seismic waves generated by the glacier during the rupture maturation\nprocess. Three types of precursory signals of the imminent catastrophic rupture\nwere identified: (i) an increasing seismic activity within the glacier, (ii) a\nchange in the size-frequency distribution of icequake energy, and (iii) a\nlog-periodic oscillating behavior superimposed on power law acceleration of the\ninverse of waiting time between two icequakes. The analysis of the seismic\nactivity gave indications of the rupture process and led to the identification\nof two regimes: a stable one where events are isolated and non correlated which\nis characteristic of diffuse damage, and an unstable and dangerous one in which\nevents become synchronized and large icequakes are triggered.\n",
      "subjects": [
        "physics.geo-ph",
        "physics.data-an"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1126-6708/2009/08/111",
      "title": "Patterns of remnant discrete symmetries",
      "abstract": "  We analyze patterns of remnant discrete symmetries that arise from U(1)^N\ntheories by spontaneous breaking. We describe a simple, geometrical way to\nunderstand these patterns and provide methods for identifying the discrete\nsymmetries and bringing them to the simplest possible form. Applications in GUT\nand string model building are briefly discussed.\n",
      "subjects": [
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.4204/EPTCS.3.1",
      "title": "Probabilistic Automata over Infinite Words: Expressiveness, Efficiency,\n  and Decidability",
      "abstract": "  Probabilistic omega-automata are variants of nondeterministic automata for\ninfinite words where all choices are resolved by probabilistic distributions.\nAcceptance of an infinite input word can be defined in different ways: by\nrequiring that (i) the probability for the accepting runs is positive (probable\nsemantics), or (ii) almost all runs are accepting (almost-sure semantics), or\n(iii) the probability measure of the accepting runs is greater than a certain\nthreshold (threshold semantics). The underlying notion of an accepting run can\nbe defined as for standard omega-automata by means of a Buechi condition or\nother acceptance conditions, e.g., Rabin or Streett conditions. In this paper,\nwe put the main focus on the probable semantics and provide a summary of the\nfundamental properties of probabilistic omega-automata concerning\nexpressiveness, efficiency, and decision problems.\n",
      "subjects": [
        "cs.FL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Probing New Physics in Charm Couplings with Kaon and Other Hadron\n  Processes",
      "abstract": "  It is possible that the low-energy effects of physics beyond the standard\nmodel can be parametrized mainly by anomalous couplings of quarks to the W\nboson. Such couplings can generate potentially significant contributions to\nvarious transitions that can be probed by current and future experiments. This\nwork explores constraints on anomalous charm-W couplings from a number of\nCP-conserving and -violating processes involving the kaon and other flavored\nhadrons.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Manipulation and gender neutrality in stable marriage procedures",
      "abstract": "  The stable marriage problem is a well-known problem of matching men to women\nso that no man and woman who are not married to each other both prefer each\nother. Such a problem has a wide variety of practical applications ranging from\nmatching resident doctors to hospitals to matching students to schools. A\nwell-known algorithm to solve this problem is the Gale-Shapley algorithm, which\nruns in polynomial time.\n  It has been proven that stable marriage procedures can always be manipulated.\nWhilst the Gale-Shapley algorithm is computationally easy to manipulate, we\nprove that there exist stable marriage procedures which are NP-hard to\nmanipulate. We also consider the relationship between voting theory and stable\nmarriage procedures, showing that voting rules which are NP-hard to manipulate\ncan be used to define stable marriage procedures which are themselves NP-hard\nto manipulate. Finally, we consider the issue that stable marriage procedures\nlike Gale-Shapley favour one gender over the other, and we show how to use\nvoting rules to make any stable marriage procedure gender neutral.\n",
      "subjects": [
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.4204/EPTCS.9.9",
      "title": "An Intuitive Automated Modelling Interface for Systems Biology",
      "abstract": "  We introduce a natural language interface for building stochastic pi calculus\nmodels of biological systems. In this language, complex constructs describing\nbiochemical events are built from basic primitives of association, dissociation\nand transformation. This language thus allows us to model biochemical systems\nmodularly by describing their dynamics in a narrative-style language, while\nmaking amendments, refinements and extensions on the models easy. We\ndemonstrate the language on a model of Fc-gamma receptor phosphorylation during\nphagocytosis. We provide a tool implementation of the translation into a\nstochastic pi calculus language, Microsoft Research's SPiM.\n",
      "subjects": [
        "cs.PL",
        "cs.CE",
        "cs.LO",
        "q-bio.QM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Correlations beyond the horizon",
      "abstract": "  We have imaged spontaneously created arrays of vortices (magnetic flux\nquanta), generated in a superconducting film quenched through its transition\ntemperature at rates around $10^9 K/s$. Spontaneous appearance of vortices is\npredicted by Kibble-Zurek and by Hindmarsh-Rajantie models of phase transitions\nunder non-equilibrium conditions. Differentiating between these models requires\na measurement of the internal correlations within the emerging vortex array. In\naddition to short range correlations predicted by Kibble and Zurek, we found\nunexpected long range correlations which are not described by any of the\nexisting models.\n",
      "subjects": [
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dynamical behavior of Darboux curves",
      "abstract": "  In 1872 G. Darboux defined a family of curves on surfaces of R^3 which are\npreserved by the action of the Mobius group and share many properties with\ngeodesics. Here we characterize these curves under the view point of Lorentz\ngeometry and prove some general properties and make them explicit them on\nsimple surfaces, retrieving results of Pell (1900) and Santalo (1941).\n",
      "subjects": [
        "math.DG",
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epja/i2010-10929-7",
      "title": "Interplay of quark and meson degrees of freedom in a near-threshold\n  resonance",
      "abstract": "  We investigate the interplay of quark and meson degrees of freedom in a\nphysical state representing a near-threshold resonance for the case of a single\ncontinuum channel. We demonstrate that such a near-threshold resonance may\npossess quite peculiar properties if both quark and meson dynamics generate\nweakly coupled near-threshold poles in the S-matrix. In particular, the\nscattering t-matrix may possess zeros in this case. We also discuss possible\nimplications for production reactions as well as studies within lattice QCD.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.84.034312",
      "title": "Reduced neutron widths in the nuclear data ensemble: Experiment and\n  theory do not agree",
      "abstract": "  I have analyzed reduced neutron widths ({\\Gamma}_{n}^0) for the subset of\n1245 resonances in the nuclear data ensemble (NDE) for which they have been\nreported. Random matrix theory (RMT) predicts for the Gaussian orthogonal\nensemble (GOE) that these widths should follow a \\c{hi}^2 distribution having\none degree of freedom ({\\nu}=1) - the Porter Thomas distribution (PTD). Careful\nanalysis of the {\\Gamma}_{n}^2 values in the NDE rejects the validity of the\nPTD with a statistical significance of at least 99.97% ({\\nu}=0.801\\pm0.052).\nThis striking disagreement with the RMT prediction is most likely due to the\ninclusion of significant p-wave contamination to the supposedly pure s-wave\nNDE. When an energy dependent threshold is used to remove the p-wave\ncontamination, the PTD is still rejected with a statistical significance of at\nleast 98.17% ({\\nu}=1.217\\pm0.092). Furthermore, examination of the primary\nreferences for the NDE reveals that many resonances in most of the individual\ndata sets were selected using methods derived from RMT. Therefore, using the\nfull NDE data set to test RMT predictions seems highly questionable. These\nresults cast very serious doubt on claims that the NDE represents a striking\nconfirmation of RMT.\n",
      "subjects": [
        "nucl-th",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the Makar-Limanov, Derksen invariants, and finite automorphism groups\n  of algebraic varieties",
      "abstract": "  A simple method of constructing a big stock of algebraic varieties with\ntrivial Makar-Limanov invariant is described, the Derksen invariant of some\nvarieties is computed, the generalizations of the Makar-Limanov and Derksen\ninvariants are introduced and discussed, and some results on the Jordan\nproperty of automorphism groups of algebraic varieties are obtained.\n",
      "subjects": [
        "math.AG",
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non-Gaussian Quasi Maximum Likelihood Estimation of GARCH Models",
      "abstract": "  The non-Gaussian quasi maximum likelihood estimator is frequently used in\nGARCH models with intension to improve the efficiency of the GARCH parameters.\nHowever, unless the quasi-likelihood happens to be the true one, non-Gaussian\nQMLE methods suffers inconsistency even if shape parameters in the\nquasi-likelihood are estimated. To correct this bias, we identify an unknown\nscale parameter that is critical to the consistent estimation of non-Gaussian\nQMLE, and propose a two-step non-Gaussian QMLE (2SNG-QMLE) for estimation of\nthe scale parameter and GARCH parameters. This novel approach is consistent and\nasymptotically normal. Moreover, it has higher efficiency than the Gaussian\nQMLE, particularly when the innovation error has heavy tails. Two extensions\nare proposed to further improve the efficiency of 2SNG-QMLE. The impact of\nrelative heaviness of tails of the innovation and quasi-likelihood\ndistributions on the asymptotic efficiency has been thoroughly investigated.\nMonte Carlo simulations and an empirical study confirm the advantages of the\nproposed approach.\n",
      "subjects": [
        "stat.ME",
        "math.ST",
        "stat.AP",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1209/0295-5075/90/60003",
      "title": "Conservation laws for strings in the Abelian Sandpile Model",
      "abstract": "  The Abelian Sandpile generates complex and beautiful patterns and seems to\ndisplay allometry. On the plane, beyond patches, patterns periodic in both\ndimensions, we remark the presence of structures periodic in one dimension,\nthat we call strings. We classify completely their constituents in terms of\ntheir principal periodic vector k, that we call momentum. We derive a simple\nrelation between the momentum of a string and its density of particles, E,\nwhich is reminiscent of a dispersion relation, E=k^2. Strings interact: they\ncan merge and split and within these processes momentum is conserved. We reveal\nthe role of the modular group SL(2,Z) behind these laws.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "hep-lat",
        "math.CO",
        "nlin.CG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Gradings by Groups on Graded Cartan Type Lie Algebras",
      "abstract": "  In this paper we describe all gradings by abelian groups without elements of\norder p, where p > 2 is the characteristic of the base field, on the simple\ngraded Cartan type Lie algebras.\n",
      "subjects": [
        "math.RA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.81.104046",
      "title": "Accelerated expansion from a non-minimal gravitational coupling to\n  matter",
      "abstract": "  It is shown that a non-minimal coupling between the scalar curvature and the\nmatter Lagrangian density may account for the accelerated expansion of the\nUniverse and provide, through mimicking, for a viable unification of dark\nenergy and dark matter. An analytical exploration is first performed, and a\nnumerical study is then used to validate the obtained results. The encountered\nscenario allows for a better grasp of the proposed mechanism, and sets up the\ndiscussion for improvements that can lead to a complete agreement with the\nobservational data.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s13130-010-0528-2",
      "title": "NLIE and finite size effects of the spin-1/2 XXZ and sine-Gordon models\n  with two boundaries revisited",
      "abstract": "  Starting from the T-Q equation of an open integrable spin-1/2 XXZ quantum\nspin chain with nondiagonal boundary terms, we derive a nonlinear integral\nequation (NLIE) of the sine-Gordon model on a finite interval. We compute the\nboundary energy and the Casimir energy for the sine-Gordon model with both left\nand right boundaries. A relation between the boundary parameters of the\ncontinuum model and the lattice model is given. We also present numerical\nresults for the effective central charge of an open spin-1/2 XXZ quantum spin\nchain which find agreement with our analytical result for the central charge of\nthe sine-Gordon model in the ultraviolet (UV) limit.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/715/1/477",
      "title": "The role of newly born magnetars in gamma-ray burst X-ray afterglow\n  emission: Energy injection and internal emission",
      "abstract": "  Swift observations suggest that the central compact objects of some gamma-ray\nbursts (GRBs) could be newly born millisecond magnetars. Therefore, by\nconsidering the spin evolution of the magnetars against r-mode instability, we\ninvestigate the role of the magnetars in GRB X-ray afterglow emission. Besides\nmodifying the conventional energy injection model, we pay particular attention\nto the internal X-ray afterglow emission, whose luminosity is assumed to track\nthe magnetic dipole luminosity of the magentars with a certain fraction.\nFollowing a comparison between the model and some selected observational\nsamples, we suggest that some so-called \"canonical\" X-ray afterglows including\nthe shallow decay, normal decay, and steeper-than-normal decay phases could be\ninternally produced by the magnetars (possibly through some internal\ndissipations of the magnetar winds), while the (energized) external shocks are\nassociated with another type of X-ray afterglows. If this is true, from those\ninternal X-ray afterglows, we can further determine the magnetic field\nstrengths and the initial spin periods of the corresponding magnetars.\n",
      "subjects": [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Reversibility of Whole-Plane SLE",
      "abstract": "  The main result of this paper is that, for $\\kappa\\in(0,4]$, whole-plane\nSLE$_\\kappa$ satisfies reversibility, which means that the time-reversal of a\nwhole-plane SLE$_\\kappa$ trace is still a whole-plane SLE$_\\kappa$ trace. In\naddition, we find that the time-reversal of a radial SLE$_\\kappa$ trace for\n$\\kappa\\in(0,4]$ is a disc SLE$_\\kappa$ trace with a marked boundary point. The\nmain tool used in this paper is a stochastic coupling technique, which is used\nto couple two whole-plane SLE$_\\kappa$ traces so that they overlap. Another\ntool used is the Feynman-Kac formula, which is used to solve a PDE. The\nsolution of this PDE is then used to construct the above coupling.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Impact on cosmology of the celestial anisotropy of the short gamma-ray\n  bursts",
      "abstract": "  Recently the anisotropy of the short gamma-ray bursts detected by BATSE was\nannounced (Vavrek et al. 2008). The impact of this discovery on cosmology is\ndiscussed. It is shown that the anisotropy found may cause the breakdown of the\ncosmological principle.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Solving Inverse Problems with Piecewise Linear Estimators: From Gaussian\n  Mixture Models to Structured Sparsity",
      "abstract": "  A general framework for solving image inverse problems is introduced in this\npaper. The approach is based on Gaussian mixture models, estimated via a\ncomputationally efficient MAP-EM algorithm. A dual mathematical interpretation\nof the proposed framework with structured sparse estimation is described, which\nshows that the resulting piecewise linear estimate stabilizes the estimation\nwhen compared to traditional sparse inverse problem techniques. This\ninterpretation also suggests an effective dictionary motivated initialization\nfor the MAP-EM algorithm. We demonstrate that in a number of image inverse\nproblems, including inpainting, zooming, and deblurring, the same algorithm\nproduces either equal, often significantly better, or very small margin worse\nresults than the best published ones, at a lower computational cost.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1155/2013/543717",
      "title": "Dark energy from the gas of wormholes",
      "abstract": "  We assume the space-time foam picture in which the vacuum is filled with a\ngas of virtual wormholes. It is shown that virtual wormholes form a finite (of\nthe Planckian order) value of the energy density of zero-point fluctuations.\nHowever such a huge value is compensated by the contribution of virtual\nwormholes to the mean curvature and the observed value of the cosmological\nconstant is close to zero. A non-vanishing value appears due to the\npolarization of vacuum in external classical fields. In the early Universe some\nvirtual wormholes may form actual ones. We show that in the case of actual\nwormholes vacuum polarization effects are negligible while their contribution\nto the mean curvature is apt to form the observed dark energy phenomenon. Using\nthe contribution of wormholes to dark matter and dark energy we find estimates\nfor characteristic parameters of the gas of wormholes.\n",
      "subjects": [
        "astro-ph.CO",
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/721/1/547",
      "title": "Pressure Support in Galaxy Disks: Impact on Rotation Curves and Dark\n  Matter Density Profiles",
      "abstract": "  Rotation curves constrain a galaxy's underlying mass density profile, under\nthe assumption that the observed rotation produces a centripetal force that\nexactly balances the inward force of gravity. However, most rotation curves are\nmeasured using emission lines from gas, which can experience additional forces\ndue to pressure. In realistic galaxy disks, the gas pressure declines with\nradius, providing additional radial support to the disk. The measured\ntangential rotation speed will therefore tend to lag the true circular velocity\nof a test particle. The gas pressure is dominated by turbulence, and we\nevaluate its likely amplitude from recent estimates of the gas velocity\ndispersion and surface density. We show that where the amplitude of the\nrotation curve is comparable to the characteristic velocities of the\ninterstellar turbulence, pressure support may lead to underestimates of the\nmass density of the underlying dark matter halo and the inner slope of its\ndensity profile. These effects may be significant for galaxies with rotation\nspeeds <75km/s, but are unlikely to be significant in higher mass galaxies. We\nfind that pressure support can be sustained over long timescales, because any\nreduction in support due to the conversion of gas into stars is compensated for\nby an inward flow of gas. However, we point to many uncertainties in assessing\nthe importance of pressure support in galaxies. Thus, while pressure support\nmay alleviate possible tensions between rotation curve observations and\nLambdaCDM on kiloparsec scales, it should not be viewed as a definitive\nsolution at this time.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1475-7516/2011/04/019",
      "title": "A Matter Bounce By Means of Ghost Condensation",
      "abstract": "  Assuming the existence of a scalar field which undergoes \"ghost condensation\"\nand which has a suitably chosen potential, it is possible to obtain a\nnon-singular bouncing cosmology in the presence of regular matter and\nradiation. The potential for the ghost condensate field can be chosen such that\nthe cosmological bounce is stable against the presence of anisotropic stress.\nCosmological fluctuations on long wavelengths relevant to current cosmological\nobservations pass through the bounce unaffected by the new physics which yields\nthe bounce. Thus, this model allows for the realization of the \"matter bounce\"\nscenario, an alternative to inflationary cosmology for the generation of the\nobserved primordial fluctuations in which the inhomogeneities originate as\nquantum vacuum perturbations which exit the Hubble radius in the\nmatter-dominated phase of contraction.\n",
      "subjects": [
        "hep-th",
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Process convergence of self normalized sums of i.i.d. random variables\n  coming from domain of attraction of stable distributions",
      "abstract": "  In this paper we show that the continuous version of the self normalised\nprocess $Y_{n,p}(t)= S_n(t)/V_{n,p}+(nt-[nt])X_{[nt]+1}/V_{n,p}$ where\n$S_n(t)=\\sum_{i=1}^{[nt]} X_i$ and $V_{(n,p)}=\n\\sum_{i=1}^{n}|X_i|^p)^{\\frac{1}{p}}$ and $X_i$ i.i.d. random variables belong\nto $DA(\\alpha)$, has a non trivial distribution iff $p=\\alpha=2$. The case for\n$2 > p > \\alpha$ and $p \\le \\alpha < 2$ is systematically eliminated by showing\nthat either of tightness or finite dimensional convergence to a non-degenerate\nlimiting distribution does not hold. This work is an extension of the work by\nCs\\\"org\\\"o et al. who showed Donsker's theorem for $Y_{n,2}(\\cdot)$, i.e., for\n$p=2$, holds iff $\\alpha =2$ and identified the limiting process as standard\nBrownian motion in sup norm.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.82.074023",
      "title": "Forward dijets in high-energy collisions: evolution of QCD n-point\n  functions beyond the dipole approximation",
      "abstract": "  Present knowledge of QCD n-point functions of Wilson lines at high energies\nis rather limited. In practical applications, it is therefore customary to\nfactorize higher n-point functions into products of two-point functions\n(dipoles) which satisfy the BK evolution equation. We employ the JIMWLK\nformalism to derive explicit evolution equations for the 4- and 6-point\nfunctions of fundamental Wilson lines and show that if the Gaussian\napproximation is carried out before the rapidity evolution step is taken, then\nmany leading order N_c contributions are missed. Our evolution equations could\nspecifically be used to improve calculations of forward dijet angular\ncorrelations, recently measured by the STAR collaboration in deuteron-gold\ncollisions at the RHIC collider. Forward dijets in proton-proton collisions at\nthe LHC probe QCD evolution at even smaller light-cone momentum fractions. Such\ncorrelations may provide insight into genuine differences between the JIMWLK\nand BK approaches.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2010.17542.x",
      "title": "The optical morphologies of the 2Jy sample of radio galaxies: evidence\n  for galaxy interactions",
      "abstract": "  We present deep GMOS-S/Gemini optical broad-band images for a complete sample\nof 46 southern 2Jy radio galaxies at intermediate redshifts (0.05<z<0.7). The\nhigh-quality observations show for the first time that the overall majority of\nPRGs at intermediate redshifts (78-85%) show peculiarities in their optical\nmorphologies at relatively high levels of surface brightness ($\\mu$v=23.6 and\n{\\Delta}$\\mu$v~[21,26] mag arcsec-2) including tails, fans, bridges, shells,\ndust lanes, irregular features, amorphous haloes, and multiple nuclei. While\nthe results for many of the galaxies are consistent with them being observed\nat, or after, the time of coalescence of the nuclei in a galaxy merger, we find\nthat more than 1/3 of the sample are observed in a pre-coalescence phase of the\nmerger, or following a close encounter between galaxies. By dividing the sample\ninto Weak-Line Radio Galaxies (WLRGs; 11 objects) and Strong-Line Radio\nGalaxies (SLRGs; 35 objects) we find that only 27% of the former show clear\nevidence for interactions in their optical morphologies, in contrast to the\nSLRGs, of which at least 94% appear interacting. This is consistent with the\nidea that many WLRGs are fuelled/triggered by Bondi accretion of hot gas. Of\nthe 28% of the sample that display evidence for significant starburst activity,\nwe find that 92% present disturbed morphologies, following the same general\ntrend as the total and SLRG samples. By comparing our PRGs with various samples\nof quiescent ellipticals from the literature, we conclude that the percentage\nof morphological disturbance that we find here exceeds that found for quiescent\nellipticals when similar surface brightnesses are considered. Overall, our\nstudy indicates that galaxy interactions are likely to play a key role in the\ntriggering of AGN/jet activity.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/726/2/102",
      "title": "Spatial Damping of Propagating Kink Waves in Prominence Threads",
      "abstract": "  Transverse oscillations and propagating waves are frequently observed in\nthreads of solar prominences/filaments and have been interpreted as kink\nmagnetohydrodynamic (MHD) modes. We investigate the spatial damping of\npropagating kink MHD waves in transversely nonuniform and partially ionized\nprominence threads. Resonant absorption and ion-neutral collisions (Cowling's\ndiffusion) are the damping mechanisms taken into account. The dispersion\nrelation of resonant kink waves in a partially ionized magnetic flux tube is\nnumerically solved by considering prominence conditions. Analytical expressions\nof the wavelength and damping length as functions of the kink mode frequency\nare obtained in the Thin Tube and Thin Boundary approximations. For typically\nreported periods of thread oscillations, resonant absorption is an efficient\nmechanism for the kink mode spatial damping, while ion-neutral collisions have\na minor role. Cowling's diffusion dominates both the propagation and damping\nfor periods much shorter than those observed. Resonant absorption may explain\nthe observed spatial damping of kink waves in prominence threads. The\ntransverse inhomogeneity length scale of the threads can be estimated by\ncomparing the observed wavelengths and damping lengths with the theoretically\npredicted values. However, the ignorance of the form of the density profile in\nthe transversely nonuniform layer introduces inaccuracies in the determination\nof the inhomogeneity length scale.\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.83.044022",
      "title": "Quantum dynamics of the Einstein-Rosen wormhole throat",
      "abstract": "  We consider the polymer quantization of the Einstein wormhole throat theory\nfor an eternal Schwarzschild black hole. We numerically solve the difference\nequation describing the quantum evolution of an initially Gaussian,\nsemi-classical wave packet. As expected from previous work on loop quantum\ncosmology, the wave packet remains semi-classical until it nears the classical\nsingularity at which point it enters a quantum regime in which the fluctuations\nbecome large. The expectation value of the radius reaches a minimum as the wave\npacket is reflected from the origin and emerges to form a near Gaussian but\nasymmetrical semi-classical state at late times. The value of the minimum\ndepends in a non-trivial way on the initial mass/energy of the pulse, its width\nand the polymerization scale. For wave packets that are sufficiently narrow\nnear the bounce, the semi-classical bounce radius is obtained. Although the\nnumerics become difficult to control in this limit, we argue that for pulses of\nfinite width the bounce persists as the polymerization scale goes to zero,\nsuggesting that in this model the loop quantum gravity effects mimicked by\npolymer quantization do not play a crucial role in the quantum bounce.\n",
      "subjects": [
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Existence of Weighted Pseudo Almost Periodic Solutions to Some Classes\n  of Nonautonomous Partial Evolution Equations",
      "abstract": "  In this paper, under Acquistpace-Terreni conditions, we make extensive use of\ninterpolation spaces and exponential dichotomy techniques to obtain the\nexistence of weighted pseudo almost periodic solutions to some classes of\nnonautonomous partial evolution equations. Applications include the existence\nof weighted pseudo almost periodic solutions to a nonautonomous heat equation\nwith gradient coefficients.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/OL.36.000280",
      "title": "Diode-pumped Pr:BaY2F8 cw orange laser",
      "abstract": "  We report the realization of the continuous wave laser emission in the orange\nat 607 nm from a Pr:BaY2F8 (Pr:BYF) crystal pumped by a blue GaN laser diode. A\nmaximal output power of 78 mW is obtained in a quasi single transverse mode\nbeam. The effect of reabsorption losses at the laser wavelength is also\nevidenced\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2010.17937.x",
      "title": "Particle reacceleration by compressible turbulence in galaxy clusters:\n  effects of reduced mean free path",
      "abstract": "  Direct evidence for in situ particle acceleration mechanisms in the\ninter-galactic-medium (IGM) is provided by the diffuse Mpc--scale synchrotron\nemissions observed from galaxy clusters. It has been proposed that MHD\nturbulence, generated during cluster-cluster mergers, may be a source of\nparticle reacceleration in the IGM. Calculations of turbulent acceleration must\naccount self-consistently for the complex non--linear coupling between\nturbulent waves and particles. This has been calculated in some detail under\nthe assumption that turbulence interacts in a collisionless way with the IGM.\nIn this paper we explore a different picture of acceleration by compressible\nturbulence in galaxy clusters, where the interaction between turbulence and the\nIGM is mediated by plasma instabilities and maintained collisional at scales\nmuch smaller than the Coulomb mean free path. In this regime most of the energy\nof fast modes is channeled into the reacceleration of relativistic particles\nand the acceleration process approaches a universal behaviour being\nself-regulated by the back-reaction of the accelerated particles on turbulence\nitself. Assuming that relativistic protons contribute to several percent (or\nless) of the cluster energy, consistent with the FERMI observations of nearby\nclusters, we find that compressible turbulence at the level of a few percent of\nthe thermal energy can reaccelerate relativistic electrons at GeV energies,\nthat are necessary to explain the observed diffuse radio emission in the form\nof giant radio halos.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Free energy computations by minimization of Kullback-Leibler divergence:\n  an efficient adaptive biasing potential method for sparse representations",
      "abstract": "  The present paper proposes an adaptive biasing potential for the computation\nof free energy landscapes. It is motivated by statistical learning arguments\nand unifies the tasks of biasing the molecular dynamics to escape free energy\nwells and estimating the free energy function, under the same objective. It\noffers rigorous convergence diagnostics even though history dependent,\nnon-Markovian dynamics are employed. It makes use of a greedy optimization\nscheme in order to obtain sparse representations of the free energy function\nwhich can be particularly useful in multidimensional cases. It employs\nembarrassingly parallelizable sampling schemes that are based on adaptive\nSequential Monte Carlo and can be readily coupled with legacy molecular\ndynamics simulators. The sequential nature of the learning and sampling scheme\nenables the efficient calculation of free energy functions parametrized by the\ntemperature. The characteristics and capabilities of the proposed method are\ndemonstrated in three numerical examples.\n",
      "subjects": [
        "math-ph",
        "math.MP",
        "physics.comp-ph",
        "stat.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP01(2011)123",
      "title": "The first order hydrodynamics via AdS/CFT correspondence in the\n  Gauss-Bonnet gravity",
      "abstract": "  In the spirit of the AdS/CFT correspondence, we investigate the hydrodynamics\nof the dual conformal field in the Gauss-Bonnet gravity. By considering the\nparameters of the boosted black brane in the Gauss-Bonnet gravity as functions\nof boundary coordinates, and then solving the corresponding correction terms,\nwe calculate the first order stress-energy tensor of the dual conformal field.\nFrom this first order stress-energy tensor, we also obtain the shear viscosity\nand entropy density. And these results are consistent with those of some\nprevious works from the effective coupling of gravitons.\n",
      "subjects": [
        "hep-th",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.83.032011",
      "title": "Measurement of the underground atmospheric muon charge ratio using the\n  MINOS Near Detector",
      "abstract": "  The magnetized MINOS Near Detector, at a depth of 225 meters of water\nequivalent (mwe), is used to measure the atmospheric muon charge ratio. The\nratio of observed positive to negative atmospheric muon rates, using 301 days\nof data, is measured to be 1.266+/-0.001(stat.)+0.015/-0.014(syst.). This\nmeasurement is consistent with previous results from other shallow underground\ndetectors, and is 0.108+/-0.019(stat. + syst.) lower than the measurement at\nthe functionally identical MINOS Far Detector at a depth of 2070 mwe. This\nincrease in charge ratio as a function of depth is consistent with an increase\nin the fraction of muons arising from kaon decay for increasing muon surface\nenergies.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Logarithmic tensor category theory, VI: Expansion condition,\n  associativity of logarithmic intertwining operators, and the associativity\n  isomorphisms",
      "abstract": "  This is the sixth part in a series of papers in which we introduce and\ndevelop a natural, general tensor category theory for suitable module\ncategories for a vertex (operator) algebra. In this paper (Part VI), we\nconstruct the appropriate natural associativity isomorphisms between triple\ntensor product functors. In fact, we establish a \"logarithmic operator product\nexpansion\" theorem for logarithmic intertwining operators. In this part, a\ngreat deal of analytic reasoning is needed; the statements of the main theorems\nthemselves involve convergence assertions.\n",
      "subjects": [
        "math.QA",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.83.037503",
      "title": "Vector meson dominance and the pi^0 transition form factor",
      "abstract": "  It is shown that the pi^0 transition form factor F(Q_1^2,Q_2^2) differs\nsubstantially from its one-real-photon limit F(Q_1^2,0) even for rather small\nvalues of Q_2^2 (approx 0.1 GeV^2), which cannot be excluded in experiments\nwith one \"untagged\" electron. It indicates that the comparison of data with\ntheoretical calculations, which usually assume Q_2^2=0, may be untrustworthy.\nOur phenomenological model of the pi^0 transition form factor is based on the\nvector-meson-dominance hypothesis and all its parameters are fixed by using the\nexperimental data on the decays of vector mesons. The model soundness is\nchecked in the two-real-photon limit, where it provides a good parameter-free\ndescription of the pi^0 -> 2 gamma decay rate, and in the pi^0 Dalitz decay.\nThe dependence of F(Q_1^2,Q_2^2) on Q_1^2 at several fixed values of Q_2^2 is\npresented and the comparison with existing data performed.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.84.035109",
      "title": "Conductivity between Luttinger liquids: coupled chains and bilayer\n  graphene",
      "abstract": "  The conductivity properties between Luttinger liquids are analyzed by exact\nRenormalization Group methods. We prove that in a two chain system or in a\nmodel of bilayer graphene, described by two coupled fermionic honeycomb\nlattices interacting with a gauge field, the transverse optical conductivity at\nfinite temperature is anomalous and decreasing together with the frequency as a\npower law with Luttinger liquid exponent.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2011.18305.x",
      "title": "Mass segregation in diverse environments",
      "abstract": "  In this paper, using 2MASS photometry, we study the mass functions $\\phi(M) =\ndN/dM \\propto M^{-\\alpha}$ of a sample of nine clusters of ages varying from 4\nMyr--1.2 Gyr and Galactocentric distances from 6--12 kpc. We look for evidence\nof mass segregation in these clusters by tracing the variation in the value of\n$\\alpha$ in different regions of the cluster as a function of the parameter\n$\\tau = t_{age}/t_{relax}$ (where $t_{age}$ is the age of the cluster and\n$t_{relax}$ is the relaxation time of the cluster), Galactocentric distance,\nage and size of the cluster. The value of $\\alpha$ value increases with age and\n$\\tau$ and fits straight lines with slopes $m$ and y-intercepts $c$ given by\n$m=0.40\\pm0.03$, $c=-1.86\\pm0.27$ and $m=0.01\\pm0.001$, $c=-0.85\\pm0.02$,\nrespectively and is a clear indicator of the dynamical processes involved. The\nconfidence level of the Pearson's product-moment correlation of $\\alpha$ with\nage is 0.76 with p=0.002 and with $\\tau$ is 0.71 with p=0.007. The value of\n$\\alpha$ also increases with Galactocentric distance, indicating the presence\nof a larger relative number of low mass stars in clusters at larger\nGalactocentric distances. We find two clusters, viz. IC 1805 and NGC 1893, with\nevidence of primordial or early dynamical mass segregation. Implications of\nprimordial mass segregation on the formation of massive stars and recent\nresults supporting early dynamical mass segregation are discussed.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.3666020 10.1063/1.4736999",
      "title": "Dynamically defined measures and equilibrium states",
      "abstract": "  A technique of dynamically defined measures is developed and its relation to\nthe theory of equilibrium states is shown. The technique uses Caratheodory's\nmethod and the outer measure introduced in (I. Werner, Math. Proc. Camb. Phil.\nSoc. 140 (2) (2006) 333-347). As an application, equilibrium states for\ncontractive Markov systems (I. Werner, J. London Math. Soc. 71 (2005), no. 1,\n236-258) are obtained.\n",
      "subjects": [
        "math-ph",
        "math.DS",
        "math.MP",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/201116559",
      "title": "Characterizing Precursors to Stellar Clusters with Herschel",
      "abstract": "  Context: Despite their profound effect on the universe, the formation of\nmassive stars and stellar clusters remains elusive. In the past decade,\ncompelling evidence has emerged that suggests Infrared Dark Clouds (IRDCs) may\nbe precursors to stellar clusters. However, the usual method for identifying\nIRDCs is biased by the requirement that they are seen in absorption against\nbright mid-IR emission, whereas dust continuum observations allow cold, dense\npre-stellar-clusters to be identified anywhere. Aims: We aim to understand what\nphysical properties characterize IRDCs, to explore the population of dust\ncontinuum sources that are not IRDCs, and to roughly characterize the star\nformation activity in dust continuum sources. Results: We present temperature\nand column density maps in the Hi-GAL l=30 and l=59 SDP fields, as well as a\nrobust algorithm for cirrus subtraction and source identification using Hi-GAL.\nWe report on the fraction of Hi-GAL sources which are mid-IR-dark, -neutral, or\n-bright in both fields. We find significant trends in column density and\ntemperature between mid-IR-dark and -bright pixels; mid-IR-dark pixels are\nabout 10 K colder and have a factor of 2 higher column density on average than\nmid-IR-bright pixels. We find that Hi-GAL dust continuum sources span a range\nof evolutionary states from pre- to star-forming, and that warmer sources are\nassociated with more star formation tracers. There is a trend of increasing\ntemperature with tracer type from mid-IR-dark at the coldest, to outflow/maser\nsources in the middle, and finally to 8 and 24 micron bright sources at the\nwarmest. Finally, we identify five candidate IRDC-like sources on the far-side\nof the Galaxy. These are cold (~ 20 K), high column density (N(H2) > 10^22\ncm^-2) clouds identified with Hi-GAL which, despite bright surrounding mid-IR\nemission, show little to no absorption at 8 micron. (abridged)\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Representations of Quantum Double of Dihedral Groups",
      "abstract": "  Let $k$ be an algebraically closed field of odd characteristic $p$, and let\n$D_n$ be the dihedral group of order $2n$ such that $p\\mid 2n$. Let $D(kD_n)$\ndenote the quantum double of the group algebra $kD_n$. In this paper, we\ndescribe the structures of all finite dimensional indecomposable left\n$D(kD_n)$-modules, equivalently, of all finite dimensional indecomposable\nYetter-Drinfeld $kD_n$-modules, and classify them.\n",
      "subjects": [
        "math.QA",
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/735/2/84",
      "title": "Properties of the Compact HII Region Complex G-0.02-0.07",
      "abstract": "  We present new extinction maps and high-resolution Paschen alpha images of\nG-0.02-0.07, a complex of compact HII regions located adjacent to the\nM-0.02-0.07 giant molecular cloud, 6 parsecs in projection from the center of\nthe Galaxy. These HII regions, which lie in projection just outside the\nboundary of the Sgr A East supernova remnant, represent one of the most recent\nepisodes of star formation in the central parsecs of the Galaxy. The 1.87\nmicron extinctions of regions A, B and C are almost identical, approximately\n1.5 magnitudes. Region D, in contrast, has a peak 1.87 micron extinction of 2.3\nmagnitudes. Adopting the Nishiyama et al. (2008) extinction law, we find these\nextinctions correspond to visual extinctions of A_V = 44.5 and A_V = 70,\nrespectively. The similar and uniform extinctions of regions A, B and C are\nconsistent with that expected for foreground extinction in the direction of the\nGalactic center, suggesting that they lie at the front side of the M-0.02-0.07\nmolecular cloud. Region D is more compact, has a higher extinction and is thus\nsuspected to be younger and embedded in a dense core in a compressed ridge on\nthe western edge of this cloud.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.106.160601",
      "title": "Diffusion with Stochastic Resetting",
      "abstract": "  We study simple diffusion where a particle stochastically resets to its\ninitial position at a constant rate r. A finite resetting rate leads to a\nnonequilibrium stationary state with non-Gaussian fluctuations for the particle\nposition. We also show that the mean time to find a stationary target by a\ndiffusive searcher is finite and has a minimum value at an optimal resetting\nrate r^*. Resetting also alters fundamentally the late time decay of the\nsurvival probability of a stationary target when there are multiple searchers:\nwhile the typical survival probability decays exponentially with time, the\naverage decays as a power law with an exponent depending continuously on the\ndensity of searchers.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/OE.19.009127",
      "title": "Suspended core subwavelength fibers: practical designs for the low-loss\n  terahertz guidance",
      "abstract": "  In this work we report two designs of subwavelength fibers packaged for\npractical terahertz wave guiding. We describe fabrication, modeling and\ncharacterization of microstructured polymer fibers featuring a\nsubwavelength-size core suspended in the middle of a large porous outer\ncladding. This design allows convenient handling of the subwavelength fibers\nwithout distorting their modal profile. Additionally, the air-tight porous\ncladding serves as a natural enclosure for the fiber core, thus avoiding the\nneed for a bulky external enclosure for humidity-purged atmosphere. Fibers of 5\nmm and 3 mm in outer diameters with a 150 \\mu m suspended solid core and a 900\n\\mu m suspended porous core respectively, were obtained by utilizing a\ncombination of drilling and stacking techniques. Characterization of the fiber\noptical properties and the near-field imaging of the guided modes were\nperformed using a terahertz near-field microscopy setup. Near-field imaging of\nthe modal profiles at the fiber output confirmed the effectively single-mode\nbehavior of such waveguides. The suspended core fibers exhibit broadband\ntransmission from 0.10 THz to 0.27 THz (larger core), and from 0.25 THz to 0.51\nTHz (smaller core). Due to the large fraction of power that is guided in the\nholey cladding, fiber propagation losses as low as 0.02 cm-1 are demonstrated.\nLow-loss guidance combined with the core isolated from environmental\nperturbations make these all-dielectric fibers suitable for practical terahertz\nimaging and sensing applications.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The conjugacy relation on unitary representations",
      "abstract": "  We show that the unitary conjugacy relation for unitary representations of a\nsecond countable locally compact group on a separable Hilbert space is a Borel\nequivalence relation.\n",
      "subjects": [
        "math.LO",
        "math.GR",
        "math.OA",
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.107.037202",
      "title": "Suppression of Standing Spin Waves in Low-Dimensional Ferromagnets",
      "abstract": "  We examine the experimental absence of standing spin wave modes in thin\nmagnetic films, by means of atomistic spin dynamics simulations. Using Co on\nCu(001) as a model system, we demonstrate that by increasing the number of\nlayers, the \"optical\" branches predicted from adiabatic first-principles\ncalculations are strongly suppressed, in agreement with spin-polarized electron\nenergy loss spectroscopy measurements reported in the literature. Our results\nsuggest that a dynamical analysis of the Heisenberg model is sufficient in\norder to capture the strong damping of the standing modes.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jcta.2012.03.009",
      "title": "Chains of modular elements and shellability",
      "abstract": "  Let L be a lattice admitting a left-modular chain of length r, not\nnecessarily maximal. We show that if either L is graded or the chain is\nmodular, then the (r-2)-skeleton of L is vertex-decomposable (hence shellable).\nThis proves a conjecture of Hersh. Under certain circumstances, we can find\nshellings of higher skeleta. For instance, if the left-modular chain consists\nof every other element of some maximum length chain, then L itself is\nshellable. We apply these results to give a new characterization of finite\nsolvable groups in terms of the topology of subgroup lattices.\n  Our main tool relaxes the conditions for an EL-labeling, allowing multiple\nascending chains as long as they are lexicographically before non-ascending\nchains. We extend results from the theory of EL-shellable posets to such\nlabelings. The shellability of certain skeleta is one such result. Another is\nthat a poset with such a labeling is homotopy equivalent (by discrete Morse\ntheory) to a cell complex with cells in correspondence to weakly descending\nchains.\n",
      "subjects": [
        "math.CO",
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Accessing GPDs from experiment --- potential of a high-luminosity EIC\n  ---",
      "abstract": "  We discuss modeling of generalized parton distributions (GPDs), their access\nfrom present experiments, and the phenomenological potential of an electron-ion\ncollider. In particular, we present a comparison of phenomenological models of\nGPD H, extracted from hard exclusive meson and photon production. Specific\nemphasis is given to the utilization of evolution effects at moderate x_Bj in a\nfuture high-luminosity experiment within a larger Q^2 lever arm.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/201015929",
      "title": "An accurate measurement of the anisotropies and mean level of the Cosmic\n  Infrared Background at 100 and 160 um",
      "abstract": "  The measurement of the anisotropies in the cosmic infrared background (CIB)\nis a powerful mean of studying the evolution of galaxies and large-scale\nstructures. These anisotropies have been measured by a number of experiments,\nfrom the far-infrared to the millimeter. One of the main impediments to an\naccurate measurement on large scales is the contamination of the foreground\nsignal by Galactic dust emission. Our goal is to show that we can remove the\nGalactic cirrus contamination using HI data, and thus accurately measure the\nclustering of starburst galaxies in the CIB. We use observations of the ELAIS\nN1 field at far-infrared (100 and 160{\\mu}m) and radio (21 cm) wavelengths. We\ncompute the correlation between dust emission, traced by far-infrared\nobservations, and HI gas traced by 21cm observations, and derive dust\nemissivities that enable us to subtract the cirrus emission from the\nfar-infrared maps. We then derive the power spectrum of the CIB anisotropies,\nas well as its mean level at 100{\\mu}m and 160{\\mu}m. We also combine the HI\ndata and Spitzer total power mode absolute measurements to determine the CIB\nmean level at 160{\\mu}m. We find B160=0.77\\pm0.04\\pm0.12MJy/sr,where the first\nerror is statistical and the second systematic. Combining this measurement with\nthe B100/B160 color of the correlated anisotropies, we also derive the CIB mean\nat 100 {\\mu}m, B100=0.24\\pm0.08\\pm0.04 MJy/sr. This measurement is in line with\nvalues obtained with recent models of infrared galaxy evolution and\nHerschel/PACS data, but is much smaller than the previous DIRBE measurements.\nThe use of high-angular resolution Hi data is mandatory to accurately\ndifferentiate the cirrus from the CIB emission. The 100 {\\mu}m IRAS map (and\nthus the map developed by Schlegel and collaborators) in such extragalactic\nfields is highly contaminated by the CIB anisotropies and hence cannot be used\nas a Galactic cirrus tracer.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.84.115125",
      "title": "Combined analytical and numerical approach to study magnetization\n  plateaux in doped quasi-one-dimensional antiferromagnets",
      "abstract": "  We investigate the magnetic properties of quasi-one-dimensional quantum\nspin-S antiferromagnets. We use a combination of analytical and numerical\ntechniques to study the presence of plateaux in the magnetization curve. The\nanalytical technique consists in a path integral formulation in terms of\ncoherent states. This technique can be extended to the presence of doping and\nhas the advantage of a much better control for large spins than the usual\nbosonization technique. We discuss the appearance of doping-dependent plateaux\nin the magnetization curves for spin-S chains and ladders. The analytical\nresults are complemented by a density matrix renormalization group (DMRG) study\nfor a trimerized spin-1/2 and anisotropic spin-3/2 doped chains.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.84.074027",
      "title": "Theoretical support for the $\\pi(1300)$ and the recently claimed\n  $f_0(1790)$ as molecular resonances",
      "abstract": "  A study of three-pseudoscalar $\\pi K \\bar{K}$ and $\\pi \\pi \\eta$ coupled\nsystem is made by solving the Faddeev equations within an approach based on\nunitary chiral dynamics. A resonance with total isospin one and spin-parity\n$J^\\pi = 0^-$ is found with mass $\\sim$ 1400 MeV when the $K \\bar{K}$ system\ngets reorganized as the $f_0(980)$. This resonance is identified with the $\\pi\n(1300)$ listed by the Particle Data Group. Further, the two-body amplitude\nwhich describes the interaction between a $\\pi$ and the $f_0(980)$ is extracted\nfrom the study of the $\\pi K\\bar K$ and $\\pi\\pi\\eta$ system and is then\nemployed to study the $f_0(980)\\pi \\pi $ system. As a result, a scalar\nresonance is found near 1790 MeV which drives the two $ f_0 (980)\\pi$ systems\nto resonate as the $\\pi (1300)$ while the invariant mass of the two pions falls\nin the mass region of the scalar $\\sigma (600)$. These findings support the\nexistence of a new $f_0$ resonance near 1790 MeV, as found by the BES and\nCrystal Barrel collaborations. Our results show that this $f_0(1790)$ is\ndefinitely distinct to $f_0(1710)$, the latter of which seems to possess a\nglueball structure dominantly.\n",
      "subjects": [
        "nucl-th",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Transmission eigenvalue distributions in highly-conductive molecular\n  junctions",
      "abstract": "  The transport through a quantum-scale device may be characterized by the\ntransmission eigenvalues. These values constitute a junction PIN code where,\nfor example, in single-atom metallic contacts the number of transmission\nchannels is also the chemical valence of the atom. Recently, highly conductive\nsingle-molecule junctions (SMJ) with multiple transport channels have been\nformed from benzene molecules between Pt electrodes. Transport through these\nmulti-channel SMJs is a probe of both the bonding properties at the\nlead-molecule interface and of the molecular symmetry.\n  Here we utilize a many-body theory that properly describes the complementary\nnature of the charge carrier to calculate transport distributions through\nPt-benzene-Pt junctions. We develop an effective field theory of interacting\npi-electrons to accurately model the electrostatic influence of the leads and\nan ab initio tunneling model to describe the lead-molecule bonding. With this\nstate-of-the-art many-body technique we calculate the transport using the full\nmolecular spectrum and using an `isolated resonance approximation' for the\nmolecular Green's function.\n  We confirm that the number of transmission channels in a SMJ is equal to the\ndegeneracy of the relevant molecular orbital. In addition, we demonstrate that\nthe isolated resonance approximation is extremely accurate and determine that\ntransport occurs predominantly via the HOMO orbital in Pt-benzene-Pt junctions.\nFinally, we show that the transport occurs in a lead-molecule coupling regime\nwhere the charge carriers are both particle-like and wave-like simultaneously,\nrequiring a many-body description.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.other",
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1122/1.3676741",
      "title": "Three Dimensional Flow of Colloidal Glasses",
      "abstract": "  Recent experiments performed on a variety of soft glassy materials have\ndemonstrated that any imposed shear flow serves to simultaneously fluidize\nthese systems in all spatial directions [Ovarlez \\textit{et al.} (2010)]. When\nprobed with a second shear flow, the viscous response of the experimental\nsystem is determined by the rate of the primary, fluidizing flow. Motivated by\nthese findings, we employ a recently developed schematic mode-coupling theory\n[Brader \\textit{et al.} (2009)] to investigate the three dimensional flow of a\ncolloidal glass, subject to a combination of simple shear and uniaxial\ncompression. Despite differences in the specific choice of superposed flow, the\nflow curves obtained show good qualitative agreement with the experimental\nfindings and recover the observed power law describing the decay of the scaled\nviscosity as a function of the dominant rate. We then proceed to perform a more\nformal analysis of our constitutive equation for different kind of `mixed'\nflows consisting of a dominant primary flow subject to a weaker perturbing\nflow. Our study provides further evidence that the theory of Brader \\textit{et\nal.} (2009) reliably describes the dynamic arrest and mechanical fluidization\nof dense particulate suspensions.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/746/1/41",
      "title": "Unraveling the Geometry of the Crab Nebula's \"Inner Ring\"",
      "abstract": "  Chandra images of the Crab Nebula resolve the detailed structure of its\n\"inner ring\", possibly a termination shock where pulsar-accelerated\nrelativistic particles begin to emit X radiation. Analysis of these images\nfinds that the center of the ellipse-presumably a circular ring in\nprojection-lies about 0.9\" (10 light-days at 2 kpc) from the pulsar's image, at\na position angle of about 300{\\deg} (East of North). This analysis also\nmeasures properties of the ellipse: The position angle of the semi-major axis\nis about 210{\\deg} (East of North); the aspect ratio, 0.49.\n  In a simple-albeit, not unique-de-projection of the observed geometry, a\ncircular ring is centered on the axis of symmetry of the pulsar wind nebula.\nThis ring is not equatorial but rather lies near +4.5{\\deg} latitude in\npulsar-centered coordinates. Alternative geometries are briefly discussed.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2012.21466.x",
      "title": "Moving mesh cosmology: the hydrodynamics of galaxy formation",
      "abstract": "  We present a detailed comparison between the well-known SPH code GADGET and\nthe new moving-mesh code AREPO on a number of hydrodynamical test problems.\nThrough a variety of numerical experiments we establish a clear link between\ntest problems and systematic numerical effects seen in cosmological simulations\nof galaxy formation. Our tests demonstrate deficiencies of the SPH method in\nseveral sectors. These accuracy problems not only manifest themselves in\nidealized hydrodynamical tests, but also propagate to more realistic simulation\nsetups of galaxy formation, ultimately affecting gas properties in the full\ncosmological framework, as highlighted in papers by Vogelsberger et al. (2011)\nand Keres et al. (2011). We find that an inadequate treatment of fluid\ninstabilities in GADGET suppresses entropy generation by mixing, underestimates\nvorticity generation in curved shocks and prevents efficient gas stripping from\ninfalling substructures. In idealized tests of inside-out disk formation, the\nconvergence rate of gas disk sizes is much slower in GADGET due to spurious\nangular momentum transport. In simulations where we follow the interaction\nbetween a forming central disk and orbiting substructures in a halo, the final\ndisk morphology is strikingly different. In AREPO, gas from infalling\nsubstructures is readily depleted and incorporated into the host halo\natmosphere, facilitating the formation of an extended central disk. Conversely,\ngaseous sub-clumps are more coherent in GADGET simulations, morphologically\ntransforming the disk as they impact it. The numerical artefacts of the SPH\nsolver are particularly severe for poorly resolved flows, and thus inevitably\naffect cosmological simulations due to their hierarchical nature. Our numerical\nexperiments clearly demonstrate that AREPO delivers a physically more reliable\nsolution.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/201117970",
      "title": "No magnetic field in the spotted HgMn star mu Leporis",
      "abstract": "  Chemically peculiar stars of the mercury-manganese (HgMn) type represent a\nnew class of spotted late-B stars, in which evolving surface chemical\ninhomogeneities are apparently unrelated to the presence of strong magnetic\nfields but are produced by some hitherto unknown astrophysical mechanism. The\ngoal of this study is to perform a detailed line profile variability analysis\nand carry out a sensitive magnetic field search for one of the brightest HgMn\nstars - mu Lep. We acquired a set of very high-quality intensity and\npolarization spectra of mu Lep with the HARPSpol polarimeter. These data were\nanalyzed with the multiline technique of least-squares deconvolution in order\nto extract information on the magnetic field and line profile variability. Our\nspectra show very weak but definite variability in the lines of Sc, all Fe-peak\nelements represented in the spectrum of mu Lep, as well as Y, Sr, and Hg.\nVariability might also be present in the lines of Si and Mg. Anomalous profile\nshapes of Ti II and Y II lines suggest a dominant axisymmetric distribution of\nthese elements. At the same time, we found no evidence of the magnetic field in\nmu Lep, with the 3 sigma upper limit of only 3 G for the mean longitudinal\nmagnetic field. This is the most stringent upper limit on the possible magnetic\nfield derived for a spotted HgMn star. The very weak variability detected for\nmany elements in the spectrum mu Lep suggests that low-contrast chemical\ninhomogeneities may be common in HgMn stars and that they have not been\nrecognized until now due to the limited precision of previous spectroscopic\nobservations and a lack of time-series data. The null result of the magnetic\nfield search reinforces the conclusion that formation of chemical spots in HgMn\nstars is not magnetically driven.\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Reversible Markov structures on divisible set partitions",
      "abstract": "  We study $k$-divisible partition structures, which are families of random set\npartitions whose block sizes are divisible by an integer $k=1,2,\\ldots$. In\nthis setting, exchangeability corresponds to the usual invariance under\nrelabeling by arbitrary permutations; however, for $k>1$, the ordinary deletion\nmaps on partitions no longer preserve divisibility, and so a random deletion\nprocedure is needed to obtain a partition structure. We describe explicit\nChinese restaurant-type seating rules for generating families of exchangeable\n$k$-divisible partitions that are consistent under random deletion. We further\nintroduce the notion of {\\em Markovian partition structures}, which are\nensembles of exchangeable Markov chains on $k$-divisible partitions that are\nconsistent under a random process of {\\em Markovian deletion}. The Markov\nchains we study are reversible and refine the class of Markov chains introduced\nin {\\em J.\\ Appl.\\ Probab.}~{\\bf48}(3):778--791.\n",
      "subjects": [
        "math.ST",
        "math.CO",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Bruno Rossi and Cosmic Rays: From Earth laboratories to Physics in Space",
      "abstract": "  Rossi's career paralleled the evolution of cosmic-ray physics. Starting from\nthe early 1930s his pioneering work on the nature and behavior of cosmic rays\nled to fundamental contributions in the field of experimental cosmic-ray\nphysics and laid the foundation for high-energy particle physics. After the\nwar, under his leadership the Cosmic Ray group at MIT investigated the\nproperties of the primary cosmic rays elucidating the processes involved in\ntheir propagation through the atmosphere, and measuring the unstable particles\ngenerated in the interactions with matter. When accelerators came to dominate\nparticle physics, Rossi's attention focused on the new opportunities for\nexploratory investigations made possible by the availability of space vehicles.\nHe initiated a research program which led to the first in situ measurements of\nthe density, speed and direction of the solar wind at the boundary of Earth's\nmagnetosphere and inspired the search for extra-solar X-ray sources resulting\nin the detection of what revealed to be the most powerful X-ray source in\nEarth's skies. The discovery of Scorpius X-1 marked the beginning of X-ray\nastronomy, which soon became a principal tool of astrophysics research.\n",
      "subjects": [
        "physics.hist-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.85.021149",
      "title": "Percolation in a kinetic opinion exchange model",
      "abstract": "  We study the percolation transition of the geometrical clusters in the square\nlattice LCCC model (a kinetic opinion exchange model introduced by Lallouache\net al. in Phys. Rev. E 82 056112 (2010)) with the change in conviction and\ninfluencing parameter. The cluster comprises of the adjacent sites having an\nopinion value greater than or equal to a prefixed threshold value of opinion\n(\\Omega). The transition point is different from that obtained for the\ntransition of the order parameter (average opinion value) found by Lallouache\net al. Although the transition point varies with the change in the threshold\nvalue of the opinion, the critical exponents for the percolation transition\nobtained from the data collapses of the maximum cluster size, cluster size\ndistribution and Binder cumulant remain same. The exponents are also\nindependent of the values of conviction and influencing parameters indicating\nthe robustness of this transition. The exponents do not match with that of any\nother known percolation exponents (e.g. the static Ising, dynamic Ising,\nstandard percolation) and thus characterizes the LCCC model to belong to a\nseparate universality class.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.3665649",
      "title": "Nanoshells as a high-pressure gauge analyzed to 200 GPa",
      "abstract": "  In this article we present calculations which indicate that nanoshells can be\nused as a high pressure gauge in Diamond Anvil Cells (DACs). Nanoparticles have\nimportant advantages in comparison with the currently used ruby fluorescence\ngauge. Because of their small dimensions they can be spread uniformly over a\ndiamond surface without bridging between the two diamond anvils. Furthermore\ntheir properties are measured by broad band optical transmission spectroscopy\nleading to a very large signal-to-noise ratio even in the multi-megabar\npressure regime where ruby measurements become challenging. Finally their\nresonant frequencies can be tuned to lie in a convenient part of the visible\nspectrum accessible to CCD detectors. Theoretical calculations for a nanoshell\nwith a SiO2 core and a golden shell, using both the hybridization model and Mie\ntheory, are presented here. The calculations for the nanoshell in vacuum\npredict that nanoshells can indeed have a measurable pressure-dependent optical\nresponse desirable for gauges.However when the nanoshells are placed in\ncommonly used DAC pressure media, resonance peak positions as a function of\npressure are no longer single-valued and depend on the pressure media,\nrendering them impractical as a pressure gauge. To overcome these problems an\nalternative nanoparticle is studied: coating the nanoshell with an extra\ndielectric layer (SiO2) provides an easy way to shield the pressure gauge from\nthe influence of the medium, leaving the compression of the particle due to the\npressure as the main effect on the spectrum. We have analyzed the response to\npressure up to 200 GPa. We conclude that a coated nanoshell could provide a new\ngauge for high-pressure measurements that has advantages over current methods.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.laa.2011.05.039",
      "title": "Integral circulant graphs of prime power order with maximal energy",
      "abstract": "  The energy of a graph is the sum of the moduli of the eigenvalues of its\nadjacency matrix. We study the energy of integral circulant graphs, also called\ngcd graphs, which can be characterized by their vertex count n and a set D of\ndivisors of n in such a way that they have vertex set Zn and edge set {{a, b} :\na, b in Zn; gcd(a - b, n) in D}. Using tools from convex optimization, we study\nthe maximal energy among all integral circulant graphs of prime power order ps\nand varying divisor sets D. Our main result states that this maximal energy\napproximately lies between s(p - 1)p^(s-1) and twice this value. We construct\nsuitable divisor sets for which the energy lies in this interval. We also\ncharacterize hyperenergetic integral circulant graphs of prime power order and\nexhibit an interesting topological property of their divisor sets.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1515/astro-2017-0337",
      "title": "The Influence of Chemi-ionization and Recombination Processes on\n  Spectral Line Shapes in Stellar Atmospheres",
      "abstract": "  In this work, the chemi-ionization processes in atom- Rydberg atom\ncollisions, as well as the corresponding chemi-recombination processes are\nconsidered as factors of influence on the atom exited-state populations in\nweakly ionized layers of stellar atmospheres. The presented results are related\nto the photospheres of the Sun and some M red dwarfs as well as weakly ionized\nlayers of DB white dwarfs atmospheres. It has been found that the mentioned\nchemi ionization/recombination processes dominate over the relevant concurrent\nelectron-atom and electron-ion ionization and recombination process in all\nparts of considered stellar atmospheres. The obtained results demonstrate the\nfact that the considered chemi ionization/recombination processes must have a\nvery significant influence on the optical properties of the stellar\natmospheres. Thus, it is shown that these processes and their importance for\nnon-local thermodynamic equilibrium (non-LTE) modeling of the solar atmospheres\nshould be investigated further.\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1674-1137/36/7/002",
      "title": "Discussions on Stability of Diquarks",
      "abstract": "  Since the birth of the quark model, the diquark which is composed of two\nquarks has been considered as a substantial structure of color anti-triplet.\nThis is not only a mathematical simplification for dealing with baryons, but\nalso provides a physical picture where the diquark would behave as a whole\nobject. It is natural to ask whether such a structure is sufficiently stable\nagainst external disturbance. The mass spectra of the ground states of the\nscalar and axial-vector diquarks which are composed of two-light (L-L),\none-light-one-heavy (H-L) and two-heavy quarks (H-H) respectively have been\ncalculated in terms of the QCD sum rules. We suggest a criterion as the\nquantitative standard for the stability of the diquark. It is the gap between\nthe masses of the diquark and $\\sqrt{s_0}$ where $s_0$ is the threshold of the\nexcited states and continuity, namely the larger the gap is, the more stable\nthe diquark would be. In this work, we calculate the masses of the type H-H to\ncomplete the series of the spectra of the ground state diquarks. However, as\nthe criterion being taken, we find that all the gaps for the various diquaks\nare within a small range, especially the gap for the diquark with two heavy\nquarks which is believed to be a stable structure, is slightly smaller than\nthat for other two types of diquarks, therefore we conclude that because of the\nlarge theoretical uncertainty, we cannot use the numerical results obtained\nwith the QCD sum rules to assess the stability of diquarks, but need to invoke\nother theoretical framework.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Double exponential growth of the vorticity gradient for the\n  two-dimensional Euler equation",
      "abstract": "  For the two-dimensional Euler equation on the torus, we prove that the\nuniform norm of the vorticity gradient can grow as double exponential over\narbitrarily long but finite time provided that at time zero it is already\nsufficiently large. Our result is equivalent to the statement that the Euler\nevolutions is linearly unbounded in Lipschitz norm for any time t>0.\n",
      "subjects": [
        "math.AP",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/747/2/121",
      "title": "Search for Dark Matter Satellites using the FERMI-LAT",
      "abstract": "  Numerical simulations based on the Lambda-CDM model of cosmology predict a\nlarge number of as yet unobserved Galactic dark matter satellites. We report\nthe results of a Large Area Telescope (LAT) search for these satellites via the\ngamma-ray emission expected from the annihilation of weakly interacting massive\nparticle (WIMP) dark matter. Some dark matter satellites are expected to have\nhard gamma-ray spectra, finite angular extents, and a lack of counterparts at\nother wavelengths. We sought to identify LAT sources with these\ncharacteristics, focusing on gamma-ray spectra consistent with WIMP\nannihilation through the $b \\bar b$ channel. We found no viable dark matter\nsatellite candidates using one year of data, and we present a framework for\ninterpreting this result in the context of numerical simulations to constrain\nthe velocity-averaged annihilation cross section for a conventional 100 GeV\nWIMP annihilating through the $b \\bar b$ channel.\n",
      "subjects": [
        "astro-ph.HE",
        "hep-ex",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fell bundles and imprimitivity theorems",
      "abstract": "  Our goal in this paper and two sequels is to apply the\nYamagami-Muhly-Williams equivalence theorem for Fell bundles over groupoids to\nrecover and extend all known imprimitivity theorems involving groups. Here we\nextend Raeburn's symmetric imprimitivity theorem, and also, in an appendix, we\ndevelop a number of tools for the theory of Fell bundles that have not\npreviously appeared in the literature.\n",
      "subjects": [
        "math.OA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/748/2/133",
      "title": "Temporal and spectral evolution in X- and gamma-rays of magnetar 1E\n  1547.0-5408 since its October 2008 outburst: the discovery of a transient\n  hard pulsed component after its January 2009 outburst",
      "abstract": "  The magnetar 1E 1547.0-5408 exhibited outbursts in October 2008 and January\n2009. In this paper we present in great detail the evolution of the temporal\nand spectral characteristics of the persistent total and pulsed emission of 1E\n1547.0-5408 between ~1 and 300 keV starting in October 3, 2008, and ending in\nJanuary 2011. We analyzed data collected with the Rossi X-ray Timing Explorer,\nthe International Gamma-Ray Astrophysics Laboratory and the Swift satellite.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.4718590",
      "title": "Multielectron effects in high harmonic generation in N2 and benzene:\n  simulation using a non-adiabatic quantum molecular dynamics approach for\n  laser-molecule interactions",
      "abstract": "  A mixed quantum-classical approach is introduced which allows the dynamical\nresponse of molecules driven far from equilibrium to be modeled. This method is\napplied to the interaction of molecules with intense, short-duration laser\npulses. The electronic response of the molecule is described using\ntime-dependent density functional theory (TDDFT) and the resulting Kohn-Sham\nequations are solved numerically using finite difference techniques in\nconjunction with local and global adaptations of an underlying grid in\ncurvilinear coordinates. Using this approach, simulations can be carried out\nfor a wide range of molecules and both all-electron and pseudopotential\ncalculations are possible. The approach is applied to the study of high\nharmonic generation in N2 and benzene using linearly-polarized laser pulses\nand, to the best of our knowledge, the results for benzene represent the first\nTDDFT calculations of high harmonic generation in benzene using linearly\npolarized laser pulses. For N2 an enhancement of the cut-off harmonics is\nobserved whenever the laser polarization is aligned perpendicular to the\nmolecular axis. This enhancement is attributed to the symmetry properties of\nthe Kohn-Sham orbital that responds predominantly to the pulse. In benzene we\npredict that a suppression in the cut-off harmonics occurs whenever the laser\npolarization is aligned parallel to the molecular plane. We attribute this\nsuppression to the symmetry-induced response of the highest-occupied molecular\norbital.\n",
      "subjects": [
        "physics.atom-ph",
        "physics.chem-ph",
        "physics.comp-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1112/jlms/jdt009",
      "title": "Noncommutative Fitting invariants and improved annihilation results",
      "abstract": "  To each finitely presented module M over a commutative ring R one can\nassociate an R-ideal Fit_R(M) which is called the (zeroth) Fitting ideal of M\nover R and which is always contained in the R-annihilator of M. In an earlier\narticle, the second author generalised this notion by replacing R with a (not\nnecessarily commutative) o-order Lambda in a finite dimensional separable\nalgebra, where o is an integrally closed complete commutative noetherian local\ndomain. To obtain annihilators, one has to multiply the Fitting invariant of a\n(left) Lambda-module M by a certain ideal H(Lambda) of the centre of Lambda. In\ncontrast to the commutative case, this ideal can be properly contained in the\ncentre of Lambda. In the present article, we determine explicit lower bounds\nfor H(Lambda) in many cases. Furthermore, we define a class of `nice' orders\nLambda over which Fitting invariants have several useful properties such as\ngood behaviour with respect to direct sums of modules, computability in a\ncertain sense, and H(Lambda) being the best possible.\n",
      "subjects": [
        "math.RA",
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An efficient algorithm for the diameter of Cayley graphs generated by\n  transposition trees",
      "abstract": "  A problem of practical and theoretical interest is to determine or estimate\nthe diameter of various families of Cayley networks. The previously known\nestimate for the diameter of Cayley graphs generated by transposition trees is\nan upper bound given in the oft-cited paper of Akers and Krishnamurthy (1989).\nIn this work, we first assess the performance of their upper bound. We show\nthat for every $n$, there exists a tree on $n$ vertices, such that the\ndifference between the upper bound and the true diameter value is at least\n$n-4$.\n  Evaluating their upper bound takes time $\\Omega(n!)$. In this paper, we\nprovide an algorithm that obtains an estimate of the diameter, but which\nrequires only time $O(n^2)$; furthermore, the value obtained by our algorithm\nis less than or equal to the previously known diameter upper bound. Such an\nimprovement to polynomial time, while still performing at least as well as the\nprevious bound, is possible because our algorithm works directly with the\ntransposition tree on $n$ vertices and does not require examining any of the\npermutations. We also provide a tree for which the value computed by our\nalgorithm is not necessarily unique, which is an important result because such\nexamples are quite rare. For all families of trees we have investigated so far,\neach of the possible values computed by our algorithm happens to also be an\nupper bound on the diameter.\n",
      "subjects": [
        "cs.DM",
        "cs.DS",
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Construction of fixed points of certain substitution systems by\n  interlacing arrays in 1 and 2 dimensions",
      "abstract": "  This paper describes an alternative method of generating fixed points of\ncertain substitution systems. This method centres on taking infinite words\nconsisting of one repeated letter per word. These infinite words are then\ninterlaced to form a new, more complex, infinite word. By considering\nparticular limits of interlacings of words, fixed points of substitutions are\ngenerated. This method is then extended to two dimensions, where a structure\nequivalent to a well known aperiodic tiling (the Robinson tiling) is\nconstructed.\n",
      "subjects": [
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Minimax bounds for sparse PCA with noisy high-dimensional data",
      "abstract": "  We study the problem of estimating the leading eigenvectors of a\nhigh-dimensional population covariance matrix based on independent Gaussian\nobservations. We establish a lower bound on the minimax risk of estimators\nunder the $l_2$ loss, in the joint limit as dimension and sample size increase\nto infinity, under various models of sparsity for the population eigenvectors.\nThe lower bound on the risk points to the existence of different regimes of\nsparsity of the eigenvectors. We also propose a new method for estimating the\neigenvectors by a two-stage coordinate selection scheme.\n",
      "subjects": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.86.066320",
      "title": "The decay of Batchelor and Saffman rotating turbulence",
      "abstract": "  The decay rate of isotropic and homogeneous turbulence is known to be\naffected by the large-scale spectrum of the initial perturbations, associated\nwith at least two cannonical self-preserving solutions of the von\nK\\'arm\\'an-Howarth equation: the so-called Batchelor and Saffman spectra. The\neffect of long-range correlations in the decay of anisotropic flows is less\nclear, and recently it has been proposed that the decay rate of rotating\nturbulence may be independent of the large-scale spectrum of the initial\nperturbations. We analyze numerical simulations of freely decaying rotating\nturbulence with initial energy spectra $\\sim k^4$ (Batchelor turbulence) and\n$\\sim k^2$ (Saffman turbulence) and show that, while a self-similar decay\ncannot be identified for the total energy, the decay is indeed affected by\nlong-range correlations. The decay of two-dimensional and three-dimensional\nmodes follows distinct power laws in each case, which are consistent with\npredictions derived from the anisotropic von K\\'arm\\'an-Howarth equation, and\nwith conservation of anisotropic integral quantities by the flow evolution.\n",
      "subjects": [
        "physics.flu-dyn",
        "physics.ao-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.elstat.2012.02.001",
      "title": "Dynamics of a dielectric droplet suspended in a magnetic fluid in\n  electric and magnetic fields",
      "abstract": "  The behavior of a microdrop of dielectric liquid suspended in a magnetic\nfluid and exposed to the action of electric and magnetic fields is studied\nexperimentally. With increasing electric field, the deformation of droplets\ninto oblate ellipsoid, toroid and curved toroid was observed. At the further\nincrease in the electric field, the bursting of droplets was also revealed. The\nelectrorotation of deformed droplets was observed and investigated. The\ninfluence of an additional magnetic field on the droplet dynamics was studied.\nThe main features of the droplet dynamics were interpreted and theoretically\nexamined.\n",
      "subjects": [
        "cond-mat.soft",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.geomphys.2012.09.009",
      "title": "Chern-Simons theory for the noncommutative 3-torus",
      "abstract": "  We study the Chern-Simons action, which was defined for noncommutative spaces\nin general by the author, for the noncommutative 3-torus, the universal\nC*-algebra generated by 3 unitaries. D. Essouabri, B. Iochum, C. Levy, and A.\nSitarz constructed a spectral triple for the noncommutative 3-torus. We compute\nthe Chern-Simons action for this noncommutative space. In connection with this\ncomputation we calculate the first coefficient in the loop expansion series of\nthe corresponding Feynman path integral with the Chern-Simons action as\nLagrangian. The result is independent of the deformation matrix of the\nnoncommutative 3-torus and always 0.\n",
      "subjects": [
        "math.OA",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2012.21031.x",
      "title": "Formation of unsaturated hydrocarbons in interstellar ice analogs by\n  cosmic rays",
      "abstract": "  The formation of double and triple C-C bonds from the processing of pure\nc-C6H12 (cyclohexane) and mixed H2O:NH3:c-C6H12 (1:0.3:0.7) ices by\nhighly-charged, and energetic ions (219 MeV O^{7+} and 632 MeV Ni^{24+}) is\nstudied. The experiments simulate the physical chemistry induced by medium-mass\nand heavy-ion cosmic rays in interstellar ices analogs. The measurements were\nperformed inside a high vacuum chamber at the heavy-ion accelerator GANIL\n(Grand Accel\\'erat\\'eur National d'Ions Lourds) in Caen, France. The gas\nsamples were deposited onto a polished CsI substrate previously cooled to 13 K.\nIn-situ analysis was performed by a Fourier transform infrared (FTIR)\nspectrometry at different ion fluences. Dissociation cross section of\ncyclohexane and its half-life in astrophysical environments were determined. A\ncomparison between spectra of bombarded ices and young stellar sources\nindicates that the initial composition of grains in theses environments should\ncontain a mixture of H2O, NH3, CO (or CO2), simple alkanes, and CH3OH. Several\nspecies containing double or triple bounds were identified in the radiochemical\nproducts, such as hexene, cyclohexene, benzene, OCN-, CO, CO2, as well as\nseveral aliphatic and aromatic alkenes and alkynes. The results suggest an\nalternative scenario for the production of unsaturated hydrocarbons and\npossibly aromatic rings (via dehydrogenation processes) in interstellar ices\ninduced by cosmic ray bombardment.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.IM",
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jcrysgro.2011.04.033",
      "title": "On the effect of oxygen partial pressure on the chromium distribution\n  coefficient in melt-grown ruby crystals",
      "abstract": "  Small ruby crystals were grown by the Czochralski technique in different\natmospheres and their actual chromium content was analysed by a wet chemical\nmethod. The chromium distribution coefficient k was found to be strongly\ndependent on oxygen partial pressure p(O2). It ranges from k=0.3 in a reducing\natmosphere to k=1.2 in a slightly oxidizing atmosphere and to a good\napproximation k depends linearly on log(p(O2)). The experimental data are\ndiscussed on the basis of thermodynamic equilibrium calculations.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Finite Geometry Behind the Harvey-Chryssanthacopoulos Four-Qubit Magic\n  Rectangle",
      "abstract": "  A \"magic rectangle\" of eleven observables of four qubits, employed by Harvey\nand Chryssanthacopoulos (2008) to prove the Bell-Kochen-Specker theorem in a\n16-dimensional Hilbert space, is given a neat finite-geometrical\nreinterpretation in terms of the structure of the symplectic polar space $W(7,\n2)$ of the real four-qubit Pauli group. Each of the four sets of observables of\ncardinality five represents an elliptic quadric in the three-dimensional\nprojective space of order two (PG$(3, 2)$) it spans, whereas the remaining set\nof cardinality four corresponds to an affine plane of order two. The four\nambient PG$(3, 2)$s of the quadrics intersect pairwise in a line, the resulting\nsix lines meeting in a point. Projecting the whole configuration from this\ndistinguished point (observable) one gets another, complementary \"magic\nrectangle\" of the same qualitative structure.\n",
      "subjects": [
        "quant-ph",
        "math-ph",
        "math.CO",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A newly discovered VHE gamma-ray PWN candidate around PSR J1459-60",
      "abstract": "  Observations of the Galactic Plane performed by the H.E.S.S. telescope array\nhave revealed a significant excess at very-high-energies (VHE; E>0.1 TeV) from\nthe direction of PSR J1459-60, a rather old gamma-ray pulsar (64 kyr) with a\nspindown energy of ~10^36 erg/s, discovered by the Fermi/LAT satellite in\nhigh-energy (HE) gamma-rays. The X-ray pulsar counterpart has been recently\ndetected using the Suzaku satellite. In this contribution, we present the\ndiscovery of a new VHE gamma-ray source, including morphological and spectral\nanalyses. Its association with the gamma-ray pulsar in a PWN scenario will be\ndiscussed.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/755/2/134",
      "title": "Two Distant Halo Velocity Groups Discovered by the Palomar Transient\n  Factory",
      "abstract": "  We report the discovery of two new halo velocity groups (Cancer groups A and\nB) traced by 8 distant RR Lyrae stars and observed by the Palomar Transient\nFactory (PTF) survey at R.A.~129 deg, Dec~20 deg (l~205 deg, b~32 deg). Located\nat 92 kpc from the Galactic center (86 kpc from the Sun), these are some of the\nmost distant substructures in the Galactic halo known to date. Follow-up\nspectroscopic observations with the Palomar Observatory 5.1-m Hale telescope\nand W. M. Keck Observatory 10-m Keck I telescope indicate that the two groups\nare moving away from the Galaxy at v_{gsr} = 78.0+-5.6 km/s (Cancer group A)\nand v_{gsr} = 16.3+-7.1 km/s (Cancer group B). The groups have velocity\ndispersions of \\sigma_{v_{gsr}}=12.4+-5.0 km/s and \\sigma_{v_{gsr}}=14.9+-6.2\nkm/s, and are spatially extended (about several kpc) making it very unlikely\nthat they are bound systems, and are more likely to be debris of tidally\ndisrupted dwarf galaxies or globular clusters. Both groups are metal-poor\n(median metallicities of [Fe/H] = -1.6 dex and [Fe/H] =-2.1 dex), and have a\nsomewhat uncertain (due to small sample size) metallicity dispersion of ~0.4\ndex, suggesting dwarf galaxies as progenitors. Two additional RR Lyrae stars\nwith velocities consistent with those of the Cancer groups have been observed\n~25 deg east, suggesting possible extension of the groups in that direction.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Slow mixing of Glauber Dynamics for the hard-core model on regular\n  bipartite graphs",
      "abstract": "  Let $\\gS=(V,E)$ be a finite, $d$-regular bipartite graph. For any $\\lambda>0$\nlet $\\pi_\\lambda$ be the probability measure on the independent sets of $\\gS$\nin which the set $I$ is chosen with probability proportional to $\\lambda^{|I|}$\n($\\pi_\\lambda$ is the {\\em hard-core measure with activity $\\lambda$ on\n$\\gS$}). We study the Glauber dynamics, or single-site update Markov chain,\nwhose stationary distribution is $\\pi_\\lambda$. We show that when $\\lambda$ is\nlarge enough (as a function of $d$ and the expansion of subsets of\nsingle-parity of $V$) then the convergence to stationarity is exponentially\nslow in $|V(\\gS)|$. In particular, if $\\gS$ is the $d$-dimensional hypercube\n$\\{0,1\\}^d$ we show that for values of $\\lambda$ tending to 0 as $d$ grows, the\nconvergence to stationarity is exponentially slow in the volume of the cube.\nThe proof combines a conductance argument with combinatorial enumeration\nmethods.\n",
      "subjects": [
        "math.CO",
        "cs.DM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Valuation and parities for exchange options",
      "abstract": "  Valuation and parity formulas for both European-style and American-style\nexchange options are presented in a general financial model allowing for jumps,\npossibility of default and \"bubbles\" in asset prices. The formulas are given\nvia expectations of auxiliary probabilities using the change-of-numeraire\ntechnique. Extensive discussion is provided regarding the way that folklore\nresults such as Merton's no-early-exercise theorem and traditional parity\nrelations have to be altered in this more versatile framework.\n",
      "subjects": [
        "q-fin.PR",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Minimising the expected commute time",
      "abstract": "  Motivated in part by a problem in simulated tempering (a form of Markov chain\nMonte Carlo) we seek to minimise, in a suitable sense, the time it takes a\n(regular) diffusion with instantaneous reflection at 0 and 1 to travel from the\norigin to $1$ and then return (the so-called commute time from 0 to 1).\n  We consider the static and dynamic versions of this problem where the control\nmechanism is related to the diffusion\\rq{}s drift via the corresponding scale\nfunction. In the static version the diffusion's drift can be chosen at each\npoint in [0,1], whereas in the dynamic version, we are only able to choose the\ndrift at each point at the time of first visiting that point. The dynamic\nversion leads to a novel type of stochastic control problem.\n",
      "subjects": [
        "math.PR",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Identifying Conditional Causal Effects",
      "abstract": "  This paper concerns the assessment of the effects of actions from a\ncombination of nonexperimental data and causal assumptions encoded in the form\nof a directed acyclic graph in which some variables are presumed to be\nunobserved. We provide a procedure that systematically identifies cause effects\nbetween two sets of variables conditioned on some other variables, in time\npolynomial in the number of variables in the graph. The identifiable\nconditional causal effects are expressed in terms of the observed joint\ndistribution.\n",
      "subjects": [
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.109.160403",
      "title": "Exact results for classical Casimir interactions: Dirichlet and Drude\n  model in the sphere-sphere and sphere-plane geometry",
      "abstract": "  Analytic expressions that describe Casimir interactions over the entire range\nof separations have been limited to planar surfaces. Here we derive analytic\nexpressions for the classical or high-temperature limit of Casimir interactions\nbetween two spheres (interior and exterior configurations), including the\nsphere-plane geometry as a special case, using bispherical coordinates. We\nconsider both Dirichlet boundary conditions and metallic boundary conditions\ndescribed by the Drude model. At short distances, closed-form expansions are\nderived from the exact result, displaying an intricate structure of deviations\nfrom the commonly employed proximity force approximation.\n",
      "subjects": [
        "quant-ph",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1742-6596/402/1/012020",
      "title": "Numerical studies of the fractional quantum Hall effect in systems with\n  tunable interactions",
      "abstract": "  The discovery of the fractional quantum Hall effect in GaAs-based\nsemiconductor devices has lead to new advances in condensed matter physics, in\nparticular the possibility for exotic, topological phases of matter that\npossess fractional, and even non-Abelian, statistics of quasiparticles. One of\nthe main limitations of the experimental systems based on GaAs has been the\nlack of tunability of the effective interactions between two-dimensional\nelectrons, which made it difficult to stabilize some of the more fragile\nstates, or induce phase transitions in a controlled manner. Here we review the\nrecent studies that have explored the effects of tunability of the interactions\noffered by alternative two-dimensional systems, characterized by non-trivial\nBerry phases and including graphene, bilayer graphene and topological\ninsulators. The tunability in these systems is achieved via external fields\nthat change the mass gap, or by screening via dielectric plate in the vicinity\nof the device. Our study points to a number of different ways to manipulate the\neffective interactions, and engineer phase transitions between quantum Hall\nliquids and compressible states in a controlled manner.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.86.106004",
      "title": "Semi-classical correlator for 1/4 BPS Wilson loop and chiral primary\n  operator with large R-charge",
      "abstract": "  We study a holographic description for correlation function of 1/4 BPS Wilson\nloop operator and 1/2 BPS local operator carrying a large R-charge of order\n\\sqrt \\lambda. We construct a rotating string solution which is extended in S5\nas well as in AdS5. The string solution preserves the 1/8 of the supersymmetry\nas expected from the gauge theory computation. By evaluating the string action\nincluding boundary terms we show that the string solution reproduces\ncorrelation function in large J \\sim O(\\sqrt \\lambda) limit. In addition, we\nfound the second solution for which the \"size\" of the string becomes larger\nthan the radius of S5. In the case J=0, this solution reduces to the previously\nknown unstable string configuration. The gauge theory side also contains a\nsaddle point which is not on the steepest descent path. We show that the saddle\npoint value matches for this case as well.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.90.042710",
      "title": "Quantum dynamics of the avian compass",
      "abstract": "  The ability of migratory birds to orient relative to the Earth's magnetic\nfield is believed to involve a coherent superposition of two spin states of a\nradical electron pair. However, the mechanism by which this coherence can be\nmaintained in the face of strong interactions with the cellular environment has\nremained unclear. This Letter addresses the problem of decoherence between two\nelectron spins due to hyperfine interaction with a bath of spin 1/2 nuclei.\nDynamics of the radical pair density matrix are derived and shown to yield a\nsimple mechanism for sensing magnetic field orientation. Rates of dephasing and\ndecoherence are calculated ab initio and found to yield millisecond coherence\ntimes, consistent with behavioral experiments.\n",
      "subjects": [
        "physics.bio-ph",
        "physics.atom-ph",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1134/S106377611209004X",
      "title": "Condensation of water vapor in the gravitational field",
      "abstract": "  Physical peculiarities of water vapor condensation under conditions of\nhydrostatic equilibrium are considered. The power of stationary dynamic air\nfluxes and the vertical temperature distribution caused by condensation on\nlarge horizontal scales are estimated.\n",
      "subjects": [
        "physics.flu-dyn",
        "physics.ao-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Cohomological length functions",
      "abstract": "  We study certain integer valued length functions on triangulated categories\nand establish a correspondence between such functions and cohomological\nfunctors taking values in the category of finite length modules over some ring.\nThe irreducible cohomological functions form a topological space. We discuss\nits basic properties and include explicit calculations for the category of\nperfect complexes over some specific rings.\n",
      "subjects": [
        "math.RT",
        "math.CT",
        "math.KT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Robust PCA and subspace tracking from incomplete observations using\n  L0-surrogates",
      "abstract": "  Many applications in data analysis rely on the decomposition of a data matrix\ninto a low-rank and a sparse component. Existing methods that tackle this task\nuse the nuclear norm and L1-cost functions as convex relaxations of the rank\nconstraint and the sparsity measure, respectively, or employ thresholding\ntechniques. We propose a method that allows for reconstructing and tracking a\nsubspace of upper-bounded dimension from incomplete and corrupted observations.\nIt does not require any a priori information about the number of outliers. The\ncore of our algorithm is an intrinsic Conjugate Gradient method on the set of\northogonal projection matrices, the so-called Grassmannian. Non-convex sparsity\nmeasures are used for outlier detection, which leads to improved performance in\nterms of robustly recovering and tracking the low-rank matrix. In particular,\nour approach can cope with more outliers and with an underlying matrix of\nhigher rank than other state-of-the-art methods.\n",
      "subjects": [
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1080/02664760500389475",
      "title": "Properties of the Weibull cumulative exposure model",
      "abstract": "  This article is aimed at the investigation of some properties of the Weibull\ncumulative exposure model on multiple-step step-stress accelerated life test\ndata. Although the model includes a probabilistic idea of Miner's rule in order\nto express the effect of cumulative damage in fatigue, our result shows that\nthe application of only this is not sufficient to express degradation of\nspecimens and the shape parameter must be larger than 1. For a random variable\nobeying the model, its average and standard deviation are investigated on a\nvarious sets of parameter values. In addition, a way of checking the validity\nof the model is illustrated through an example of the maximum likelihood\nestimation on an actual data set, which is about time to breakdown of\ncross-linked polyethylene-insulated cables.\n",
      "subjects": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Low complexity sum rate maximization for single and multiple stream MIMO\n  AF relay networks",
      "abstract": "  A multiple-antenna amplify-and-forward two-hop interference network with\nmultiple links and multiple relays is considered. We optimize transmit\nprecoders, receive decoders and relay AF matrices to maximize the achievable\nsum rate. Under per user and total relay sum power constraints, we propose an\nefficient algorithm to maximize the total signal to total interference plus\nnoise ratio (TSTINR). Computational complexity analysis shows that our proposed\nalgorithm for TSTINR has lower complexity than the existing weighted minimum\nmean square error (WMMSE) algorithm. We analyze and confirm by simulations that\nthe TSTINR, WMMSE and the total leakage interference plus noise (TLIN)\nminimization models with per user and total relay sum power constraints can\nonly transmit a single data stream for each user. Thus we propose a novel\nmultiple stream TSTINR model with requirement of orthogonal columns for\nprecoders, in order to support multiple data streams and thus utilize higher\nDegrees of Freedom. Multiple data streams and larger multiplexing gains are\nguaranteed. Simulation results show that for single stream models, our TSTINR\nalgorithm outperforms the TLIN algorithm generally and outperforms WMMSE in\nmedium to high Signal-to-Noise-Ratio scenarios; the system sum rate\nsignificantly benefits from multiple data streams in medium to high SNR\nscenarios.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/sts569",
      "title": "X-ray and radio observations of the magnetar Swift J1834.9-0846 and its\n  dust-scattering halo",
      "abstract": "  We present a long-term study of the 2011 outburst of the magnetar Swift\nJ1834.9-0846 carried out using new Chandra observations, as well as all the\navailable Swift, RXTE, and XMM-Newton data. The last observation was performed\non 2011 November 12, about 100 days after the onset of the bursting activity\nthat had led to the discovery of the source on 2011 August 07. This long time\nspan enabled us to refine the rotational ephemeris and observe a downturn in\nthe decay of the X-ray flux. Assuming a broken power law for the long-term\nlight curve, the break was at ~46 d after the outburst onset, when the decay\nindex changed from alpha ~ 0.4 to ~4.5. The flux decreased by a factor ~2 in\nthe first ~50 d and then by a factor ~40 until November 2011 (overall, by a\nfactor ~70 in ~100 d). At the same time, the spectrum, which was well described\nby an absorbed blackbody all along the outburst, softened, the temperature\ndropping from ~1 to ~0.6 keV. Diffuse X-ray emission extending up to 20\" from\nthe source was clearly detected in all Chandra observations. Its spatial and\nspectral properties, as well as its time evolution, are consistent with a\ndust-scattering halo due to a single cloud located at a distance of\n$\\approx$200 pc from Swift J1834.9-0846, which should be in turn located at a\ndistance of ~5 kpc. Considering the time delay of the scattered photons, the\nsame dust cloud might also be responsible for the more extended emission\ndetected in XMM-Newton data taken in September 2011. We searched for the radio\nsignature of Swift J1834.9-0846 at radio frequencies using the Green Bank Radio\nTelescope and in archival data collected at Parkes from 1998 to 2003. No\nevidence for radio emission was found, down to a flux density of 0.05 mJy (at 2\nGHz) during the outburst and ~0.2-0.3 mJy (at 1.4 GHz) in the older data.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Do we have the explanation for the Higgs and Yukawa couplings of the\n  standard model?",
      "abstract": "  The spin-charge-family theory offers a possible explanation for the\nassumptions of the standard model, interpreting the standard model as its low\nenergy effective manifestation. The theory predicts several scalar fields\ndetermining masses and mixing matrices of fermions and weak bosons. The scalar\nfields manifest as doublets with respect to the weak charge, while they are\ntriplets with respect to the family quantum numbers. Since free scalar fields\n(mass eigen states) differ from those which couple to $Z_m$ and to\n$W^{\\pm}_{m}$ or to each family member of each of the family the\nspin-charge-family theory predictions for LHC might differ from those of the\nstandard model.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/2041-8205/763/1/L17",
      "title": "Very Metal-Poor Outer-Halo Stars with Round Orbits",
      "abstract": "  The orbital motions of halo stars in the Milky Way reflect the orbital\nmotions of the progenitor systems in which they formed, making it possible to\ntrace the mass-assembly history of the Galaxy. Direct measurement of\nthree-dimensional velocities, based on accurate proper motions and\nline-of-sight velocities, has revealed that the majority of halo stars in the\ninner-halo region move on eccentric orbits. However, our understanding of the\nmotions of distant, in-situ halo-star samples is still limited, due to the lack\nof accurate proper motions for these stars. Here we explore a model-independent\nanalysis of the line-of-sight velocities and spatial distribution of a recent\nsample of 1865 carefully selected halo blue horizontal-branch (BHB) stars\nwithin 30 kpc of the Galactic center. We find that the mean rotational velocity\nof the very metal-poor ([Fe/H] < -2.0) BHB stars significantly lags behind that\nof the relatively more metal-rich ([Fe/H] > -2.0) BHB stars. We also find that\nthe relatively more metal-rich BHB stars are dominated by stars with eccentric\norbits, as previously observed for other stellar samples in the inner-halo\nregion. By contrast, the very metal-poor BHB stars are dominated by stars on\nrounder, lower-eccentricity orbits. Our results indicate that the motion of the\nprogenitor systems of the Milky Way that contributed to the stellar populations\nfound within 30 kpc correlates directly with their metal abundance, which may\nbe related to their physical properties such as gas fractions. These results\nare consistent with the existence of an inner/outer halo structure for the halo\nsystem, as advocated by Carollo et al. (2010).\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.110.047003",
      "title": "Spin-state transition in the Fe-pnictides",
      "abstract": "  We report a Fe K\\beta x-ray emission spectroscopy study of local magnetic\nmoments in the rare-earth doped iron pnictide Ca_{1-x}RE_xFe_2As_2 (RE=La, Pr,\nand Nd). In all samples studied the size of the Fe local moment is found to\ndecrease significantly with temperature and goes from ~0.9 \\mu_B at T = 300 K\nto ~0.45 \\mu_B at T = 70 K. In the collapsed tetragonal (cT) phase of Nd- and\nPr-doped samples (T<70K) the local moment is quenched, while the moment remains\nunchanged for the La-doped sample, which does not show lattice collapse. Our\nresults show that Ca_{1-x}RE_xFe_2As_2 (RE= Pr and Nd) exhibits a spin-state\ntransition and provide direct evidence for a non-magnetic Fe^{2+} ion in the\ncT-phase, as predicted by Yildirim. We argue that the gradual change of the the\nspin-state over a wide temperature range reveals the importance of multiorbital\nphysics, in particular the competition between the crystal field split Fe 3d\norbitals and the Hund's rule coupling.\n",
      "subjects": [
        "cond-mat.supr-con",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.4789365",
      "title": "High Mobility Ambipolar MoS2 Field-Effect Transistors: Substrate and\n  Dielectric Effects",
      "abstract": "  We fabricate MoS2 field effect transistors on both SiO2 and polymethyl\nmethacrylate (PMMA) dielectrics and measure charge carrier mobility in a\nfour-probe configuration. For multilayer MoS2 on SiO2, the mobility is 30-60\ncm2/Vs, relatively independent of thickness (15-90 nm), and most devices\nexhibit unipolar n-type behavior. In contrast, multilayer MoS2 on PMMA shows\nmobility increasing with thickness, up to 470 cm2/Vs (electrons) and 480 cm2/Vs\n(holes) at thickness ~50 nm. The dependence of the mobility on thickness points\nto a long-range dielectric effect of the bulk MoS2 in increasing mobility.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Boundary of a Square Tiling of a Graph coincides with the Poisson\n  Boundary",
      "abstract": "  Answering a question of Benjamini & Schramm [8], we show that the Poisson\nboundary of any planar, uniquely absorbing (e.g. one-ended and transient) graph\nwith bounded degrees can be realised geometrically as a circle, namely as the\nboundary of a tiling of a cylinder by squares. This implies a conjecture of\nNorthshield [34] of similar flavour. For our proof we introduce a general\ncriterion for identifying the Poisson boundary of a stochastic process that\nmight have further applications.\n",
      "subjects": [
        "math.PR",
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Compact Securities Markets for Pareto Optimal Reallocation of Risk",
      "abstract": "  The emph{securities market} is the fundamental theoretical framework in\neconomics and finance for resource allocation under uncertainty. Securities\nserve both to reallocate risk and to disseminate probabilistic information.\nemph{Complete} securities markets - which contain one security for every\npossible state of nature - support Pareto optimal allocations of risk. Complete\nmarkets suffer from the same exponential dependence on the number of underlying\nevents as do joint probability distributions. We examine whether markets can be\nstructured and \"compacted\" in the same manner as Bayesian network\nrepresentations of joint distributions. We show that, if all agents'\nrisk-neutral independencies agree with the independencies encoded in the market\nstructure, then the market is emph{operationally complete}: risk is still\nPareto optimally allocated, yet the number of securities can be exponentially\nsmaller. For collections of agents of a certain type, agreement on Markov\nindependencies is sufficient to admit compact and operationally complete\nmarkets.\n",
      "subjects": [
        "cs.GT",
        "q-fin.GN"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On Alexander-Conway polynomials of two-bridge links",
      "abstract": "  We consider Conway polynomials of two-bridge links as Euler continuant\npolynomials. As a consequence, we obtain new and elementary proofs of classical\nMurasugi's 1958 alternating theorem and Hartley's 1979 trapezoidal theorem. We\ngive a modulo 2 congruence for links, which implies the classical Murasugi's\n1971 congruence for knots. We also give sharp bounds for the coefficients of\nEuler continuants and deduce bounds for the Alexander polynomials of two-bridge\nlinks. These bounds improve and generalize those of Nakanishi Suketa'96. We\neasily obtain some bounds for the roots of the Alexander polynomials of\ntwo-bridge links. This is a partial answer to Hoste's conjecture on the roots\nof Alexander polynomials of alternating knots.\n",
      "subjects": [
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.4830316",
      "title": "Group-invariant solutions of semilinear Schrodinger equations in multi-\n  dimensions",
      "abstract": "  Symmetry group methods are applied to obtain all explicit group-invariant\nradial solutions to a class of semilinear Schrodinger equations in dimensions\n$n\\neq 1$. Both focusing and defocusing cases of a power nonlinearity are\nconsidered, including the special case of the conformal power $p=4/n$ relevant\nfor critical dynamics.The methods involve, firstly, reduction of the semilinear\nSchrodinger equations to group-invariant complex 2nd order ODEs with respect to\nan optimal set of one-dimensional point symmetry groups, and secondly, use of\ninherited symmetries, hidden symmetries, and conditional symmetries to solve\neach ODE by quadratures. Through Noether's theorem, all conservation laws\narising from these point symmetry groups are listed.\n",
      "subjects": [
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.88.165202",
      "title": "The Infrared Absorption Band and Vibronic Structure of the\n  Nitrogen-Vacancy Center in Diamond",
      "abstract": "  Negatively-charged nitrogen-vacancy (NV$^-$) color centers in diamond have\ngenerated much interest for use in quantum technology. Despite the progress\nmade in developing their applications, many questions about the basic\nproperties of NV$^-$ centers remain unresolved. Understanding these properties\ncan validate theoretical models of NV$^-$, improve their use in applications,\nand support their development into competitive quantum devices. In particular,\nknowledge of the phonon modes of the $^1A_1$ electronic state is key for\nunderstanding the optical pumping process. Using pump-probe spectroscopy, we\nmeasured the phonon sideband of the ${^1}E\\rightarrow{^1}A_1$ electronic\ntransition in the NV$^-$ center. From this we calculated the\n${^1}E\\rightarrow{^1}A_1$ one-phonon absorption spectrum and found it to differ\nfrom that of the ${^3}E\\rightarrow{^3}A_2$ transition, a result which is not\nanticipated by previous group-theoretical models of the NV$^-$ electronic\nstates. We identified a high-energy 169 meV localized phonon mode of the\n$^1A_1$ level.\n",
      "subjects": [
        "physics.atom-ph",
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Local mean dimension of ASD moduli spaces over the cylinder",
      "abstract": "  We study an infinite dimensional ASD moduli space over the cylinder. Our main\nresult is the formula of its local mean dimension. A key ingredient of the\nargument is the notion of non-degenerate ASD connections. We develop its\ndeformation theory and show that there exist sufficiently many non-degenerate\nASD connections by using the method of gluing infinitely many instantons.\n",
      "subjects": [
        "math.DG",
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.87.062122",
      "title": "Experimental Adaptive Bayesian Tomography",
      "abstract": "  We report an experimental realization of an adaptive quantum state tomography\nprotocol. Our method takes advantage of a Bayesian approach to statistical\ninference and is naturally tailored for adaptive strategies. For pure states we\nobserve close to 1/N scaling of infidelity with overall number of registered\nevents, while best non-adaptive protocols allow for $1/\\sqrt{N}$ scaling only.\nExperiments are performed for polarization qubits, but the approach is readily\nadapted to any dimension.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physletb.2013.07.057",
      "title": "Colored bosons on top FBA and angular cross section for $t \\bar t$\n  production",
      "abstract": "  With full data set that corresponds to an integrated luminosity of 9.4\nfb$^{-1}$, CDF has updated the top quark forward-backward asymmetry (FBA) as\nfunctions of rapidity difference $|\\Delta y|$ and $t\\bar t$ invariant mass\n$M_{t\\bar t}$. Beside the sustained inconsistency between experiments and\nstandard model (SM) predictions at large $|\\Delta y|$ and $M_{t\\bar t}$, an\nunexpected large first Legendre moment with $a_1= 0.39\\pm 0.108 $ is found. In\norder to solve the large top FBA, we study the contributions of color triplet\nscalar and color octet vector boson. We find that the top FBA at $|\\Delta y|\n>1$ and $M_{t\\bar t} > 450$ GeV in triplet and octet model could be enhanced to\nbe around 30% and 20%, whereas the first Legendre moment is $a^{\\bf Di}_1=\n0.38$ and $a^{\\bf Axi}_1= 0.23$, respectively.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jfa.2014.03.012",
      "title": "Weak and cyclic amenability for Fourier algebras of connected Lie groups",
      "abstract": "  Using techniques of non-abelian harmonic analysis, we construct an explicit,\nnon-zero cyclic derivation on the Fourier algebra of the real $ax+b$ group. In\nparticular this provides the first proof that this algebra is not weakly\namenable. Using the structure theory of Lie groups, we deduce that the Fourier\nalgebras of connected, semisimple Lie groups also support non-zero, cyclic\nderivations and are likewise not weakly amenable. Our results complement\nearlier work of Johnson (JLMS, 1994), Plymen (unpublished note) and\nForrest--Samei--Spronk (IUMJ 2009). As an additional illustration of our\ntechniques, we construct an explicit, non-zero cyclic derivation on the Fourier\nalgebra of the reduced Heisenberg group, providing the first example of a\nconnected nilpotent group whose Fourier algebra is not weakly amenable.\n",
      "subjects": [
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.4813244",
      "title": "Heat Transport in Confined Strongly Coupled 2D Dust Clusters",
      "abstract": "  Dusty plasmas are a model system for studying strong correlation. The dust\ngrains' size of a few micro-meters and their characteristic oscillation\nfrequency of a few hertz allows for an investigation of many particle effects\non an atomic level. In this article, we model the heat transport through an\naxially confined 2D dust cluster from the center to the outside. The system\nbehaves particularly interesting since heat is not only conducted within the\ndust component but also transfered to the neutral gas. Fitting the analytical\nsolution to the obtained radial temperature profiles allows to determine the\nheat conductivity $\\kheat$. The heat conductivity is found to be constant over\na wide range of coupling strengths even including the phase transition from\nsolid to liquid here, as it was also found in extended systems by V. Nosenko et\nal. in 2008 \\cite{PhysRevLett.100.025003}\n",
      "subjects": [
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/TAC.2014.2364971",
      "title": "Optimal Kullback-Leibler Aggregation via Information Bottleneck",
      "abstract": "  In this paper, we present a method for reducing a regular, discrete-time\nMarkov chain (DTMC) to another DTMC with a given, typically much smaller number\nof states. The cost of reduction is defined as the Kullback-Leibler divergence\nrate between a projection of the original process through a partition function\nand a DTMC on the correspondingly partitioned state space. Finding the reduced\nmodel with minimal cost is computationally expensive, as it requires an\nexhaustive search among all state space partitions, and an exact evaluation of\nthe reduction cost for each candidate partition. Our approach deals with the\nlatter problem by minimizing an upper bound on the reduction cost instead of\nminimizing the exact cost; The proposed upper bound is easy to compute and it\nis tight if the original chain is lumpable with respect to the partition. Then,\nwe express the problem in the form of information bottleneck optimization, and\npropose using the agglomerative information bottleneck algorithm for searching\na sub-optimal partition greedily, rather than exhaustively. The theory is\nillustrated with examples and one application scenario in the context of\nmodeling bio-molecular interactions.\n",
      "subjects": [
        "cs.SY",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Structured $H_\\infty$-Optimal Control for Nested Interconnections: A\n  State-Space Solution",
      "abstract": "  If imposing general structural constraints on controllers, it is unknown how\nto design $H_\\infty$-controllers by convex optimization. Under a so-called\nquadratic invariance structure of the generalized plant, the Youla\nparametrization allows to translate the structured synthesis problem into an\ninfinite-dimensional convex program. Nested interconnections that are\ncharacterized by a standard plant with a block-triangular structure fall into\nthis class. Recently it has been shown how to design optimal $H_2$-controllers\nfor such nested structures in the state-space by solving algebraic Riccati\nequations. In the present paper we provide a state-space solution of the\ncorresponding output-feedback $H_\\infty$ synthesis problem without any\ncounterpart in the literature. We argue that a solution based on Riccati\nequations is - even for state-feedback problems - not feasible and we\nillustrate our results by means of a simple numerical example.\n",
      "subjects": [
        "math.OC",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.3573616",
      "title": "Rigorous bounds for Renyi entropies of spherically symmetric potentials",
      "abstract": "  The R\\'enyi and Shannon entropies are information-theoretic measures which\nhave enabled to formulate the position-momentum uncertainty principle in a much\nmore adequate and stringent way than the (variance-based) Heisenberg-like\nrelation. Moreover, they are closely related to various energetic\ndensity-functionals of quantum systems. Here we find sharp upper bounds to\nthese quantities in terms of the second order moment $\\langle r^2\\rangle$ for\ngeneral spherically symmetric potentials, which substantially improve previous\nresults of this type, by means of the R\\'enyi maximization procedure with a\ncovariance constraint due to Costa, Hero and Vignat \\cite{CosHer03}. The\ncontributions to these bounds coming from the radial and angular parts of the\nphysical wavefunctions are explicitly given.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Photoionization Delay in He, Ne, Ar and Kr",
      "abstract": "  We study photoionization of various noble gas atoms by attosecond pulses\nproduced in High Harmonic Generation (HHG). We use a pump-probe experiment to\nmeasure the time delays of electrons photoionized from Neon, Argon, and Krypton\nrelative to those photoionized from Helium atoms. The Attosecond Pulse Train\n(APT) is characterized and the relative delay in photoionization of various\nnoble gases is measured. The photoionization delay of Ne, Ar, and Kr is\ndetermined using previously calculated values for the He atomic delay and the\ndelay associated with the probe process.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/773/1/4",
      "title": "Dependence of Nebular Heavy-Element Abundance on H I Content for Spiral\n  Galaxies",
      "abstract": "  We analyze the galactic H I content and nebular log(O/H) for 60 spiral\ngalaxies in the Moustakas et al. (2006) spectral catalog. After correcting for\nthe mass-metallicity relationship, we show that the spirals in cluster\nenvironments show a positive correlation for log(O/H) on DEF, the galactic H I\ndeficiency parameter, extending the results of previous analyses of the Virgo\nand Pegasus I clusters. Additionally, we show for the first time that galaxies\nin the field obey a similar dependence. The observed relationship between H I\ndeficiency and galactic metallicity resembles similar trends shown by\ncosmological simulations of galaxy formation including inflows and outflows.\nThese results indicate the previously observed metallicity-DEF correlation has\na more universal interpretation than simply a cluster's effects on its member\ngalaxies. Rather, we observe in all environments the stochastic effects of\nmetal-poor infall as minor mergers and accretion help to build giant spirals.\n",
      "subjects": [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.112.026403",
      "title": "Resonant X-ray scattering and the $j_{\\mathrm{eff}}=1/2$ electronic\n  ground state in iridate perovskites",
      "abstract": "  The resonant X-ray scattering (magnetic elastic, RXMS, and inelastic, RIXS)\nof Ir$^{4+}$ at the L$_{2,3}$ edges relevant to spin-orbit Mott insulators\nA$_{n+1}$Ir$_{n}$O$_{3n+1}$ (A=Sr, Ba, etc.) are calculated using a single-ion\nmodel which treats the spin-orbit and tetragonal crystal-field terms on an\nequal footing. Both RXMS and RIXS in the spin-flip channel are found to display\na non-trivial dependence on the direction of the magnetic moment,\n$\\boldsymbol\\mu$. Crucially, we show that for $\\boldsymbol\\mu$ in the\n\\emph{ab}-plane, RXMS at the L$_2$ edge is zero \\emph{irrespective} of the\ntetragonal crystal-field; spin-flip RIXS, relevant to measurements of magnons,\nbehaves reciprocally being zero at L$_2$ when $\\boldsymbol\\mu$ is perpendicular\nto the \\emph{ab}-plane. Our results provide important insights into the\ninterpretation of X-ray data from the iridates, including that a\n$j_{\\mathrm{eff}}=1/2$ ground state cannot be assigned on the basis of\nL$_2$/L$_3$ intensity ratio alone.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP10(2013)167",
      "title": "Measurement of the W-boson helicity in top-quark decays from ttbar\n  production in lepton+jets events in pp collisions at sqrt(s) = 7 TeV",
      "abstract": "  The W-boson helicity fractions in top-quark decays are measured with ttbar\nevents in the lepton+jets final state, using proton-proton collisions at a\ncentre-of-mass energy of 7 TeV, collected in 2011 with the CMS detector at the\nLHC. The data sample corresponds to an integrated luminosity of 5.0 inverse\nfemtobarns. The measured fractions of longitudinal, left-, and right-handed\nhelicity are F0 = 0.682 +/- 0.030 (stat.) +/- 0.033 (syst.), FL = 0.310 +/-\n0.022 (stat.) +/- 0.022 (syst.), and FR = 0.008 +/- 0.012 (stat.) +/- 0.014\n(syst.), consistent with the standard model predictions. The measured fractions\nare used to probe the existence of anomalous Wtb couplings. Exclusion limits on\nthe real components of the anomalous couplings gL, gR are also derived.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.89.045134",
      "title": "Relationship between Fermi-Surface Warping and Out-of-Plane Spin\n  Polarization in Topological Insulators: a View from Spin-Resolved ARPES",
      "abstract": "  We have performed spin- and angle-resolved photoemission spectroscopy of the\ntopological insulator Pb(Bi,Sb)2Te4 (Pb124) and observed significant\nout-of-plane spin polarization on the hexagonally warped Dirac-cone surface\nstate. To put this into context, we carried out quantitative analysis of the\nwarping strengths for various topological insulators (Pb124, Bi2Te3, Bi2Se3,\nand TlBiSe2) and elucidated that the out-of-plane spin polarization Pz is\nsystematically correlated with the warping strength. However, the magnitude of\nPz is found to be only half of that expected from the kp theory when the\nwarping is strong, which points to the possible role of many-body effects.\nBesides confirming a universal relationship between the spin polarization and\nthe surface state structure, our data provide an empirical guiding principle\nfor tuning the spin polarization in topological insulators.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1371/journal.pcbi.1003299",
      "title": "A Computational Model of Liver Iron Metabolism",
      "abstract": "  Iron is essential for all known life due to its redox properties, however\nthese same properties can also lead to its toxicity in overload through the\nproduction of reactive oxygen species. Robust systemic and cellular control are\nrequired to maintain safe levels of iron and the liver seems to be where this\nregulation is mainly located. Iron misregulation is implicated in many diseases\nand as our understanding of iron metabolism improves the list of iron-related\ndisorders grows. Recent developments have resulted in greater knowledge of the\nfate of iron in the body and have led to a detailed map of its metabolism,\nhowever a quantitative understanding at the systems level of how its components\ninteract to produce tight regulation remains elusive.\n  A mechanistic computational model of human liver iron metabolism, which\nincludes the core regulatory components, was constructed based on known\nmechanisms of regulation and on their kinetic properties, obtained from several\npublications. The model was then quantitatively validated by comparing its\nresults with previously published physiological data, and it is able to\nreproduce multiple experimental findings. A time course simulation following an\noral dose of iron was compared to a clinical time course study and the\nsimulation was found to recreate the dynamics and time scale of the systems\nresponse to iron challenge. A disease simulation of haemochromatosis was\ncreated by altering a single reaction parameter that mimics a human\nhaemochromatosis gene (HFE) mutation. The simulation provides a quantitative\nunderstanding of the liver iron overload that arises in this disease.\n  This model supports and supplements understanding of the role of the liver as\nan iron sensor and provides a framework for further modelling, including\nsimulations to identify valuable drug targets and design of experiments to\nimprove further our knowledge of this system.\n",
      "subjects": [
        "q-bio.MN"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Infinite Dimensional Choi-Jamiolkowski States and Time Reversed Quantum\n  Markov Semigroups",
      "abstract": "  We propose a definition of infinite dimensional Choi-Jamiolkowski state\nassociated with a completely positive trace preserving map. We introduce the\nnotion of Theta-KMS adjoint of a quantum Markov semigroup, which is identified\nwith the time reversed semigroup. The break down of Theta-KMS symmetry (or\nTheta-standard quantum detailed balance in the sense of Fagnola-Umanita) is\nmeasured by means of the von Neumann relative entropy of the Choi-Jamiolkowski\nstates associated with the semigroup and its Theta-KMS adjoint.\n",
      "subjects": [
        "math-ph",
        "math.MP",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Minimal Supersymmetric Model of Particle Physics and the Early\n  Universe",
      "abstract": "  We consider a minimal supersymmetric extension of the Standard Model, with\nright-handed neutrinos and local B-L, the difference between baryon and lepton\nnumber, a symmetry which is spontaneously broken at the scale of grand\nunification. To a large extent, the parameters of the model are determined by\ngauge and Yukawa couplings of quarks and leptons. We show that this minimal\nmodel can successfully account for the earliest phases of the cosmological\nevolution: Inflation is driven by the energy density of a false vacuum of\nunbroken B-L symmetry, which ends in tachyonic preheating, i.e. the decay of\nthe false vacuum, followed by a matter dominated phase with heavy B-L Higgs\nbosons. Nonthermal and thermal processes produce an abundance of heavy\nneutrinos whose decays generate primordial entropy, baryon asymmetry via\nleptogenesis and dark matter consisting of gravitinos or nonthermal WIMPs. The\nmodel predicts relations between neutrino and superparticle masses and a\ncharacteristic spectrum of gravitational waves.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stt1808",
      "title": "The X-ray Spectrum and Spectral Energy Distribution of FIRST\n  J155633.8+351758: a LoBAL Quasar with a Probable Polar Outflow",
      "abstract": "  We report the results of a new 60 ks Chandra X-ray Observatory Advanced CCD\nImaging Spectrometer S-array (ACIS-S) observation of the reddened,\nradio-selected, highly polarized `FeLoBAL' quasar FIRST J1556+3517. We\ninvestigated a number of models of varied sophistication to fit the 531-photon\nspectrum. These models ranged from simple power laws to power laws absorbed by\nhydrogen gas in differing ionization states and degrees of partial covering.\nPreferred fits indicate that the intrinsic X-ray flux is consistent with that\nexpected for quasars of similarly high luminosity, i.e., an intrinsic,\ndereddened and unabsorbed optical to X-ray spectral index of -1.7. We cannot\ntightly constrain the intrinsic X-ray power-law slope, but find indications\nthat it is flat (photon index Gamma = 1.7 or flatter at a >99% confidence for a\nneutral hydrogen absorber model). Absorption is present, with a column density\na few times 10^23 cm^-2, with both partially ionized models and partially\ncovering neutral hydrogen models providing good fits. We present several lines\nof argument that suggest the fraction of X-ray emissions associated with the\nradio jet is not large.\n  We combine our Chandra data with observations from the literature to\nconstruct the spectral energy distribution of FIRST J1556+3517 from radio to\nX-ray energies. We make corrections for Doppler beaming for the pole-on radio\njet, optical dust reddening, and X-ray absorption, in order to recover a\nprobable intrinsic spectrum. The quasar FIRST J1556+3517 seems to be an\nintrinsically normal radio-quiet quasar with a reddened optical/UV spectrum, a\nDoppler-boosted but intrinsically weak radio jet, and an X-ray absorber not\ndissimilar from that of other broad absorption line quasars.\n",
      "subjects": [
        "astro-ph.HE",
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.tsf.2013.11.090",
      "title": "Transmission electron microscopy and ferromagnetic resonance\n  investigations of tunnel magnetic junctions using Co2MnGe Heusler alloy as\n  magnetic electrodes",
      "abstract": "  HRTEM, nano-beam electronic diffraction, energy dispersive X-rays scanning\nspectroscopy, Vibrating Sample Magnetometry (VSM) and FerroMagnetic Resonance\n(FMR) techniques are used in view of comparing (static and dynamic) magnetic\nand structural properties of Co2MnGe (13 nm)/Al2O3 (3 nm)/Co (13 nm) tunnel\nmagnetic junctions (TMJ), deposited on various single crystalline substrates\n(a-plane sapphire, MgO(100) and Si(111)). They allow for providing a\ncorrelation between these magnetic properties and the fine structure\ninvestigated at atomic scale. The Al2O3 tunnel barrier is always amorphous and\ncontains a large concentration of Co atoms, which, however, is significantly\nreduced when using a sapphire substrate. The Co layer is polycrystalline and\nshows larger grains for films grown on a sapphire substrate. The VSM\ninvestigation reveals in-plane anisotropy only for samples grown on a sapphire\nsubstrate. The FMR spectra of the TMJs are compared to the obtained ones with a\nsingle Co and Co2MnGe films of identical thickness deposited on a sapphire\nsubstrate. As expected, two distinct modes are detected in the TMJs while only\none mode is observed in each single film. For the TMJ grown on a sapphire\nsubstrate the FMR behavior does not significantly differ from the superposition\nof the individual spectra of the single films, allowing for concluding that the\nexchange coupling between the two magnetic layers is too small to give rise to\nobservable shifts. For TMJs grown on a Si or on a MgO substrate the resonance\nspectra reveal one mode which is nearly identical to the obtained one in the\nsingle Co film, while the other observed resonance shows a considerably smaller\nintensity and cannot be described using the magnetic parameters appropriate to\nthe single Co2MnGe film.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0031-9155/59/3/747",
      "title": "Radiotherapy planning for glioblastoma based on a tumor growth model:\n  Improving target volume delineation",
      "abstract": "  Glioblastoma are known to infiltrate the brain parenchyma instead of forming\na solid tumor mass with a defined boundary. Only the part of the tumor with\nhigh tumor cell density can be localized through imaging directly. In contrast,\nbrain tissue infiltrated by tumor cells at low density appears normal on\ncurrent imaging modalities. In clinical practice, a uniform margin is applied\nto account for microscopic spread of disease.\n  The current treatment planning procedure can potentially be improved by\naccounting for the anisotropy of tumor growth: Anatomical barriers such as the\nfalx cerebri represent boundaries for migrating tumor cells. In addition, tumor\ncells primarily spread in white matter and infiltrate gray matter at lower\nrate. We investigate the use of a phenomenological tumor growth model for\ntreatment planning. The model is based on the Fisher-Kolmogorov equation, which\nformalizes these growth characteristics and estimates the spatial distribution\nof tumor cells in normal appearing regions of the brain. The target volume for\nradiotherapy planning can be defined as an isoline of the simulated tumor cell\ndensity.\n  A retrospective study involving 10 glioblastoma patients has been performed.\nTo illustrate the main findings of the study, a detailed case study is\npresented for a glioblastoma located close to the falx. In this situation, the\nfalx represents a boundary for migrating tumor cells, whereas the corpus\ncallosum provides a route for the tumor to spread to the contralateral\nhemisphere. We further discuss the sensitivity of the model with respect to the\ninput parameters. Correct segmentation of the brain appears to be the most\ncrucial model input.\n  We conclude that the tumor growth model provides a method to account for\nanisotropic growth patterns of glioblastoma, and may therefore provide a tool\nto make target delineation more objective and automated.\n",
      "subjects": [
        "physics.med-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Asymptotic expansions for SDE's with small multiplicative noise",
      "abstract": "  Asymptotic expansions are derived as power series in a small coefficient\nentering a nonlinear multiplicative noise and a deterministic driving term in a\nnonlinear evolution equation. Detailed estimates on remainders are provided.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epjc/s10052-016-3947-6",
      "title": "Measurement of the radiative decay of polarized muons in the MEG\n  experiment",
      "abstract": "  We studied the radiative muon decay $\\mu^+ \\to e^+\\nu\\bar{\\nu}\\gamma$ by\nusing for the first time an almost fully polarized muon source. We identified a\nlarge sample (~13000) of these decays in a total sample of 1.8x10^14 positive\nmuon decays collected in the MEG experiment in the years 2009--2010 and\nmeasured the branching ratio B($\\mu^+ \\to e^+\\nu\\bar{\\nu}\\gamma$) =\n(6.03+-0.14(stat.)+-0.53(sys.))x10^-8 for E_e > 45 MeV and E_{\\gamma} > 40 MeV,\nconsistent with the Standard Model prediction. The precise measurement of this\ndecay mode provides a basic tool for the timing calibration, a normalization\nchannel, and a strong quality check of the complete MEG experiment in the\nsearch for $\\mu^+ \\to e^+\\gamma$ process.\n",
      "subjects": [
        "hep-ex",
        "hep-ph",
        "physics.ins-det"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Extreme points of the Vandermonde determinant on the sphere and some\n  limits involving the generalized Vandermonde determinant",
      "abstract": "  The values of the determinant of Vandermonde matrices with real elements are\nanalyzed both visually and analytically over the unit sphere in various\ndimensions. For three dimensions some generalized Vandermonde matrices are\nanalyzed visually. The extreme points of the ordinary Vandermonde determinant\non finite-dimensional unit spheres are given as the roots of rescaled Hermite\npolynomials and a recursion relation is provided for the polynomial\ncoefficients. Analytical expressions for these roots are also given for\ndimension three to seven. A transformation of the optimization problem is\nprovided and some relations between the ordinary and generalized Vandermonde\nmatrices involving limits are discussed.\n",
      "subjects": [
        "math.CA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Cayley isomorphism property for groups of order p^3q",
      "abstract": "  For every prime $p > 3$ and for every prime $q>p^3$ we prove that\n$\\mathbb{Z}_q \\times \\mathbb{Z}_p^3$ is a DCI-group.\n",
      "subjects": [
        "math.GR",
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1367-2630/16/7/073029",
      "title": "Accelerating the Averaging Rate of Atomic Ensemble Clock Stability using\n  Atomic Phase Lock",
      "abstract": "  We experimentally demonstrated that the stability of an atomic clock improves\nat fastest rate $\\tau^{-1}$ (where $\\tau$ is the averaging time) when the phase\nof a local oscillator is genuinely compared to the continuous phase of many\natoms in a single trap (atomic phase lock). For this demonstration, we\ndeveloped a simple method that repeatedly monitors the atomic phase while\nretaining its coherence by observing only a portion of the whole ion cloud.\nUsing this new method, we measured the continuous phase over 3 measurement\ncycles, and thereby improved the stability scaling from $\\tau^{-1/2}$ to\n$\\tau^{-1}$ during the 3 measurement cycles.\n  %Compared with the standard method that initialize phase during each\nmeasurement cycle, the long term stability was improved by a factor of\n$\\sqrt{n_{cp}}$ (where $n_{cp}$ is the number of continuous phase\nmeasurements).\n  This simple method provides a path by which atomic clocks can approach a\nquantum projection noise limit, even when the measurement noise is dominated by\nthe technical noise.\n",
      "subjects": [
        "quant-ph",
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1613/jair.3509",
      "title": "Computing All-Pairs Shortest Paths by Leveraging Low Treewidth",
      "abstract": "  We present two new and efficient algorithms for computing all-pairs shortest\npaths. The algorithms operate on directed graphs with real (possibly negative)\nweights. They make use of directed path consistency along a vertex ordering d.\nBoth algorithms run in O(n^2 w_d) time, where w_d is the graph width induced by\nthis vertex ordering. For graphs of constant treewidth, this yields O(n^2)\ntime, which is optimal. On chordal graphs, the algorithms run in O(nm) time. In\naddition, we present a variant that exploits graph separators to arrive at a\nrun time of O(n w_d^2 + n^2 s_d) on general graphs, where s_d andlt= w_d is the\nsize of the largest minimal separator induced by the vertex ordering d. We show\nempirically that on both constructed and realistic benchmarks, in many cases\nthe algorithms outperform Floyd-Warshalls as well as Johnsons algorithm, which\nrepresent the current state of the art with a run time of O(n^3) and O(nm + n^2\nlog n), respectively. Our algorithms can be used for spatial and temporal\nreasoning, such as for the Simple Temporal Problem, which underlines their\nrelevance to the planning and scheduling community.\n",
      "subjects": [
        "cs.DS",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jpaa.2014.10.004",
      "title": "Functoriality of groupoid quantales. I",
      "abstract": "  We provide three functorial extensions of the equivalence between localic\netale groupoids and their quantales. The main result is a biequivalence between\nthe bicategory of localic etale groupoids, with bi-actions as 1-cells, and a\nbicategory of inverse quantal frames whose 1-cells are bimodules. As a\nconsequence, the category InvQuF of inverse quantale frames, whose morphisms\nare the (necessarily involutive) homomorphisms of unital quantales, is\nequivalent to a category of localic etale groupoids whose arrows are the\nalgebraic morphisms in the sense of Buneci and Stachura. We also show that the\nsubcategory of InvQuF with the same objects and whose morphisms preserve finite\nmeets is dually equivalent to a subcategory of the category of localic etale\ngroupoids and continuous functors whose morphisms, in the context of\ntopological groupoids, have been studied by Lawson and Lenz.\n",
      "subjects": [
        "math.CT",
        "math.OA",
        "math.RA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1613/jair.3770",
      "title": "Irrelevant and independent natural extension for sets of desirable\n  gambles",
      "abstract": "  The results in this paper add useful tools to the theory of sets of desirable\ngambles, a growing toolbox for reasoning with partial probability assessments.\nWe investigate how to combine a number of marginal coherent sets of desirable\ngambles into a joint set using the properties of epistemic irrelevance and\nindependence. We provide formulas for the smallest such joint, called their\nindependent natural extension, and study its main properties. The independent\nnatural extension of maximal coherent sets of desirable gambles allows us to\ndefine the strong product of sets of desirable gambles. Finally, we explore an\neasy way to generalise these results to also apply for the conditional versions\nof epistemic irrelevance and independence. Having such a set of tools that are\neasily implemented in computer programs is clearly beneficial to fields, like\nAI, with a clear interest in coherent reasoning under uncertainty using general\nand robust uncertainty models that require no full specification.\n",
      "subjects": [
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On a finite 2,3-generated group of period 12",
      "abstract": "  Using calculations in computer algebra systems along with some theoretic\nresults, we construct the largest finite group of period 12 generated by an\nelement of order 2 and an element of order 3. In particular, we prove that this\ngroup has order $2^{66}.3^7$.\n",
      "subjects": [
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On monotonicity and order-preservation for multidimensional G-diffusion\n  processes",
      "abstract": "  In this paper, we prove a comparison theorem for multidimensional G-SDEs.\nMoreover we obtain respectively the sufficient conditions and necessary\nconditions of the monotonicity and order-preservation for two multidimensional\nG-diffusion processes. Finally, we give some applications.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On conformable fractional calulus",
      "abstract": "  Recently, the authors Khalil, R., Al Horani, M., Yousef. A. and Sababheh, M.,\nin \" A new Denition Of Fractional Derivative, J. Comput. Appl. Math. 264. pp.\n6570, 2014. \" introduced a new simple well-behaved definition of the fractional\nderivative called conformable fractional derivative. In this article we proceed\non to develop the definitions there and set the basic concepts in this new\nsimple interesting fractional calculus. The fractional versions of chain rule,\nexponential functions, Gronwall's inequality, integration by parts, Taylor\npower series expansions, Laplace transforms and linear differential systems are\nproposed and discussed.\n",
      "subjects": [
        "math.DS",
        "math.CA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.89.052335",
      "title": "Randomized Graph States and their Entanglement Properties",
      "abstract": "  We introduce a class of mixed multiqubit states, that corresponds to a\nrandomized version of graph states. Such states arise when a graph state is\nprepared with noisy or imperfect controlled-Z gates. We study the entanglement\nfeatures of these states by investigating both bipartite and genuine\nmultipartite entanglement. Bipartite entanglement is studied via the concepts\nof connectedness and persistency, which are related to measurement based\nquantum computation. The presence of multipartite entanglement is instead\nrevealed by the use of witness operators which are subsequently adapted to\nstudy nonlocal properties through the violation of suitable Bell inequalities.\nWe also present results on the entanglement detection of particular randomized\ngraph states, by deriving explicit thresholds for entanglement and nonlocality\nin terms of the noise parameter that characterizes the controlled-Z gates\nexploited for their generation. Finally, we propose a method to further improve\nthe detection of genuine multipartite entanglement in this class of states.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP12(2014)138",
      "title": "Effective Field Theory of Relativistic Quantum Hall Systems",
      "abstract": "  Motivated by the observation of the fractional quantum Hall effect in\ngraphene, we consider the effective field theory of relativistic quantum Hall\nstates. We find that, beside the Chern-Simons term, the effective action also\ncontains a term of topological nature, which couples the electromagnetic field\nwith a topologically conserved current of $2+1$ dimensional relativistic fluid.\nIn contrast to the Chern-Simons term, the new term involves the spacetime\nmetric in a nontrivial way. We extract the predictions of the effective theory\nfor linear electromagnetic and gravitational responses. For fractional quantum\nHall states at the zeroth Landau level, additional holomorphic constraints\nallow one to express the results in terms of two dimensionless constants of\ntopological nature.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.str-el",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Differential Dual-Hop Relaying over Time-Varying Rayleigh-Fading\n  Channels",
      "abstract": "  This paper studies dual-hop amplify-and-forward relaying over time-varying\nRayleigh fading channels with differential M-PSK modulation and non-coherent\ndetection. For the case of \"two-symbol\" detection, a first order time-series\nmodel is utilized to characterize the time-varying nature of the cascaded\nchannel. Based on this model, an exact bit error rate (BER) expression is\nderived and confirmed with simulation results. The obtained expression shows\nthat the BER is related to the auto-correlation of the cascaded channel and an\nirreducible error floor exists at high transmit power. To overcome the error\nfloor experienced with fast-fading, a nearly optimal multiple-symbol\ndifferential sphere detection (MSDSD) is also developed. The error performance\nof MSDSD is illustrated with simulation results under different fading\nscenarios.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Chern class map on abelian surfaces",
      "abstract": "  We examine the Chern class map ${c}_{1}: {\\rm NS}(S)/p{\\rm NS}(S) \\rightarrow\n{\\rm H}^{1}(S, \\Omega^{1}_{S})$ for an abelian surface $S$ in characteristic $p\n\\geq 3$, and give a basis of the kernel $c_{1}$ for the superspecial abelian\nsurface.\n",
      "subjects": [
        "math.AG",
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.89.064006",
      "title": "Statistical Error analysis of Nucleon-Nucleon phenomenological\n  potentials",
      "abstract": "  Nucleon-Nucleon potentials are commonplace in nuclear physics and are\ndetermined from a finite number of experimental data with limited precision\nsampling the scattering process. We study the statistical assumptions implicit\nin the standard least squares fitting procedure and apply, along with more\nconventional tests, a tail sensitive quantile-quantile test as a simple and\nconfident tool to verify the normality of residuals. We show that the\nfulfilment of normality tests is linked to a judicious and consistent selection\nof a nucleon-nucleon database. These considerations prove crucial to a proper\nstatistical error analysis and uncertainty propagation. We illustrate these\nissues by analyzing about 8000 proton-proton and neutron-proton scattering\npublished data. This enables the construction of potentials meeting all\nstatistical requirements necessary for statistical uncertainty estimates in\nnuclear structure calculations.\n",
      "subjects": [
        "nucl-th",
        "hep-ph",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Improving Bilayer Product Quantization for Billion-Scale Approximate\n  Nearest Neighbors in High Dimensions",
      "abstract": "  The top-performing systems for billion-scale high-dimensional approximate\nnearest neighbor (ANN) search are all based on two-layer architectures that\ninclude an indexing structure and a compressed datapoints layer. An indexing\nstructure is crucial as it allows to avoid exhaustive search, while the lossy\ndata compression is needed to fit the dataset into RAM. Several of the most\nsuccessful systems use product quantization (PQ) for both the indexing and the\ndataset compression layers. These systems are however limited in the way they\nexploit the interaction of product quantization processes that happen at\ndifferent stages of these systems.\n  Here we introduce and evaluate two approximate nearest neighbor search\nsystems that both exploit the synergy of product quantization processes in a\nmore efficient way. The first system, called Fast Bilayer Product Quantization\n(FBPQ), speeds up the runtime of the baseline system (Multi-D-ADC) by several\ntimes, while achieving the same accuracy. The second system, Hierarchical\nBilayer Product Quantization (HBPQ) provides a significantly better recall for\nthe same runtime at a cost of small memory footprint increase. For the BIGANN\ndataset of billion SIFT descriptors, the 10% increase in Recall@1 and the 17%\nincrease in Recall@10 is observed.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0264-9381/32/1/015021",
      "title": "Lorentz Invariance in Shape Dynamics",
      "abstract": "  Shape dynamics is a reframing of canonical general relativity in which time\nreparametrization invariance is \"traded\" for a local conformal invariance. We\nexplore the emergence of Lorentz invariance in this model in three contexts: as\na maximal symmetry, an asymptotic symmetry, and a local invariance.\n",
      "subjects": [
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Rescaling mechanism and effective symmetry from the ideal cancellation\n  of the $S$ parameter in custodial models",
      "abstract": "  We present a model independent analysis of custodial corrections to the $S$\nparameter. The negative contributions coming from direct corrections, i.e. the\ncorrections associated to effects of new physics in the fermionic sector, can\nbe used to eliminate unwanted positive oblique contributions to $S$. By means\nof such an ideal cancellation among oblique and direct corrections the\nelectroweak physics can be made insensitive to custodial new physics. The\nLagrangian analysis of the ideal cancellation reveals a possible sizable\nredefinition of the effective electroweak energy scale with respect to models\nwith only oblique corrections. We then infer from general principles the full\nexpression for the effective custodial operator responsible in the gauge sector\nfor the contribution to $S$. We show that the ideal cancellation exactly\neliminates all the custodial corrections, including those in the non-abelian\nand longitudinal terms. Indeed, provided redefinitions of the physical\nparameters, the standard model Lagrangian can be equivalently defined modulo\ncustodial corrections in the gauge and fermionic sectors. Thus the ideal\ncancellation can be regarded as an effective symmetry. Finally we investigate\nthe theoretical origin of this effective symmetry in terms of the effective\ngauge structure induced by custodial new physics.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Valuation and Divisibility",
      "abstract": "  In this paper, we explain how some basic facts about valuation can help\nclarify many questions about divisibility in integral domains.\n",
      "subjects": [
        "math.AC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.4310/HHA.2015.v17.n2.a10",
      "title": "The hammock localization preserves homotopies",
      "abstract": "  The hammock localization provides a model for a homotopy function complex in\nany Quillen model category. We prove that a homotopy between a pair of\nmorphisms induces a homotopy between the maps induced by taking the hammock\nlocalization. We describe applications of this fact to the study of homotopy\nalgebras over monads and homotopy idempotent functors. Among other things, we\nprove that, under Vop\\v{e}nka's principle, every homotopy idempotent functor in\na cofibrantly generated model category is determined by simplicial\northogonality with respect to a set of morphisms. We also give a new proof of\nthe fact that left Bousfield localizations with respect to a class of morphisms\nalways exist in any left proper combinatorial model category under\nVop\\v{e}nka's principle.\n",
      "subjects": [
        "math.AT",
        "math.CT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/ptep/ptu104",
      "title": "Self-organization in foliated phase space: Construction of a scale\n  hierarchy by adiabatic invariants of magnetized particles",
      "abstract": "  Adiabatic invariants foliate phase space, and impart a macro-scale hierarchy\nby separating microscopic variables. On a macroscopic leaf, long-scale ordered\nstructures are created while maximizing entropy. A plasma confined in a\nmagnetosphere is invoked for unveiling the organizing principle ---in the\nvicinity of a magnetic dipole, the plasma self-organizes to a state with a\nsteep density gradient. The resulting nontrivial structure has maximum entropy\nin an appropriate, constrained phase space. One could view such a phase space\nas a leaf foliated in terms of Casimir invariants ---adiabatic invariants\nmeasuring the number of quasi-particles (macroscopic representation of periodic\nmotions) are identified as the relevant Casimir invariants. The density clump\nis created in response to the inhomogeneity of the energy level (frequency) of\nquasi-particles.\n",
      "subjects": [
        "physics.plasm-ph",
        "nlin.AO",
        "physics.space-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Boundary feedback stabilization of a chain of serially connected strings",
      "abstract": "  We consider N strings connected to one another and forming a particular\nnetwork which is a chain of strings. We study a stabilization problem and\nprecisley we prove that the energy of the solutions of the dissipative system\ndecay exponentially to zero when the time tends to infinity, independently of\nthe densities of the strings. Our technique is based on a frequency domain\nmethod and a special analysis for the resolvent. Moreover, by same appraoch, we\nstudy the transfert function associated to the chain of strings and the\nstability of the Schr\\\"odinger system.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Controller selection in a Wireless Mesh SDN under network partitioning\n  and merging scenarios",
      "abstract": "  In this paper we consider a Wireless Mesh Network (WMN) integrating SDN\nprinciples. The Wireless Mesh Routers (WMR) are OpenFlow capable switches that\ncan be controlled by SDN controllers, according to the wmSDN (wireless mesh\nSDN) architecture that we have introduced in a previous work. We consider the\nissue of controller selection in a scenario with intermittent connectivity. We\nassume that over time a single WMN can become split in two or more partitions\nand that separate partitions can merge into a larger one. We assume that a set\nof SDN controllers can potentially take control of the WMRs. At a given time\nonly one controller should be the master of a WMR and it should be the most\nappropriate one according to some metric. We argue that the state of the art\nsolutions for \"master election\" among distributed controllers are not suitable\nin a mesh networking environment, as they could easily be affected by\ninconsistencies. We envisage a \"master selection\" approach which is under the\ncontrol of each WMR, and guarantees that at a given time only one controller\nwill be master of a WMR. We designed a specific master selection procedure\nwhich is very simple in terms of the control logic to be executed in the WMR.\nWe have implemented the proposed solution and deployed it over a network\nemulator (CORE) and over the combination of two physical wireless testbeds\n(NITOS and wiLab.t).\n",
      "subjects": [
        "cs.NI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0067-0049/213/2/22",
      "title": "YSO search toward the boundary of the Central Molecular Zone with\n  near-infrared polarimetry",
      "abstract": "  We have carried out near-infrared polarimetry toward the boundary of the\nCentral Molecular Zone, in the field of (-1.4 deg $\\lesssim l \\lesssim$ -0.3\ndeg and 1.0 deg $\\lesssim l \\lesssim$ 2.9 deg, $|b|\\lesssim$ 0.1 deg), using\nthe near-infrared polarimetric camera SIRPOL on the 1.4 m Infrared Survey\nFacility telescope. We have selected 112 intrinsically polarized sources on the\nbasis of the estimate of interstellar polarization on Stokes $Q/I-U/I$ planes.\nThe selected sources are brighter than $K_S=14.5$ mag and have polarimetric\nuncertainty $\\delta P<1\\,%$. Ten of these distinctive polarized sources are fit\nwell with spectral energy distributions of young stellar objects when using the\nphotometry in the archive of the Spitzer Space Telescope mid-infrared data.\nHowever, many sources have spectral energy distributions of normal stars\nsuffering heavy interstellar extinction; these might be stars behind dark\nclouds. Due to the small number of distinctive polarized sources and candidates\nof young stellar object, we cannot judge if there is a decline of them outside\nthe Central Molecular Zone. Many of massive candidates of young stellar object\nin the literature have only small intrinsic polarization. This might suggest\nthat their masses are 4-15 M$_{{\\rm sun}}$, whose intrinsic polarization has\nbeen expected to be small.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On a Class of Two-Dimensional Einstein Finsler Metrics of Vanishing\n  S-Curvature",
      "abstract": "  An $(\\alpha,\\beta)$-metric is defined by a Riemannian metric $\\alpha$ and\n$1$-form $\\beta$. In this paper, we study a known class of two-dimensional\n$(\\alpha,\\beta)$-metrics of vanishing S-curvature. We determine the local\nstructure of those metrics and show that those metrics are Einsteinian\n(equivalently, isotropic flag curvature) but generally are not Ricci-flat.\n",
      "subjects": [
        "math.DG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Future mmVLBI Research with ALMA: A European vision",
      "abstract": "  Very long baseline interferometry at millimetre/submillimetre wavelengths\n(mmVLBI) offers the highest achievable spatial resolution at any wavelength in\nastronomy. The anticipated inclusion of ALMA as a phased array into a global\nVLBI network will bring unprecedented sensitivity and a transformational leap\nin capabilities for mmVLBI. Building on years of pioneering efforts in the US\nand Europe the ongoing ALMA Phasing Project (APP), a US-led international\ncollaboration with MPIfR-led European contributions, is expected to deliver a\nbeamformer and VLBI capability to ALMA by the end of 2014 (APP: Fish et al.\n2013, arXiv:1309.3519).\n  This report focuses on the future use of mmVLBI by the international users\ncommunity from a European viewpoint. Firstly, it highlights the intense science\ninterest in Europe in future mmVLBI observations as compiled from the responses\nto a general call to the European community for future research projects. A\nwide range of research is presented that includes, amongst others:\n  - Imaging the event horizon of the black hole at the centre of the Galaxy\n  - Testing the theory of General Relativity an/or searching for alternative\ntheories\n  - Studying the origin of AGN jets and jet formation\n  - Cosmological evolution of galaxies and BHs, AGN feedback\n  - Masers in the Milky Way (in stars and star-forming regions)\n  - Extragalactic emission lines and astro-chemistry\n  - Redshifted absorption lines in distant galaxies and study of the ISM and\ncircumnuclear gas\n  - Pulsars, neutron stars, X-ray binaries\n  - Testing cosmology\n  - Testing fundamental physical constants\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "First Experiences With Validating and Using the Cray Power Management\n  Database Tool",
      "abstract": "  In October 2013 CSCS installed the first hybrid Cray XC-30 system, dubbed Piz\nDaint. This system features the power management database (PMDB), that was\nrecently introduced by Cray to collect detailed power consumption information\nin a non-intrusive manner. Power measurements are taken on each node, with\nadditional measurements for the Aries network and blowers, and recorded in a\ndatabase. This enables fine-grained reporting of power consumption that is not\npossible with external power meters, and is useful to both application\ndevelopers and facility operators. This paper will show how benchmarks of\nrepresentative applications at CSCS were used to validate the PMDB on Piz\nDaint. Furthermore we will elaborate, with the well-known HPL benchmark serving\nas prototypical application, on how the PMDB streamlines the tuning for optimal\npower efficiency in production, which lead to Piz Daint being recognised as the\nmost energy efficient petascale supercomputer presently in operation.\n",
      "subjects": [
        "cs.DC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0264-9381/32/7/075002",
      "title": "What is faster -- light or gravity?",
      "abstract": "  General relativity lacks the notion of the speed of gravity. This is\ninconvenient and the present paper is aimed at filling this gap up. To that end\nI introduce the concept of the \"alternative\" and argue that its variety called\nthe \"superluminal alternative\" describes exactly what one understands by the\n\"superluminal gravitational signal\". Another, closely related, object called\nthe \"semi-superluminal alternative\" corresponds to the situation in which a\nmassive (and therefore gravitating) body reaches its destination sooner than a\nphoton \\emph{would}, be the latter sent \\emph{instead} of the body. I prove\nthat in general relativity constrained by the condition that only globally\nhyperbolic spacetimes are allowed 1) semi-superluminal alternatives are absent\nand 2) under some natural conditions and conventions admissible superluminal\nalternative are absent too.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non-Unitary Holography",
      "abstract": "  We propose gauge theory/gravity duality involving conformal theories based on\nU(N+k|k) gauge groups. We show that to all orders in 1/N these non-unitary\ntheories based on supergroups are indistinguishable from the corresponding\nunitary theories where the gauge group is replaced by U(N). This leads to\nnon-unitary gravity duals which to all orders in 1/N are indistinguishable from\ntheir unitary cousins. They are distinguished by operators whose correlation\nfunctions differ by O(exp(-aN)). The celebrated type IIB on AdS^5 x S^5 and\nM-theory on AdS^4 x S^7 fall in this class and thus seem to also admit\nnon-unitary non-perturbative completions. It is tempting to conjecture that\nthis setup may provide a non-unitary model for black hole evaporation.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.91.022117",
      "title": "Optimal recruitment strategies for groups of interacting walkers with\n  leaders",
      "abstract": "  We introduce a model of interacting random walkers on a finite one\ndimensional chain with absorbing boundaries or targets at the ends. Walkers are\nof two types: informed particles that move ballistically towards a given\ntarget, and diffusing uninformed particles that are biased towards close\ninformed particles. This model mimics the dynamics of hierarchical groups of\nanimals, where an informed individual tries to persuade and lead the movement\nof its conspecifics. We characterize the success of the persuasion by the\nfirst-passage probability of the uninformed particle to the target, and we\ninterpret the speed of the informed particle as a strategic parameter that the\nparticle tunes to maximize its success. We find that the success probability is\nnon-monotonic, reaching its maximum at an intermediate speed whose value\nincreases with the diffusing rate of the uninformed particle. When two\ndifferent groups of informed leaders traveling in opposite directions compete,\nusually the largest group is the most successful. However, the minority can\nreverse this situation and become the most probable winner by following two\ndifferent strategies: increasing its attraction strength or adjusting its speed\nto an optimal value relative to the majority's speed.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "physics.bio-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0953-4075/48/2/025002",
      "title": "Measurements and identifications of extreme ultraviolet spectra of\n  highly-charged Sm and Er",
      "abstract": "  We report spectroscopic measurements of highly charged samarium and erbium\nperformed at the National Institute of Standards and Technology (NIST) Electron\nBeam Ion Trap (EBIT). These measurements are in the extreme ultraviolet (EUV)\nrange, and span electron beam energies from 0.98 keV to 3.00 keV. We observed\n71 lines from Kr-like Sm$^{26+}$ to Ni-like Sm$^{34+}$, connecting 83 energy\nlevels, and 64 lines from Rb-like Er$^{32+}$ to Ni-like Er$^{40+}$, connecting\n78 energy levels. Of these lines, 64 in Sm and 60 in Er are new. Line\nidentifications are performed using collisional-radiative modeling of the EBIT\nplasma. All spectral lines are assigned individual uncertainties, most in the\n$\\sim$0.001 nm range. Energy levels are derived from the wavelength\nmeasurements.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Quasars as tracers of cosmic flows",
      "abstract": "  Quasars, as the most luminous persistent sources in the Universe, have broad\napplications for cosmological studies. In particular, they can be employed to\ndirectly measure the expansion history of the Universe, similarly to SNe Ia.\nThe advantage of quasars is that they are numerous, cover a broad range of\nredshifts, up to $z = 7$, and do not show significant evolution of metallicity\nwith redshift. The idea is based on the relation between the time delay of an\nemission line and the continuum, and the absolute monochromatic luminosity of a\nquasar. For intermediate redshift quasars, the suitable line is Mg II. Between\nDecember 2012 and March 2014, we performed five spectroscopic observations of\nthe QSO CTS C30.10 ($z = 0.900$) using the South African Large Telesope (SALT),\nsupplemented with photometric monitoring, with the aim of determining the\nvariability of the line shape, changes in the total line intensity and in the\ncontinuum. We show that the method is very promising.\n",
      "subjects": [
        "astro-ph.CO",
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Insights from Nature for Cybersecurity",
      "abstract": "  The alarming rise in the quantity of malware in the last few years poses a\nserious challenge to the security community and requires urgent response.\nHowever, current countermeasures seem to be no longer effective. Thus, it is\nour belief that it is now time for researchers and security experts to turn to\nnature in the search for novel inspirations for defense systems. Nature has\nprovided species with a whole range of offensive and defensive techniques,\nwhich have been developing and improving in the course of billions of years of\nevolution. The extremely diverse living conditions have promoted a large\nvariation in the devised bio-security solutions. In this paper we introduce a\nnovel PROTECTION framework in which common denominators of the encountered\noffensive and defensive means are proposed and presented. The bio-inspired\nsolutions are discussed in the context of cybersecurity, where some principles\nhave already been adopted. The deployment of the whole nature-based framework\nshould aid the design and improvement process of modern cyber-defense systems.\n",
      "subjects": [
        "cs.CR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Managing Hardware Configurations and Data Products for the Canadian\n  Hydrogen Intensity Mapping Experiment",
      "abstract": "  The Canadian Hydrogen Intensity Mapping Experiment (CHIME) is an ambitious\nnew radio telescope project for measuring cosmic expansion and investigating\ndark energy. Keeping good records of both physical configuration of its 1280\nantennas and their analogue signal chains as well as the ~100 TB of data\nproduced daily from its correlator will be essential to the success of CHIME.\nIn these proceedings we describe the database-driven software we have developed\nto manage this complexity.\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Indestructibility properties of remarkable cardinals",
      "abstract": "  Remarkable cardinals were introduced by Schindler, who showed that the\nexistence of a remarkable cardinal is equiconsistent with the assertion that\nthe theory of $L(\\mathbb R)$ is absolute for proper forcing. Here, we study the\nindestructibility properties of remarkable cardinals. We show that if $\\kappa$\nis remarkable, then there is a forcing extension in which the remarkability of\n$\\kappa$ becomes indestructible by all $\\lt\\kappa$-closed\n$\\leq\\kappa$-distributive forcing and all two-step iterations of the form ${\\rm\nAdd}(\\kappa,\\theta)*\\dot{\\mathbb R}$, where $\\dot{\\mathbb R}$ is forced to be\n$\\lt\\kappa$-closed and $\\leq\\kappa$-distributive. In the process, we introduce\nthe notion of a remarkable Laver function and show that every remarkable\ncardinal carries such a function. We also show that remarkability is preserved\nby the canonical forcing of the ${\\rm GCH}$.\n",
      "subjects": [
        "math.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.114.141801",
      "title": "Anomalous solutions to the strong CP problem",
      "abstract": "  We present a new mechanism for solving the strong CP problem using a Z2\ndiscrete symmetry and an anomalous U(1) symmetry. A Z2 symmetry is used so that\ntwo gauge groups have the same theta angle. An anomalous U(1) symmetry makes\nthe difference between the two theta angles physical and the sum unphysical.\nTwo models are presented where the anomalous symmetry manifests itself in the\nIR in different ways. In the first model there are massless bifundamental\nquarks, a solution reminiscent of the massless up quark solution. In the IR of\nthis model, the $\\eta'$ boson relaxes the QCD theta angle to the difference\nbetween the two theta angles - in this case zero. In the second model, the\nanomalous U(1) symmetry is realized in the IR as a dynamically generated mass\nterm that has exactly the phase needed to cancel the theta angle. Both of these\nmodels make the extremely concrete prediction that there exist new colored\nparticles at the TeV scale.\n",
      "subjects": [
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.91.125128",
      "title": "Direct observation of fragile Mott insulators on plaquette Hubbard\n  lattices",
      "abstract": "  Employing extensive cellular dynamical mean-field theory (CDMFT) calculations\nwith exact diagonalization impurity solver, we investigate the ground state\nphase diagrams and non-magnetic metal-insulator transitions of the half-filled\nHubbard model on two plaquette -- the 1/5 depleted and checkerboard -- square\nlattices. We identify three different insulators in the phase diagrams: dimer\ninsulator, antiferromagnetic insulator, and plaquette insulator. And we\ndemonstrate that the plaquette insulator is a novel fragile Mott insulator\n(FMI) which features a nontrivial one-dimensional irreducible representation of\nthe $C_{4v}$ crystalline point-group and cannot be adiabatically connected to\nany band insulator with time-reversal symmetry. Furthermore, we study the\nnon-magnetic quantum phase transitions from the metal to the FMI and find that\nthis Mott metal-insulator transition is characterized by the splitting of the\nnon-interacting bands due to interaction effects.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Decomposition of number arrangements in the cube",
      "abstract": "  A subset $M \\subset \\textbf{R}^3$ is called a \\emph{basic subset}, if for any\nfunciton $f \\colon M \\to \\textbf{R}$ there exist such functions $f_1; f_2; f_3\n\\colon \\textbf{R} \\to \\textbf{R}$ that $f(x_1, x_2, x_3) = f_1(x_1) + f_2(x_2)\n+ f_3(x_3)$ for each point $(x_1, x_2, x_3)\\in M$. In this article we prove a\ncriterion for a basic subset for some specific subsets in terms of some graph\nproperties. We also introduce several constructions for mimimal non-basic\nsubsets. The article is written in Russian.\n",
      "subjects": [
        "math.CO",
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Equivalence and Symmetries for Linear Parabolic Equations and\n  Applications Revisited",
      "abstract": "  A systematic and unified approach to transformations and symmetries of\ngeneral second order linear parabolic partial differential equations is\npresented. Equivalence group is used to derive the Appell type transformations,\nspecifically Mehler's kernel in any dimension. The complete symmetry group\nclassification is re-performed. A new criterion which is necessary and\nsufficient for reduction to the standard heat equation by point transformations\nis established. A similar criterion is also valid for the equations to have a\nfour- or six-dimensional symmetry group (nontrivial symmetry groups). In this\nsituation, the basis elements are listed in terms of coefficients. A number of\nillustrative examples are given. In particular, some applications from the\nrecent literature are re-examined in our new approach. Applications include a\ncomparative discussion of heat kernels based on group-invariant solutions and\nthe idea of connecting Lie symmetries and classical integral transforms\nintroduced by Craddock and his coworkers. Multidimensional parabolic PDEs of\nheat and Schr\\\"odinger type are also considered.\n",
      "subjects": [
        "math-ph",
        "math.AP",
        "math.MP",
        "nlin.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/srep22761",
      "title": "Transport in serial spinful multiple-dot systems: The role of\n  electron-electron interactions and coherences",
      "abstract": "  Quantum dots are nanoscopic systems, where carriers are confined in all three\nspatial directions. Such nanoscopic systems are suitable for fundamental\nstudies of quantum mechanics and are candidates for applications such as\nquantum information processing. It was also proposed that linear arrangements\nof quantum dots could be used as quantum cascade laser. In this work we study\nthe impact of electron-electron interactions on transport in a spinful serial\ntriple quantum dot system weakly coupled to two leads. We find that due to\nelectron-electron scattering processes the transport is enabled beyond the\ncommon single-particle transmission channels. This shows that the scenario in\nthe serial quantum dots intrinsically deviates from layered structures such as\nquantum cascade lasers, where the presence of well-defined single-particle\nresonances between neighboring levels are crucial for device operation.\nAdditionally, we check the validity of the Pauli master equation by comparing\nit with the first-order von Neumann approach. Here we demonstrate that\ncoherences are of relevance if the energy spacing of the eigenstates is smaller\nthan the lead transition rate multiplied by $\\hbar$.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Singular limit of the generalized Burgers equation with absorption",
      "abstract": "  We prove the convergence of the solutions $u_{m,p}$ of the equation\n$u_t+(u^m)_x=-u^p$ in $\\R\\times (0,\\infty)$, $u(x,0)=u_0(x)\\ge 0$ in $\\R$, as\n$m\\to\\infty$ for any $p>1$ and $u_0\\in L^1(\\R)\\cap L^{\\infty}(\\R)$ or as\n$p\\to\\infty$ for any $m>1$ and $u_0\\in L^{\\infty}(\\R)$ . We also show that in\ngeneral $\\underset{p\\to\\infty}\\lim\\underset{m\\to\\infty}\\lim\nu_{m,p}\\ne\\underset{m\\to\\infty}\\lim\\underset{p\\to\\infty}\\lim u_{m,p}$.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fast Embedding for JOFC Using the Raw Stress Criterion",
      "abstract": "  The Joint Optimization of Fidelity and Commensurability (JOFC) manifold\nmatching methodology embeds an omnibus dissimilarity matrix consisting of\nmultiple dissimilarities on the same set of objects. One approach to this\nembedding optimizes the preservation of fidelity to each individual\ndissimilarity matrix together with commensurability of each given observation\nacross modalities via iterative majorization of a raw stress error criterion by\nsuccessive Guttman transforms. In this paper, we exploit the special structure\ninherent to JOFC to exactly and efficiently compute the successive Guttman\ntransforms, and as a result we are able to greatly speed up the JOFC procedure\nfor both in-sample and out-of-sample embedding. We demonstrate the scalability\nof our implementation on both real and simulated data examples.\n",
      "subjects": [
        "stat.ML",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3842/SIGMA.2015.047",
      "title": "Higher Order Deformations of Complex Structures",
      "abstract": "  Deformations of complex structures by finite Beltrami differentials are\nconsidered on general Riemann surfaces. Exact formulas to any fixed order are\nderived for the corresponding deformations of the period matrix, Green's\nfunctions, and correlation functions in conformal field theories with vanishing\ntotal central charge. The stress tensor is shown to give a simple\nrepresentation of these deformations valid to all orders. Such deformation\nformulas naturally enter into the evaluation of superstring amplitudes at\ntwo-loop order with Ramond punctures, and at higher loop order, in the\nsupergravity formulation of the RNS superstring.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On topological lower bounds for algebraic computation trees",
      "abstract": "  We prove that the height of any algebraic computation tree for deciding\nmembership in a semialgebraic set is bounded from below (up to a multiplicative\nconstant) by the logarithm of m-th Betti number (with respect to singular\nhomology) of the set, divided by m+1. This result complements the well known\nlower bound by Yao for locally closed semialgebraic sets in terms of the total\nBorel-Moore Betti number. We also prove that the height is bounded from below\nby the logarithm of m-th Betti number of a projection of the set onto a\ncoordinate subspace, divided by (m+1)^2. We illustrate these general results by\nexamples of lower complexity bounds for some specific computational problems.\n",
      "subjects": [
        "cs.CC",
        "math.AT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1017/S1474748016000177",
      "title": "Central limit theorem for the modulus of continuity of averages of\n  observables on transversal families of piecewise expanding unimodal maps",
      "abstract": "  We prove that the Newton quotient of the average R(t) of a lipschitzian\nfunction (with non vanishing variation) with respect to the SRB measure on a\ntransversal family f_t of piecewise expanding unimodal maps, after an\nappropriated normalization, converges in distribution to the normal\ndistribution.\n",
      "subjects": [
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0957-4484/26/40/405201",
      "title": "Suspended graphene devices with local gate control on an insulating\n  substrate",
      "abstract": "  We present a fabrication process for graphene-based devices where a graphene\nmonolayer is suspended above a local metallic gate placed in a trench. As an\nexample we detail the fabrication steps of a graphene field-effect transistor.\nThe devices are built on a bare high-resistivity silicon substrate. At\ntemperatures of 77~K and below, we observe the field-effect modulation of the\ngraphene resistivity by a voltage applied to the gate. This fabrication\napproach enables new experiments involving graphene-based superconducting\nqubits and nano-electromechanical resonators. The method is applicable to other\ntwo-dimensional materials.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Laplace Eigenfunctions And Damped Wave Equation Ii: Product Manifolds",
      "abstract": "  - The purpose of this article is to study possible concentrations of\neigenfunc-tions of Laplace operators (or more generally quasi-modes) on product\nmanifolds. We show that the approach of the first author and Zworski [10, 11]\napplies (modulo rescalling) and deduce new stabilization results for weakly\ndamped wave equations which extend to product manifolds previous results by\nLeautaud-Lerner [12] obtained for products of tori.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.91.063534",
      "title": "Expansion and Growth of Structure Observables in a Macroscopic Gravity\n  Averaged Universe",
      "abstract": "  We investigate the effect of averaging inhomogeneities on expansion and\nlarge-scale structure growth observables using the exact and covariant\nframework of Macroscopic Gravity (MG). It is well-known that applying the\nEinstein's equations and spatial averaging do not commute and lead to the\naveraging problem. For the MG formalism applied to the\nFriedmann-Lemaitre-Robertson-Walker (FLRW) metric, this gives an extra\ndynamical term encapsulated as an averaging density parameter denoted\n$\\Omega_A$. An exact isotropic cosmological solution of MG for the flat FLRW\nmetric is already known in the literature, we derive here an anisotropic exact\nsolution. Using the isotropic solution, we compare the expansion history to\ncurrent data of distances to supernovae, Baryon Acoustic Oscillations, CMB last\nscattering surface, and Hubble constant measurements, and find $-0.05 \\le\n\\Omega_A \\le 0.07$ (at the 95% CL). For the flat metric case this reduces to\n$-0.03 \\le \\Omega_A \\le 0.05$. We also find that the inclusion of this term in\nthe fits can shift the values of the usual cosmological parameters by a few to\nseveral percents. Next, we derive an equation for the growth rate of large\nscale structure in MG that includes a term due to the averaging and compare it\nto that of the LCDM concordance model. We find that an $\\Omega_A$ of an\namplitude range within the bounds above leads to a relative deviation of the\ngrowth from that of the LCDM of up to 2-4% at late times. Thus, the shift in\nthe growth could be of comparable amplitude to that caused by similar changes\nin cosmological parameters like the dark energy density parameter or its\nequation of state. The effect could also be comparable in amplitude to some\nsystematic effects considered for future surveys. This indicates that the\naveraging term and its possible effect need to be tightly constrained in future\nprecision cosmological studies. (Abridged)\n",
      "subjects": [
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s00023-016-0463-z",
      "title": "Indefinite Kasparov modules and pseudo-Riemannian manifolds",
      "abstract": "  We present a definition of indefinite Kasparov modules, a generalisation of\nunbounded Kasparov modules modelling non-symmetric and non-elliptic (e.g.\nhyperbolic) operators. Our main theorem shows that to each indefinite Kasparov\nmodule we can associate a pair of (genuine) Kasparov modules, and that this\nprocess is reversible. We present three examples of our framework: the Dirac\noperator on a pseudo-Riemannian spin manifold (i.e. a manifold with an\nindefinite metric), the harmonic oscillator, and the construction via the\nKasparov product of an indefinite spectral triple from a family of spectral\ntriples. This last construction corresponds to a foliation of a globally\nhyperbolic spacetime by spacelike hypersurfaces.\n",
      "subjects": [
        "math.KT",
        "math.DG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Measuring Complexity through Average Symmetry",
      "abstract": "  This work introduces a complexity measure which addresses some conflicting\nissues between existing ones by using a new principle - measuring the average\namount of symmetry broken by an object. It attributes low (although different)\ncomplexity to either deterministic or random homogeneous densities and higher\ncomplexity to the intermediate cases. This new measure is easily computable,\nbreaks the coarse graining paradigm and can be straightforwardly generalised,\nincluding to continuous cases and general networks. By applying this measure to\na series of objects, it is shown that it can be consistently used for both\nsmall scale structures with exact symmetry breaking and large scale patterns,\nfor which, differently from similar measures, it consistently discriminates\nbetween repetitive patterns, random configurations and self-similar structures.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "cond-mat.dis-nn",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Hardy and Hardy-Sobolev inequalities on Riemannian manifolds",
      "abstract": "  Let $ (M,g) $ be a smooth compact Riemannian manifold of dimension $ N \\geq 3\n$. Given $p_0 \\in M$, $\\lambda \\in \\mathcal{R}$ and $\\sigma \\in (0,2]$, we\nstudy existence and non existence of minimizers of the following quotient:\n\\begin{equation}\\label{Paper Equation} \\mu_{\\lambda,\\sigma}=\\inf_{u \\in\nH^1(M)\\setminus \\lbrace0\\rbrace} \\frac{\\displaystyle\\int_M |\\nabla u|^2 dv_g\n-\\lambda \\int_M u^2 dv_g }{\\biggl(\\displaystyle\\int_M \\rho^{-\\sigma}\n|u|^{2^*(\\sigma)} dv_g\\biggl)^{2/2^*(\\sigma)}}, \\end{equation} where\n$\\rho(.):=dist(p_0,.)$ denoted the geodesic distance from $p \\in M$ to $p_0$.\nIn particular for $\\sigma=2$, we provide sufficient and necessary conditions of\nexistence of minimizers in terms of $\\lambda$. For $\\sigma\\in (0,2)$ we prove\nexistence of minimizers under scalar curvature pinching.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Constructive Interference through Symbol Level Precoding for Multi-level\n  Modulation",
      "abstract": "  The constructive interference concept in the downlink of multiple-antenna\nsystems is addressed in this paper. The concept of the joint exploitation of\nthe channel state information (CSI) and data information (DI) is discussed.\nUsing symbol-level precoding, the interference between data streams is\ntransformed Under certain conditions into useful signal that can improve the\nsignal to interference noise ratio (SINR) of the downlink transmissions. In the\nprevious work, different constructive interference precoding techniques have\nbeen proposed for the MPSK scenario. In this context, a novel constructive\ninterference precoding technique that tackles the transmit power minimization\n(min-power) with individual SINR constraints at each user's receivers is\nproposed assuming MQAM modulation. Extensive simulations are performed to\nvalidate the proposed technique.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The absolute continuity of convolutions of orbital measures in symmetric\n  spaces",
      "abstract": "  We characterize the absolute continuity of convolution products of orbital\nmeasures on the classical, irreducible Riemannian symmetric spaces $G/K$ of\nCartan type $III$, where $G$ is a non-compact, connected Lie group and $K$ is a\ncompact, connected subgroup. By the orbital measures, we mean the uniform\nmeasures supported on the double cosets, $KzK,$ in $G$. The characterization\ncan be expressed in terms of dimensions of eigenspaces or combinatorial\nproperties of the annihilating roots of the elements $z$.\n  A consequence of our work is to show that the convolution product of any\nrank% $G/K,$ continuous, $K$-bi-invariant measures is absolutely continuous in\nany of these symmetric spaces, other than those whose restricted root system is\ntype $A_{n}$ or $D_{3}$, when rank$G/K$ $+1$ is needed.\n",
      "subjects": [
        "math.RT",
        "math.CA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Encoding by DNA Relations and Randomization Through Chaotic Sequences\n  for Image Encryption",
      "abstract": "  Researchers in the field of DNA-based chaotic cryptography have recently\nproposed a set of novel and efficient image encryption algorithms. In this\npaper, we present a comprehensive summary of those techniques, which are\navailable in the literature. The discussion given in this paper is grouped into\nthree main areas. At first, we give a brief sketch of the backbone architecture\nand the theoretical foundation of this field, based on which all the algorithms\nwere proposed. Next, we briefly discuss the set of image encryption algorithms\nbased on this architecture and categorized them as either encryption or\ncryptanalyzing techniques. Finally, we present the different evaluation metrics\nused to quantitatively measure the performance of such algorithms. We also\ndiscuss the characteristic differences among these algorithms. We further\nhighlight the potential advances that are needed to improvise the present\nstate-of-the-art image encryption technique using DNA computing and chaos\ntheory. The primary objective of this survey is to provide researchers in the\nfield of DNA computing and chaos theory based image encryption a comprehensive\nsummary of the progress achieved so far and to facilitate them to identify a\nfew challenging future research areas.\n",
      "subjects": [
        "cs.CR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Synchrotron radiation of higher order soliton",
      "abstract": "  We demonstrate radiation mechanism exhibited by higher order soliton. In a\ncourse of its evolution higher order soliton emits polychromatic radiation\nresulting in appearance of multipeak frequency comb like spectral band. The\nshape and spectral position of this band can be effectively controlled by the\nrelative strength of the third order dispersion. An analytical description is\ncompletely corroborated by numerical simulations. An analogy between this\nradiation and the radiation of moving charges is presented. For longer pulses\nthe described effect persists also under the action of higher order\nperturbations such as Raman and self-steepening.\n",
      "subjects": [
        "physics.optics",
        "nlin.PS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0004-637X/808/2/162",
      "title": "The connection between the radio jet and the gamma-ray emission in the\n  radio galaxy 3C 120",
      "abstract": "  We present the analysis of the radio jet evolution of the radio galaxy 3C 120\nduring a period of prolonged gamma-ray activity detected by the Fermi satellite\nbetween December 2012 and October 2014. We find a clear connection between the\ngamma-ray and radio emission, such that every period of gamma-ray activity is\naccompanied by the flaring of the mm-VLBI core and subsequent ejection of a new\nsuperluminal component. However, not all ejections of components are associated\nwith gamma-ray events detectable by Fermi. Clear gamma-ray detections are\nobtained only when components are moving in a direction closer to our line of\nsight.This suggests that the observed gamma-ray emission depends not only on\nthe interaction of moving components with the mm-VLBI core, but also on their\norientation with respect to the observer. Timing of the gamma-ray detections\nand ejection of superluminal components locate the gamma-ray production to\nwithin almost 0.13 pc from the mm-VLBI core, which was previously estimated to\nlie about 0.24 pc from the central black hole. This corresponds to about twice\nthe estimated extension of the broad line region, limiting the external photon\nfield and therefore suggesting synchrotron self Compton as the most probable\nmechanism for the production of the gamma-ray emission. Alternatively, the\ninteraction of components with the jet sheath can provide the necessary photon\nfield to produced the observed gamma-rays by Compton scattering.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jcp.2015.12.030",
      "title": "An Extension of Godunov SPH: Application to Negative Pressure Media",
      "abstract": "  The modification of Smoothed Particle Hydrodynamics (SPH) method with Riemann\nSolver is called Godunov SPH. We further extend the Godunov SPH to the\ndescription of a medium with negative pressure. Under certain circumstances,\nthe SPH method shows an unphysical instability that results in particle\nclustering. This instability is called the tensile instability. The tensile\ninstability occurs in positive pressure regions in a regular fluid if a very\nlarge number of neighbor particles are used with certain shapes of kernel\nfunctions, and it is significant in negative pressure regions that emerge in\nstretched elastic bodies. We must suppress the tensile instability in SPH for\ncalculations of elastic bodies. In this study, we develop a new technique to\nremove the tensile instability by extending the Godunov SPH method and\nconducting a linear stability analysis of the equation of motion for the\nextended method. We find that the tensile instability can be suppressed by\nchoosing an appropriate order of interpolation in the equation of motion of the\nGodunov SPH method. We also derive an analytic solution for a Riemann solver\nfor a simple equation of state of an elastic body, and construct a Godunov SPH\nmethod for the equation of state that allows negative pressure.\n",
      "subjects": [
        "astro-ph.IM",
        "astro-ph.EP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Asymptotic Freeness for Rectangular Random Matrices and Large Deviations\n  for Sample Covariance Matrices With Sub-Gaussian Tails",
      "abstract": "  We establish a large deviation principle for the empirical spectral measure\nof a sample covariance matrix with sub-Gaussian entries, which extends\nBordenave and Caputo's result for Wigner matrices having the same type of\nentries [7]. To this aim, we need to establish an asymptotic freeness result\nfor rectangular free convolution, more precisely, we give a bound in the\nsubordination formula for information-plus-noise matrices.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Predictable patterns of CTL escape and reversion across host populations\n  and viral subtypes in HIV-1 evolution",
      "abstract": "  The twin processes of viral evolutionary escape and reversion in response to\nhost immune pressure, in particular the cytotoxic T-lymphocyte (CTL) response,\nshape Human Immunodeficiency Virus-1 sequence evolution in infected host\npopulations. The tempo of CTL escape and reversion is known to differ between\nCTL escape variants in a given host population. Here, we ask: are rates of\nescape and reversion comparable across infected host populations? For three\ncohorts taken from three continents, we estimate escape and reversion rates at\n23 escape sites in optimally defined Gag epitopes. We find consistent escape\nrate estimates across the examined cohorts. Reversion rates are also consistent\nbetween a Canadian and South African infected host population. Certain Gag\nescape variants that incur a large replicative fitness cost are known to revert\nrapidly upon transmission. However, the relationship between escape/reversion\nrates and viral replicative capacity across a large number of epitopes has not\nbeen interrogated. We investigate this relationship by examining $in$ $vitro$\nreplicative capacities of viral sequences with minimal variation: point escape\nmutants induced in a lab strain. Remarkably, despite the complexities of\nepistatic effects exemplified by pathways to escape in famous epitopes, and the\ndiversity of both hosts and viruses, CTL escape mutants which escape rapidly\ntend to be those with the highest replicative capacity when applied as a single\npoint mutation. Similarly, mutants inducing the greatest costs to viral\nreplicative capacity tend to revert more quickly. These data suggest that\nescape rates in Gag are consistent across host populations, and that in general\nthese rates are dominated by site specific effects upon viral replicative\ncapacity.\n",
      "subjects": [
        "q-bio.PE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.92.016003",
      "title": "Spectral representation for u- and t-channel exchange processes in a\n  partial-wave decomposition",
      "abstract": "  We study the analytic structure of partial-wave amplitudes derived from u-\nand t-channel exchange processes. The latter plays a crucial role in\ndispersion-theory approaches to coupled-channel systems that model final state\ninteractions in QCD. A general spectral representation is established that is\nvalid in the presence of anomalous thresholds, decaying particles or\noverlapping left-hand and right-hand cut structures as it occurs frequently in\nhadron physics. The results are exemplified at hand of ten specific processes.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "One-Component Regular Variation and Graphical Modeling of Extremes",
      "abstract": "  The problem of inferring the distribution of a random vector given that its\nnorm is large requires modeling a homogeneous limiting density. We suggest an\napproach based on graphical models which is suitable for high-dimensional\nvectors.\n  We introduce the notion of one-component regular variation to describe a\nfunction that is regularly varying in its first component. We extend the\nrepresentation and Karamata's theorem to one-component regularly varying\nfunctions, probability distributions and densities, and explain why these\nresults are fundamental in multivariate extreme-value theory. We then\ngeneralize Hammersley-Clifford theorem to relate asymptotic conditional\nindependence to a factorization of the limiting density, and use it to model\nmultivariate tails.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Truthful Linear Regression",
      "abstract": "  We consider the problem of fitting a linear model to data held by individuals\nwho are concerned about their privacy. Incentivizing most players to truthfully\nreport their data to the analyst constrains our design to mechanisms that\nprovide a privacy guarantee to the participants; we use differential privacy to\nmodel individuals' privacy losses. This immediately poses a problem, as\ndifferentially private computation of a linear model necessarily produces a\nbiased estimation, and existing approaches to design mechanisms to elicit data\nfrom privacy-sensitive individuals do not generalize well to biased estimators.\nWe overcome this challenge through an appropriate design of the computation and\npayment scheme.\n",
      "subjects": [
        "cs.GT",
        "cs.DS",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/OL.40.003368",
      "title": "An on-chip optical lattice for cold atom experiments",
      "abstract": "  An atom-chip-based integrated optical lattice system for cold and ultracold\natom applications is presented. The retro-reflection optics necessary for\nforming the lattice are bonded directly to the atom chip, enabling a compact\nand robust on-chip optical lattice system. After achieving Bose-Einstein\ncondensation in a magnetic chip trap, we load atoms directly into a vertically\noriented 1D optical lattice and demonstrate Landau-Zener tunneling. The atom\nchip technology presented here can be readily extended to higher dimensional\noptical lattices.\n",
      "subjects": [
        "cond-mat.quant-gas",
        "physics.atom-ph",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Breakdown of metastable political duopoly due to asymmetry of emotions\n  in partisan propaganda",
      "abstract": "  We present results of opinion dynamics simulations based on the\nemotion/information/opinion (E/I/O) model, applied to a strongly polarized\nsociety. Under certain conditions the model leads to metastable coexistence of\ntwo subcommunities (supporting each of the opinions) of comparable size --\nwhich corresponds to bipartisan split found in many real world communities.\nSpurred by the recent breakdown of such system, which existed in Poland for\nover 9 years, we extend the model by allowing a third opinion. We show that if\nthe propaganda messages of the two incumbent parties differ in emotional tone,\nthe system may be \"invaded\" by a newcomer third party very quickly -- in\nqualitative agreement with the actual political situation in Poland in 2015.\n",
      "subjects": [
        "physics.soc-ph",
        "cs.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On a conjecture by Blocki-Zwonek",
      "abstract": "  The article provides a counterexample to a conjecture by Blocki-Zwonek.\n",
      "subjects": [
        "math.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stv2842",
      "title": "The universality of the virial halo mass function and models for\n  non-universality of other halo definitions",
      "abstract": "  The abundance of galaxy clusters can constrain both the geometry and growth\nof structure in our Universe. However, this probe could be significantly\ncomplicated by recent claims of nonuniversality -- non-trivial dependences with\nrespect to the cosmological model and redshift. In this work we analyse the\ndependance of the mass function on the way haloes are identified and establish\nif this can cause departures from universality. In order to explore this\ndependance, we use a set of different N-body cosmological simulations (Le\nSBARBINE simulations), with the latest cosmological parameters from the Planck\ncollaboration; this first suite of simulations is followed by a lower\nresolution set, carried out with different cosmological parameters. We identify\ndark matter haloes using a Spherical Overdensity algorithm with varying\noverdensity thresholds (virial, 2000rho_c, 1000rho_c, 500rho_c, 200rho_c and\n200rho_b) at all redshifts. We notice that, when expressed in term of the\nrescaled variable nu, the mass functionfor virial haloes is a nearly universal\nas a function of redshift and cosmology, while this is clearly not the case for\nthe other overdensities we considered. We provide fitting functions for the\nhalo mass function parameters as a function of overdensity, that allow to\npredict, to within a few percent accuracy, the halo mass function for a wide\nrange of halo definitions, redshifts and cosmological models. We then show how\nthe departures from universality associated with other halo definitions can be\nderived by combining the universality of the virial definition with the\nexpected shape of the density profile of halos.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Optional and predictable projections of normal integrands and\n  convex-valued processes",
      "abstract": "  This article studies optional and predictable projections of integrands and\nconvex-valued stochastic processes. The existence and uniqueness are shown\nunder general conditions that are analogous to those for conditional\nexpectations of integrands and random sets. In the convex case, duality\ncorrespondences between the projections and projections of epigraphs are given.\nThese results are used to study projections of set-valued integrands.\nConsistently with the general theory of stochastic processes, projections are\nnot constructed using reference measures on the optional and predictable\nsigma-algebras.\n",
      "subjects": [
        "math.PR",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.92.063528",
      "title": "Cosmic string loop shapes",
      "abstract": "  We analyze the shapes of cosmic string loops found in large-scale simulations\nof an expanding-universe string network. The simulation does not include\ngravitational back reaction, but we model that process by smoothing the loop\nusing Lorentzian convolution. We find that loops at formation consist of\ngenerally straight segments separated by kinks. We do not see cusps or any\ncusp-like structure at the scale of the entire loop, although we do see very\nsmall regions of string that move with large Lorentz boosts. However, smoothing\nof the string almost always introduces two cusps on each loop. The smoothing\nprocess does not lead to any significant fragmentation of loops that were in\nnon-self-intersecting trajectories before smoothing.\n",
      "subjects": [
        "astro-ph.CO",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A note on the avoidability of binary patterns with variables and\n  reversals",
      "abstract": "  In this note we present a characterisation of all unary and binary patterns\nthat do not only contain variables, but also reversals of their instances.\nThese types of variables were studied recently in either more general or\nparticular cases. We show that the results are not surprising at all in the\ngeneral case, and extend the avoidability of these patterns to enforce\naperiodic words.\n",
      "subjects": [
        "cs.FL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10444-016-9474-z",
      "title": "Approximation by planar elastic curves",
      "abstract": "  We give an algorithm for approximating a given plane curve segment by a\nplanar elastic curve. The method depends on an analytic representation of the\nspace of elastic curve segments, together with a geometric method for obtaining\na good initial guess for the approximating curve. A gradient-driven\noptimization is then used to find the approximating elastic curve.\n",
      "subjects": [
        "math.NA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/ncomms7313",
      "title": "Emergence of coherence in the charge-density wave state of 2H-NbSe$_2$",
      "abstract": "  A charge-density wave (CDW) state has a broken symmetry described by a\ncomplex order parameter with an amplitude and a phase. The conventional view,\nbased on clean, weak-coupling systems, is that a finite amplitude and\nlong-range phase coherence set in simultaneously at the CDW transition\ntemperature T$_{cdw}$. Here we investigate, using photoemission, X-ray\nscattering and scanning tunneling microscopy, the canonical CDW compound\n2H-NbSe$_2$ intercalated with Mn and Co, and show that the conventional view is\nuntenable. We find that, either at high temperature or at large intercalation,\nCDW order becomes short-ranged with a well-defined amplitude that impacts the\nelectronic dispersion, giving rise to an energy gap. The phase transition at\nT$_{cdw}$ marks the onset of long-range order with global phase coherence,\nleading to sharp electronic excitations. Our observations emphasize the\nimportance of phase fluctuations in strongly coupled CDW systems and provide\ninsights into the significance of phase incoherence in `pseudogap' states.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Diffusive limits for a barotropic model of radiative flow",
      "abstract": "  Here we aim at justifying rigorously different types of physically relevant\ndiffusive limits for radiative flows. For simplicity, we consider the\nbarotropic situation, and adopt the so-called P1-approximation of the radiative\ntransfer equation. In the critical functional framework, we establish the\nexistence of global-in-time strong solutions corresponding to small enough\ndata, and exhibit uniform estimates with respect to the coefficients of the\nsystem. Combining with standard compactness arguments, this enables us to\njustify rigorously the convergence of the solutions to the expected limit\nsystems. Our results hold true in the whole space as well as in a periodic box\nin dimension n $\\ge$ 2.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Modeling and interpolation of the ambient magnetic field by Gaussian\n  processes",
      "abstract": "  Anomalies in the ambient magnetic field can be used as features in indoor\npositioning and navigation. By using Maxwell's equations, we derive and present\na Bayesian non-parametric probabilistic modeling approach for interpolation and\nextrapolation of the magnetic field. We model the magnetic field components\njointly by imposing a Gaussian process (GP) prior on the latent scalar\npotential of the magnetic field. By rewriting the GP model in terms of a\nHilbert space representation, we circumvent the computational pitfalls\nassociated with GP modeling and provide a computationally efficient and\nphysically justified modeling tool for the ambient magnetic field. The model\nallows for sequential updating of the estimate and time-dependent changes in\nthe magnetic field. The model is shown to work well in practice in different\napplications: we demonstrate mapping of the magnetic field both with an\ninexpensive Raspberry Pi powered robot and on foot using a standard smartphone.\n",
      "subjects": [
        "cs.RO",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non-central sections of convex bodies",
      "abstract": "  We study the following open problem, suggested by Barker and Larman. Let $K$\nand $L$ be convex bodies in $\\mathbb R^n$ ($n\\ge 2$) that contain a Euclidean\nball $B$ in their interiors. If $\\mathrm{vol}_{n-1}(K\\cap H) =\n\\mathrm{vol}_{n-1}(L\\cap H)$ for every hyperplane $H$ that supports $B$, does\nit follow that $K=L$? We discuss various modifications of this problem. In\nparticular, we show that in $\\mathbb R^2$ the answer is positive if the above\ncondition is true for two disks, none of which is contained in the other. We\nalso study some higher dimensional analogues.\n",
      "subjects": [
        "math.MG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.93.165103",
      "title": "Efficient implementation of the parquet equations -- role of the\n  reducible vertex function and its kernel approximation",
      "abstract": "  We present an efficient implementation of the parquet formalism which\nrespects the asymptotic structure of the vertex functions at both single- and\ntwo-particle levels in momentum- and frequency-space. We identify the\ntwo-particle reducible vertex as the core function which is essential for the\nconstruction of the other vertex functions. This observation stimulates us to\nconsider a two-level parameter-reduction for this function to simplify the\nsolution of the parquet equations. The resulting functions, which depend on\nfewer arguments, are coined \"kernel functions\". With the use of the \"kernel\nfunctions\", the open boundary of various vertex functions in the\nMatsubara-frequency space can be faithfully satisfied. We justify our\nimplementation by accurately reproducing the dynamical mean-field theory\nresults from momentum-independent parquet calculations. The high-frequency\nasymptotics of the single-particle self-energy and the two-particle vertex are\ncorrectly reproduced, which turns out to be essential for the self-consistent\ndetermination of the parquet solutions. The current implementation is also\nfeasible for the dynamical vertex approximation.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Saturation Time of Graph Bootstrap Percolation",
      "abstract": "  The process of $H$-bootstrap percolation for a graph $H$ is a cellular\nautomaton, where, given a subset of the edges of $K_n$ as initial set, an edge\nis added at time $t$ if it is the only missing edge in a copy of $H$ in the\ngraph obtained through this process at time $t-1$. We discuss an extremal\nquestion about the time of $K_r$-bootstrap percolation, namely determining\nmaximal times for an $n$-vertex graph before the process stops. We determine\nexact values for $r=4$ and find a lower bound for the asymptotics for $r \\geq\n5$ by giving an explicit construction.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.93.035026",
      "title": "Probing Higgs self-interactions in proton-proton collisions at a\n  center-of-mass energy of 100 TeV",
      "abstract": "  We present a phenomenological study of triple-Higgs production in which we\nestimate the prospects for measuring the form of the Higgs potential at future\ncircular collider projects. We analyze proton-proton collisions at a\ncenter-of-mass energy of 100 TeV and focus on two different signatures in which\nthe final state is made of four b-jets and either a pair of photons or a pair\nof tau leptons. We study the resulting sensitivity on the Higgs cubic and\nquartic self-interactions and investigate how it depends on the b-tagging,\ntau-tagging and photon resolution performances of detectors that could be\ndesigned for these future machines. We then discuss possible luminosity goals\nfor future 100 TeV collider projects that would allow for a measurement of the\nHiggs potential and its possible departures from the Standard Model\nexpectation.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.2140/pjm.2016.285.345",
      "title": "A strong multiplicity one theorem for SL(2)",
      "abstract": "  It is known that multiplicity one property holds for SL(2), while the strong\nmultiplicity one property fails. However, in this paper, we show that if we\nrequire further that a pair of cuspidal representations $\\pi$ and $\\pi'$ of\nSL(2) have the same local components at archimedean places and the places above\n2, and they are generic with respect to the same additive character, then they\nalso satisfy the strong multiplicity one property. The proof is based on a\nlocal converse theorem for SL(2).\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Thermal evolution of the one-flavour Schwinger model using Matrix\n  Product States",
      "abstract": "  The Schwinger model, or 1+1 dimensional QED, offers an interesting object of\nstudy, both at zero and non-zero temperature, because of its similarities to\nQCD. In this proceeding, we present the a full calculation of the temperature\ndependent chiral condensate of this model in the continuum limit using Matrix\nProduct States (MPS). MPS methods, in general tensor networks, constitute a\nvery promising technique for the non-perturbative study of Hamiltonian quantum\nsystems. In the last few years, they have shown their suitability as ansatzes\nfor ground states and low-lying excita- tions of lattice gauge theories. We\nshow the feasibility of the approach also for finite temperature, both in the\nmassless and in the massive case.\n",
      "subjects": [
        "hep-lat",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.93.043539",
      "title": "Second-order cosmological perturbation theory and initial conditions for\n  $N$-body simulations",
      "abstract": "  We use gauge-invariant cosmological perturbation theory to calculate the\ndisplacement field that sets the initial conditions for $N$-body simulations.\nUsing first and second-order fully relativistic perturbation theory in the\nsynchronous-comoving gauge, allows us to go beyond the Newtonian predictions\nand to calculate relativistic corrections to it. We use an Einstein--de Sitter\nmodel, including both growing and decaying modes in our solutions. The impact\nof our results should be assessed through the implementation of the featured\ndisplacement in cosmological $N$-body simulations.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An algebraic model for rational G-spectra over an exceptional subgroup",
      "abstract": "  We give a simple algebraic model for rational G-spectra over an exceptional\nsubgroup, for any compact Lie group G. Moreover, all our Quillen equivalences\nare symmetric monoidal, so as a corollary we obtain a monoidal algebraic model\nfor rational G-spectra when G is finite. We also present a study of the\nrelationship between induction - restriction - coinduction adjunctions and left\nBousfield localizations at idempotents of the rational Burnside ring.\n",
      "subjects": [
        "math.AT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Discretisations of rough stochastic PDEs",
      "abstract": "  We develop a general framework for spatial discretisations of parabolic\nstochastic PDEs whose solutions are provided in the framework of the theory of\nregularity structures and which are functions in time. As an application, we\nshow that the dynamical $\\Phi^4_3$ model on the dyadic grid converges after\nrenormalisation to its continuous counterpart. This result in particular\nimplies that, as expected, the $\\Phi^4_3$ measure with a sufficiently small\ncoupling constant is invariant for this equation and that the lifetime of its\nsolutions is almost surely infinite for almost every initial condition.\n",
      "subjects": [
        "math.PR",
        "math.AP",
        "math.NA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.93.042128",
      "title": "Site and bond percolation thresholds in $K_{n,n}$-based lattices:\n  Vulnerability of quantum annealers to random qubit and coupler failures on\n  chimera topologies",
      "abstract": "  We estimate the critical thresholds of bond and site percolation on\nnonplanar, effectively two-dimensional graphs with chimera like topology. The\nbuilding blocks of these graphs are complete and symmetric bipartite subgraphs\nof size $2n$, referred to as $K_{n,n}$ graphs. For the numerical simulations we\nuse an efficient union-find based algorithm and employ a finite-size scaling\nanalysis to obtain the critical properties for both bond and site percolation.\nWe report the respective percolation thresholds for different sizes of the\nbipartite subgraph and verify that the associated universality class is that of\nstandard two-dimensional percolation. For the canonical chimera graph used in\nthe D-Wave Systems Inc.~quantum annealer ($n = 4$), we discuss device failure\nin terms of network vulnerability, i.e., we determine the critical fraction of\nqubits and couplers that can be absent due to random failures prior to losing\nlarge-scale connectivity throughout the device.\n",
      "subjects": [
        "cond-mat.dis-nn",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Geometry of Thin Films",
      "abstract": "  We study ray optics in the context of double mirror systems, in the limit as\nthe two mirrors approach one another (thin films). This leads to a novel set of\ndifferential equations on a mirror surface which have interesting structure as\nseen from the perspective of symplectic geometry and Hamiltonian mechanics.\n",
      "subjects": [
        "nlin.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/0004-637X/832/1/44",
      "title": "Ocean g-modes on transient neutron stars",
      "abstract": "  The neutron star ocean is a plasma of ions and electrons that extends from\nthe base of the neutron star's envelope to a depth where the plasma\ncrystallizes into a solid crust. During an accretion outburst in an X-ray\ntransient, material accumulates in the envelope of the neutron star primary.\nThis accumulation compresses the neutron star's outer layers and induces\nnuclear reactions in the ocean and crust. Accretion-driven heating raises the\nocean's temperature and increases the frequencies of g-modes in the ocean; when\naccretion halts, the ocean cools and ocean g-mode frequencies decrease. If the\nobserved low-frequency quasi-periodic oscillations on accreting neutron stars\nare g-modes in the ocean, the observed quasi-periodic oscillation frequencies\nwill increase during outburst---reaching a maximum when the ocean temperature\nreaches steady state --- and subsequently decrease during quiescence. For\ntime-averaged accretion rates during outbursts between $\\langle \\dot{M} \\rangle\n= 0.1 \\textrm{--} 1.0\\, \\dot{M}_{\\rm Edd}$ the predicted g-mode fundamental\n$n=1$ $l=2$ frequency is between $\\approx 3 \\textrm{--} 7 \\, \\mathrm{Hz}$ for\nslowly rotating neutron stars. Accreting neutron stars that require extra\nshallow heating, such as the Z-sources MAXI J0556-332, MXB 1659-29, and XTE\nJ1701-462, have predicted g-mode fundamental frequencies between $\\approx 3\n\\textrm{--} 16 \\, \\mathrm{Hz}$. Therefore, observations of low-frequency\nquasi-periodic oscillations between $\\approx 8 \\textrm{--} 16\\, \\mathrm{Hz}$ in\nthese sources, or in other transients that require shallow heating, will\nsupport a g-mode origin for the observed quasi-periodic oscillations.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.dark.2016.02.003",
      "title": "Interference of Dark Matter Solitons and Galactic Offsets",
      "abstract": "  By performing numerical simulations, we discuss the collisional dynamics of\nstable solitary waves in the Schrodinger-Poisson equation. In the framework of\na model in which part or all of dark matter is a Bose-Einstein condensate of\nultralight axions, we show that these dynamics can naturally account for the\nrelative displacement between dark and ordinary matter in the galactic cluster\nAbell 3827, whose recent observation is the first empirical evidence of dark\nmatter interactions beyond gravity. The essential assumption is the existence\nof solitonic galactic cores in the kiloparsec scale. For this reason, we\npresent simulations with a benchmark value of the axion mass $m_a = 2 \\times\n10^{-24}$ eV, which is somewhat lower than the one preferred for cosmological\nstructure formation if the field is all of dark matter ($m_a \\approx\n10^{-22}$eV). We argue that future observations might bear out or falsify this\ncoherent wave interpretation of dark matter offsets.\n",
      "subjects": [
        "astro-ph.CO",
        "hep-ph",
        "nlin.PS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.nuclphysa.2016.01.019",
      "title": "Measurement of neutral mesons in pp and Pb-Pb collisions at mid-rapidity\n  with ALICE",
      "abstract": "  One of the key signatures of the Quark-Gluon Plasma (QGP), is the\nmodification of hadron transverse momentum differential cross-sections in\nheavy-ion collisions (HIC) as compared to proton-proton (pp) collisions.\nSuppression of hadron production at high transverse momenta (\\pt)~in HIC has\nbeen explained by the energy loss of the partons produced in the hard\nscattering processes which traverse the deconfined quantum chromodynamic (QCD)\nmatter. The dependence of the observed suppression on the \\pt~ of the measured\nhadron towards higher \\pt~ is an important input for the theoretical\nunderstanding of jet quenching effects in the QGP and the nature of the energy\nloss. The ALICE experiment at the Large Hadron Collider (LHC) performs\nmeasurements of neutral meson inclusive spectra at mid-rapidity in a wide \\pt~\nrange in $pp$, $p$-Pb and Pb-Pb collisions. Neutral mesons ($\\pi^{0}$, $\\eta$,\n$\\omega$) are reconstructed via complementary methods, using the ALICE\nelectromagnetic calorimeters, PHOS and EMCal, and by the central tracking\nsystem, identifying photons converted into $e^+e^-$ pairs in the material of\nthe inner barrel detectors (TPC and ITS). In this presentation, an overview of\ncurrent $\\pi^{0}$ and $\\eta$ measurements by the ALICE experiment in HIC and pp\ncollisions will be given.\n",
      "subjects": [
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epjc/s10052-016-4187-5",
      "title": "Decoherence and oscillations of supernova neutrinos",
      "abstract": "  Supernova neutrinos have several exceptional features which can lead to\ninteresting physical consequences. At the production point their wave packets\nhave an extremely small size $\\sigma_x \\sim 10^{-11}$ cm; hence the energy\nuncertainty can be as large as the energy itself, $\\sigma_E \\sim E$, and the\ncoherence length is short. On the way to the Earth the wave packets of mass\neigenstates spread to macroscopic sizes and separate. Inside the Earth the mass\neigenstates split into eigenstates in matter and oscillate again. The coherence\nlength in the Earth is comparable with the radius of the Earth. We explore\nthese features and their consequences. (i) We present new estimates of the wave\npacket size. (ii) We consider the decoherence condition for the case of wave\npackets with spatial spread and show that it is not modified by the spread.\n(iii) We study the coherence of neutrinos propagating in a multi-layer medium\nwith density jumps at the borders of layers. In this case coherence can be\npartially restored due to a \"catch-up effect\", increasing the coherence length\nbeyond the usual estimate. This catch-up effect can occur for supernova\nneutrinos as they cross the shock wave fronts in the exploding star or the core\nof the Earth.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s11128-016-1331-y",
      "title": "Tripartite Entanglement Dynamics in the presence of Non-Markovian\n  Environment",
      "abstract": "  We study on the tripartite entanglement dynamics when each party is initially\nentangled with other parties, but they locally interact with their own\nnon-Markovian environment. First, we consider three GHZ-type initial states,\nall of which have GHZ symmetry provided that the parameters are chosen\nappropriately. However, this symmetry is broken due to the effect of\nenvironment. The corresponding $\\pi$-tangles, one of the tripartite\nentanglement measure, are analytically computed at arbitrary time. The revival\nphenomenon of entanglement occurs after complete disappearance of entanglement.\nWe also consider two W-type initial states. The revival phenomenon also occurs\nin this case. On the analytical ground the robustness issue against the effect\nof environment is examined for both GHZ-type and W-type initial states.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3311/PPee.9724",
      "title": "Constructions for the optimal pebbling of grids",
      "abstract": "  In [C. Xue, C. Yerger: Optimal Pebbling on Grids, Graphs and Combinatorics]\nthe authors conjecture that if every vertex of an infinite square grid is\nreachable from a pebble distribution, then the covering ratio of this\ndistribution is at most $3.25$. First we present such a distribution with\ncovering ratio $3.5$, disproving the conjecture. The authors in the above paper\nalso claim to prove that the covering ratio of any pebble distribution is at\nmost $6.75$. The proof contains some errors. We present a few interesting\npebble distributions that this proof does not seem to cover and highlight some\nother difficulties of this topic.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217732316500541",
      "title": "The fate of Schwarzschild-de Sitter Black Holes in $f(R)$ gravity",
      "abstract": "  The semiclassical effects of antievaporating black holes can be discussed in\nthe framework of $f(R)$ gravity. In particular, the\nBousso-Hawking-Nojiri-Odinstov antievaporation instability of degenerate\nSchwarzschild-de Sitter black holes (the so called Nariai space-time) leads to\na dynamical increasing of black hole horizon in $f(R)$ gravity. This phenomenon\ncauses the following transition: emitting marginally trapped surfaces become\nspace-like surfaces before the effective Bekenstein-Hawking emission time. As a\nconsequence, Bousso-Hawking thermal radiation cannot be emitted in an\nantievaporating Nariai black hole. Possible implications in cosmology and black\nhole physics are also discussed.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.HE",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.93.043421",
      "title": "Perpendicular laser cooling with a rotating wall potential in a Penning\n  trap",
      "abstract": "  We investigate the impact of a rotating wall potential on perpendicular laser\ncooling in a Penning ion trap. By including energy exchange with the rotating\nwall, we extend previous Doppler laser cooling theory and show that low\nperpendicular temperatures are more readily achieved with a rotating wall than\nwithout. Detailed numerical studies determine optimal operating parameters for\nproducing low temperature, stable 2-dimensional crystals, important for quantum\ninformation processing experiments employing Penning traps.\n",
      "subjects": [
        "quant-ph",
        "physics.atom-ph",
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "vDNN: Virtualized Deep Neural Networks for Scalable, Memory-Efficient\n  Neural Network Design",
      "abstract": "  The most widely used machine learning frameworks require users to carefully\ntune their memory usage so that the deep neural network (DNN) fits into the\nDRAM capacity of a GPU. This restriction hampers a researcher's flexibility to\nstudy different machine learning algorithms, forcing them to either use a less\ndesirable network architecture or parallelize the processing across multiple\nGPUs. We propose a runtime memory manager that virtualizes the memory usage of\nDNNs such that both GPU and CPU memory can simultaneously be utilized for\ntraining larger DNNs. Our virtualized DNN (vDNN) reduces the average GPU memory\nusage of AlexNet by up to 89%, OverFeat by 91%, and GoogLeNet by 95%, a\nsignificant reduction in memory requirements of DNNs. Similar experiments on\nVGG-16, one of the deepest and memory hungry DNNs to date, demonstrate the\nmemory-efficiency of our proposal. vDNN enables VGG-16 with batch size 256\n(requiring 28 GB of memory) to be trained on a single NVIDIA Titan X GPU card\ncontaining 12 GB of memory, with 18% performance loss compared to a\nhypothetical, oracular GPU with enough memory to hold the entire DNN.\n",
      "subjects": [
        "cs.DC",
        "cs.LG",
        "cs.NE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Estimating Quantile Families of Loss Distributions for Non-Life\n  Insurance Modelling via L-moments",
      "abstract": "  This paper discusses different classes of loss models in non-life insurance\nsettings. It then overviews the class Tukey transform loss models that have not\nyet been widely considered in non-life insurance modelling, but offer\nopportunities to produce flexible skewness and kurtosis features often required\nin loss modelling. In addition, these loss models admit explicit quantile\nspecifications which make them directly relevant for quantile based risk\nmeasure calculations. We detail various parameterizations and sub-families of\nthe Tukey transform based models, such as the g-and-h, g-and-k and g-and-j\nmodels, including their properties of relevance to loss modelling.\n  One of the challenges with such models is to perform robust estimation for\nthe loss model parameters that will be amenable to practitioners when fitting\nsuch models. In this paper we develop a novel, efficient and robust estimation\nprocedure for estimation of model parameters in this family Tukey transform\nmodels, based on L-moments. It is shown to be more robust and efficient than\ncurrent state of the art methods of estimation for such families of loss models\nand is simple to implement for practical purposes.\n",
      "subjects": [
        "q-fin.RM",
        "math.ST",
        "stat.AP",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The gradient flow of a generalized Fisher information functional with\n  respect to modified Wasserstein distances",
      "abstract": "  This article is concerned with the existence of nonnegative weak solutions to\na particular fourth-order partial differential equation: it is a formal\ngradient flow with respect to a generalized Wasserstein transportation distance\nwith nonlinear mobility. The corresponding free energy functional is referred\nto as generalized Fisher information functional since it is obtained by\nautodissipation of another energy functional which generates the heat flow as\nits gradient flow with respect to the aforementioned distance. Our main results\nare twofold: For mobility functions satisfying a certain regularity condition,\nwe show the existence of weak solutions by construction with the well-known\nminimizing movement scheme for gradient flows. Furthermore, we extend these\nresults to a more general class of mobility functions: a weak solution can be\nobtained by approximation with weak solutions of the problem with regularized\nmobility.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.93.161303",
      "title": "Quadrupolar Effects on Nuclear Spins of Neutral Arsenic Donors in\n  Silicon",
      "abstract": "  We present electrically detected electron nuclear double resonance\nmeasurements of the nuclear spins of ionized and neutral arsenic donors in\nstrained silicon. In addition to a reduction of the hyperfine coupling, we find\nsignificant quadrupole interactions of the nuclear spin of the neutral donors\nof the order of 10 kHz. By comparing these to the quadrupole shifts due to\ncrystal fields measured for the ionized donors, we identify the effect of the\nadditional electron on the electric field gradient at the nucleus. This extra\ncomponent is expected to be caused by the coupling to electric field gradients\ncreated due to changes in the electron wavefunction under strain.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Online Learning with Low Rank Experts",
      "abstract": "  We consider the problem of prediction with expert advice when the losses of\nthe experts have low-dimensional structure: they are restricted to an unknown\n$d$-dimensional subspace. We devise algorithms with regret bounds that are\nindependent of the number of experts and depend only on the rank $d$. For the\nstochastic model we show a tight bound of $\\Theta(\\sqrt{dT})$, and extend it to\na setting of an approximate $d$ subspace. For the adversarial model we show an\nupper bound of $O(d\\sqrt{T})$ and a lower bound of $\\Omega(\\sqrt{dT})$.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/0004-637X/825/1/71",
      "title": "Orbital evolution of mass-transferring eccentric binary systems. II.\n  Secular Evolution",
      "abstract": "  Finite eccentricities in mass-transferring eccentric binary systems can be\nexplained by taking into account mass-loss and mass-transfer processes that\noften occur in these systems. These processes can be treated as perturbations\nto the general two-body problem. The time-evolution equations for the\nsemi-major axis and the eccentricity derived from perturbative methods are in\ngeneral phase-dependent. The osculating semi-major axis and eccentricity change\nover the orbital timescale and they are not easy to implement in binary\nevolution codes like MESA. However, the secular orbital element evolution\nequations can be simplified averaging over the rapidly varying true anomalies.\nIn this paper, we derive the secular time-evolution equations for the\nsemi-major axis and the eccentricity for various mass-loss/transfer processes\nusing either the adiabatic approximation or the assumption of delta-function\nmass-loss/transfer at periastron. We begin with the cases of isotropic and\nanisotropic wind mass-loss. We continue with conservative and non-conservative\nnon-isotropic mass ejection/accretion (including RLOF) for both point-masses\nand extended bodies. We conclude with the case of phase-dependent mass\naccretion. Comparison of the derived equations with similar work in the\nliterature is included and explanation of the existing discrepancies is\nprovided.\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physletb.2016.05.043",
      "title": "Twist-3 effect from the longitudinally polarized proton for $A_{LT}$ in\n  hadron production from $pp$ collisions",
      "abstract": "  We compute the contribution from the longitudinally polarized proton to the\ntwist-3 double-spin asymmetry $A_{LT}$ in inclusive (light) hadron production\nfrom proton-proton collisions,i.e., $p^\\uparrow \\vec{p}\\to h\\,X$. We show that\nusing the relevant QCD equation-of-motion relation and Lorentz invariance\nrelation allows one to eliminate the twist-3 quark-gluon correlator (associated\nwith the longitudinally polarized proton) in favor of one-variable twist-3\nquark distributions and the (twist-2) transversity parton density. Including\nthis result with the twist-3 pieces associated with the transversely polarized\nproton and unpolarized final-state hadron (which have already been calculated\nin the literature), we now have the complete leading-order cross section for\nthis process.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1021/acs.nanolett.5b04988",
      "title": "Ultrafast mid-infrared nanoscopy of strained vanadium dioxide nanobeams",
      "abstract": "  Long regarded as a model system for studying insulator-to-metal phase\ntransitions, the correlated electron material vanadium dioxide (VO$_2$) is now\nfinding novel uses in device applications. Two of its most appealing aspects\nare its accessible transition temperature ($\\sim$341 K) and its rich phase\ndiagram. Strain can be used to selectively stabilize different VO$_2$\ninsulating phases by tuning the competition between electron and lattice\ndegrees of freedom. It can even break the mesoscopic spatial symmetry of the\ntransition, leading to a quasi-periodic ordering of insulating and metallic\nnanodomains. Nanostructuring of strained VO$_2$ could potentially yield unique\ncomponents for future devices. However, the most spectacular property of VO$_2$\n- its ultrafast transition - has not yet been studied on the length scale of\nits phase heterogeneity. Here, we use ultrafast near-field microscopy in the\nmid-infrared to study individual, strained VO$_2$ nanobeams on the 10 nm scale.\nWe reveal a previously unseen correlation between the local steady-state\nswitching susceptibility and the local ultrafast response to below-threshold\nphotoexcitation. These results suggest that it may be possible to tailor the\nlocal photo-response of VO$_2$ using strain and thereby realize new types of\nultrafast nano-optical devices.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Termination Analysis of Probabilistic Programs through\n  Positivstellensatz's",
      "abstract": "  We consider nondeterministic probabilistic programs with the most basic\nliveness property of termination. We present efficient methods for termination\nanalysis of nondeterministic probabilistic programs with polynomial guards and\nassignments. Our approach is through synthesis of polynomial ranking\nsupermartingales, that on one hand significantly generalizes linear ranking\nsupermartingales and on the other hand is a counterpart of polynomial\nranking-functions for proving termination of nonprobabilistic programs. The\napproach synthesizes polynomial ranking-supermartingales through\nPositivstellensatz's, yielding an efficient method which is not only sound, but\nalso semi-complete over a large subclass of programs. We show experimental\nresults to demonstrate that our approach can handle several classical programs\nwith complex polynomial guards and assignments, and can synthesize efficient\nquadratic ranking-supermartingales when a linear one does not exist even for\nsimple affine programs.\n",
      "subjects": [
        "cs.PL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.94.013616",
      "title": "Dynamics of Hubbard Hamiltonians with the multiconfigurational\n  time-dependent Hartree method for indistinguishable particles",
      "abstract": "  We apply the multiconfigurational time-dependent Hartree method for\nindistinguishable particles (MCTDH-X) to systems of bosons or fermions in\nlattices described by Hubbard type Hamiltonians with long-range or short-range\ninterparticle interactions. The wavefunction is expanded in a variationally\noptimized time-dependent many-body basis generated by a set of effective\ncreation operators that are related to the original particle creation operators\nby a time-dependent unitary transform. We use the time-dependent variational\nprinciple for the coefficients of this transform as well as the expansion\ncoefficients of the wavefunction in the time-dependent many-body basis as\nvariational parameters to derive equations of motion. The convergence of\nMCTDH-X is shown by comparing its results to the exact diagonalization of one-,\ntwo-, and three-dimensional lattices filled with bosons with contact\ninteractions. We use MCTDH-X to study the buildup of correlations in the\nlong-time splitting dynamics of a Bose-Einstein condensate loaded into a large\ntwo-dimensional lattice subject to a barrier that is ramped up in the center.\nWe find that the system is split into two parts with emergent time-dependent\ncorrelations that depend on the ramping time -- for most barrier-raising-times\nthe system becomes two-fold fragmented, but for some of the very fast ramps,\nthe system shows revivals of coherence.\n",
      "subjects": [
        "cond-mat.quant-gas"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/MPRV.2017.33",
      "title": "An analysis of visitors' length of stay through noninvasive Bluetooth\n  monitoring in the Louvre Museum",
      "abstract": "  Art Museums traditionally employ observations and surveys to enhance their\nknowledge of visitors' behavior and experience. However, these approaches often\nproduce spatially and temporally limited empirical evidence and measurements.\nOnly recently has the ubiquity of digital technologies revolutionized the\nability to collect data on human behavior. Consequently, the greater\navailability of large-scale datasets based on quantifying visitors' behavior\nprovides new opportunities to apply computational and comparative analytical\ntechniques. In this paper, we attempt to analyze visitors' behavior in the\nLouvre Museum from anonymized longitudinal datasets collected from noninvasive\nBluetooth sensors. We examine visitors' length of stay in the museum and\nconsider this relationship with occupation density around artwork. This data\nanalysis increases the knowledge and understanding of museum professionals\nrelated to the experience of visitors.\n",
      "subjects": [
        "cs.CY",
        "cs.SI",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/201628348",
      "title": "The LOFAR search for radio pulsars and fast transients in M33, M81 & M82",
      "abstract": "  The radio pulsar and rotating radio transient populations are only known in\nand near the Milky Way. Investigating such populations in other galaxies\nrequires deep pulsar and transient searches. We performed 4-h radio\nobservations of nearby galaxies M33, M81 and M82 with LOFAR. Our main purpose\nwas to characterise the bright end of the pulsar population in other galaxies,\nand compare it to that of the Milky Way. We searched for extragalactic radio\npulsars through a periodic-pulse search, and for sporadic fast radio transients\nthrough a single-pulse search. We coherently combined at most 23 LOFAR Core\nHigh-Band Antenna (HBA) stations and covered M33, M81, and M82 in their\nentirety using multiple tied-array beams. No pulsating sources or single pulses\nwere found. We have, therefore established stricter limits on the extragalactic\npulsar flux density at lower frequencies than those obtained in previous\nArecibo, GBT, and WSRT searches. We conclude that in nearby galaxies M33, M81,\nand M82 there are no pulsars shining toward Earth with pseudo luminosities\ngreater than a few times that of the brightest pulsars in our Milky Way.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s12555-017-0271-3",
      "title": "Estimation of CD4+ T Cell Count Parameters in HIV/AIDS Patients Based on\n  Real-time Nonlinear Receding Horizon Control",
      "abstract": "  An increasing number of control techniques are introduced to HIV infection\nproblem to explore the options of helping clinical testing, optimizing drug\ntreatments and to study the drug resistance situations. In such cases,\ncomplete/accurate knowledge of the HIV model and/or parameters is critical not\nonly to monitor the dynamics of the system, but also to adjust the therapy\naccordingly. In those studies, existence of any type of unknown parameters\nimposes severe set-backs and becomes problematic for the treatment of the\npatients. In this work, we develop a real-time adaptive nonlinear receding\nhorizon control approach to aid such scenarios and to estimate unknown\nconstant/time-varying parameters of nonlinear HIV system models. For this\npurpose, the problem of estimation is updated by a series of finite-time\noptimization problem which can be solved by backwards sweep Riccati method in\nreal time without employing any iteration techniques. The simulation results\ndemonstrates the fact that proposed algorithm is able to estimate unknown\nconstant/time-varying parameters of HIV/AIDS model effectively and provide a\nunique, adaptive solution methodology to an important open problem.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stw2421",
      "title": "Reconstructing the high energy irradiation of the evaporating hot\n  Jupiter HD 209458b",
      "abstract": "  The atmosphere of the exoplanet HD 209458b is undergoing sustained mass loss,\nbelieved to be caused by X-ray and extreme-ultraviolet (XUV) irradiation from\nits star. The majority of this flux is not directly observable due to\ninterstellar absorption, but is required in order to correctly model the\nphoto-evaporation of the planet and photo-ionisation of the outflow. We present\na recovered high energy spectrum for HD\\,209458 using a Differential Emission\nMeasure (DEM) retrieval technique. We construct a model of the stellar corona\nand transition region for temperatures between 10$^{4.1}$ and 10$^{8}$ K which\nis constrained jointly by ultraviolet line strengths measured with the Cosmic\nOrigins Spectrograph (COS) on the Hubble Space Telescope (HST) and X-ray flux\nmeasurements from XMM-Newton. The total hydrogen ionising luminosity ($\\lambda\n< 912$ \\AA) is found to be 10$^{28.26}$ erg s$^{-1}$, which is similar to the\nvalue for the mean activity level of the Sun. This luminosity is incompatible\nwith energy limited mass loss rates estimated from the same COS dataset, even\nthe lower bound requires an uncomfortably high energetic efficiency of >40%.\nHowever, our luminosity is compatible with early estimates of the mass loss\nrate of HD 209458b based on results from the HST Space Telescope Imaging\nSpectrograph (STIS). Precisely reconstructed XUV irradiation is a key input to\ndetermining mass loss rates and efficiencies for exoplanet atmospheres.\n",
      "subjects": [
        "astro-ph.EP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jmps.2016.08.007",
      "title": "Cyclic Density Functional Theory : A route to the first principles\n  simulation of bending in nanostructures",
      "abstract": "  We formulate and implement Cyclic Density Functional Theory (Cyclic DFT) -- a\nself-consistent first principles simulation method for nanostructures with\ncyclic symmetries. Using arguments based on Group Representation Theory, we\nrigorously demonstrate that the Kohn-Sham eigenvalue problem for such systems\ncan be reduced to a fundamental domain (or cyclic unit cell) augmented with\ncyclic-Bloch boundary conditions. Analogously, the equations of electrostatics\nappearing in Kohn-Sham theory can be reduced to the fundamental domain\naugmented with cyclic boundary conditions. By making use of this symmetry cell\nreduction, we show that the electronic ground-state energy and the\nHellmann-Feynman forces on the atoms can be calculated using quantities defined\nover the fundamental domain. We develop a symmetry-adapted finite-difference\ndiscretization scheme to obtain a fully functional numerical realization of the\nproposed approach. We verify that our formulation and implementation of Cyclic\nDFT is both accurate and efficient through selected examples.\n  The connection of cyclic symmetries with uniform bending deformations\nprovides an elegant route to the ab-initio study of bending in nanostructures\nusing Cyclic DFT. As a demonstration of this capability, we simulate the\nuniform bending of a silicene nanoribbon and obtain its energy-curvature\nrelationship from first principles. A self-consistent ab-initio simulation of\nthis nature is unprecedented and well outside the scope of any other systematic\nfirst principles method in existence. Our simulations reveal that the bending\nstiffness of the silicene nanoribbon is intermediate between that of graphene\nand molybdenum disulphide. We describe several future avenues and applications\nof Cyclic DFT, including its extension to the study of non-uniform bending\ndeformations and its possible use in the study of the nanoscale flexoelectric\neffect.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Temporal Topic Modeling to Assess Associations between News Trends and\n  Infectious Disease Outbreaks",
      "abstract": "  In retrospective assessments, internet news reports have been shown to\ncapture early reports of unknown infectious disease transmission prior to\nofficial laboratory confirmation. In general, media interest and reporting\npeaks and wanes during the course of an outbreak. In this study, we quantify\nthe extent to which media interest during infectious disease outbreaks is\nindicative of trends of reported incidence. We introduce an approach that uses\nsupervised temporal topic models to transform large corpora of news articles\ninto temporal topic trends. The key advantages of this approach include,\napplicability to a wide range of diseases, and ability to capture disease\ndynamics - including seasonality, abrupt peaks and troughs. We evaluated the\nmethod using data from multiple infectious disease outbreaks reported in the\nUnited States of America (U.S.), China and India. We noted that temporal topic\ntrends extracted from disease-related news reports successfully captured the\ndynamics of multiple outbreaks such as whooping cough in U.S. (2012), dengue\noutbreaks in India (2013) and China (2014). Our observations also suggest that\nefficient modeling of temporal topic trends using time-series regression\ntechniques can estimate disease case counts with increased precision before\nofficial reports by health organizations.\n",
      "subjects": [
        "cs.SI",
        "cs.CL",
        "cs.IR",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.94.065014",
      "title": "Maximally supersymmetric solutions of $R^2$ supergravity",
      "abstract": "  There are five maximally supersymmetric backgrounds in four-dimensional\noff-shell N=1 supergravity, two of which are well known: Minkowski superspace\nM^{4|4} and anti-de Sitter superspace AdS^{4|4}. The three remaining\nsupermanifolds support spacetimes of different topology, which are: R x S^3,\nAdS_3 x R, and a supersymmetric plane wave isometric to the Nappi-Witten group.\nAs is well known, the Minkowski and anti-de Sitter superspaces are solutions of\nthe Poincar\\'e and anti-de Sitter supergravity theories, respectively. Here we\ndemonstrate that the other three superspaces are solutions of no-scale $R^2$\nsupergravity. We also present a new (probably the simplest) derivation of the\nmaximally supersymmetric backgrounds of off-shell N=1 supergravity.\n",
      "subjects": [
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stw1656",
      "title": "Using baseline-dependent window functions for data compression and\n  field-of-interest shaping in radio interferometry",
      "abstract": "  In radio interferometry, observed visibilities are intrinsically sampled at\nsome interval in time and frequency. Modern interferometers are capable of\nproducing data at very high time and frequency resolution; practical limits on\nstorage and computation costs require that some form of data compression be\nimposed. The traditional form of compression is a simple averaging of the\nvisibilities over coarser time and frequency bins. This has an undesired side\neffect: the resulting averaged visibilities \"decorrelate\", and do so\ndifferently depending on the baseline length and averaging interval. This\ntranslates into a non-trivial signature in the image domain known as\n\"smearing\", which manifests itself as an attenuation in amplitude towards\noff-centre sources. With the increasing fields of view and/or longer baselines\nemployed in modern and future instruments, the trade-off between data rate and\nsmearing becomes increasingly unfavourable. In this work we investigate\nalternative approaches to low-loss data compression. We show that averaging of\nthe visibility data can be treated as a form of convolution by a boxcar-like\nwindow function, and that by employing alternative baseline-dependent window\nfunctions a more optimal interferometer smearing response may be induced. In\nparticular, we show improved amplitude response over a chosen field of\ninterest, and better attenuation of sources outside the field of interest. The\nmain cost of this technique is a reduction in nominal sensitivity; we\ninvestigate the smearing vs. sensitivity trade-off, and show that in certain\nregimes a favourable compromise can be achieved. We show the application of\nthis technique to simulated data from the Karl G. Jansky Very Large Array (VLA)\nand the European Very-long-baseline interferometry Network (EVN).\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1478-3975/13/6/066004",
      "title": "Temperature Dependent Heterogeneous Rotational Correlation in Lipids",
      "abstract": "  Lipid structures exhibit complex and highly dynamic lateral structure; and\nchanges in lipid density and fluidity are believed to play an essential role in\nmembrane targeting and function. The dynamic structure of liquids on the\nmolecular scale can exhibit complex transient density fluctuations. Here the\nlateral heterogeneity of lipid dynamics is explored in free standing lipid\nmonolayers. As the temperature is lowered the probes exhibit increasingly broad\nand heterogeneous rotational correlation. This increase in heterogeneity\nappears to exhibit a critical onset, similar to those observed for glass\nforming fluids. We explore heterogeneous relaxation in in a single constituent\nlipid monolayer of 1,2-dimyristoyl-sn-glycero-3-phosphocholine (DMPC) by\nmeasuring the rotational diffusion of a fluorescent probe,\n1-palmitoyl-2-[1]-sn-glycero-3-phosphocholine (NBD-PC), using wide-field\ntime-resolved fluorescence anisotropy (TRFA). The observed relaxation exhibits\na narrow, liquid-like distribution at high temperatures ({\\tau} ~ 2.4 ns),\nconsistent with previous experimental measures [1, 2]. However, as the\ntemperature is quenched, the distribution broadens, and we observe the\nappearance of a long relaxation population ({\\tau} ~ 16.5 ns). This supports\nthe heterogeneity observed for lipids at high packing densities, and\ndemonstrates that the nanoscale diffusion and reorganization in lipid\nstructures can be significantly complex, even in the simplest amorphous\narchitectures. Dynamical heterogeneity of this form can have a significant\nimpact on the organization, permeability and energetics of lipid membrane\nstructures.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.96.075438",
      "title": "Line nodes, Dirac points and Lifshitz transition in 2D nonsymmorphic\n  photonic crystals",
      "abstract": "  Topological phase transitions, which have fascinated generations of\nphysicists, are always demarcated by gap closures. In this work, we propose\nvery simple 2D photonic crystal lattices with gap closure points, i.e. band\ndegeneracies protected by nonsymmorphic symmetry. Our photonic structures are\nrelatively easy to fabricate, consisting of two inequivalent dielectric\ncylinders per unit cell. Along high symmetry directions, they exhibit line\ndegeneracies protected by glide reflection symmetry, which we explicitly\ndemonstrate for $pg,pmg,pgg$ and $p4g$ nonsymmorphic groups. In the presence of\ntime reversal symmetry, they also exhibit point degeneracies (Dirac points)\nprotected by a $Z_2$ topological number associated with crystalline symmetry.\nStrikingly, the robust protection of $pg$-symmetry allows a Lifshitz transition\nto a type II Dirac cone across a wide range of experimentally accessible\nparameters, thus providing a convenient route for realizing anomalous\nrefraction. Further potential applications include a stoplight device based on\nelectrically induced strain that dynamically switches the lattice symmetry from\n$pgg$ to the higher $p4g$ symmetry. This controls the coalescence of Dirac\npoints and hence the group velocity within the crystal.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/978-3-319-50478-0_16",
      "title": "Network-Guided Biomarker Discovery",
      "abstract": "  Identifying measurable genetic indicators (or biomarkers) of a specific\ncondition of a biological system is a key element of precision medicine. Indeed\nit allows to tailor diagnostic, prognostic and treatment choice to individual\ncharacteristics of a patient. In machine learning terms, biomarker discovery\ncan be framed as a feature selection problem on whole-genome data sets.\nHowever, classical feature selection methods are usually underpowered to\nprocess these data sets, which contain orders of magnitude more features than\nsamples. This can be addressed by making the assumption that genetic features\nthat are linked on a biological network are more likely to work jointly towards\nexplaining the phenotype of interest. We review here three families of methods\nfor feature selection that integrate prior knowledge in the form of networks.\n",
      "subjects": [
        "stat.ML",
        "cs.LG",
        "q-bio.QM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.95.012324",
      "title": "Growing complex network of citations of scientific papers --\n  measurements and modeling",
      "abstract": "  To quantify the mechanism of a complex network growth we focus on the network\nof citations of scientific papers and use a combination of the theoretical and\nexperimental tools to uncover microscopic details of this network growth.\nNamely, we develop a stochastic model of citation dynamics based on\ncopying/redirection/triadic closure mechanism. In a complementary and coherent\nway, the model accounts both for statistics of references of scientific papers\nand for their citation dynamics. Originating in empirical measurements, the\nmodel is cast in such a way that it can be verified quantitatively in every\naspect. Such verification is performed by measuring citation dynamics of\nPhysics papers. The measurements revealed nonlinear citation dynamics, the\nnonlinearity being intricately related to network topology. The nonlinearity\nhas far-reaching consequences including non-stationary citation distributions,\ndiverging citation trajectory of similar papers, runaways or \"immortal papers\"\nwith infinite citation lifetime etc. Thus, our most important finding is\nnonlinearity in complex network growth. In a more specific context, our results\ncan be a basis for quantitative probabilistic prediction of citation dynamics\nof individual papers and of the journal impact factor.\n",
      "subjects": [
        "cs.DL",
        "physics.data-an",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.nima.2016.09.051",
      "title": "High Precision Momentum Calibration of the Magnetic Spectrometers at\n  MAMI for Hypernuclear Binding Energy Determination",
      "abstract": "  We propose a new method for absolute momentum calibration of magnetic\nspectrometers used in nuclear physics, using the time-of-flight (TOF),\ndifferences of pairs of particles with different masses. In cases where the\nflight path is not known, a calibration can be determined by using the TOF\ndifferences of two pair combinations of three particles. A Cherenkov detector,\nread out by a radio frequency photomultiplier tube, is considered as the\nhigh-resolution and highly stable TOF detector. By means of Monte Carlo\nsimulations it is demonstrated that the magnetic spectrometers at the MAMI\nelectron-scattering facility can be calibrated absolutely with an accuracy\n$\\delta p/p\\leq 10^{-4}$, which will be crucial for high precision\ndetermination of hypernuclear masses.\n",
      "subjects": [
        "physics.ins-det",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217732317500638",
      "title": "Physical Angular Momentum Separation for QED",
      "abstract": "  We study the non-uniqueness problem of the gauge-invariant angular momentum\nseparation for the case of QED, which stems from the recent controversy\nconcerning the proper definitions of the orbital angular momentum and spin\noperator of the individual parts of a gauge field system. For the free quantum\nelectrodynamics without matter, we show that the basic requirement of Euclidean\nsymmetry selects a unique physical angular momentum separation scheme from the\nmultitude of the possible angular momentum separation schemes constructed using\nthe various Gauge Invariant Extentions. Based on these results, we propose a\nset of natural angular momentum separation schemes for the case of interacting\nQED by invoking the formalism of asymptotic fields. Some perspectives on such a\nproblem for the case of QCD are briefly discussed.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Capacity of the Energy Harvesting Gaussian MAC",
      "abstract": "  We consider an energy harvesting multiple access channel (MAC) where the\ntransmitters are powered by an exogenous stochastic energy harvesting process\nand equipped with finite batteries. We characterize the capacity region of this\nchannel as n-letter mutual information rate and develop inner and outer bounds\nthat differ by a constant gap. An interesting conclusion that emerges from our\nresults is that the sum-capacity approaches that of a standard AWGN MAC (with\nonly an average constraint on the transmitted power), as the number of users in\nthe MAC becomes large.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.95.020501",
      "title": "Conductance spectroscopy of nontopological-topological superconductor\n  junctions",
      "abstract": "  We calculate the zero-temperature differential conductance $dI/dV$ of a\nvoltage-biased one-dimensional junction between a nontopological and a\ntopological superconductor for arbitrary junction transparency using the\nscattering matrix formalism. We consider two representative models for the\ntopological superconductors: (i) spinful $p$-wave and (ii) $s$-wave with\nspin-orbit coupling and spin splitting. We verify that in the tunneling limit\n(small junction transparencies) where only single Andreev reflections\ncontribute to the current, the conductance for voltages below the\nnontopological superconductor gap $\\Delta_s$ is zero and there are two\nsymmetric conductance peaks appearing at $eV = \\pm \\Delta_s$ with the quantized\nvalue $(4-\\pi)2e^2/h$ due to resonant Andreev reflection from the Majorana zero\nmode. However, when the junction transparency is not small, there is a finite\nconductance for $e|V| < \\Delta_s$ arising from multiple Andreev reflections.\nThe conductance at $eV = \\pm \\Delta_s$ in this case is no longer quantized. In\ngeneral, the conductance is particle-hole asymmetric except for sufficiently\nsmall transparencies. We further show that, for certain values of parameters,\nthe tunneling conductance from a zero-energy conventional Andreev bound state\ncan be made to mimic the conductance from a true Majorana mode.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.95.012004",
      "title": "Search for Proton Decay via $p \\to e^+\\pi^0$ and $p \\to \\mu^+\\pi^0$ in\n  0.31 megaton$\\cdot$years exposure of the Super-Kamiokande Water Cherenkov\n  Detector",
      "abstract": "  We have searched for proton decay via $p \\rightarrow e^{+} \\pi^{0}$ and $p\n\\rightarrow \\mu^{+} \\pi^{0}$ using Super-Kamiokande data from April 1996 to\nMarch 2015, 0.306 megaton$\\cdot$years exposure in total. The atmospheric\nneutrino background rate in Super-Kamiokande IV is reduced to almost half that\nof phase I-III by tagging neutrons associated with neutrino interactions. The\nreach of the proton lifetime is further enhanced by introducing new signal\ncriteria that select the decay of a proton in a hydrogen atom. No candidates\nwere seen in the $p \\rightarrow e^{+} \\pi^{0}$ search. Two candidates that\npassed all of the selection criteria for $p \\rightarrow \\mu^{+} \\pi^{0}$ have\nbeen observed, but these are consistent with the expected number of background\nevents of 0.87. Lower limits on the proton lifetime are set at $\\tau/B(p\n\\rightarrow e^{+} \\pi^{0}) > 1.6 \\times 10^{34}$ years and $\\tau/B(p\n\\rightarrow \\mu^{+} \\pi^{0}) > 7.7 \\times 10^{33}$ years at 90% confidence\nlevel.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A simple proof of Feuerbach's theorem",
      "abstract": "  The theorem of Feuerbach states that the nine-point circle of a\nnonequilateral triangle is tangent to both its incircle and its three\nexcircles. We give a simple proof of this theorem.\n",
      "subjects": [
        "math.HO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.96.036012",
      "title": "Model independent analysis of $b \\to (c,\\,u)\\,\\tau\\nu$ leptonic and\n  semileptonic decays",
      "abstract": "  Latest measurement of the ratio of branching ratios $R_D = \\mathcal B(B \\to\nD\\,\\tau\\,\\nu)/\\mathcal B(B \\to D\\,l\\,\\nu)$ and $R_{D^{\\ast}} = \\mathcal B(B \\to\nD^{\\ast}\\,\\tau\\,\\nu)/\\mathcal B(B \\to D^{\\ast}\\,l\\,\\nu)$, where $l$ is either\nan electron or muon, differs from the standard model expectation by $1.9\\sigma$\nand $3.3\\sigma$, respectively. Similar tension has been observed in purely\nleptonic $B \\to \\tau\\nu$ decays as well. In this context, we consider the most\ngeneral effective Lagrangian in the presence of new physics and perform a model\nindependent analysis to explore various new physics couplings. Motivated by the\nrecently proposed new observables $R_D^{\\tau} = R_D/\\mathcal B(B \\to \\tau\\nu)$\nand $R_{D^{\\ast}}^{\\tau} = R_{D^{\\ast}}/\\mathcal B(B \\to \\tau\\nu)$, we impose\n$2\\sigma$ constraints coming from $R_D^{\\tau}$ and $R_{D^{\\ast}}^{\\tau}$ in\naddition to the constraints coming from $R_D$, $R_{D^{\\ast}}$, and $\\mathcal\nB(B \\to \\tau\\nu)$ to constrain the new physics parameter space. We study the\nimpact of new physics on various observables related to $B_s \\to\n(D_s,\\,D^{\\ast}_s)\\tau\\nu$ and $B \\to \\pi\\tau\\nu$ decay processes.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Investigating the Transition Region in Scanned Probe Images of the\n  Cyclotron Orbit in Graphene",
      "abstract": "  A cooled scanning probe microscope (SPM) has been used to image cyclotron\norbits of electrons through high-mobility graphene in a magnetic field.1-5 In a\nhBN-graphene-hBN device patterned into a hall bar geometry, the magnetic field\nfocuses a current Ii injected from one narrow contact into another narrow\ncontact located an integer number of cyclotron diameters away, creating a\nvoltage Vc. The degree of focusing is measured by the transresistance Rm =\nVc/Ii. In SPM, the tip can either enhance or decrease conductance in the sample\nby deflecting electrons into or away from the second contact, respectively.3,4\nOur SPM images of magnetic focusing feature a region in which the tip\ntransitions from enhancing to decreasing the conductance in the sample where\nthe change in transresistance caused by the tip is equal to zero. In this\npaper, we investigate how the location of this region in the graphene sample\nchanges as we modulate the electron density n and magnetic field B. By plotting\nline-cuts of the change in trans-resistance for different electron densities\nand magnetic fields, we identify trends in the inflection point where the tip\nchanges from enhancing to decreasing the conductance in the sample. From the\nlocation of each transition region, we show that the cyclotron diameter of the\nelectron trajectories can be obtained, and explain the trends in inflection\npoint location for different electron densities and magnetic fields.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.96.043847",
      "title": "Greatly enhanced intensity-difference squeezing for narrow-band quantum\n  metrology applications",
      "abstract": "  Narrow-band intensity-difference squeezing beams have important applications\nin quantum metrology and gravitational wave detection. The best way to generate\nnarrow-band intensity-difference squeezing is to employ\nparametrically-amplified four-wave mixing process in high-gain atomic media.\nSuch IDS can be further enhanced by cascading multiple parametrically-amplified\nfour-wave mixing processes in separate atomic media. The complicated\nexperimental setup, added losses and required high-power pump laser with the\nincrease of number of stages can limit the wide uses of such scheme in\npractical applications. Here, we show that by modulating the internal energy\nlevel(s) with additional laser(s), the degree of original intensity-difference\nsqueezing can be substantially increased. With an initial intensity-difference\nsqueezing of $-8.5\\pm0.4$ dB using parametrically-amplified-non-degenerate\nfour-wave mixing process in a three-level $\\Lambda$-type configuration, the\ndegree of intensity-difference squeezing can be enhanced to $-11.9\\pm0.4$\ndB/$-13.9\\pm0.4$ dB (corrected for losses) when we use one/two laser beam(s) to\nmodulate the involved ground/excited state(s). More importantly, a maximal\nnoise reduction of $-9.7\\pm0.4$ dB (only corrected for electronic noise) is\nobserved below the standard quantum limit, which is the strongest reported to\ndate in phase insensitive amplification in four-wave mixing. Applying the model\nto quantum metrology, the signal-to-noise ratio is improved by 23 dB compared\nto the conventional Mach-Zehnder interferometer under the same phase-sensing\nintensity, which is a 14-fold enhancement in rms phase measurement sensitivity\nbeyond the shot noise limit. Our results show a low-loss, robust and efficient\nway to produce high degree of IDS and facilitate its potential applications.\n",
      "subjects": [
        "physics.optics",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10714-016-2156-9",
      "title": "Torsion effects on a relativistic position-dependent mass system",
      "abstract": "  We analyse a relativistic scalar particle with a position-dependent mass in a\nspacetime with a space-like dislocation by showing that relativistic bound\nstates solutions can be achieved. Further, we consider the presence of the\nCoulomb potential and analyse the relativistic position-dependent mass system\nsubject to the Coulomb potential in the spacetime with a space-like\ndislocation. We also show that a new set of relativistic bound states solutions\ncan be obtained, where there also exists the influence of torsion of the\nrelativistic energy levels. Finally, we investigate an analogue of the\nAharonov-Bohm effect for bound states in this position-dependent mass in a\nspacetime with a space-like dislocation.\n",
      "subjects": [
        "quant-ph",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.96.045006",
      "title": "R\\'enyi Mutual Information for Free Scalar in Even Dimensions",
      "abstract": "  We compute the R\\'enyi mutual information of two disjoint spheres in free\nmassless scalar theory in even dimensions higher than two. The spherical twist\noperator in a conformal field theory can be expanded into the sum of local\nprimary operators and their descendants. We analyze the primary operators in\nthe replicated scalar theory and find the ones of the fewest dimensions and\nspins. We study the one-point function of these operators in the conical\ngeometry and obtain their expansion coefficients in the OPE of spherical twist\noperators. We show that the R\\'enyi mutual information can be expressed in\nterms of the conformal partial waves. We compute explicitly the R\\'enyi mutual\ninformation up to order $z^d$, where $z$ is the cross ratio and $d$ is the\nspacetime dimension.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physletb.2017.03.018",
      "title": "Final COMPASS results on the deuteron spin-dependent structure function\n  $g_1^{\\rm d}$ and the Bjorken sum rule",
      "abstract": "  Final results are presented from the inclusive measurement of deep-inelastic\npolarised-muon scattering on longitudinally polarised deuterons using a $^6$LiD\ntarget. The data were taken at $160~{\\rm GeV}$ beam energy and the results are\nshown for the kinematic range $1~({\\rm GeV}/c)^2 < Q^2 < 100~({\\rm GeV}/c)^2$\nin photon virtuality, $0.004<x<0.7$ in the Bjorken scaling variable and $W >\n4~{\\rm GeV}/c^2$ in the mass of the hadronic final state. The deuteron\ndouble-spin asymmetry $A_1^{\\rm d}$ and the deuteron longitudinal-spin\nstructure function $g_1^{\\rm d}$ are presented in bins of $x$ and $Q^2$.\nTowards lowest accessible values of $x$, $g_1^{\\rm d}$ decreases and becomes\nconsistent with zero within uncertainties. The presented final $g_1^{\\rm d}$\nvalues together with the recently published final $g_1^{\\rm p}$ values of\nCOMPASS are used to again evaluate the Bjorken sum rule and perform the QCD fit\nto the $g_1$ world data at next-to-leading order of the strong coupling\nconstant. In both cases, changes in central values of the resulting numbers are\nwell within statistical uncertainties. The flavour-singlet axial charge $a_0$,\n{which is identified in the $\\overline{\\rm MS}$ renormalisation scheme with the\ntotal contribution of quark helicities to the nucleon spin}, is extracted from\nonly the COMPASS deuteron data with negligible extrapolation uncertainty: $a_0\n(Q^2 = 3~({\\rm GeV}/c)^2) = 0.32 \\pm 0.02_{\\rm stat} \\pm0.04_{\\rm syst} \\pm\n0.05_{\\rm evol}$. Together with the recent results on the proton spin structure\nfunction $g_1^{\\rm p}$, the results on $g_1^{\\rm d}$ constitute the COMPASS\nlegacy on the measurements of $g_1$ through inclusive spin-dependent deep\ninelastic scattering.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/TIFS.2018.2812146",
      "title": "LoPub: High-Dimensional Crowdsourced Data Publication with Local\n  Differential Privacy",
      "abstract": "  High-dimensional crowdsourced data collected from a large number of users\nproduces rich knowledge for our society. However, it also brings unprecedented\nprivacy threats to participants. Local privacy, a variant of differential\nprivacy, is proposed as a means to eliminate the privacy concern.\nUnfortunately, achieving local privacy on high-dimensional crowdsourced data\nraises great challenges on both efficiency and effectiveness. Here, based on EM\nand Lasso regression, we propose efficient multi-dimensional joint distribution\nestimation algorithms with local privacy. Then, we develop a Locally\nprivacy-preserving high-dimensional data Publication algorithm, LoPub, by\ntaking advantage of our distribution estimation techniques. In particular, both\ncorrelations and joint distribution among multiple attributes can be identified\nto reduce the dimension of crowdsourced data, thus achieving both efficiency\nand effectiveness in locally private high-dimensional data publication.\nExtensive experiments on real-world datasets demonstrated that the efficiency\nof our multivariate distribution estimation scheme and confirm the\neffectiveness of our LoPub scheme in generating approximate datasets with local\nprivacy.\n",
      "subjects": [
        "cs.CR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Skew-rank of an oriented graph in terms of the rank and dimension of\n  cycle space of its underlying graph",
      "abstract": "  Let $G^{\\sigma}$ be an oriented graph and $S(G^{\\sigma})$ be its\nskew-adjacency matrix, where $G$ is called the underlying graph of\n$G^{\\sigma}$. The skew-rank of $G^{\\sigma}$, denoted by $sr(G^{\\sigma})$, is\nthe rank of $S(G^{\\sigma})$. Denote by $d(G)=|E(G)|-|V(G)|+\\theta(G)$ the\ndimension of cycle spaces of $G$, where $|E(G)|$, $|V(G)|$ and $\\theta(G)$ are\nthe edge number, vertex number and the number of connected components of $G$,\nrespectively. Recently, Wong, Ma and Tian [European J. Combin. 54 (2016)\n76--86] proved that $sr(G^{\\sigma})\\leq r(G)+2d(G)$ for an oriented graph\n$G^{\\sigma}$, where $r(G)$ is the rank of the adjacency matrix of $G$, and\ncharacterized the graphs whose skew-rank attain the upper bound. However, the\nproblem of the lower bound of $sr(G^{\\sigma})$ of an oriented graph\n$G^{\\sigma}$ in terms of $r(G)$ and $d(G)$ of its underlying graph $G$ is left\nopen till now. In this paper, we prove that $sr(G^{\\sigma})\\geq r(G)-2d(G)$ for\nan oriented graph $G^{\\sigma}$ and characterize the graphs whose skew-rank\nattain the lower bound.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the Correlation Distribution for a Ternary Niho Decimation",
      "abstract": "  In this paper, let $n=2m$ and $d=3^{m+1}-2$ with $m\\geq2$ and\n$\\gcd(d,3^n-1)=1$. By studying the weight distribution of the ternary\nZetterberg code and counting the numbers of solutions of some equations over\nthe finite field $\\mathbb{F}_{3^n}$, the correlation distribution between a\nternary $m$-sequence of period $3^n-1$ and its $d$-decimation sequence is\ncompletely determined. This is the first time that the correlation distribution\nfor a non-binary Niho decimation has been determined since 1976.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On How the Introducing of a New $\\theta$ Function Symbol Into\n  Arithmetic's Formalism Is Germane to Devising Axiom Systems that Can\n  Appreciate Fragments of Their Own Hilbert Consistency",
      "abstract": "  A new $\\theta$ function primitive is proposed that almost achieves the\ncombined efficiency of the addition, multiplication and successor growth\noperations. This $\\theta$ function symbol enables the constructing of an\n\"IQFS(PA+)\" axiom system that can corroborate a fragmentary definition of its\nown Hilbert consistency, while it will simultaneously verify isomorphic\ncounterparts of all Peano Arithmetic's $\\Pi_1$ theorems. Many propositions and\nintermediate results are also established. Only one intermediate result, which\nmost readers will intuit should be true, does remain formally unproven.\n",
      "subjects": [
        "math.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Intelligent information extraction based on artificial neural network",
      "abstract": "  Question Answering System (QAS) is used for information retrieval and natural\nlanguage processing (NLP) to reduce human effort. There are numerous QAS based\non the user documents present today, but they all are limited to providing\nobjective answers and process simple questions only. Complex questions cannot\nbe answered by the existing QAS, as they require interpretation of the current\nand old data as well as the question asked by the user. The above limitations\ncan be overcome by using deep cases and neural network. Hence we propose a\nmodified QAS in which we create a deep artificial neural network with\nassociative memory from text documents. The modified QAS processes the contents\nof the text document provided to it and find the answer to even complex\nquestions in the documents.\n",
      "subjects": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nonperturbative Transverse Momentum Effects in Dihadron and Direct\n  Photon-Hadron Angular Correlations",
      "abstract": "  Two-particle angular correlations have long been used as an observable for\nmeasuring the initial-state partonic transverse momentum $k_T$. Sensitivity to\nthis small transverse momentum scale allows nonperturbative transverse momentum\ndependent effects to be probed in high $p_T$ dihadron and direct photon-hadron\ncorrelations. The observable $p_{out}$, the out-of-plane transverse momentum\ncomponent from a near-side $\\pi^0$ or direct photon, is sensitive to\ninitial-state $k_T$ and final-state fragmentation transverse momentum $j_T$ and\nthus can probe nonperturbative transverse-momentum-dependent effects. In the\ntransverse-momentum-dependent framework, nearly back-to-back particle\nproduction in $p$+$p$ collisions with a measured final-state hadron has been\npredicted to break factorization due to the possibility of gluon exchanges with\ncolored remnants in the initial and final states. For this reason, the\ninteracting partons are predicted to be correlated; however, there is so far no\nquantitative prediction for the magnitude of such effects. In this talk, recent\nmeasurements of dihadron and direct-photon hadron correlations in $p$+$p$\ncollisions at $\\sqrt{s}$=510 GeV at the PHENIX experiment will be presented.\n",
      "subjects": [
        "hep-ex",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.7566/JPSJ.86.043801",
      "title": "Swimmer-microrheology",
      "abstract": "  We discuss a locomotion of a three-sphere microswimmer in a viscoelastic\nmedium and propose a new type of active microrheology. We derive a relation\nwhich connects average swimming velocity and frequency-dependent viscosity of\nthe surrounding medium. In this relation, the viscous contribution can exist\nonly when the time-reversal symmetry is broken, whereas the elastic\ncontribution is present only when the structural symmetry of the swimmer is\nbroken. The Purcell's scallop theorem breaks down for a three-sphere swimmer in\na viscoelastic medium.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/ncomms15219",
      "title": "Thermoelectric quantum oscillations in ZrSiS",
      "abstract": "  Topological semimetals are systems in which the conduction and the valence\nbands cross each other and this crossing is protected by topological\nconstraints. These materials provide an intriguing test of fundamental theory\nand their exceptional physical properties promise a wide range of possible\napplications. Here we report a study of the thermoelectric power (S) for a\nsingle crystal of ZrSiS that is believed to be a topological nodal-line\nsemimetal. We detect multiple quantum oscillations in the magnetic field\ndependence of S that are still visible at temperature as high as T = 100 K. Two\nof these oscillation frequencies are shown to arise from 3D and 2D bands, each\nwith linear dispersion and the additional Berry phase expected theoretically.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Flagged Grothendieck polynomials",
      "abstract": "  We show that the flagged Grothendieck polynomials defined as the generating\nfunctions of flagged set-valued tableaux of Knutson-Miller-Yong can be\nexpressed by a Jacobi-Trudi type determinant formula generalizing the work of\nHudson-Matsumura. We also introduce the flagged skew Grothendieck polynomials\nin these two expressions and show that they coincide.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/s41598-017-09864-0",
      "title": "3D Printing of Polymer Bonded Rare-Earth Magnets With a Variable\n  Magnetic Compound Density for a Predefined Stray Field",
      "abstract": "  Additive manufacturing of polymer bonded magnets is a recently developed\ntechnique, for single-unit production, and for structures that have been\nimpossible to manufacture previously. Also new possibilities to create a\nspecific stray field around the magnet are triggered. The current work presents\na method to 3D print polymer bonded magnets with a variable magnetic compound\ndensity distribution. A low-cost, end-user 3D printer with a mixing extruder is\nused to mix permanent magnetic filaments with pure PA12 filaments. The magnetic\nfilaments are compounded, extruded, and characterized for the printing process.\nTo deduce the quality of the manufactured magnets with a variable compound\ndensity, an inverse stray field framework is used. The effectiveness of the\nprinting process and the simulation method is shown. It can also be used to\nmanufacture magnets that produce a predefined stray field in a given region.\nExamples for sensor applications are presented. This setup and simulation\nframework allows the design and manufacturing of polymer bonded permanent\nmagnets which are impossible to create with conventional methods.\n",
      "subjects": [
        "physics.ins-det",
        "cond-mat.mtrl-sci",
        "physics.comp-ph",
        "physics.pop-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1475-7516/2017/04/010",
      "title": "Constraining Secluded Dark Matter models with the public data from the\n  79-string IceCube search for dark matter in the Sun",
      "abstract": "  The 79-string IceCube search for dark matter in the Sun public data is used\nto test Secluded Dark Matter models. No significant excess over background is\nobserved and constraints on the parameters of the models are derived. Moreover,\nthe search is also used to constrain the dark photon model in the region of the\nparameter space with dark photon masses between 0.22 and $\\sim$ 1 GeV and a\nkinetic mixing parameter $\\varepsilon \\sim 10^{-9}$, which remains\nunconstrained. These are the first constraints of dark photons from neutrino\ntelescopes. It is expected that neutrino telescopes will be efficient tools to\ntest dark photons by means of different searches in the Sun, Earth and Galactic\nCenter, which could complement constraints from direct detection, accelerators,\nastrophysics and indirect detection with other messengers, such as gamma rays\nor antiparticles.\n",
      "subjects": [
        "astro-ph.HE",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1209/0295-5075/117/47001",
      "title": "Valence state of Sm in single crystalline EuO thin films",
      "abstract": "  Samarium has two stable valence states, 2+ and 3+, which coexist in many\ncompounds forming spatially homogeneous intermediate valence states. We study\nthe valence state of samarium when incorporated in a single crystalline EuO\nthin film which crystallizes in a $fcc$-structure similar to that of the\nintermediate valence SmO, but with a larger lattice constant. Due to the\nincreased lattice spacing, a stabilization of the larger Sm$^{2+}$ ion is\nexpected. Surprisingly, the samarium incorporated in\nSm$_{\\mathrm{x}}$Eu$_{\\mathrm{1-x}}$O thin films shows a predominantly\ntrivalent character, as determined by x-ray photoelectron spectroscopy and\nmagnetometry measurements. We infer that the O$^{2-}$ ions in the EuO lattice\nhave enough room to move locally, so as to reduce the Sm-O distance and\nstabilize the Sm$^{3+}$ valence.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.95.043422",
      "title": "Ground-state properties of Ca$_2$ from narrow line two-color\n  photoassociation",
      "abstract": "  By two-color photoassociation of $^{40}$Ca four weakly bound vibrational\nlevels in the Ca$_2$ \\Xpot ground state potential were measured, using highly\nspin-forbidden transitions to intermediate states of the coupled system\n$^3\\Pi_{u}$ and $^3\\Sigma^+ _{u}$ near the ${^3P_1}$+${^1S_0}$ asymptote. From\nthe observed binding energies, including the least bound state, the long range\ndispersion coefficients $\\mathrm{C}_6, \\mathrm{C}_8,\\mathrm{C}_{10}$ and a\nprecise value for the s-wave scattering length of 308.5(50)~$a_0$ were derived.\nFrom mass scaling we also calculated the corresponding scattering length for\nother natural isotopes. From the Autler-Townes splitting of the spectra, the\nmolecular Rabi frequency has been determined as function of the laser intensity\nfor one bound-bound transition. The observed value for the Rabi-frequency is in\ngood agreement with calculated transition moments based on the derived\npotentials, assuming a dipole moment being independent of internuclear\nseparation for the atomic pair model.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1126/science.aam5538",
      "title": "A Fermi-degenerate three-dimensional optical lattice clock",
      "abstract": "  Strontium optical lattice clocks have the potential to simultaneously\ninterrogate millions of atoms with a high spectroscopic quality factor of $4\n\\times 10^{-17}$. Previously, atomic interactions have forced a compromise\nbetween clock stability, which benefits from a large atom number, and accuracy,\nwhich suffers from density-dependent frequency shifts. Here, we demonstrate a\nscalable solution which takes advantage of the high, correlated density of a\ndegenerate Fermi gas in a three-dimensional optical lattice to guard against\non-site interaction shifts. We show that contact interactions are resolved so\nthat their contribution to clock shifts is orders of magnitude lower than in\nprevious experiments. A synchronous clock comparison between two regions of the\n3D lattice yields a $5 \\times 10^{-19}$ measurement precision in 1 hour of\naveraging time.\n",
      "subjects": [
        "physics.atom-ph",
        "cond-mat.quant-gas",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stx1385",
      "title": "Dynamics of jets during the Common Envelope phase",
      "abstract": "  Common envelope (CE) is an important phase in the evolution of many binary\nsystems. Giant star / compact object interaction in binaries plays an important\nrole in high-energy phenomena as well as in the evolution of their environment.\nMaterial accreted onto the compact object may form a disk and power a jet. We\nstudy analytically and through numerical simulations the interaction between\nthe jet and the CE. We determine the conditions under which accreting material\nquenches the jet or allows it to propagate successfully, in which case even the\nenvelope may be ejected. Close to the stellar core of the companion the compact\nobject accretes at a larger rate. A jet launched from this region needs a\nlarger accretion-to-ejection efficiency to successfully propagate through the\nCE compared to a jet launched far from the stellar core, and is strongly\ndeflected by the orbital motion. The energy deposited by the jet may be larger\nthan the binding energy of the envelope. The jet can, thus, play a fundamental\nrole in the CE evolution. We find that the energy dissipation of the jet into\nthe CE may stop accretion onto the disk. We expect the jet to be intermittent,\nunless the energy deposited is large enough to lead to the unbinding of the\nouter layers of the CE. Given that the energy and duration of the jet are\nsimilar to those of ultra-long GRBs, we suggest this as a new channel to\nproduce these events.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.95.074027",
      "title": "Towards tests of quark-hadron duality with functional analysis and\n  spectral function data",
      "abstract": "  The presence of terms that violate quark-hadron duality in the expansion of\nQCD Green's functions is a generally accepted fact. Recently, a new approach\nwas proposed for the study of duality violations (DVs), which exploits the\nexistence of a rigorous lower bound on the functional distance, measured in a\ncertain norm, between a \"true\" correlator and its approximant calculated\ntheoretically along a contour in the complex energy plane. In the present paper\nwe pursue the investigation of functional-analysis based tests towards their\napplication to real spectral function data. We derive a closed analytic\nexpression for the minimal functional distance based on the general weighted\n$L^2$ norm and discuss its relation with the distance measured in $L^\\infty$\nnorm. Using fake data sets obtained from a realistic toy model in which we\nallow for covariances inspired from the publicly available ALEPH spectral\nfunctions, we obtain by Monte Carlo simulations the statistical distribution of\nthe strength parameter that measures the magnitude of the DV term added to the\nusual operator product expansion (OPE). The results show that, if the region\nwith large errors near the end-point of the spectrum in $\\tau$ decays is\nexcluded, the functional-analysis based tests using either $L^2$ or $L^\\infty$\nnorms are able to detect, in a statistically significant way, the presence of\nDVs in realistic spectral function pseudodata.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.95.033835",
      "title": "Kerr Superoscillator Model for Microresonator Frequency Combs",
      "abstract": "  Microresonator-based optical frequency combs, or \"microcombs\", have attracted\nlots of attention in the last few years thanks to their promising applications\nin telecommunications, spectroscopy and optical clocks. The process of comb\ngeneration in microresonators can be modelled in the frequency domain using\ncoupled mode equations, and has also recently been successfully described in\nthe time domain using a nonlinear Schr\\\"odinger equation known as the\nLugiato-Lefever equation. Though time-domain approaches have brought many\ninteresting insights for the understanding of microcombs, an intuitive\nfrequency-domain model has not yet been established. In this work we present a\nfrequency-domain model of microcombs that describes the overall structure of\nthe spectra in terms of a few collective excitations of groups of neighboring\ncomb lines, which we term \"superoscillators\". This approach ties in nicely with\nthe recently-developed time-domain model based on soliton crystals, and links\nthe microcomb generation process with frequency response theory.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1209/0295-5075/117/30003",
      "title": "Spread of wave packets in disordered hierarchical lattices",
      "abstract": "  We consider the spreading of the wave packet in the generalized\nRosenzweig-Porter random matrix ensemble in the region of non-ergodic extended\nstates $1<\\gamma<2$. We show that despite non-trivial fractal dimensions $0 <\nD_{q}=2-\\gamma<1$ characterize wave function statistics in this region, the\nwave packet spreading $\\langle r^{2} \\rangle \\propto t^{\\beta}$ is governed by\nthe \"diffusion\" exponent $\\beta=1$ outside the ballistic regime $t>\\tau\\sim 1$\nand $\\langle r^{2}\\rangle \\propto t^{2}$ in the ballistic regime for\n$t<\\tau\\sim 1$. This demonstrates that the multifractality exhibits itself only\nin {\\it local} quantities like the wave packet survival probability but not in\nthe large-distance spreading of the wave packet.\n",
      "subjects": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cond-mat.str-el",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s00601-017-1321-3",
      "title": "Experimentally accessible invariants encoded in interparticle\n  correlations of harmonically trapped ultra-cold few-fermion mixtures",
      "abstract": "  System of a two-flavor mixture of ultra-cold fermions confined in a\none-dimensional harmonic trap is studied in the frame of the center of mass. We\npresent a numerical method of obtaining energetic spectra in this frame for an\narbitrary mass ratio of fermionic species. We identify a specific invariant\nencoded in many-body correlations which enable one to determine an eigenstate\nof the Hamiltonian and to label excitations of the center of mass. The tool\npresented may be particularly useful in experimental analysis of the\ninterparticle interactions which do not affect the center of mass excitations\nin a harmonic potential.\n",
      "subjects": [
        "cond-mat.quant-gas",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Proof of Correspondence between Keys and Encoding Maps in an\n  Authentication Code",
      "abstract": "  In a former paper the authors introduced two new systematic authentication\ncodes based on the Gray map over a Galois ring. In this paper, it is proved the\none-to-one onto correspondence between keys and encoding maps for the second\nintroduced authentication code.\n",
      "subjects": [
        "math.NT",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Online Degree-Bounded Steiner Network Design",
      "abstract": "  We initiate the study of degree-bounded network design problems in the online\nsetting. The degree-bounded Steiner tree problem { which asks for a subgraph\nwith minimum degree that connects a given set of vertices { is perhaps one of\nthe most representative problems in this class. This paper deals with its\nwell-studied generalization called the degree-bounded Steiner forest problem\nwhere the connectivity demands are represented by vertex pairs that need to be\nindividually connected. In the classical online model, the input graph is given\nonline but the demand pairs arrive sequentially in online steps. The selected\nsubgraph starts off as the empty subgraph, but has to be augmented to satisfy\nthe new connectivity constraint in each online step. The goal is to be\ncompetitive against an adversary that knows the input in advance. We design a\nsimple greedy-like algorithm that achieves a competitive ratio of O(log n)\nwhere n is the number of vertices. We show that no (randomized) algorithm can\nachieve a (multiplicative) competitive ratio o(log n); thus our result is\nasymptotically tight. We further show strong hardness results for the group\nSteiner tree and the edge-weighted variants of degree-bounded connectivity\nproblems. Fourer and Raghavachari resolved the online variant of degree-bounded\nSteiner forest in their paper in SODA'92. Since then, the natural family of\ndegree-bounded network design problems has been extensively studied in the\nliterature resulting in the development of many interesting tools and numerous\npapers on the topic. We hope that our approach in this paper, paves the way for\nsolving the online variants of the classical problems in this family of network\ndesign problems.\n",
      "subjects": [
        "cs.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.2140/pjm.2018.295.317",
      "title": "Hamiltonian stationary cones with isotropic links",
      "abstract": "  We show that any closed oriented immersed Hamiltonian stationary isotropic\nsurface $\\Sigma$ with genus $g_{\\Sigma}$ in $S^{5}\\subset\\mathbb{C}^{3}$ is (1)\nLegendrian and minimal if $g_{\\Sigma}=0$; (2) either Legendrian or with exactly\n$2g_{\\Sigma}-2$ Legendrian points if $g_{\\Sigma}\\geq1.$ In general, every\ncompact oriented immersed isotropic submanifold $L^{n-1}\\subset\nS^{2n-1}\\subset\\mathbb{C}^{n}$ such that the cone $C\\left( L^{n-1}\\right) $ is\nHamiltonian stationary must be Legendrian and minimal if its first Betti number\nis zero. Corresponding results for non-orientable links are also provided.\n",
      "subjects": [
        "math.DG",
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/aa71a9",
      "title": "Quenching or Bursting: Star Formation Acceleration--A New Methodology\n  for Tracing Galaxy Evolution",
      "abstract": "  We introduce a new methodology for the direct extraction of galaxy physical\nparameters from multi-wavelength photometry and spectroscopy. We use\nsemi-analytic models that describe galaxy evolution in the context of large\nscale cosmological simulation to provide a catalog of galaxies, star formation\nhistories, and physical parameters. We then apply stellar population synthesis\nmodels and a simple extinction model to calculate the observable broad-band\nfluxes and spectral indices for these galaxies. We use a linear regression\nanalysis to relate physical parameters to observed colors and spectral indices.\nThe result is a set of coefficients that can be used to translate observed\ncolors and indices into stellar mass, star formation rate, and many other\nparameters, including the instantaneous time derivative of the star formation\nrate which we denote the {\\it Star Formation Acceleration (SFA)}, We apply the\nmethod to a test sample of galaxies with GALEX photometry and SDSS\nspectroscopy, deriving relationships between stellar mass, specific star\nformation rate, and star formation acceleration. We find evidence for a\nmass-dependent SFA in the green valley, with low mass galaxies showing greater\nquenching and higher mass galaxies greater bursting. We also find evidence for\nan increase in average quenching in galaxies hosting AGN. A simple scenario in\nwhich lower mass galaxies accrete and become satellite galaxies, having their\nstar forming gas tidally and/or ram-pressure stripped, while higher mass\ngalaxies receive this gas and react with new star formation can qualitatively\nexplain our results.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The linearization of periodic Hamiltonian systems with one degree of\n  freedom under the Diophantine condition",
      "abstract": "  In this paper we are concerned with the periodic Hamiltonian system with one\ndegree of freedom, where the origin is a trivial solution. We assume that the\ncorresponding linearized system at the origin is elliptic, and the\ncharacteristic exponents of the linearized system are $\\pm i\\omega$ with\n$\\omega$ be a Diophantine number, moreover if the system is formally\nlinearizable, then it is analytically linearizable. As a result, the origin is\nalways stable in the sense of Liapunov in this case.\n",
      "subjects": [
        "math.CA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Presymplectic convexity and (ir)rational polytopes",
      "abstract": "  In this paper, we extend the Atiyah--Guillemin--Sternberg convexity theorem\nand Delzant's classification of symplectic toric manifolds to presymplectic\nmanifolds. We also define and study the Morita equivalence of presymplectic\ntoric manifolds and of their corresponding framed momentum polytopes, which may\nbe rational or non-rational. Toric orbifolds, quasifolds and non-commutative\ntoric varieties may be viewed as the quotient of our presymplectic toric\nmanifolds by the kernel isotropy foliation of the presymplectic form.\n",
      "subjects": [
        "math.SG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Opportunistic-Bit Scheme with IP Styled Communication",
      "abstract": "  This work is motivated by the need for the fundamental increase of spectral\nefficiency with the transmissions on the Transmission Control Protocol and the\nInternet Protocol (TCP/IP). To emphasize the work in physical layer, we define\na bit-unit (BU) that is conceptually similar to an IP packet that contains\nsufficient information for its destination node to identify the address and\ninterpret the contents in performing the message communication. Armed with\nthese functions, we divide one BU into two parts, which are defined as\nopportunistic bit (OB) and conventional bit (CB), respectively. In addition, we\ndesign the sequential time-slots (TSs) in such a way that the OB can be mapped\nto the index of a TS, and the CB can be carried by the corresponding TS. To\nenable the communication, we pre-store a bit-to-TS mapping table at both of the\ntransmitter and the receiver. As result, we can save time resource and gain\nspectral efficiency as shown in the theoretical analysis confirmed by the\nsimulations.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.4990810",
      "title": "Real-time digital signal recovery for a multi-pole low-pass transfer\n  function system",
      "abstract": "  In order to solve the problems of waveform distortion and signal delay by\nmany physical and electrical systems with multi-pole linear low-pass transfer\ncharacteristics, a simple digital-signal-processing (DSP)-based method of\nreal-time recovery of the original source waveform from the distorted output\nwaveform is proposed. A mathematical analysis on the convolution kernel\nrepresentation of the single-pole low-pass transfer function shows that the\noriginal source waveform can be accurately recovered in real time using a\nparticular moving average algorithm applied on the input stream of the\ndistorted waveform, which can also significantly reduce the overall delay time\nconstant. This method is generalized for multi-pole low-pass systems and has\nnoise characteristics of the inverse of the low-pass filter characteristics.\nThis method can be applied to most sensors and amplifiers operating close to\ntheir frequency response limits to improve the overall performances of data\nacquisition systems and digital feedback control systems.\n",
      "subjects": [
        "physics.ins-det"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.119.073901",
      "title": "Optical Momentum, Spin, and Angular Momentum in Dispersive Media",
      "abstract": "  We examine the momentum, spin, and orbital angular momentum of structured\nmonochromatic optical fields in dispersive inhomogeneous isotropic media. There\nare two bifurcations in this general problem: the Abraham-Minkowski dilemma and\nthe kinetic (Poynting-like) versus canonical (spin-orbital) pictures. We show\nthat the kinetic Abraham momentum describes the energy flux and group velocity\nof the wave in the medium. At the same time, we introduce novel canonical\nMinkowsky-type momentum, spin, and orbital angular momentum densities of the\nfield. These quantities exhibit fairly natural forms, analogous to the\nBrillouin energy density, as well as multiple advantages as compared with\npreviously considered formalisms. We apply this general theory to inhomogeneous\nsurface plasmon-polariton (SPP) waves at a metal-vacuum interface and show that\nSPPs carry a \"super-momentum\", proportional to the wave vector $k_{p} >\n\\omega/c$, and a transverse spin, which can change its sign depending on the\nfrequency $\\omega$.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On topological cyclic homology",
      "abstract": "  Topological cyclic homology is a refinement of Connes--Tsygan's cyclic\nhomology which was introduced by B\\\"okstedt--Hsiang--Madsen in 1993 as an\napproximation to algebraic $K$-theory. There is a trace map from algebraic\n$K$-theory to topological cyclic homology, and a theorem of\nDundas--Goodwillie--McCarthy asserts that this induces an equivalence of\nrelative theories for nilpotent immersions, which gives a way for computing\n$K$-theory in various situations. The construction of topological cyclic\nhomology is based on genuine equivariant homotopy theory, the use of explicit\npoint-set models, and the elaborate notion of a cyclotomic spectrum.\n  The goal of this paper is to revisit this theory using only\nhomotopy-invariant notions. In particular, we give a new construction of\ntopological cyclic homology. This is based on a new definition of the\n$\\infty$-category of cyclotomic spectra: We define a cyclotomic spectrum to be\na spectrum $X$ with $S^1$-action (in the most naive sense) together with\n$S^1$-equivariant maps $\\varphi_p: X\\to X^{tC_p}$ for all primes $p$. Here\n$X^{tC_p}=\\mathrm{cofib}(\\mathrm{Nm}: X_{hC_p}\\to X^{hC_p})$ is the Tate\nconstruction. On bounded below spectra, we prove that this agrees with previous\ndefinitions. As a consequence, we obtain a new and simple formula for\ntopological cyclic homology.\n  In order to construct the maps $\\varphi_p: X\\to X^{tC_p}$ in the example of\ntopological Hochschild homology we introduce and study Tate diagonals for\nspectra and Frobenius homomorphisms of commutative ring spectra. In particular\nwe prove a version of the Segal conjecture for the Tate diagonals and relate\nthese Frobenius homomorphisms to power operations.\n",
      "subjects": [
        "math.AT",
        "math.KT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Soliton-effect self-compressed single-cycle 9.6-W mid-IR pulses from a\n  21-W OPCPA at 3.25 {\\mu}m and 160 kHz",
      "abstract": "  We report a 21-W mid-IR OPCPA that generates 131-{\\mu}J and 97 fs\n(sub-9-cycle) pulses at 160 kHz repetition rate and at a centre wavelength of\n3.25 {\\mu}m. Pulse-to-pulse stability of the CEP-stable output is excellent\nwith 0.33% rms over 288 million pulses (30 min) and compression close to a\nsingle optical cycle was achieved through soliton self- compression inside a\ngas-filled mid-IR anti-resonant-guiding photonic crystal fibre. Without any\nadditional compression device, stable generation of 14.5 fs\n(1.35-optical-cycle) pulses was achieved at an average power of 9.6 W. The\nresulting peak power of 3.9 GW in combination with the near-single-cycle\nduration and intrinsic CEP stability, make our OPCPA a key-enabling technology\nfor the next generation of extreme photonics, strong-field attosecond research\nand coherent X-ray science.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stx1781",
      "title": "MUSE stares into the shadows: the high-resolution dust attenuation curve\n  of NGC 5626",
      "abstract": "  The newest generation of integral field unit spectrographs brings\nthree-dimensional mapping of nearby galaxies one step closer. While the focus\nup to this point was mostly on stars and ionised gas, it is also possible to\nlook at dust in a new, more complete way. Using MUSE science verification\nobservations of NGC 5626, we map the interstellar matter in this dusty\nlenticular. We use the resolving power of MUSE to measure the optical\nattenuation with a spectral resolution of 6.25 \\AA, at physical scales of 0.1-1\nkpc. The integrated attenuation curve of NGC 5626 shows a smooth, slightly\nsteeper than Milky Way and SMC attenuation curves. Several sharp features are\nsuperimposed: we measure lower attenuation at spectral emission lines and\nhigher attenuation for the sodium line doublet. No correlation was observed\nbetween sodium line strength and reddening by dust on spatially resolved\nscales. Additionally, the continuum attenuation was found to be independent\nfrom the Balmer decrement (tracing ionised gas attenuation). We model and\ninterpret the variations in the attenuation curves of each spatial resolution\nelement of NGC 5626. We find that the amount and distribution of dust along the\nline-of-sight is highly degenerate with any variation in the intrinsic\nextinction law. Our analysis shows that the interstellar matter in NGC 5626\nresides in a regular and well-settled disk. Our results preach caution in the\napplication of simple recipes to de-redden global galaxy spectra and underlines\nthe need for more realistic dust geometries when constructing such correction\nformulas.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Binomial collisions and near collisions",
      "abstract": "  We describe efficient algorithms to search for cases in which binomial\ncoefficients are equal or almost equal, give a conjecturally complete list of\nall cases where two binomial coefficients differ by 1, and give some identities\nfor binomial coefficients that seem to be new.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the free boundary of an annuity purchase",
      "abstract": "  It is known that the decision to purchase an annuity may be associated to an\noptimal stopping problem. However, little is known about optimal strategies, if\nthe mortality force is a generic function of time and if the `subjective' life\nexpectancy of the investor differs from the `objective' one adopted by\ninsurance companies to price annuities. In this paper we address this problem\nconsidering an individual who invests in a fund and has the option to convert\nthe fund's value into an annuity at any time. We formulate the problem as a\nreal option and perform a detailed probabilistic study of the optimal stopping\nboundary. Due to the generic time-dependence of the mortality force, our\noptimal stopping problem requires new solution methods to deal with\nnon-monotonic optimal boundaries.\n",
      "subjects": [
        "q-fin.MF",
        "math.OC",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.96.205139",
      "title": "Renormalization of effective interactions in a negative charge-transfer\n  insulator",
      "abstract": "  We compute from first principles the effective interaction parameters\nappropriate for a low-energy description of the rare-earth nickelate\nLuNiO$_{3}$ involving the partially occupied $e_g$ states only. The calculation\nuses the constrained random-phase approximation and reveals that the effective\non-site Coulomb repulsion is strongly reduced by screening effects involving\nthe oxygen-$p$ and nickel-$t_{2g}$ states. The long-range component of the\neffective low-energy interaction is also found to be sizeable. As a result, the\neffective on-site interaction between parallel-spin electrons is reduced down\nto a small negative value. This validates effective low-energy theories of\nthese materials proposed earlier. Electronic structure methods combined with\ndynamical mean-field theory are used to construct and solve an appropriate\nlow-energy model and explore its phase diagram as a function of the on-site\nrepulsion and Hund's coupling. For the calculated values of these effective\ninteractions we find, in agreement with experiments, that LuNiO$_{3}$ is a\nmetal without disproportionation of the $e_g$ occupancy when considered in its\northorhombic structure, while the monoclinic phase is a disproportionated\ninsulator.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Retrofitting Distributional Embeddings to Knowledge Graphs with\n  Functional Relations",
      "abstract": "  Knowledge graphs are a versatile framework to encode richly structured data\nrelationships, but it can be challenging to combine these graphs with\nunstructured data. Methods for retrofitting pre-trained entity representations\nto the structure of a knowledge graph typically assume that entities are\nembedded in a connected space and that relations imply similarity. However,\nuseful knowledge graphs often contain diverse entities and relations (with\npotentially disjoint underlying corpora) which do not accord with these\nassumptions. To overcome these limitations, we present Functional Retrofitting,\na framework that generalizes current retrofitting methods by explicitly\nmodeling pairwise relations. Our framework can directly incorporate a variety\nof pairwise penalty functions previously developed for knowledge graph\ncompletion. Further, it allows users to encode, learn, and extract information\nabout relation semantics. We present both linear and neural instantiations of\nthe framework. Functional Retrofitting significantly outperforms existing\nretrofitting methods on complex knowledge graphs and loses no accuracy on\nsimpler graphs (in which relations do imply similarity). Finally, we\ndemonstrate the utility of the framework by predicting new drug--disease\ntreatment pairs in a large, complex health knowledge graph.\n",
      "subjects": [
        "stat.ML",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tests of Lepton Flavour Universality with $b \\rightarrow s\\ell \\ell$\n  transitions at LHCb",
      "abstract": "  Semileptonic $b \\rightarrow s\\ell \\ell$ processes constitute a good probe for\nnew physics phenomena: new particles contributing to the loops could affect\nbranching fractions and angular distributions, and have different couplings to\ndifferent lepton families, thus violating lepton flavour universality.\n  Recent results from the LHCb experiment are reviewed.\n",
      "subjects": [
        "hep-ex",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/201731076",
      "title": "SCALA: In-situ calibration for Integral Field Spectrographs",
      "abstract": "  The scientific yield of current and future optical surveys is increasingly\nlimited by systematic uncertainties in the flux calibration. This is the case\nfor Type Ia supernova (SN Ia) cosmology programs, where an improved calibration\ndirectly translates into improved cosmological constraints. Current methodology\nrests on models of stars. Here we aim to obtain flux calibration that is\ntraceable to state-of-the-art detector-based calibration. We present the SNIFS\nCalibration Apparatus (SCALA), a color (relative) flux calibration system\ndeveloped for the SuperNova Integral Field Spectrograph (SNIFS), operating at\nthe University of Hawaii 2.2 m (UH 88) telescope. By comparing the color trend\nof the illumination generated by SCALA during two commissioning runs, and to\nprevious laboratory measurements, we show that we can determine the light\nemitted by SCALA with a long-term repeatability better than 1%. We describe the\ncalibration procedure necessary to control for system aging. We present\nmeasurements of the SNIFS throughput as estimated by SCALA observations. The\nSCALA calibration unit is now fully deployed at the UH\\,88 telescope, and with\nit color-calibration between 4000 {\\AA} and 9000 {\\AA} is stable at the percent\nlevel over a one-year baseline.\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s00220-018-3186-9",
      "title": "On ergodicity of foliations on $\\mathbb{Z}^d$-covers of half-translation\n  surfaces and some applications to periodic systems of Eaton lenses",
      "abstract": "  We consider the geodesic flow defined by periodic Eaton lens patterns in the\nplane and discover ergodic ones among those. The ergodicity result on Eaton\nlenses is derived from a result for quadratic differentials on the plane that\nare pull backs of quadratic differentials on tori. Ergodicity itself is\nconcluded for $\\mathbb{Z}^d$-covers of quadratic differentials on compact\nsurfaces with vanishing Lyapunov exponents.\n",
      "subjects": [
        "math.DS",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1674-1137/42/6/063105",
      "title": "Cloud of strings in f(R) gravity",
      "abstract": "  We derive the solution for a spherically symmetric string cloud configuration\nin a d-dimensional spacetime in the framework of f(R) theories of gravity. We\nalso analyze some thermodynamic properties of the joint black hole - cloud of\nstrings solution. For its Hawking temperature, we found that the dependence of\nthe mass with the horizon is significantly different in both theories. For the\ninteraction of a black hole with thermal radiation, we found that the shapes of\nthe curves are similar, but shifted. Our analysis generalizes some known\nresults in the literature.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.4171/AIHPD/84",
      "title": "Feynman amplitudes on moduli spaces of graphs",
      "abstract": "  This article introduces moduli spaces of coloured graphs on which Feynman\namplitudes can be viewed as 'discrete' volume densities. The basic idea behind\nthis construction is that these moduli spaces decompose into disjoint unions of\nopen cells on which parametric Feynman integrals are defined in a natural way.\nRenormalisation of an amplitude translates then into the task of assigning to\nevery cell a finite volume such that boundary relations between neighboring\ncells are respected. It is shown that this can be organized systematically\nusing a type of Borel-Serre compactification of these moduli spaces. The key\npoint is that in each compactified cell the newly added boundary components\nhave a combinatorial description that resembles the forest structure of\nsubdivergences of the corresponding Feynman diagram.\n",
      "subjects": [
        "math-ph",
        "math.CO",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An inner-loop free solution to inverse problems using deep neural\n  networks",
      "abstract": "  We propose a new method that uses deep learning techniques to accelerate the\npopular alternating direction method of multipliers (ADMM) solution for inverse\nproblems. The ADMM updates consist of a proximity operator, a least squares\nregression that includes a big matrix inversion, and an explicit solution for\nupdating the dual variables. Typically, inner loops are required to solve the\nfirst two sub-minimization problems due to the intractability of the prior and\nthe matrix inversion. To avoid such drawbacks or limitations, we propose an\ninner-loop free update rule with two pre-trained deep convolutional\narchitectures. More specifically, we learn a conditional denoising auto-encoder\nwhich imposes an implicit data-dependent prior/regularization on ground-truth\nin the first sub-minimization problem. This design follows an empirical\nBayesian strategy, leading to so-called amortized inference. For matrix\ninversion in the second sub-problem, we learn a convolutional neural network to\napproximate the matrix inversion, i.e., the inverse mapping is learned by\nfeeding the input through the learned forward network. Note that training this\nneural network does not require ground-truth or measurements, i.e., it is\ndata-independent. Extensive experiments on both synthetic data and real\ndatasets demonstrate the efficiency and accuracy of the proposed method\ncompared with the conventional ADMM solution using inner loops for solving\ninverse problems.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Adatom diffusion in high electric fields",
      "abstract": "  Strong electric fields are known to create biased adatom migration on\nmetallic surfaces. We present a Kinetic Monte Carlo model that can simulate\nadatom migration on a tungsten (W) surface in electric fields. We validate our\nmodel by using it to calculate the drift velocity of the adatom at different\nfields and temperature and comparing the results with experimental data from\nthe literature. We obtain excellent agreement.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A sharp effectiveness result of Demailly's strong openness conjecture",
      "abstract": "  In this article, we establish a sharp effectiveness result of Demailly's\nstrong openness conjecture. We also establish a sharp effectiveness result\nrelated to a conjecture posed by Demailly and Koll\\'ar.\n",
      "subjects": [
        "math.CV",
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.5019228",
      "title": "Demonstration of Laser-produced Neutron Diagnostic by Radiative Capture\n  Gamma-rays",
      "abstract": "  We report a new scenario of time-of-flight (TOF) technique in which fast\nneutrons and delayed gamma-ray signals were both recorded in a millisecond time\nwindow in harsh environments induced by high-intensity lasers. The delayed\ngamma signals, arriving far later than the original fast neutron and often\nbeing ignored previously, were identified to be the results of radiative\ncaptures of thermalized neutrons. The linear correlation between gamma photon\nnumber and the fast neutron yield shows that these delayed gamma events can be\nemployed for neutron diagnosis. This method can reduce the detecting efficiency\ndropping problem caused by prompt high-flux gamma radiation, and provides a new\nway for neutron diagnosing in high-intensity laser-target interaction\nexperiments.\n",
      "subjects": [
        "physics.ins-det",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "De novo construction of polyploid linkage maps using discrete graphical\n  models",
      "abstract": "  Linkage maps are used to identify the location of genes responsible for\ntraits and diseases. New sequencing techniques have created opportunities to\nsubstantially increase the density of genetic markers. Such revolutionary\nadvances in technology have given rise to new challenges, such as creating\nhigh-density linkage maps. Current multiple testing approaches based on\npairwise recombination fractions are underpowered in the high-dimensional\nsetting and do not extend easily to polyploid species. We propose to construct\nlinkage maps using graphical models either via a sparse Gaussian copula or a\nnonparanormal skeptic approach. Linkage groups (LGs), typically chromosomes,\nand the order of markers in each LG are determined by inferring the conditional\nindependence relationships among large numbers of markers in the genome.\nThrough simulations, we illustrate the utility of our map construction method\nand compare its performance with other available methods, both when the data\nare clean and contain no missing observations and when data contain genotyping\nerrors and are incomplete. We apply the proposed method to two genotype\ndatasets: barley and potato from diploid and polypoid populations,\nrespectively. Our comprehensive map construction method makes full use of the\ndosage SNP data to reconstruct linkage map for any bi-parental diploid and\npolyploid species. We have implemented the method in the R package netgwas.\n",
      "subjects": [
        "stat.AP",
        "q-bio.GN",
        "q-bio.MN",
        "q-bio.PE",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Double balanced homodyne detection",
      "abstract": "  In the context of the readout scheme for gravitational-wave detectors, the\n\"double balanced homodyne detection\" proposed in [K.~Nakamura and\nM.-K.~Fujimoto, arXiv:1709.01697.] is discussed in detail. This double balanced\nhomodyne detection enables us to measure the expectation values of the photon\ncreation and annihilation operators. Although it has been said that the\noperator $\\hat{b}_{\\theta}:=\\cos\\theta\\hat{b}_{1}+\\sin\\theta\\hat{b}_{2}$ can be\nmeasured through the homodyne detection in literature, we first show that the\nexpectation value of the operator $\\hat{b}_{\\theta}$ cannot be measured as the\nlinear combination of the upper- and lower-sidebands from the output of the\nbalanced homodyne detection. Here, the operators $\\hat{b}_{1}$ and\n$\\hat{b}_{2}$ are the amplitude and phase quadrature in the two-photon\nformulation, respectively. On the other hand, it is shown that the above double\nbalanced homodyne detection enables us to measure the expectation value of the\noperator $\\hat{b}_{\\theta}$ if we can appropriately prepare the complex\namplitude of the coherent state from the local oscillator. It is also shown\nthat the interferometer set up of the eight-port homodyne detection realizes\nour idea of the double balanced homodyne detection. We also evaluate the\nnoise-spectral density of the gravitational-wave detectors when our double\nbalanced homodyne detection is applied as their readout scheme. Some\nrequirements for the coherent state from the local oscillator to realize the\ndouble balanced homodyne detection are also discussed.\n",
      "subjects": [
        "quant-ph",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "AON: Towards Arbitrarily-Oriented Text Recognition",
      "abstract": "  Recognizing text from natural images is a hot research topic in computer\nvision due to its various applications. Despite the enduring research of\nseveral decades on optical character recognition (OCR), recognizing texts from\nnatural images is still a challenging task. This is because scene texts are\noften in irregular (e.g. curved, arbitrarily-oriented or seriously distorted)\narrangements, which have not yet been well addressed in the literature.\nExisting methods on text recognition mainly work with regular (horizontal and\nfrontal) texts and cannot be trivially generalized to handle irregular texts.\nIn this paper, we develop the arbitrary orientation network (AON) to directly\ncapture the deep features of irregular texts, which are combined into an\nattention-based decoder to generate character sequence. The whole network can\nbe trained end-to-end by using only images and word-level annotations.\nExtensive experiments on various benchmarks, including the CUTE80,\nSVT-Perspective, IIIT5k, SVT and ICDAR datasets, show that the proposed\nAON-based method achieves the-state-of-the-art performance in irregular\ndatasets, and is comparable to major existing methods in regular datasets.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.100.224407",
      "title": "Highly-symmetric random one-dimensional spin models",
      "abstract": "  The interplay of disorder and interactions is a challenging topic of\ncondensed matter physics, where correlations are crucial and exotic phases\ndevelop. In one spatial dimension, a particularly successful method to analyze\nsuch problems is the strong-disorder renormalization group (SDRG). This method,\nwhich is asymptotically exact in the limit of large disorder, has been\nsuccessfully employed in the study of several phases of random magnetic chains.\nHere we develop an SDRG scheme capable to provide in-depth information on a\nlarge class of strongly disordered one-dimensional magnetic chains with a\nglobal invariance under a generic continuous group. Our methodology can be\napplied to any Lie-algebra valued spin Hamiltonian, in any representation. As\nexamples, we focus on the physically relevant cases of SO(N) and Sp(N)\nmagnetism, showing the existence of different randomness-dominated phases.\nThese phases display emergent SU(N) symmetry at low energies and fall in two\ndistinct classes, with meson-like or baryon-like characteristics. Our\nmethodology is here explained in detail and helps to shed light on a general\nmechanism for symmetry emergence in disordered systems.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Ranking of nodes of networks taking into account the power function of\n  its weight of connections",
      "abstract": "  To rank nodes in quasi-hierarchical networks of social nature, it is\nnecessary to carry out a detailed analysis of the network and evaluate the\nresults obtained according to all the given criteria and identify the most\ninfluential nodes. Existing ranking algorithms in the overwhelming majority\nestimate such networks in general, which does not allow to clearly determine\nthe influence of nodes among themselves. In the course of the study, an\nanalysis of the results of known algorithms for ranking the nodes of HITS,\nPageRank and compares the obtained data with the expert evaluation of the\nnetwork. For the effective analysis of quasi-hierarchical networks, the basic\nalgorithm of HITS is modified, which allows to evaluate and rank nodes\naccording to the given criteria (the number of input and output links among\nthemselves), which corresponds to the results of expert evaluation. It is shown\nthat the received method in some cases provides results that correspond to the\nreal social relation, and the indexes of the authorship of the nodes -\npre-assigned social roles.\n",
      "subjects": [
        "cs.SI",
        "cs.NI",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/ACCESS.2019.2894344",
      "title": "Emerging Privacy Issues and Solutions in Cyber-Enabled Sharing Services:\n  From Multiple Perspectives",
      "abstract": "  Fast development of sharing services has become a crucial part of the\ncyber-enabled world construction process, as sharing services reinvent how\npeople exchange and obtain goods or services. However, privacy leakage or\ndisclosure remains a key concern during the sharing service development\nprocess. While significant efforts have been undertaken to address various\nprivacy issues in recent years, there is a surprising lack of review for\nprivacy concerns in the cyber-enabled sharing world. To bridge the gap, in this\nstudy, we survey and evaluate existing and emerging privacy issues relating to\nsharing services from various perspectives. Differing from existing similar\nworks on surveying sharing practices in various fields, our work\ncomprehensively covers six branches of sharing services in the cyber-enabled\nworld and selects solutions mostly from the recent five to six years. We\nconclude the issues and solutions from three perspectives, namely, from users',\nplatforms' and service providers' perspectives. Hot topics and less discussed\ntopics are identified, which provides hints to researchers for their future\nstudies.\n",
      "subjects": [
        "cs.CY",
        "cs.CR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Lattice envelopes",
      "abstract": "  We introduce a class of countable groups by some abstract group-theoretic\nconditions. It includes linear groups with finite amenable radical and finitely\ngenerated residually finite groups with some non-vanishing $\\ell^2$-Betti\nnumbers that are not virtually a product of two infinite groups. Further, it\nincludes acylindrically hyperbolic groups. For any group $\\Gamma$ in this class\nwe determine the general structure of its possible lattice embeddings, i.e. of\nall compactly generated, locally compact groups that contain $\\Gamma$ as a\nlattice. This leads to a precise description of possible non-uniform lattice\nembeddings of groups in this class. Further applications include the\ndetermination of possible lattice embeddings of fundamental groups of closed\nmanifolds with pinched negative curvature.\n",
      "subjects": [
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Equivalence of Equilibrium Propagation and Recurrent Backpropagation",
      "abstract": "  Recurrent Backpropagation and Equilibrium Propagation are supervised learning\nalgorithms for fixed point recurrent neural networks which differ in their\nsecond phase. In the first phase, both algorithms converge to a fixed point\nwhich corresponds to the configuration where the prediction is made. In the\nsecond phase, Equilibrium Propagation relaxes to another nearby fixed point\ncorresponding to smaller prediction error, whereas Recurrent Backpropagation\nuses a side network to compute error derivatives iteratively. In this work we\nestablish a close connection between these two algorithms. We show that, at\nevery moment in the second phase, the temporal derivatives of the neural\nactivities in Equilibrium Propagation are equal to the error derivatives\ncomputed iteratively by Recurrent Backpropagation in the side network. This\nwork shows that it is not required to have a side network for the computation\nof error derivatives, and supports the hypothesis that, in biological neural\nnetworks, temporal derivatives of neural activities may code for error signals.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fixed Points of anti-attracting maps and Eigenforms on Fractals",
      "abstract": "  An important problem in analysis on fractals is the existence of a\nself-similar energy on finitely ramified fractals. The self-similar energies\nare constructed in terms of eigenforms, that is, eigenvectors of a special\nnonlinear operator. Previous results by C. Sabot and V. Metz give conditions\nfor the existence of an eigenform. In this paper, I give a different and\nprobably shorter proof of the previous results, which appears to be suitable\nfor improvements. Such a proof is based on a fixed-point theorem for\nanti-attracting maps on a convex set.\n",
      "subjects": [
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/aad002",
      "title": "The Star Formation Rate in the Gravoturbulent Interstellar Medium",
      "abstract": "  Stars form in supersonic turbulent molecular clouds that are\nself-gravitating. We present an analytic determination of the star formation\nrate (SFR) in a gravoturbulent medium based on the density probability\ndistribution function of molecular clouds having a piecewise lognormal and\npower law form. This is in contrast to previous analytic SFR models that are\ngoverned primarily by interstellar turbulence which sets purely lognormal\ndensity PDFs. In the gravoturbulent SFR model described herein, low density gas\nresides in the lognormal portion of the PDF. Gas becomes gravitationally\nunstable past a critical density ($\\rho_{crit}$), and the PDF begins to forms a\npower law. As the collapse of the cloud proceeds, the transitional density\n($\\rho_t$) between the lognormal and power law portions of the PDF moves\ntowards lower-density while the slope of the power law ($\\alpha$) becomes\nincreasingly shallow. The star formation rate per free-fall time is calculated\nvia an integral over the lognormal from $\\rho_{crit}$ to $\\rho_t$ and an\nintegral over the power law from $\\rho_t$ to the maximum density. As $\\alpha$\nbecomes shallower the SFR accelerates beyond the expected values calculated\nfrom a lognormal density PDF. We show that the star formation efficiency per\nfree fall time in observations of local molecular cloud increases with\nshallower PDF power law slopes, in agreement with our model. Our model can\nexplain why star formation is spatially and temporally variable within a cloud\nand why the depletion times observed in local and extragalactic giant molecular\nclouds vary. Both star-bursting and quiescent star-forming systems can be\nexplained without the need to invoke extreme variations of turbulence in the\nlocal interstellar environment.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.spmi.2018.01.027",
      "title": "Chemically stabilized epitaxial wurtzite-BN thin film",
      "abstract": "  We report on the chemically stabilized epitaxial w-BN thin film grown on\nc-plane sapphire by pulsed laser deposition under slow kinetic condition.\nTraces of no other allotropes such as cubic (c) or hexagonal (h) BN phases are\npresent. Sapphire substrate plays a significant role in stabilizing the\nmetastable w-BN from h-BN target under unusual PLD growth condition involving\nlow temperature and pressure and is explained based on density functional\ntheory calculation. The hardness and the elastic modulus of the w-BN film are\n37 & 339 GPa, respectively measured by indentation along <0001> direction. The\nresults are extremely promising in advancing the microelectronic and mechanical\ntooling industry.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1112/S0010437X19007401",
      "title": "Affine quadrics and the Picard group of the motivic category",
      "abstract": "  In this article we study the subgroup of the Picard group of Voevodsky's\ncategory of geometric motives generated by the reduced motives of affine\nquadrics. Our main tools here are the functors of Bachmann, but we also provide\nan alternative method. We show that the group in question can be described in\nterms of indecomposable direct summands in the motives of projective quadrics.\nIn particular, we describe all the relations among the reduced motives of\naffine quadrics. We also extend the Criterion of motivic equivalence of\nprojective quadrics.\n",
      "subjects": [
        "math.AG",
        "math.AT",
        "math.KT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP07(2018)087",
      "title": "Constraining the Higgs self couplings at $e^+e^-$ colliders",
      "abstract": "  We study the sensitivity to the shape of the Higgs potential of single,\ndouble, and triple Higgs production at future $e^+e^-$ colliders. Physics\nbeyond the Standard Model is parameterised through the inclusion of\nhigher-dimensional operators $(\\Phi^\\dagger \\Phi- v^2/2)^n/\\Lambda^{(2n-4)}$\nwith $n=3,4$, which allows a consistent treatment of independent deviations of\nthe cubic and quartic self couplings beyond the tree level. We calculate the\neffects induced by a modified potential up to one loop in single and double\nHiggs production and at the tree level in triple Higgs production, for both $Z$\nboson associated and $W$ boson fusion production mechanisms. We consider two\ndifferent scenarios. First, the dimension six operator provides the dominant\ncontribution (as expected, for instance, in a linear\neffective-field-theory(EFT)); we find in this case that the corresponding\nWilson coefficient can be determined at $\\mathcal{O}(10\\%)$ accuracy by just\ncombining accurate measurements of single Higgs cross sections at $\\sqrt{\\hat\ns}=$240-250 GeV and double Higgs production in $W$ boson fusion at higher\nenergies. Second, both operators of dimension six and eight can give effects of\nsimilar order, i.e., independent quartic self coupling deviations are present.\nConstraints on Wilson coefficients can be best tested by combining measurements\nfrom single, double and triple Higgs production. Given that the sensitivity of\nsingle Higgs production to the dimension eight operator is presently unknown,\nwe consider double and triple Higgs production and show that combining their\ninformation colliders at higher energies will provide first coarse constraints\non the corresponding Wilson coefficient.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/epjn/2018013",
      "title": "Estimating model bias over the complete nuclide chart with sparse\n  Gaussian processes at the example of INCL/ABLA and double-differential\n  neutron spectra",
      "abstract": "  Predictions of nuclear models guide the design of nuclear facilities to\nensure their safe and efficient operation. Because nuclear models often do not\nperfectly reproduce available experimental data, decisions based on their\npredictions may not be optimal. Awareness about systematic deviations between\nmodels and experimental data helps to alleviate this problem. This paper shows\nhow a sparse approximation to Gaussian processes can be used to estimate the\nmodel bias over the complete nuclide chart at the example of inclusive\ndouble-differential neutron spectra for incident protons above 100\\,MeV. A\npowerful feature of the presented approach is the ability to predict the model\nbias for energies, angles, and isotopes where data are missing. The number of\nexperimental data points that can be taken into account is at least in the\norder of magnitude of~$10^4$ thanks to the sparse approximation. The approach\nis applied to the Li\\`ege Intranuclear Cascade Model (INCL) coupled to the\nevaporation code ABLA. The results suggest that sparse Gaussian process\nregression is a viable candidate to perform global and quantitative assessments\nof models. Limitations of a philosophical nature of this (and any other)\napproach are also discussed.\n",
      "subjects": [
        "nucl-th",
        "physics.data-an"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jcp.2018.06.063",
      "title": "A Phase-Field Model for Fluid-Structure-Interaction",
      "abstract": "  In this paper, we develop a novel phase-field model for fluid-structure\ninteraction (FSI), that is capable to handle very large deformations as well as\ntopology changes like contact of the solid to the domain boundary. The model is\nbased on a fully Eulerian description of the velocity field in both, the fluid\nand the elastic domain. Viscous and elastic stresses in the Navier-Stokes\nequations are restricted to the corresponding domains by multiplication with\ntheir characteristic functions. To obtain the elastic stress, an additional\nOldroyd-B - like equation is solved. Thermodynamically consistent forces are\nderived by energy variation. The convergence of the derived equations to the\ntraditional sharp interface formulation of fluid-structure interaction is shown\nby matched asymptotic analysis. The model is evaluated in a challenging\nbenchmark scenario of an elastic body traversing a fluid channel. A comparison\nto reference values from Arbitrary Lagrangian Eulerian (ALE) simulations shows\nvery good agreement. We highlight some distinct advantages of the new model,\nlike the avoidance of re-triangulations and the stable inclusion of surface\ntension. Further, we demonstrate how simple it is to include contact dynamics\ninto the model, by simulating a ball bouncing off a wall. We extend this\nscenario to include adhesion of the ball, which to our knowledge, cannot be\nsimulated with any other FSI model. While we have restricted simulations to\nfluid-structure interaction, the model is capable to simulate any combination\nof viscous fluids, visco-elastic fluids and elastic solids.\n",
      "subjects": [
        "physics.comp-ph",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1371/journal.pone.0198883",
      "title": "Classification of crystallization outcomes using deep convolutional\n  neural networks",
      "abstract": "  The Machine Recognition of Crystallization Outcomes (MARCO) initiative has\nassembled roughly half a million annotated images of macromolecular\ncrystallization experiments from various sources and setups. Here,\nstate-of-the-art machine learning algorithms are trained and tested on\ndifferent parts of this data set. We find that more than 94% of the test images\ncan be correctly labeled, irrespective of their experimental origin. Because\ncrystal recognition is key to high-density screening and the systematic\nanalysis of crystallization experiments, this approach opens the door to both\nindustrial and fundamental research applications.\n",
      "subjects": [
        "q-bio.BM",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Automatically augmenting an emotion dataset improves classification\n  using audio",
      "abstract": "  In this work, we tackle a problem of speech emotion classification. One of\nthe issues in the area of affective computation is that the amount of annotated\ndata is very limited. On the other hand, the number of ways that the same\nemotion can be expressed verbally is enormous due to variability between\nspeakers. This is one of the factors that limits performance and\ngeneralization. We propose a simple method that extracts audio samples from\nmovies using textual sentiment analysis. As a result, it is possible to\nautomatically construct a larger dataset of audio samples with positive,\nnegative emotional and neutral speech. We show that pretraining recurrent\nneural network on such a dataset yields better results on the challenging\nEmotiW corpus. This experiment shows a potential benefit of combining textual\nsentiment analysis with vocal information.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tight-binding model and ab initio calculation of silicene with strong\n  spin-orbit coupling in low-energy limit",
      "abstract": "  We carry out both the tight-binding model and the $ab\\ initio$ to study the\nlayered silicene, the spin, valley, sublattice degrees of freedom are taken\ninto consider and the effects of electric field, magnetic field, and even the\nlight in finite frequency together with its interesting optical propertice,\nwhich are all closely related to the spin-orbit coupling and Rashba coupling\nand lead to the tunable phase transitions (between the nontrivial topological\nphase which has nonzero Chern number or nonzero spin Chern number and the\ntrivial phase). An exotic quantum anomalous Hall insulator phase are found\nwhich has nonzero spin Chern number and nonzero valley Chern number and as a\ngiant-application-potential spintronic and valleytronics in the two-ternimate\ndevices based on the monolayer silicene for the information transmission. In\nfact, the gap-out action can be understanded by analyse the Dirac mass as well\nas the Zeeman splitting or the external-field-induced symmetry-broken, and the\nchanges of gap has a general nonmonotone-variation characteristic under both\nthe effects of electron filed-induced Rashba-coupling $R_{2}(E_{\\perp})$ and\nthe electron field-induced band gap, and the band inversion related to the\nspin-orbit coupling which absorbs both the spin and orbital angular of momentum\nmay happen during this process. The quantized Hall/longitudinal conductivity\ntogether with the optical conductivity are also explored, we see that even in\nthe quantum spin Hall phase without any magnetic field, the two-terminate\nconductivity can be reduced to the value $e^{2}/h$ by controlling the helical\nedge model, and it can be further reduced to $e^{2}/2h$ by applying the\nmagnetic field which similar to the graphene.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "From the master equation to mean field game limit theory: A central\n  limit theorem",
      "abstract": "  Mean field games (MFGs) describe the limit, as $n$ tends to infinity, of\nstochastic differential games with $n$ players interacting with one another\nthrough their common empirical distribution. Under suitable smoothness\nassumptions that guarantee uniqueness of the MFG equilibrium, a form of law of\nlarge of numbers (LLN), also known as propagation of chaos, has been\nestablished to show that the MFG equilibrium arises as the limit of the\nsequence of empirical measures of the $n$-player game Nash equilibria,\nincluding the case when player dynamics are driven by both idiosyncratic and\ncommon sources of noise. The proof of convergence relies on the so-called\nmaster equation for the value function of the MFG, a partial differential\nequation on the space of probability measures. In this work, under additional\nassumptions, we establish a functional central limit theorem (CLT) that\ncharacterizes the limiting fluctuations around the LLN limit as the unique\nsolution of a linear stochastic PDE. The key idea is to use the solution to the\nmaster equation to construct an associated McKean-Vlasov interacting\n$n$-particle system that is sufficiently close to the Nash equilibrium dynamics\nof the $n$-player game for large $n$. We then derive the CLT for the latter\nfrom the CLT for the former. Along the way, we obtain a new multidimensional\nCLT for McKean-Vlasov systems. We also illustrate the broader applicability of\nour methodology by applying it to establish a CLT for a specific\nlinear-quadratic example that does not satisfy our main assumptions, and we\nexplicitly solve the resulting stochastic PDE in this case.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Unified approaches based effective capacity analysis over composite\n  $\\alpha-\\eta-\\mu$/gamma fading channels",
      "abstract": "  This letter analyses the effective capacity of communications system using\nunified models. In order to obtain a simple closed-form mathematically\ntractable expression, two different unified approximate models have been used.\nThe mixture gamma (MG) distribution which is highly accurate approximation\napproach has been firstly employed to represent the signal-to-noise-ratio (SNR)\nof fading channel. In the second approach, the mixture of Gaussian (MoG)\ndistribution which is another unified representation approach has been\nutilised. A comparison between the simulated and numerical results using both\ndistributions over composite $\\alpha-\\eta-\\mu$/gamma fading channels has been\nprovided.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Irrational-slope Thompson's Group",
      "abstract": "  The purpose of this paper is to study the properties of the irrational-slope\nThompson's group $F_\\tau$ introduced by Cleary in 1995. We construct\npresentations, both finite and infinite and we describe its combinatorial\nstructure using binary trees. We show that its commutator group is simple.\nFinally, inspired by the case of Thompson's group F, we define a unique normal\nform for the elements of the group and study the metric properties for the\nelements based on this normal form. As a corollary, we see that several\nembeddings of $F$ in $F_\\tau$ are undistorted.\n",
      "subjects": [
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Robust TMA using the possibility particle filter",
      "abstract": "  The problem is target motion analysis (TMA), where the objective is to\nestimate the state of a moving target from noise corrupted bearings-only\nmeasurements. The focus is on recursive TMA, traditionally solved using the\nBayesian filters (e.g. the extended or unscented Kalman filters, particle\nfilters). The TMA is a difficult problem and may cause the algorithms to\ndiverge, especially when the measurement noise model is imperfect or\nmismatched. As a robust alternative to the Bayesian filters for TMA, we propose\nthe recently introduced possibility filter. This filter is implemented in the\nsequential Monte Carlo framework, and referred to as the possibility particle\nfilter. The paper demonstrates its superior performance against the standard\nparticle filter in the presence of a model mismatch, and equal performance in\nthe case of the exact model match.\n",
      "subjects": [
        "cs.CE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Mining large-scale human mobility data for long-term crime prediction",
      "abstract": "  Traditional crime prediction models based on census data are limited, as they\nfail to capture the complexity and dynamics of human activity. With the rise of\nubiquitous computing, there is the opportunity to improve such models with data\nthat make for better proxies of human presence in cities. In this paper, we\nleverage large human mobility data to craft an extensive set of features for\ncrime prediction, as informed by theories in criminology and urban studies. We\nemploy averaging and boosting ensemble techniques from machine learning, to\ninvestigate their power in predicting yearly counts for different types of\ncrimes occurring in New York City at census tract level. Our study shows that\nspatial and spatio-temporal features derived from Foursquare venues and\ncheckins, subway rides, and taxi rides, improve the baseline models relying on\ncensus and POI data. The proposed models achieve absolute R^2 metrics of up to\n65% (on a geographical out-of-sample test set) and up to 89% (on a temporal\nout-of-sample test set). This proves that, next to the residential population\nof an area, the ambient population there is strongly predictive of the area's\ncrime levels. We deep-dive into the main crime categories, and find that the\npredictive gain of the human dynamics features varies across crime types: such\nfeatures bring the biggest boost in case of grand larcenies, whereas assaults\nare already well predicted by the census features. Furthermore, we identify and\ndiscuss top predictive features for the main crime categories. These results\noffer valuable insights for those responsible for urban policy or law\nenforcement.\n",
      "subjects": [
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s41114-018-0017-4",
      "title": "Testing General Relativity in Cosmology",
      "abstract": "  We review recent developments and results in testing general relativity (GR)\nat cosmological scales. The subject has witnessed rapid growth during the last\ntwo decades with the aim of addressing the question of cosmic acceleration and\nthe dark energy associated with it. However, with the advent of precision\ncosmology, it has also become a well-motivated endeavor by itself to test\ngravitational physics at cosmic scales. We overview cosmological probes of\ngravity, formalisms and parameterizations for testing deviations from GR at\ncosmological scales, selected modified gravity (MG) theories, gravitational\nscreening mechanisms, and computer codes developed for these tests. We then\nprovide summaries of recent cosmological constraints on MG parameters and\nselected MG models. We supplement these cosmological constraints with a summary\nof implications from the recent binary neutron star merger event. Next, we\nsummarize some results on MG parameter forecasts with and without astrophysical\nsystematics that will dominate the uncertainties. The review aims at providing\nan overall picture of the subject and an entry point to students and\nresearchers interested in joining the field. It can also serve as a quick\nreference to recent results and constraints on testing gravity at cosmological\nscales.\n",
      "subjects": [
        "astro-ph.CO",
        "astro-ph.GA",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Deep Cross-modality Adaptation via Semantics Preserving Adversarial\n  Learning for Sketch-based 3D Shape Retrieval",
      "abstract": "  Due to the large cross-modality discrepancy between 2D sketches and 3D\nshapes, retrieving 3D shapes by sketches is a significantly challenging task.\nTo address this problem, we propose a novel framework to learn a discriminative\ndeep cross-modality adaptation model in this paper. Specifically, we first\nseparately adopt two metric networks, following two deep convolutional neural\nnetworks (CNNs), to learn modality-specific discriminative features based on an\nimportance-aware metric learning method. Subsequently, we explicitly introduce\na cross-modality transformation network to compensate for the divergence\nbetween two modalities, which can transfer features of 2D sketches to the\nfeature space of 3D shapes. We develop an adversarial learning based method to\ntrain the transformation model, by simultaneously enhancing the holistic\ncorrelations between data distributions of two modalities, and mitigating the\nlocal semantic divergences through minimizing a cross-modality mean discrepancy\nterm. Experimental results on the SHREC 2013 and SHREC 2014 datasets clearly\nshow the superior retrieval performance of our proposed model, compared to the\nstate-of-the-art approaches.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epjds/s13688-018-0158-4",
      "title": "Spatio-temporal variations in the urban rhythm: the travelling waves of\n  crime",
      "abstract": "  In the last decades, the notion that cities are in a state of equilibrium\nwith a centralised organisation has given place to the viewpoint of cities in\ndisequilibrium and organised from bottom to up. In this perspective, cities are\nevolving systems that exhibit emergent phenomena built from local decisions.\nWhile urban evolution promotes the emergence of positive social phenomena such\nas the formation of innovation hubs and the increase in cultural diversity, it\nalso yields negative phenomena such as increases in criminal activity. Yet, we\nare still far from understanding the driving mechanisms of these phenomena. In\nparticular, approaches to analyse urban phenomena are limited in scope by\nneglecting both temporal non-stationarity and spatial heterogeneity. In the\ncase of criminal activity, we know for more than one century that crime peaks\nduring specific times of the year, but the literature still fails to\ncharacterise the mobility of crime. Here we develop an approach to describe the\nspatial, temporal, and periodic variations in urban quantities. With crime data\nfrom 12 cities, we characterise how the periodicity of crime varies spatially\nacross the city over time. We confirm one-year criminal cycles and show that\nthis periodicity occurs unevenly across the city. These `waves of crime' keep\ntravelling across the city: while cities have a stable number of regions with a\ncircannual period, the regions exhibit non-stationary series. Our findings\nsupport the concept of cities in a constant change, influencing urban\nphenomena---in agreement with the notion of cities not in equilibrium.\n",
      "subjects": [
        "cs.CY",
        "cs.SI",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10957-020-01649-2",
      "title": "Representation of Hamilton-Jacobi equation in optimal control theory\n  with unbounded control set",
      "abstract": "  In this paper we study the existence of sufficiently regular representations\nof Hamilton-Jacobi equations in the optimal control theory with unbounded\ncontrol set. We use a new method to construct representations for a wide class\nof Hamiltonians. This class is wider than any constructed before, because we do\nnot require Legendre-Fenchel conjugates of Hamiltonians to be bounded. However,\nin this case we obtain representations with unbounded control set. We apply the\nobtained results to study regularities of value functions and correlations\nbetween variational and optimal control problems.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.99.115318",
      "title": "Giant spin Meissner effect in a non-equilibrium exciton-polariton gas",
      "abstract": "  The suppression of Zeeman energy splitting due to spin-dependent interactions\nwithin a Bose-Einstein condensate (the spin Meissner effect) was predicted to\noccur up to a certain value of magnetic field strength. We report a clear\nobservation of this effect in semimagnetic microcavities which exhibit the\ngiant Zeeman energy splitting between two spin-polarised polariton states as\nhigh as 2 meV, and demonstrate that partial suppression of energy difference\noccurs already in the uncondensed phase in a striking similarity to the\nup-critical superconductors in the fluctuation dominated regime. These\nobservations are explained quantitatively by a kinetic model accounting for\nboth the condensed and uncondensed polaritons and taking into account the\nnon-equilibrium character of the system.\n",
      "subjects": [
        "cond-mat.quant-gas"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217732318502425",
      "title": "Highest Energy Proton-Nucleus Cross Sections",
      "abstract": "  The description of very high energy proton-proton cross sections in terms of\na `black disc' with an `edge' allows of a simple generalization to highest\nenergy proton-nucleus cross sections. This results in a leading $ln^2W$ term\nand a $ln\\, W$ term whose coefficient depends linearly on the radius of the\nnucleus ($W$ the c.m. energy). The necessary parameters are determined from the\nfits to p-p data. Since the coefficient of the $ln W$ term is rather large, it\nis doubtful that the regime of $ln^2W$ dominance can be reached with available\nenergies in accelerators or cosmic rays. However, the $ln W$ term can be\nrelevant for highest energy cosmic rays in the atmosphere, where a large\nincrease for the cross section on nitrogen is expected. Tests of the theory\nshould be possible by studying the coefficient of $ln W$ at p-nucleus\ncolliders.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.HE",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/978-3-030-01267-0_37",
      "title": "3DFeat-Net: Weakly Supervised Local 3D Features for Point Cloud\n  Registration",
      "abstract": "  In this paper, we propose the 3DFeat-Net which learns both 3D feature\ndetector and descriptor for point cloud matching using weak supervision. Unlike\nmany existing works, we do not require manual annotation of matching point\nclusters. Instead, we leverage on alignment and attention mechanisms to learn\nfeature correspondences from GPS/INS tagged 3D point clouds without explicitly\nspecifying them. We create training and benchmark outdoor Lidar datasets, and\nexperiments show that 3DFeat-Net obtains state-of-the-art performance on these\ngravity-aligned datasets.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Ricean K-factor Estimation based on Channel Quality Indicator in OFDM\n  Systems using Neural Network",
      "abstract": "  Ricean channel model is widely used in wireless communications to\ncharacterize the channels with a line-of-sight path. The Ricean K factor,\ndefined as the ratio of direct path and scattered paths, provides a good\nindication of the link quality. Most existing works estimate K factor based on\neither maximum-likelihood criterion or higher-order moments, and the existing\nworks are targeted at K-factor estimation at receiver side. In this work, a\nnovel approach is proposed. Cast as a classification problem, the estimation of\nK factor by neural network provides high accuracy. Moreover, the proposed\nK-factor estimation is done at transmitter side for transmit processing, thus\nsaving the limited feedback bandwidth.\n",
      "subjects": [
        "eess.SP",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fungi: Typed incremental computation with names",
      "abstract": "  Incremental computations attempt to exploit input similarities over time,\nreusing work that is unaffected by input changes. To maximize this reuse in a\ngeneral-purpose programming setting, programmers need a mechanism to identify\ndynamic allocations (of data and subcomputations) that correspond over time. We\npresent Fungi, a typed functional language for incremental computation with\nnames. Unlike prior general-purpose languages for incremental computing,\nFungi's notion of names is formal, general, and statically verifiable. Fungi's\ntype-and-effect system permits the programmer to encode (program-specific)\nlocal invariants about names, and to use these invariants to establish global\nuniqueness for their composed programs, the property of using names correctly.\nWe prove that well-typed Fungi programs respect global uniqueness. We derive a\nbidirectional version of the type and effect system, and we have implemented a\nprototype of Fungi in Rust. We apply Fungi to a library of incremental\ncollections, showing that it is expressive in practice.\n",
      "subjects": [
        "cs.PL",
        "cs.FL",
        "cs.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Training for Faster Adversarial Robustness Verification via Inducing\n  ReLU Stability",
      "abstract": "  We explore the concept of co-design in the context of neural network\nverification. Specifically, we aim to train deep neural networks that not only\nare robust to adversarial perturbations but also whose robustness can be\nverified more easily. To this end, we identify two properties of network models\n- weight sparsity and so-called ReLU stability - that turn out to significantly\nimpact the complexity of the corresponding verification task. We demonstrate\nthat improving weight sparsity alone already enables us to turn computationally\nintractable verification problems into tractable ones. Then, improving ReLU\nstability leads to an additional 4-13x speedup in verification times. An\nimportant feature of our methodology is its \"universality,\" in the sense that\nit can be used with a broad range of training procedures and verification\napproaches.\n",
      "subjects": [
        "cs.LG",
        "cs.CR",
        "cs.NE",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "VPE: Variational Policy Embedding for Transfer Reinforcement Learning",
      "abstract": "  Reinforcement Learning methods are capable of solving complex problems, but\nresulting policies might perform poorly in environments that are even slightly\ndifferent. In robotics especially, training and deployment conditions often\nvary and data collection is expensive, making retraining undesirable.\nSimulation training allows for feasible training times, but on the other hand\nsuffers from a reality-gap when applied in real-world settings. This raises the\nneed of efficient adaptation of policies acting in new environments. We\nconsider this as a problem of transferring knowledge within a family of similar\nMarkov decision processes.\n  For this purpose we assume that Q-functions are generated by some\nlow-dimensional latent variable. Given such a Q-function, we can find a master\npolicy that can adapt given different values of this latent variable. Our\nmethod learns both the generative mapping and an approximate posterior of the\nlatent variables, enabling identification of policies for new tasks by\nsearching only in the latent space, rather than the space of all policies. The\nlow-dimensional space, and master policy found by our method enables policies\nto quickly adapt to new environments. We demonstrate the method on both a\npendulum swing-up task in simulation, and for simulation-to-real transfer on a\npushing task.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.98.032413",
      "title": "A phenomenological cluster-based model of Ca2+ waves and oscillations\n  for Inositol 1,4,5-trisphosphate receptor (IP3R) channels",
      "abstract": "  Clusters of IP3 receptor channels in the membranes of the endoplasmic\nreticulum (ER) of many non-excitable cells release calcium ions in a\ncooperative manner giving rise to dynamical patterns such as Ca2+ puffs, waves,\nand oscillations that occur on multiple spatial and temporal scales. We\nintroduce a minimal yet descriptive reaction-diffusion model of IP3 receptors\nfor a saturating concentration of IP3 using a principled reduction of a\ndetailed Markov chain description of individual channels. A dynamical systems\nanalysis reveals the possibility of excitable, bistable and oscillatory\ndynamics of this model that correspond to three types of observed patterns of\ncalcium release -- puffs, waves, and oscillations respectively. We explain the\nemergence of these patterns via a bifurcation analysis of a coupled two-cluster\nmodel, compute the phase diagram and quantify the speed of the waves and period\nof oscillations in terms of system parameters. We connect the termination of\nlarge-scale Ca2+ release events to IP3 unbinding or stochasticity.\n",
      "subjects": [
        "q-bio.SC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s42452-020-03582-5",
      "title": "Determining Optimal Number of k-Clusters based on Predefined\n  Level-of-Similarity",
      "abstract": "  This paper proposes a centroid-based clustering algorithm which is capable of\nclustering data-points with n-features, without having to specify the number of\nclusters to be formed. The core logic behind the algorithm is a similarity\nmeasure, which collectively decides whether to assign an incoming data-point to\na pre-existing cluster, or create a new cluster and assign the data-point to\nit. The proposed clustering algorithm is application-specific and is applicable\nwhen the need is to perform clustering analysis of a stream of data-points,\nwhere the similarity measure between an incoming data-point and the cluster to\nwhich the data-point is to be associated with, is greater than the predefined\nLevel-of-Similarity.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Relaxation-based Network Decomposition Algorithm for Parallel\n  Transient Stability Simulation with Improved Convergence",
      "abstract": "  Transient stability simulation of a large-scale and interconnected electric\npower system involves solving a large set of differential algebraic equations\n(DAEs) at every simulation time-step. With the ever-growing size and complexity\nof power grids, dynamic simulation becomes more time-consuming and\ncomputationally difficult using conventional sequential simulation techniques.\nTo cope with this challenge, this paper aims to develop a fully distributed\napproach intended for implementation on High Performance Computer (HPC)\nclusters. A novel, relaxation-based domain decomposition algorithm known as\nParallel-General-Norton with Multiple-port Equivalent (PGNME) is proposed as\nthe core technique of a two-stage decomposition approach to divide the overall\ndynamic simulation problem into a set of subproblems that can be solved\nconcurrently to exploit parallelism and scalability. While the convergence\nproperty has traditionally been a concern for relaxation-based decomposition,\nan estimation mechanism based on multiple-port network equivalent is adopted as\nthe preconditioner to enhance the convergence of the proposed algorithm. The\nproposed algorithm is illustrated using rigorous mathematics and validated both\nin terms of speed-up and capability. Moreover, a complexity analysis is\nperformed to support the observation that PGNME scales well when the size of\nthe subproblems are sufficiently large.\n",
      "subjects": [
        "cs.DC",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1073/pnas.2022912118",
      "title": "Aggression heuristics underlie animal dominance hierarchies and provide\n  evidence of group-level social information",
      "abstract": "  Members of a social species need to make appropriate decisions about who,\nhow, and when to interact with others in their group. However, it has been\ndifficult for researchers to detect the inputs to these decisions and, in\nparticular, how much information individuals actually have about their social\ncontext. We present a new method that can serve as a social assay to quantify\nhow patterns of aggression depend upon information about the ranks of\nindividuals within social dominance hierarchies. Applied to existing data on\naggression in 172 social groups across 85 species in 23 orders, it reveals\nthree main patterns of rank-dependent social dominance: the downward heuristic\n(aggress uniformly against lower-ranked opponents), close competitors (aggress\nagainst opponents ranked slightly below self), and bullying (aggress against\nopponents ranked much lower than self). The majority of the groups (133 groups,\n77%) follow a downward heuristic, but a significant minority (38 groups, 22%)\nshow more complex social dominance patterns (close competitors or bullying)\nconsistent with higher levels of social information use. These patterns are not\nphylogenetically constrained and different groups within the same species can\nuse different patterns, suggesting that heuristics use may depend on context\nand the structuring of aggression by social information should not be\nconsidered a fixed characteristic of a species. Our approach provides new\nopportunities to study the use of social information within and across species\nand the evolution of social complexity and cognition.\n",
      "subjects": [
        "q-bio.PE",
        "nlin.AO",
        "physics.soc-ph",
        "q-bio.NC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nucleon axial charge in domain-wall QCD with physical mass",
      "abstract": "  Nucleon isovector vector, $g_V$, and axialvector, $g_A$, charges calculated\non a 2+1-flavor dynamical domain-wall-fermions (DWF) ensemble at physical mass\njointly generated by RIKEN-BNL-Columbia (RBC) and UKQCD Collaborations with\nlattice cut off of 1.730(4) GeV, are reported with about a percent statistical\nerrors, along with isovector ``scalar,'' $g_S$, and ``tensor charges,'' $g_T$,\nwith larger statistical errors. Nucleon mass is estimated as 947(6) MeV. A few\nstandard-deviation systematics is seen in the vector charge, likely from\n$O(a^2)$ discretization error through small excited-state contamination. The\naxialvector charge is found with a few to several standard-deviation systematic\ndeficit, depending on calculation methods, in comparison with the experiment.\nNucleon signal is likely lost as early as 10 lattice units or about 1.1 fm in\ntime from the source.\n",
      "subjects": [
        "hep-lat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1021/acs.nanolett.8b03266",
      "title": "Moir\\'e Intralayer Excitons in a MoSe$_2$/MoS$_2$ Heterostructure",
      "abstract": "  Spatially periodic structures with a long range period, referred to as\nmoir\\'e pattern, can be obtained in van der Waals bilayers in the presence of a\nsmall stacking angle or of lattice mismatch between the monolayers. Theoretical\npredictions suggest that the resulting spatially periodic variation of the band\nstructure modifies the optical properties of both intra and interlayer excitons\nof transition metal dichalcogenides heterostructures. Here, we report on the\nimpact of the moir\\'e pattern formed in a MoSe$_2$/MoS$_2$ heterobilayer\nencapsulated in hexagonal boron nitride. The periodic in-plane potential\nresults in a splitting of the MoSe$_2$ exciton and trion in both emission and\nabsorption spectra. The observed energy difference between the split peaks is\nfully consistent with theoretical predictions.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A proof of the Krylov-Safonov theorem without localization",
      "abstract": "  The Krylov-Safonov theorem says that solutions to non-divergence uniformly\nelliptic equations with rough coefficients are H\\\"{o}lder continuous. The proof\ncombines a basic measure estimate with delicate localization and covering\narguments. Here we give a \"global\" proof based on convex analysis that avoids\nthe localization and covering arguments. As an application of the technique we\nprove a $W^{2,\\,\\epsilon}$ estimate where $\\epsilon$ decays with the\nellipticity ratio of the coefficients at a rate that improves previous results,\nand is optimal in two dimensions.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Study on the numerical value and the distance of symptoms on the Medical\n  Decision Support System",
      "abstract": "  It is an important subject how deal with the symptom's data, input data, to\nimprove the accuracy and efficiency of the diagnostic algorithm in the medical\ndecision support systems. In this paper, we described a method for the\nnumerical value of symptoms to develop the medical decision support system that\ndiagnose a large number of diseases, not one or two diseases. The numerical\nvalue of symptoms is realized by dividing the symptom into several parts in\nconsideration of the following contents and setting up the specific value in\neach part. That is, the symptom is appeared in where, when the symptom is\nappeared, what about the symptom, How long the symptom is, etc. Then we decided\nthe distance(similarity) between symptoms on the basis of the numerical value\nof symptoms. Determination of the distance between symptoms by numerical value\nenables estimating the symptoms of which disease is nearer from the symptoms of\npatient and obtaining the suitable diagnostic result. So, we established useful\nmethod of high accuracy to diagnose various diseases revealed by different\nsymptoms.\n",
      "subjects": [
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Corresponding Projections for Orphan Screening",
      "abstract": "  We propose a novel transfer learning approach for orphan screening called\ncorresponding projections. In orphan screening the learning task is to predict\nthe binding affinities of compounds to an orphan protein, i.e., one for which\nno training data is available. The identification of compounds with high\naffinity is a central concern in medicine since it can be used for drug\ndiscovery and design. Given a set of prediction models for proteins with\nlabelled training data and a similarity between the proteins, corresponding\nprojections constructs a model for the orphan protein from them such that the\nsimilarity between models resembles the one between proteins. Under the\nassumption that the similarity resemblance holds, we derive an efficient\nalgorithm for kernel methods. We empirically show that the approach outperforms\nthe state-of-the-art in orphan screening.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Relative \\v{C}ech-Dolbeault homology and applications",
      "abstract": "  We define the relative Dolbeault homology of a complex manifold with currents\nvia a \\v{C}ech approach and we prove its equivalence with the relative\n\\v{C}ech-Dolbeault cohomology as defined in [T. Suwa, \\v{C}ech-Dolbeault\ncohomology and the $\\overline\\partial$-Thom class, {\\em\nSingularities---Niigata---Toyama 2007}, 321--340, Adv. Stud. Pure Math.,\n\\textbf{56}, Math. Soc. Japan, Tokyo, 2009. ]. This definition is then used to\ncompare the relative Dolbeault cohomology groups of two complex manifolds of\nthe same dimension related by a suitable proper surjective holomorphic map.\nFinally, an application to blow-ups is considered.\n",
      "subjects": [
        "math.DG",
        "math.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/aaf4fd",
      "title": "The Next Generation Virgo Cluster Survey. XXIII. Fundamentals of nuclear\n  star clusters over seven decades in galaxy mass",
      "abstract": "  Using deep, high resolution optical imaging from the Next Generation Virgo\nCluster Survey we study the properties of nuclear star clusters (NSCs) in a\nsample of nearly 400 quiescent galaxies in the core of Virgo with stellar\nmasses $10^{5}\\lesssim M_{*}/M_{\\odot} \\lesssim10^{12}$. The nucleation\nfraction reaches a peak value $f_{n}\\approx90\\%$ for $M_{*} \\approx 10^{9}\nM_{\\odot}$ galaxies and declines for both higher and lower masses, but nuclei\npopulate galaxies as small as $M_{*} \\approx5\\times10^{5} M_{\\odot}$.\nComparison with literature data for nearby groups and clusters shows that at\nthe low-mass end nucleation is more frequent in denser environments. The NSC\nmass function peaks at $M_{NSC}\\approx7\\times10^{5} M_{\\odot}$, a factor 3-4\ntimes larger than the turnover mass for globular clusters (GCs). We find a\nnonlinear relation between the stellar masses of NSCs and of their host\ngalaxies, with a mean nucleus-to-galaxy mass ratio that drops to\n$M_{NSC}/M_{*}\\approx3.6\\times10^{-3}$ for $M_{*} \\approx 5\\times10^{9}\nM_{\\odot}$ galaxies. Nuclei in both more and less massive galaxies are much\nmore prominent: $M_{NSC}\\propto M_{*}^{0.46}$ at the low-mass end, where nuclei\nare nearly 50% as massive as their hosts. We measure an intrinsic scatter in\nNSC masses at fixed galaxy stellar mass of 0.4 dex, which we interpret as\nevidence that the process of NSC growth is significantly stochastic. At low\ngalaxy masses we find a close connection between NSCs and GC systems, including\na very similar occupation distribution and comparable total masses. We discuss\nthese results in the context of current dissipative and dissipationless models\nof NSC formation.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3317325",
      "title": "Animation Techniques in Human-Robot Interaction User Studies: a\n  Systematic Literature Review",
      "abstract": "  There are many different ways a robot can move in Human-Robot Interaction.\nOne way is to use techniques from film animation to instruct the robot to move.\nThis article is a systematic literature review of human-robot trials, pilots,\nand evaluations that have applied techniques from animation to move a robot.\nThrough 27 articles, we find that animation techniques improves individual's\ninteraction with robots, improving individual's perception of qualities of a\nrobot, understanding what a robot intends to do, and showing the robot's state,\nor possible emotion. Animation techniques also help people relate to robots\nthat do not resemble a human or robot. The studies in the articles show further\nareas for research, such as applying animation principles in other types of\nrobots and situations, combining animation techniques with other modalities,\nand testing robots moving with animation techniques over the long term.\n",
      "subjects": [
        "cs.RO",
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Jacobians of $W^{1,p}$ homeomorphisms, case $p=[n/2]$",
      "abstract": "  We investigate a known problem whether a Sobolev homeomorphism between\ndomains in $\\mathbb{R}^n$ can change sign of the Jacobian. The only case that\nremains open is when $f\\in W^{1,[n/2]}$, $n\\geq 4$. We prove that if $n\\geq 4$,\nand a sense-preserving homeomorphism $f$ satisfies $f\\in W^{1,[n/2]}$,\n$f^{-1}\\in W^{1,n-[n/2]-1}$ and either $f$ is H\\\"older continuous on almost all\nspheres of dimension $[n/2]$, or $f^{-1}$ is H\\\"older continuous on almost all\nspheres of dimensions $n-[n/2]-1$, then the Jacobian of $f$ is non-negative,\n$J_f\\geq 0$, almost everywhere. This result is a consequence of a more general\nresult proved in the paper. Here $[x]$ stands for the greatest integer less\nthan or equal to $x$.\n",
      "subjects": [
        "math.CA",
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.nima.2020.164303",
      "title": "Modeling Magnetic Fields with Helical Solutions to Laplace's Equation",
      "abstract": "  The series solution to Laplace's equation in a helical coordinate system is\nderived and refined using symmetry and chirality arguments. These functions and\ntheir more commonplace counterparts are used to model solenoidal magnetic\nfields via linear, multidimensional curve-fitting. A judicious choice of\nfunctional forms, a small number of free parameters and sparse input data can\nlead to highly accurate, fine-grained modeling of solenoidal magnetic fields,\nincluding helical features arising from the winding of the solenoid, with\noverall field accuracy at better than one part per million.\n",
      "subjects": [
        "physics.ins-det",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Predator-prey models with competition, Part III: Classification of\n  stationary solutions",
      "abstract": "  For a stationary system representing prey and $N$ groups of competing\npredators, we show classification results about the set of positive solutions.\nIn particular, we show that if the number of components $N$ is too large or if\nthe competition between different groups is too small, then the system has only\nconstant solutions, which we then completely characterize.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/AO.59.000038",
      "title": "Multi-plane, Multi-band image projection via Broadband Diffractive\n  Optics",
      "abstract": "  We demonstrate visible and near-IR image projection via non-absorbing,\nmulti-level Broadband Diffractive-Optical Elements (BDOEs) in 1 or more planes.\nBy appropriate design of the BDOE topography, we experimentally demonstrate:\n(1) different images in different spectral bands; (2) different images in\ndifferent image planes; (3) image magnification by changing the distance\nbetween the illumination source and the BDOE; (4) completely flat BDOE via an\nindex-contrast top-coating; and (5) reflective BDOEs. All of these are\naccomplished with broadband illumination. Furthermore, the BDOEs are highly\nefficient, versatile and can be inexpensive mass manufactured using\nimprint-based replication techniques.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1478-3975/ab1563",
      "title": "Small RNA driven feed-forward loop: critical role of sRNA in noise\n  filtering",
      "abstract": "  A feed-forward loop (FFL) is a common gene-regulatory motif in which usually\nthe upstream regulator is a protein, a transcription factor, that regulates the\nexpression of the target protein in two parallel pathways. Here, we study a\ndistinct sRNA-driven FFL (sFFL) discovered recently in Salmonella enterica.\nUnlike previously studied transcriptional FFLs (tFFL) and sRNA-mediated FFLs\n(smFFL), here the upstream regulator is an sRNA that activates the target\nprotein and its transcriptional activator. Such sFFL has not been subjected to\nrigorous analysis. We, therefore, set out to understand two aspects. First is a\nquantitative comparison of the regulatory response of sFFL with tFFL and smFFL\nusing a differential equation framework. Since the process of gene expression\nis inherently stochastic, the second objective is to find how the noise affects\nthe functionality of sFFL. We find the response of sFFLto be stronger, faster,\nand more sensitive to the initial concentration of the upstream regulator than\ntFFL and smFFL. Further, a generating function based analysis and stochastic\nsimulations lead to a non-trivial prediction that an optimal noise filtration\ncan be attained depending on the synthesis rate of the sRNA and the degradation\nrate of the transcriptional activator. We conclude that in sFFL, sRNA plays a\ncritical role not only in driving a rapid and strong response, but also a\nreliable response that depends critically on its concentration. Given the\nadvantages of sFFL brought out in this work, it should not be surprising if\nfuture work reveals their employment in different biological contexts.\n",
      "subjects": [
        "q-bio.MN",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.100.044902",
      "title": "Charged-particle angular correlations in XeXe collisions at\n  $\\sqrt{s_{_\\mathrm{NN}}} =$ 5.44 TeV",
      "abstract": "  Azimuthal correlations of charged particles in xenon-xenon collisions at a\ncenter-of-mass energy per nucleon pair of $ \\sqrt{s_{_\\mathrm{NN}}} =$ 5.44 TeV\nare studied. The data were collected by the CMS experiment at the LHC with a\ntotal integrated luminosity of 3.42 $\\mu$b$^{-1}$. The collective motion of the\nsystem formed in the collision is parameterized by a Fourier expansion of the\nazimuthal particle density distribution. The azimuthal anisotropy coefficients\n$v_{2}$, $v_{3}$, and $v_{4}$ are obtained by the scalar-product, two-particle\ncorrelation, and multiparticle correlation methods. Within a hydrodynamic\npicture, these methods have different sensitivities to non-collective and\nfluctuation effects. The dependence of the Fourier coefficients on the size of\nthe colliding system is explored by comparing the xenon-xenon results with\nequivalent lead-lead data. Model calculations that include initial-state\nfluctuation effects are also compared to the experimental results. The observed\nangular correlations provide new constraints on the hydrodynamic description of\nheavy ion collisions.\n",
      "subjects": [
        "hep-ex",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dating the foundation of Augusta Taurinorum ex sole. The augustean\n  propaganda and the role of Astronomy",
      "abstract": "  The essay presents the results of a joint study of astronomy and archeology\nthat has allowed to define the foundation date of the city of Turin as a Roman\ncolony, called Iulia Augusta Taurinorum. This multidisciplinary research\nrepresents a new reading of the historical-archaeological sources and the use\nof astronomy according to the Etruscan-Latin gromatica. By taking into\nconsideration the apparent motion of a True Sun, the possible measurement\nerrors, the atmospheric refraction and the elevation of the horizon, and the\nJulian date in use in astronomy, a numerical program has been elaborated to\ndefine the coincidences of the calendars between the azimuth of the main road\naxis and the course of the sun. For a series of very particular historical and\ncontextual conditions it was therefore possible to trace with sufficient\naccuracy the day and the year of foundation of the city: January 30, 9 BC,\nwhich coincides, not surprisingly, with a particularly important anniversary\nfor Ottaviano Augusto, Emperor from 27 BC to 14 AC. In fact, the astronomical\ndata interfaced with the archaeological, epigraphic and written sources suggest\nthat Turin was born at the end of the Alpine wars, concluded after the\nacquisition of the Valle di Susa and, more extensively, of the Maritime Alps,\nPennine and Graie. Founded as a colony along the road leading to the Gauls,\nAugusta Taurinorum was inaugurated on the day of the anniversary of the feast\nof Pax, established by Augustus and celebrated at the Ara Pacis in Rome\nstarting from 9 BC. The large marble altar of Campo Marzio was, as matter of\nfact, built to celebrate the end of civil wars and the beginning of a new era\n(confirmed also by the astrological/astronomical ephemerides of that time),\nwhich is widely reported in the official Augustean literature.\n",
      "subjects": [
        "physics.hist-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0219199720500479",
      "title": "Existence of pseudo-heavy fibers of moment maps",
      "abstract": "  In the present paper, we introduce the notion of pseudo-heaviness of closed\nsubsets of closed symplectic manifolds and prove the existence of pseudo-heavy\nfibers of moment maps. In particular, we generalize Entov and Polterovich's\ntheorem, which ensures the existence of non-displaceable fibers, and provide a\npartial answer to a problem posed by them, which asks the existence of heavy\nfibers. Moreover, we apply our results to prove that some generalized coupled\nangular momenta have more than two non-displaceable fibers.\n",
      "subjects": [
        "math.SG",
        "math.DS",
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jpaa.2020.106570",
      "title": "On Suslin homology with integral coefficients in characteristic zero\n  (with an appendix by Bruno Kahn)",
      "abstract": "  We show that the Suslin homology group with integral coefficients of a scheme\n$X$ separated of finite type over an algebraically closed field of\ncharacteristic 0 is a direct sum of a uniquely divisible group, finite copies\nof $\\mathbb{Q}/\\mathbb{Z}$, and a finitely generated group. We also study the\npossible type of homomorphisms between such groups induced by the morphisms of\nschemes. An appendix written by Bruno Kahn is included, which simplifies the\nproofs and generalizes the results.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3290605.3300651",
      "title": "Analyzing the Use of Camera Glasses in the Wild",
      "abstract": "  Camera glasses enable people to capture point-of-view videos using a common\naccessory, hands-free. In this paper, we investigate how, when, and why people\nused one such product: Spectacles. We conducted 39 semi-structured interviews\nand surveys with 191 owners of Spectacles. We found that the form factor\nelicits sustained usage behaviors, and opens opportunities for new use-cases\nand types of content captured. We provide a usage typology, and highlight\nsocietal and individual factors that influence the classification of behaviors.\n",
      "subjects": [
        "cs.HC",
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Intermediate-Mass Black Holes in Extragalactic Globular Clusters",
      "abstract": "  Intermediate-mass black holes (IMBHs) have masses of about 100 to 100,000\nsolar masses. They remain elusive. Observing IMBHs in present-day globular\nclusters (GCs) would validate a formation channel for seed black holes in the\nearly universe and inform event predictions for gravitational wave facilities.\nReaching a large number of GCs per galaxy is key, as models predict that only a\nfew percent will have retained their gravitational-wave fostering IMBHs.\nRelated, many galaxies will need to be examined to establish a robust sample of\nIMBHs in GCs. These needs can be meet by using a next-generation Very Large\nArray (ngVLA) to search for IMBHs in the GCs of hundreds of galaxies out to a\ndistance of 25 Mpc. These galaxies hold tens of thousands of GCs in total. We\ndescribe how to convert an ngVLA signal from a GC to an IMBH mass according to\na semi-empirical accretion model. Simulations of gas flows in GCs would help to\nimprove the robustness of the conversion. Also, self-consistent dynamical\nmodels of GCs, with stellar and binary evolution in the presence of IMBHs,\nwould help to improve IMBH retention predictions for present-day GCs.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Simulation of distributed manufacturing enterprises: A new approach",
      "abstract": "  The globalization of markets and world-wide competition forces manufacturing\nenterprises to enter into alliances leading to the creation of distributed\nmanufacturing enterprises. Before forming a partnership it is essential to\nevaluate viability of proposed enterprise as well as how a companys operations\nare affected by the proposed virtual enterprise. Distributed simulation\nprovides an attractive tool to make decisions on such situations. However, due\nto its complexity and high cost distributed simulation failed to gain a wide\nacceptance from industrial users. This paper presents a new approach for\ndistributed manufacturing simulation (DMS) including a formal methodology for\nDMS and, implementation approach using current commercial simulation software,\nemploying widely available and cost effective technologies. The main objective\nof this work is to promote the use of distributed simulation particularly in\ndistributed manufacturing by making it fast to develop and less complicated for\nimplementation.\n",
      "subjects": [
        "cs.DC",
        "cs.MA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Duality for coalescing stochastic flows on the real line",
      "abstract": "  For a class of coalescing stochastic flows on the real line the existence of\ndual flows is proved. A stochastic flow and its dual are constructed as a\nforward and backward perfect cocycles over the same metric dynamical system.\nThe metric dynamical system itself is defined on a new state space for\ncoalescing flows. General results are applied to Arratia flows with drift.\n",
      "subjects": [
        "math.PR",
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Condition based maintenance policies under imperfect maintenance at\n  scheduled and unscheduled opportunities",
      "abstract": "  Motivated by the cost savings that can be obtained by sharing resources in a\nnetwork context, we consider a stylized, yet representative model, for the\ncoordination of maintenance and service logistics for a geographic network of\nassets. Capital assets, such as wind turbines in a wind park, require\nmaintenance throughout their long lifetimes. Two types of preventive\nmaintenance are considered: planned maintenance at periodic, scheduled\nopportunities, and opportunistic maintenance at unscheduled opportunities. The\nlatter type of maintenance arises due to the network context: when an asset in\nthe network fails, this constitutes an opportunity for preventive maintenance\nfor the other assets in the network.\n  So as to increase the realism of the model at hand and its applicability to\nvarious sectors, we consider the option of not-deferring and of deferring\nplanned maintenance after the occurrence of opportunistic maintenance. We also\nassume that preventive maintenance may not always restore the condition of the\nsystem to `as good as new'. By formulating this problem as a semi-Markov\ndecision process, we characterize the optimal policy as a control limit policy\n(depending on the remaining time until the next planned maintenance) that\nindicates on the one hand when it is optimal to perform preventive maintenance\nand on the other hand when maintenance resources should be shared if an\nopportunity in the network arises. In order to facilitate managerial insights\non the effect of each parameter on the cost, we provide a closed-form\nexpression for the long-run rate of cost for any given control limit policy\n(depending on the remaining time until the next planned maintenance) and\ncompare the costs (under the optimal policy) to these of sub-optimal policies\nthat neglect the opportunity for resource sharing. We illustrate our findings\nusing data from the wind energy industry.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stz877",
      "title": "Dynamical evolution of magnetic fields in the intracluster medium",
      "abstract": "  We investigate the evolution of magnetic fields in galaxy clusters starting\nfrom constant primordial fields using highly resolved ($\\approx \\rm 4 ~kpc$)\ncosmological MHD simulations. The magnetic fields in our sample exhibit\namplification via a small-scale dynamo and compression during structure\nformation. In particular, we study how the spectral properties of magnetic\nfields are affected by mergers, and we relate the measured magnetic energy\nspectra to the dynamical evolution of the intracluster medium. The magnetic\nenergy grows by a factor of $\\sim$ 40-50 in a time-span of $\\sim 9$ Gyr and\nequipartition between kinetic and magnetic energy occurs on a range of scales\n($< 160 \\rm ~kpc$ at all epochs) depending on the turbulence state of the\nsystem. We also find that, in general, the outer scale of the magnetic field\nand the MHD scale are not simply correlated in time. The effect of major\nmergers is to shift the peak magnetic spectra to it smaller scales, whereas the\nmagnetic amplification only starts after $\\lesssim$ 1 Gyr. In contrast,\ncontinuous minor mergers promote the steady growth of the magnetic field. We\ndiscuss the implications of these findings in the interpretation of future\nradio observations of galaxy clusters.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Partially isometric matrices: a brief and selective survey",
      "abstract": "  We survey a variety of results about partially isometric matrices. We focus\nprimarily on results that are distinctly finite-dimensional. For example, we\ncover a recent solution to the similarity problem for partial isometries. We\nalso discuss the unitary similarity problem and several other results.\n",
      "subjects": [
        "math.FA",
        "math.OA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1674-1137/44/9/093105",
      "title": "Gluon-pair-Creation Production Model of Strong Interaction Vertices",
      "abstract": "  By studying the $\\eta_c$ exclusive decay to double glueballs, we introduce a\nmodel to mimic phenomenologically the gluon-pair-vacuum interaction vertices,\nnamely the $0^{++}$ model. Based on this model, we study glueball production in\npseudoscalar quarkonium decays, explicitly $\\eta_c \\to f_0(1500)\\eta(1405)$,\n$\\eta_b\\to f_0(1500)\\eta(1405)$ and $\\eta_b\\to f_0(1710)\\eta(1405)$ processes.\nAmong them $f_0(1500)$ and $f_0(1710)$ are well-known scalars possessing large\nglue components and $\\eta(1405)$ is a potential candidate for pseudoscalar\nglueball. The preliminary calculation results indicate that these processes are\nmarginally accessible in the presently running experiments BES III, BELLE II,\nand LHCb.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevResearch.2.013379",
      "title": "Entanglement preserving local thermalization",
      "abstract": "  We investigate whether entanglement can survive the thermalization of\nsubsystems. We present two equivalent formulations of this problem: (1) Can two\nisolated agents, accessing only pre-shared randomness, locally thermalize\narbitrary input states while maintaining some entanglement? (2) Can\nthermalization with local heat baths, which may be classically correlated but\ndo not exchange information, locally thermalize arbitrary input states while\nmaintaining some entanglement? We answer these questions in the positive at\nevery nonzero temperature and provide bounds on the amount of preserved\nentanglement. We provide explicit protocols and discuss their thermodynamic\ninterpretation: we suggest that the underlying mechanism is a speed-up of the\nsubsystem thermalization process. We also present extensions to multipartite\nsystems. Our findings show that entanglement can survive locally performed\nthermalization processes accessing only classical correlations as a resource.\nThey also suggest a broader study of the channel's ability to preserve\nresources and of the compatibility between global and local dynamics.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Existence and stability analysis of solutions for a ultradian\n  glucocorticoid rhythmicity and acute stress model",
      "abstract": "  The hypothalamic pituitary adrenal (HPA) axis responds to physical and mental\nchallenge to maintain homeostasis in part by controlling the body's cortisol\nlevel. Dysregulation of the HPA axis is implicated in numerous stress-related\ndiseases. For a structured model of the HPA axis that includes the\nglucocorticoid receptor but does not take into account the system response\ndelay, we analyze linear and non-linear stability of stationary solutions. For\na second mathematical model that describes the mechanism of the HPA axis\nself-regulatory activities and takes into account a delay of system response,\nwe prove existence of periodic solutions under certain assumptions on ranges of\nparameter values and analyze stability of these solutions with respect to the\ntime delay value.\n",
      "subjects": [
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epjc/s10052-019-7105-9",
      "title": "Frequency variation for in vacuo photon propagation in the\n  Standard-Model Extension",
      "abstract": "  In the presence of Lorentz Symmetry Violation (LSV) associated with the\nStandard-Model Extension (SME), we have recently shown the non-conservation of\nthe energy-momentum tensor of a light-wave crossing an Electro-Magnetic (EM)\nbackground field even when the latter and the LSV are constant. Incidentally,\nfor a space-time dependent LSV, the presence of an EM field is not necessary.\nHerein, we infer that in a particle description, the energy non-conservation\nfor a photon implies violation of frequency invariance in vacuo giving rise to\na red or blue shift. We discuss the potential consequences on cosmology.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On stability of small solitons of the 1--D NLS with a trapping delta\n  potential",
      "abstract": "  We consider a Nonlinear Schr\\\"odinger Equation with a very general non linear\nterm and with a trapping $\\delta $ potential on the line. We then discuss the\nasymptotic behavior of all its small solutions, generalizing a recent result by\nMasaki et al. We give also a result of dispersion in the case of defocusing\nequations with a non--trapping delta potential.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1112/blms.12565",
      "title": "On proper branched coverings and a question of Vuorinen",
      "abstract": "  We study global injectivity of proper branched coverings defined on the\nEuclidean $n$-ball in the case when the branch set is compact. In particular we\nshow that such mappings are homeomorphisms when $n=3$ or when the branch set is\nempty. This proves the corresponding cases of a question of Vuorinen from\n[Vuo79].\n",
      "subjects": [
        "math.CV",
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the Convergence Rates of Learning-based Signature Generation Schemes\n  to Contain Self-propagating Malware",
      "abstract": "  In this paper, we investigate the importance of a defense system's learning\nrates to fight against the self-propagating class of malware such as worms and\nbots. To this end, we introduce a new propagation model based on the\ninteractions between an adversary (and its agents) who wishes to construct a\nzombie army of a specific size, and a defender taking advantage of standard\nsecurity tools and technologies such as honeypots (HPs) and intrusion detection\nand prevention systems (IDPSes) in the network environment. As time goes on,\nthe defender can incrementally learn from the collected/observed attack samples\n(e.g., malware payloads), and therefore being able to generate attack\nsignatures. The generated signatures then are used for filtering next attack\ntraffic and thus containing the attacker's progress in its malware propagation\nmission. Using simulation and numerical analysis, we evaluate the efficacy of\nsignature generation algorithms and in general any learning-based scheme in\nbringing an adversary's maneuvering in the environment to a halt as an\nadversarial containment strategy.\n",
      "subjects": [
        "cs.CR",
        "cs.NI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Ontological Analysis of Business Process Modeling and Execution",
      "abstract": "  This work presents a fully elaborated ontology, defined via the Ontology Web\nLanguage (OWL), of the Business Process Model and Notation (BPMN) standard to\ndefine business process models, and we demonstrate that any BPMN model can be\nserialized as OWL file. Based on ontological analysis and a corresponding\ndefinition of a modeling notation as ontology we show that business process\nmodels can be transformed from one notation into another one as long as there\nare common underlying concepts; this is demonstrated with the case of an actor\nbased, or subject-oriented, view on business processes. Furthermore, a\nreference architecture for Workflow Management Systems (WfMS) based on\nmicroservices is discussed which is capable of executing actor based business\nprocess models. As a transformation of BPMN models into the actor based view is\ngenerally possible, also BPMN models could be enacted. As a result, we can\nconclude that the actor system is a promising way to stimulate new ways to\ndesign workflow management systems and to design business process modeling\nlanguages which are more comfortable to use by non-experts without losing\nnecessary expressiveness. Another result is that an ontology is a productive\nway to define a modeling notation as it can be used as knowledge base, it is a\nformal conceptualization of the underlying notions, and can be semantically\nenriched for further use.\n",
      "subjects": [
        "cs.SE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Prioritized Inverse Kinematics: Nonsmoothness, Trajectory Existence,\n  Task Convergence, Stability",
      "abstract": "  In this paper, we study various theoretical properties of a class of\nprioritized inverse kinematics (PIK) solutions that can be considered as a\nclass of (output regulation or tracking) control laws of a dynamical system\nwith prioritized multiple outputs. We first develop tools to investigate\nnonsmoothness of PIK solutions and find a sufficient condition for\nnonsmoothness. It implies that existence and uniqueness of a joint trajectory\nsatisfying a PIK solution cannot be guaranteed by the classical theorems. So,\nwe construct an alternative existence and uniqueness theorem that uses\nstructural information of PIK solutions. Then, we narrow the class of PIK\nsolutions down to the case that all tasks are designed to follow some desired\ntask trajectories and discover a few properties related to task convergence.\nThe study goes further to analyze stability of equilibrium points of the\ndifferential equation whose right hand side is a PIK solution when all tasks\nare designed to reach some desired task positions. Finally, we furnish an\nexample with a two-link manipulator that shows how our findings can be used to\nanalyze the behavior of a joint trajectory generated from a PIK solution.\n",
      "subjects": [
        "cs.SY",
        "cs.RO",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1674-1056/27/11/110303",
      "title": "Modulating quantum Fisher information of qubit in dissipative cavity by\n  coupling strength",
      "abstract": "  By using the non-Markovian master equation, we investigate the effect of the\ncavity and the environment on the quantum Fisher information (QFI) of an atom\nqubit system in a dissipation cavity. We obtain the formulae of QFI for two\ndifferent initial states and analyze the effect of the atom-cavity coupling and\nthe cavity-reservoir coupling on the QFI. The results show that the dynamic\nbehavior of the QFI is obviously dependent on the initial atomic states, the\natom-cavity coupling and the cavity-reservoir coupling. The stronger the\natom-cavity coupling, the quicker the QFI oscillates and the slower the QFI\nreduces. Especially, the QFI will tend to a stable value not zero if the\natom-cavity coupling is large enough. On the other hand, the smaller the\ncavity-reservoir coupling, the stronger the non-Markovian effect, the slower\nthe QFI decay. In other words, choosing the best parameter can improve the\naccuracy of parameter estimation. In addition, the physical explanation of the\ndynamic behavior of the QFI is given by means of the QFI flow.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Causal Inference for Multiple Treatments using Fractional Factorial\n  Designs",
      "abstract": "  We consider the design and analysis of multi-factor experiments using\nfractional factorial and incomplete designs within the potential outcome\nframework. These designs are particularly useful when limited resources make\nrunning a full factorial design infeasible. We connect our design-based methods\nto standard regression methods. We further motivate the usefulness of these\ndesigns in multi-factor observational studies, where certain treatment\ncombinations may be so rare that there are no measured outcomes in the observed\ndata corresponding to them. Therefore, conceptualizing a hypothetical\nfractional factorial experiment instead of a full factorial experiment allows\nfor appropriate analysis in those settings. We illustrate our approach using\nbiomedical data from the 2003-2004 cycle of the National Health and Nutrition\nExamination Survey to examine the effects of four common pesticides on body\nmass index.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s44214-022-00017-7",
      "title": "Evidence of orbit-selective electronic kagome lattice with planar\n  flat-band in correlated paramagnetic YCr6Ge6",
      "abstract": "  Electronic properties of kagome lattice have drawn great attention recently.\nIn associate with flat-band induced by destructive interference and Dirac\ncone-type dispersion, abundant exotic phenomena have been theoretically\ndiscussed. The material realization of electronic kagome lattice is a crucial\nstep towards comprehending kagome physics and achieving novel quantum phases.\nHere, combining angle-resolved photoemission spectroscopy, transport\nmeasurements and first-principle calculations, we expose a planar flat-band in\nparamagnetic YCr6Ge6 as a typical signature of electronic kagome lattice. We\nunearth that the planar flat-band arises from the d_(z^2 ) electrons with\nintra-kagome-plane hopping forbidden by destructive interference. On the other\nhand, the destructive interference and flatness of the d_(x^2-y^2 ) and d_xy\nbands are decomposed possibly due to additional in-plane hopping terms, but the\nDirac cone-type dispersion is reserved near chemical potential. We explicitly\nunveil that orbital character plays an essential role to realize electronic\nkagome lattice in bulk materials with transition metal kagome layers.\nParamagnetic YCr6Ge6 provides an opportunity to comprehend intrinsic properties\nof electronic kagome lattice as well as its interplays with spin orbit coupling\nand electronic correlation of Cr-3d electrons, and be free from complications\ninduced by strong local moment of ions in kagome planes.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "ADA-Tucker: Compressing Deep Neural Networks via Adaptive Dimension\n  Adjustment Tucker Decomposition",
      "abstract": "  Despite the recent success of deep learning models in numerous applications,\ntheir widespread use on mobile devices is seriously impeded by storage and\ncomputational requirements. In this paper, we propose a novel network\ncompression method called Adaptive Dimension Adjustment Tucker decomposition\n(ADA-Tucker). With learnable core tensors and transformation matrices,\nADA-Tucker performs Tucker decomposition of arbitrary-order tensors.\nFurthermore, we propose that weight tensors in networks with proper order and\nbalanced dimension are easier to be compressed. Therefore, the high flexibility\nin decomposition choice distinguishes ADA-Tucker from all previous low-rank\nmodels. To compress more, we further extend the model to Shared Core ADA-Tucker\n(SCADA-Tucker) by defining a shared core tensor for all layers. Our methods\nrequire no overhead of recording indices of non-zero elements. Without loss of\naccuracy, our methods reduce the storage of LeNet-5 and LeNet-300 by ratios of\n691 times and 233 times, respectively, significantly outperforming state of the\nart. The effectiveness of our methods is also evaluated on other three\nbenchmarks (CIFAR-10, SVHN, ILSVRC12) and modern newly deep networks (ResNet,\nWide-ResNet).\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Densely Connected Search Space for More Flexible Neural Architecture\n  Search",
      "abstract": "  Neural architecture search (NAS) has dramatically advanced the development of\nneural network design. We revisit the search space design in most previous NAS\nmethods and find the number and widths of blocks are set manually. However,\nblock counts and block widths determine the network scale (depth and width) and\nmake a great influence on both the accuracy and the model cost (FLOPs/latency).\nIn this paper, we propose to search block counts and block widths by designing\na densely connected search space, i.e., DenseNAS. The new search space is\nrepresented as a dense super network, which is built upon our designed routing\nblocks. In the super network, routing blocks are densely connected and we\nsearch for the best path between them to derive the final architecture. We\nfurther propose a chained cost estimation algorithm to approximate the model\ncost during the search. Both the accuracy and model cost are optimized in\nDenseNAS. For experiments on the MobileNetV2-based search space, DenseNAS\nachieves 75.3% top-1 accuracy on ImageNet with only 361MB FLOPs and 17.9ms\nlatency on a single TITAN-XP. The larger model searched by DenseNAS achieves\n76.1% accuracy with only 479M FLOPs. DenseNAS further promotes the ImageNet\nclassification accuracies of ResNet-18, -34 and -50-B by 1.5%, 0.5% and 0.3%\nwith 200M, 600M and 680M FLOPs reduction respectively. The related code is\navailable at https://github.com/JaminFong/DenseNAS.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/TAP.2017.2673758",
      "title": "Cross-correlated Contrast Source Inversion",
      "abstract": "  In this paper, we improved the performance of the contrast source inversion\n(CSI) method by incorporating a so-called cross-correlated cost functional,\nwhich interrelates the state error and the data error in the measurement\ndomain. The proposed method is referred to as the cross-correlated CSI. It\nenables better robustness and higher inversion accuracy than both the classical\nCSI and multiplicative regularized CSI (MR-CSI). In addition, we show how the\ngradient of the modified cost functional can be calculated without\nsignificantly increasing the computational burden. The advantages of the\nproposed algorithms are demonstrated using a 2-D benchmark problem excited by a\ntransverse magnetic wave as well as a transverse electric wave, respectively,\nin comparison to classical CSI and MR-CSI.\n",
      "subjects": [
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1137/19M1270446",
      "title": "Total variation based community detection using a nonlinear optimization\n  approach",
      "abstract": "  Maximizing the modularity of a network is a successful tool to identify an\nimportant community of nodes. However, this combinatorial optimization problem\nis known to be NP-complete. Inspired by recent nonlinear modularity eigenvector\napproaches, we introduce the modularity total variation $TV_Q$ and show that\nits box-constrained global maximum coincides with the maximum of the original\ndiscrete modularity function. Thus we describe a new nonlinear optimization\napproach to solve the equivalent problem leading to a community detection\nstrategy based on $TV_Q$. The proposed approach relies on the use of a fast\nfirst-order method that embeds a tailored active-set strategy. We report\nextensive numerical comparisons with standard matrix-based approaches and the\nGeneralized RatioDCA approach for nonlinear modularity eigenvectors, showing\nthat our new method compares favourably with state-of-the-art alternatives.\n",
      "subjects": [
        "cs.SI",
        "math.OC",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.123.191601",
      "title": "Exact Three-Point Functions of Determinant Operators in Planar N=4\n  Supersymmetric Yang-Mills Theory",
      "abstract": "  We introduce a nonperturbative approach to correlation functions of two\ndeterminant operators and one non-protected single-trace operator in planar N=4\nsupersymmetric Yang-Mills theory. Based on the gauge/string duality, we propose\nthat they correspond to overlaps on the string worldsheet between an integrable\nboundary state and a state dual to the single-trace operator. We determine the\nboundary state using symmetry and integrability of the dual superstring sigma\nmodel, and write down expressions for the correlators at finite coupling, which\nwe conjecture to be valid for operators of arbitrary size. The proposal is put\nto test at weak coupling.\n",
      "subjects": [
        "hep-th",
        "math-ph",
        "math.MP",
        "nlin.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Groupoid Picture of Elek Algebras",
      "abstract": "  We describe a construction by G\\'abor Elek, associating C*-algebras with\nuniformly recurrent subgroups, in the language of groupoid C*-algebras. This\nallows us to simplify several proofs in the original paper and fully\ncharacterise their nuclearity. We furthermore relate our groupoids to the\ndynamics of the group acting on its uniformly recurrent subgroup.\n",
      "subjects": [
        "math.OA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.101.023511",
      "title": "Physical geometry of the quasispherical Szekeres models",
      "abstract": "  The quasispherical Szekeres metric is an exact solution to Einstein's\nequations describing an inhomogeneous and anisotropic cosmology. Though its\ngoverning equations are well-known, there are subtle, often-overlooked details\nin how the model's functions relate to its physical layout, including the\nshapes and relative positions of structures. We present an illustrated overview\nof the quasispherical Szekeres models and show exactly how the model functions\nrelate to the physical shape and distribution of matter. In particular, we\ndescribe a shell rotation effect that has not previously been fully understood.\nWe show how this effect relates to other known properties, and lay out some\nmathematical tools useful for constructing models and picturing them\naccurately.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On primeness of the Selberg zeta-function",
      "abstract": "  In this note we prove that the Selberg zeta-function associated to a compact\nRiemann surface is pseudo-prime and right-prime in the sense of a\ndecomposition.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/ptep/ptz102",
      "title": "Geometrical structure and thermal conductivity of dust aggregates formed\n  via ballistic cluster-cluster aggregation",
      "abstract": "  We herein report a theoretical study of the geometrical structure of porous\ndust aggregates formed via ballistic cluster-cluster aggregation (BCCA). We\ncalculated the gyration radius $R_{\\rm gyr}$ and the graph-based geodesic\nradius $R_{\\rm geo}$ as a function of the number of constituent particles $N$.\nWe found that $R_{\\rm gyr} / r_{0} \\sim N^{0.531 \\pm 0.011}$ and $R_{\\rm geo} /\nr_{0} \\sim N^{0.710 \\pm 0.013}$, where $r_{0}$ is the radius of constituent\nparticles. Furthermore, we defined two constants that characterize the\ngeometrical structure of fractal aggregates: $D_{\\rm f}$ and $\\alpha$. The\ndefinition of $D_{\\rm f}$ and $\\alpha$ are $N \\sim {( R_{\\rm gyr} / r_{0}\n)}^{D_{\\rm f}}$ and ${R_{\\rm geo}} / {r_{0}} \\sim {\\left( {R_{\\rm gyr}} /\n{r_{0}} \\right)}^{\\alpha}$, respectively. Our study revealed that $D_{\\rm f}\n\\simeq 1.88$ and $\\alpha \\simeq 1.34$ for the clusters of the BCCA.\n  In addition, we also studied the filling factor dependence of thermal\nconductivity of statically compressed fractal aggregates. From this study, we\nreveal that the thermal conductivity of statically compressed aggregates $k$ is\ngiven by $k \\sim 2 k_{\\rm mat} {( r_{\\rm c} / r_{0} )} \\phi^{(1 + \\alpha) / (3\n- D_{\\rm f})}$, where $k_{\\rm mat}$ is the material thermal conductivity,\n$r_{\\rm c}$ is the contact radius of constituent particles, and $\\phi$ is the\nfilling factor of dust aggregates.\n",
      "subjects": [
        "astro-ph.EP",
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1177/0962280220922256",
      "title": "Decision-making with multiple correlated binary outcomes in clinical\n  trials",
      "abstract": "  Clinical trials often evaluate multiple outcome variables to form a\ncomprehensive picture of the effects of a new treatment. The resulting\nmultidimensional insight contributes to clinically relevant and efficient\ndecision-making about treatment superiority. Common statistical procedures to\nmake these superiority decisions with multiple outcomes have two important\nshortcomings however: 1) Outcome variables are often modeled individually, and\nconsequently fail to consider the relation between outcomes; and 2) superiority\nis often defined as a relevant difference on a single, on any, or on all\noutcomes(s); and lacks a compensatory mechanism that allows large positive\neffects on one or multiple outcome(s) to outweigh small negative effects on\nother outcomes. To address these shortcomings, this paper proposes 1) a\nBayesian model for the analysis of correlated binary outcomes based on the\nmultivariate Bernoulli distribution; and 2) a flexible decision criterion with\na compensatory mechanism that captures the relative importance of the outcomes.\nA simulation study demonstrates that efficient and unbiased decisions can be\nmade while Type I error rates are properly controlled. The performance of the\nframework is illustrated for 1) fixed, group sequential, and adaptive designs;\nand 2) non-informative and informative prior distributions.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Efficient Prealignment of CT Scans for Registration through a Bodypart\n  Regressor",
      "abstract": "  Convolutional neural networks have not only been applied for classification\nof voxels, objects, or images, for instance, but have also been proposed as a\nbodypart regressor. We pick up this underexplored idea and evaluate its value\nfor registration: A CNN is trained to output the relative height within the\nhuman body in axial CT scans, and the resulting scores are used for quick\nalignment between different timepoints. Preliminary results confirm that this\nallows both fast and robust prealignment compared with iterative approaches.\n",
      "subjects": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1021/acs.nanolett.9b03971",
      "title": "Deep learning meets nanophotonics: A generalized accurate predictor for\n  near fields and far fields of arbitrary 3D nanostructures",
      "abstract": "  Deep artificial neural networks are powerful tools with many possible\napplications in nanophotonics. Here, we demonstrate how a deep neural network\ncan be used as a fast, general purpose predictor of the full near-field and\nfar-field response of plasmonic and dielectric nanostructures. A trained neural\nnetwork is shown to infer the internal fields of arbitrary three-dimensional\nnanostructures many orders of magnitude faster compared to conventional\nnumerical simulations. Secondary physical quantities are derived from the deep\nlearning predictions and faithfully reproduce a wide variety of physical\neffects without requiring specific training. We discuss the strengths and\nlimitations of the neural network approach using a number of model studies of\nsingle particles and their near-field interactions. Our approach paves the way\nfor fast, yet universal methods for design and analysis of nanophotonic\nsystems.\n",
      "subjects": [
        "physics.comp-ph",
        "cond-mat.mes-hall",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/LSP.2019.2943995",
      "title": "A Fast and Robust Algorithm for Orientation Estimation using Inertial\n  Sensors",
      "abstract": "  We present a novel algorithm for online, real-time orientation estimation.\nOur algorithm integrates gyroscope data and corrects the resulting orientation\nestimate for integration drift using accelerometer and magnetometer data. This\ncorrection is computed, at each time instance, using a single gradient descent\nstep with fixed step length. This fixed step length results in robustness\nagainst model errors, e.g. caused by large accelerations or by short-term\nmagnetic field disturbances, which we numerically illustrate using Monte Carlo\nsimulations. Our algorithm estimates a three-dimensional update to the\norientation rather than the entire orientation itself. This reduces the\ncomputational complexity by approximately 1/3 with respect to the state of the\nart. It also improves the quality of the resulting estimates, specifically when\nthe orientation corrections are large. We illustrate the efficacy of the\nalgorithm using experimental data.\n",
      "subjects": [
        "eess.SP",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Incorporating Fine-grained Events in Stock Movement Prediction",
      "abstract": "  Considering event structure information has proven helpful in text-based\nstock movement prediction. However, existing works mainly adopt the\ncoarse-grained events, which loses the specific semantic information of diverse\nevent types. In this work, we propose to incorporate the fine-grained events in\nstock movement prediction. Firstly, we propose a professional finance event\ndictionary built by domain experts and use it to extract fine-grained events\nautomatically from finance news. Then we design a neural model to combine\nfinance news with fine-grained event structure and stock trade data to predict\nthe stock movement. Besides, in order to improve the generalizability of the\nproposed method, we design an advanced model that uses the extracted\nfine-grained events as the distant supervised label to train a multi-task\nframework of event extraction and stock prediction. The experimental results\nshow that our method outperforms all the baselines and has good\ngeneralizability.\n",
      "subjects": [
        "cs.CE",
        "q-fin.ST"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.patrec.2020.06.027",
      "title": "On the expected behaviour of noise regularised deep neural networks as\n  Gaussian processes",
      "abstract": "  Recent work has established the equivalence between deep neural networks and\nGaussian processes (GPs), resulting in so-called neural network Gaussian\nprocesses (NNGPs). The behaviour of these models depends on the initialisation\nof the corresponding network. In this work, we consider the impact of noise\nregularisation (e.g. dropout) on NNGPs, and relate their behaviour to signal\npropagation theory in noise regularised deep neural networks. For ReLU\nactivations, we find that the best performing NNGPs have kernel parameters that\ncorrespond to a recently proposed initialisation scheme for noise regularised\nReLU networks. In addition, we show how the noise influences the covariance\nmatrix of the NNGP, producing a stronger prior towards simple functions away\nfrom the training points. We verify our theoretical findings with experiments\non MNIST and CIFAR-10 as well as on synthetic data.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/5.0001476",
      "title": "Hikami-Larkin-Nagaoka (HLN) Fitting of Magneto Transport of Bi2Se3\n  Single Crystal in Different Magnetic Field Ranges",
      "abstract": "  We report the detailed study of structural micro-structuraland high magnetic\nfield magneto transport propertiesof Bi2Se3single crystal. Bi2Se3 single\ncrystal is grown through conventional solid-state reaction route via the\nself-flux method. Rietveld analysis on Powder X-ray Diffraction showed that the\nstudied Bi2Se3 crystal is crystallized in single-phase without any impurity.\nThe surface morphology analyzed through Scanning Electron Microscopy study\nwhich shows that as-grown single crystal exhibit layered type structure and the\nquantitative weight of the atomic constituents (Bi and Se) are found to be\ncloseto the stoichiometric amount in energy-dispersive X-ray spectroscopy\nanalysis. Low temperature (2.5K) magneto-resistance (MR) exhibited a v-type\ncusp around origin at lower magnetic field, which is the sign of weak\nanti-localization effect. Further, Bi2Se3 single crystal magneto conductivity\ndata is fitted by well-known HLN equation in different magnetic field range of\n2Tesla, 4Tesla and 6Tesla and the resultant found that the conduction mechanism\nof Bi2Se3 is dominated by WAL state.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Game-theoretical Approach to Analyze Film Release Time",
      "abstract": "  Film release dates play an important part in box office revenues because of\nthe facts of obvious seasonality demand in the film industry and severe\ncompetition among films shown at the same time. In this paper, we study how\nfilm studios choose release time for movies they produce to maximize their box\noffices. We first formalize this problem as an attraction competition game\nwhere players (film studios) consider both potential profits and competitors'\nchoices when deciding the release time. Then we prove that there always exists\na pure Nash equilibrium and give the sufficient condition of the uniqueness of\nthe Nash equilibrium. Our model can be generalized to an extensive game and we\ncompute the subgame-perfect equilibrium for homogeneous players. For the case\nthat one film studio could have multiple movies to release, we prove that\nfinding a player's best response is NP-hard and it does not guarantee the\nexistence of a pure Nash equilibrium. Experiments are provided to support the\nsoundness of our model. In the final state, most of film studios, accounting\nfor 84 percent of the market, would not change their release time. The\nbehaviors of film studios imply they are following some strategies to reach a\nNash equilibrium.\n",
      "subjects": [
        "cs.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "ROSETLineBot: One-Wheel-Drive Low-Cost Power Line Inspection Robot\n  Design and Control",
      "abstract": "  Continuous operation of the electrical transmission lines is of great\nimportance for today's electricity-dependent world. It is crucial to detect and\ndiagnose a possible problem on the lines before that occurs. In general,\nmaintenance, repair and error detection operations of the electrical\ntransmission lines are performed by humans periodically. However, these\ndifficult tasks contain high-risks in terms of occupational health and safety.\nMoreover, it is not possible to continuously inspect these lines which extend\nover long distances by maintenance and repair personnel. For all these reasons,\nit is very convenient to use robotic systems for inspection on power\ntransmission lines. By evaluating the data which are provided from sensors and\ncameras of robotic systems, it would be possible to take precautions before an\nerror occurs. Robotic systems that can move continuously along the line would\nbe able to gather continuous and uninterrupted information. Thus, potential\nproblems can be detected and identified in advance. In this study, a single\nwheel drive low-cost mobile robot is designed and controlled which can work and\nmove on the electrical transmission lines. Because of the modular structure of\nthe designed robot, different types of sensors can be integrated into the\nrobot, easily. The designed low-cost robotic system will cause minimum losses\nin case of possible breakage.\n",
      "subjects": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Concentration and confinement of eigenfunctions in a bounded open set\n  (version 2)",
      "abstract": "  Consider the Dirichlet-Laplacian in $\\Omega:= (0,L)\\times (0,H)$ and choose\nanother open set $\\omega\\subset \\Omega$. The estimate $0<C_{\\omega}\\leq\nR_{\\omega}(u):=\\frac{\\Vert u\\Vert^{2}_{L^{2}(\\omega)}}{\\Vert\nu\\Vert^{2}_{L^{2}(\\Omega)}}\\leq \\frac{vol(\\omega)}{vol(\\omega)}$, for all the\neigenfunctions, is well known. This is no longer true for an inhomogeneous\nelliptic selfadjoint operator $A$. In this work we create a partition among the\nset of eigenfunctions: $\\forall \\omega$, the eigenfunctions satisfy\n$R_{omega}>C_{\\omega}>0,\\exists \\omega, \\omega\\not=\\emptyset$, such that $\\inf\nR_{\\omega}(u)=0$,and we wish to characterize these two sets. For two patterns\nwe give a sufficient condition, sometimes necessary. As our operator\ncorresponds to a layered media we can give another representation of its\nspectrum: i.e. a subset of points of $R\\times R$ that leads to the suggested\npartition and others connected results: micro local interpretation, default\nmeasures,... Section 4.1 of the previous version was not correct, now it is\ncorrected, many proofs are simplified and a new general result is added.\n",
      "subjects": [
        "math.AP",
        "math-ph",
        "math.MP",
        "math.OC",
        "math.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Comprehensive Review On Various State Of Art Techniques For Eye Blink\n  Detection",
      "abstract": "  Computer Vision is considered to be one of the most important areas in\nresearch and has focused on developing many applications that has proved to be\nuseful for both research and societal benefits. Today we have been witnessing\nmany of the road mishaps happening just because of the lack of concentration\nwhile driving.As a part of avoiding this kind of disaster happening in day to\nday life there are many technologies focusing on keeping track of the vehicle\ndrivers concentration.One such technology uses the method of eye blink\ndetection to find out the concentration level of the driver.With the advent of\nmany high end camera devices with cost effectiveness factor today it has become\nmore efficient and cheaper to use eye blink detection for keeping track of the\nconcentration level of the driver.Hence this paper presents an exhaustive\nreview on the implementations of various eye blink detection algorithms.The\ndetection system has also extended its application in various other fields like\ndrowsiness detection and fatigue detection and expression detection.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevApplied.14.014085",
      "title": "A solution to electric-field screening in diamond quantum electrometers",
      "abstract": "  There are diverse interdisciplinary applications for nanoscale resolution\nelectrometry of elementary charges under ambient conditions. These include\ncharacterization of 2D electronics, charge transfer in biological systems, and\nmeasurement of fundamental physical phenomena. The nitrogen-vacancy center in\ndiamond is uniquely capable of such measurements, however electrometry thus far\nhas been limited to charges within the same diamond lattice. It has been\nhypothesized that the failure to detect charges external to diamond is due to\nquenching and surface screening, but no proof, model, or design to overcome\nthis has yet been proposed. In this work we affirm this hypothesis through a\ncomprehensive theoretical model of screening and quenching within a diamond\nelectrometer and propose a solution using controlled nitrogen doping and a\nfluorine-terminated surface. We conclude that successful implementation\nrequires further work to engineer diamond surfaces with lower surface defect\nconcentrations.\n",
      "subjects": [
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Surface plasmon polariton waves with zero phase dispersion in a broad\n  spectrum at Near-infrared wavelength",
      "abstract": "  We present theory to describe an engineering dispersion technique to obtain a\nbroadband effective index near zero with an asymmetric planar photonic crystal.\nThe theory provides the manipulating surface plasmon polariton (SPP) to provide\nalternating symmetric stacks of negative and positive effective indices. The\nodd alternating effective indices, including positive and negative refraction,\narise from transverse resonance that depends on the geometry of the planar\nphotonic crystal. The purposed technique remains wavepacket in zero phase\ndispersion since the created parity-time symmetries keep the phase constant in\npropagation direction. We use the plane wave expansion method to calculate band\nstructure and transmission spectrum then validate with FDTD simulation. The\nresults are compared to the recent experimental reports and they will be of\nsignificant interest to emerging applications in designing and fabricating\nmetamaterials, optical filters, photonic sensors, photonic integrated circuits,\nnear-field optics, and optofluidic biosensing applications.\n",
      "subjects": [
        "physics.optics",
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the Hermite-Hadmard inequalities for interval-valued coordinated\n  convex functions",
      "abstract": "  In this paper, we establish Hermite-Hadamard inequality for interval-valued\nconvex function on the co-ordinates on the rectangle from the plane. We also\npresent Hermite-Hadamard inequality for the product of interval-valued convex\nfunctions on co-ordinates. Some examples are also given to clarify our new\nresults\n",
      "subjects": [
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP06(2020)128",
      "title": "New black holes with hyperscaling violation and transports of quantum\n  critical points with magnetic impurity",
      "abstract": "  We consider the magneto-transports of quantum matters doped with magnetic\nimpurities near the quantum critical points(QCP). For this, we first find new\nblack hole solution with hyper-scaling violation which is dual to such system.\nBy considering the fluctuation near this exact solution, we calculated all\ntransport coefficients using the holographic method. We applied our result to\nthe surface state of the topological insulator with magnetic doping and found\ntwo QCP's, one bosonic and the other fermionic. It turns out that doped\nBi$_2$Se$_3$ and Bi$_2$Te$_3$ correspond to different QCP's. We also\ninvestigated transports of QCP's as functions of physical parameters and found\nthat there are phase transitions as well as crossovers from weak localization\nto weak anti-localization.\n",
      "subjects": [
        "hep-th",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3394486.3403172",
      "title": "LayoutLM: Pre-training of Text and Layout for Document Image\n  Understanding",
      "abstract": "  Pre-training techniques have been verified successfully in a variety of NLP\ntasks in recent years. Despite the widespread use of pre-training models for\nNLP applications, they almost exclusively focus on text-level manipulation,\nwhile neglecting layout and style information that is vital for document image\nunderstanding. In this paper, we propose the \\textbf{LayoutLM} to jointly model\ninteractions between text and layout information across scanned document\nimages, which is beneficial for a great number of real-world document image\nunderstanding tasks such as information extraction from scanned documents.\nFurthermore, we also leverage image features to incorporate words' visual\ninformation into LayoutLM. To the best of our knowledge, this is the first time\nthat text and layout are jointly learned in a single framework for\ndocument-level pre-training. It achieves new state-of-the-art results in\nseveral downstream tasks, including form understanding (from 70.72 to 79.27),\nreceipt understanding (from 94.02 to 95.24) and document image classification\n(from 93.07 to 94.42). The code and pre-trained LayoutLM models are publicly\navailable at \\url{https://aka.ms/layoutlm}.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Inverse Iteration for the Monge-Amp\\`ere Eigenvalue Problem",
      "abstract": "  We present an iterative method based on repeatedly inverting the\nMonge-Amp\\`ere operator with Dirichlet boundary condition and prescribed\nright-hand side on a bounded, convex domain $\\Omega \\subset \\mathbb{R}^n$. We\nprove that the iterates $u_k$ generated by this method converge as $k \\to\n\\infty$ to a solution of the Monge-Amp\\`ere eigenvalue problem $$\\begin{cases}\n\\text{det} D^2u = \\lambda_{MA} (-u)^n & \\quad \\text{in } \\Omega,\\\\ u = 0 &\n\\quad \\text{on } \\partial \\Omega. \\end{cases}$$ Since the solutions of this\nproblem are unique up to a positive multiplicative constant, the normalized\niterates $\\hat{u}_k := \\frac{u_k}{||u_k||_{L^{\\infty}(\\Omega)}}$ converge to\nthe eigenfunction of unit height. In addition, we show that $\\lim\\limits_{k \\to\n\\infty} R(u_k) = \\lim\\limits_{k \\to \\infty} R(\\hat{u}_k) = \\lambda_{MA}$, where\nthe Rayleigh quotient $R(u)$ is defined as $$R(u) := \\frac{\\int_{\\Omega} (-u) \\\n\\text{det} D^2u}{\\int_{\\Omega} (-u)^{n+1}}.$$ Our method converges for a wide\nclass of initial choices $u_0$ that can be constructed explicitly, and does not\nrely on prior knowledge of the Monge-Amp\\`ere eigenvalue $\\lambda_{MA}$.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Unsupervised Learning for Passive Beamforming",
      "abstract": "  Reconfigurable intelligent surface (RIS) has recently emerged as a promising\ncandidate to improve the energy and spectral efficiency of wireless\ncommunication systems. However, the unit modulus constraint on the phase shift\nof reflecting elements makes the design of optimal passive beamforming solution\na challenging issue. The conventional approach is to find a suboptimal solution\nusing the semi-definite relaxation (SDR) technique, yet the resultant\nsuboptimal iterative algorithm usually incurs high complexity, hence is not\namenable for real-time implementation. Motivated by this, we propose a deep\nlearning approach for passive beamforming design in RIS-assisted systems. In\nparticular, a customized deep neural network is trained offline using the\nunsupervised learning mechanism, which is able to make real-time prediction\nwhen deployed online. Simulation results show that the proposed approach\nmaintains most of the performance while significantly reduces computation\ncomplexity when compared with SDR-based approach.\n",
      "subjects": [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers",
      "abstract": "  Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, \"can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?\" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.\n",
      "subjects": [
        "cs.LG",
        "cs.CR",
        "cs.IR",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/staa139",
      "title": "Cradles of the first stars: self-shielding, halo masses, and\n  multiplicity",
      "abstract": "  The formation of Population III (Pop III) stars is a critical step in the\nevolution of the early universe. To understand how these stars affected their\nmetal-enriched descendants, the details of how, why and where Pop III formation\ntakes place needs to be determined. One of the processes that is assumed to\ngreatly affect the formation of Pop III stars is the presence of a Lyman-Werner\n(LW) radiation background, that destroys H$_2$, a necessary coolant in the\ncreation of Pop III stars. Self-shielding can alleviate the effect the LW\nbackground has on the H$_2$ within haloes. In this work, we perform a\ncosmological simulation to study the birthplaces of Pop III stars, using the\nadaptive mesh refinement code Enzo. We investigate the distribution of host\nhalo masses and its relationship to the LW background intensity. Compared to\nprevious work, haloes form Pop III stars at much lower masses, up to a factor\nof a few, due to the inclusion of H$_2$ self-shielding. We see no relationship\nbetween the LW intensity and host halo mass. Most haloes form multiple Pop III\nstars, with a median number of four, up to a maximum of 16, at the instance of\nPop III formation. Our results suggest that Pop III star formation may be less\naffected by LW radiation feedback than previously thought and that Pop III\nmultiple systems are common.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevResearch.2.033071",
      "title": "Kane-Mele with a twist: Quasicrystalline higher-order topological\n  insulators with fractional mass kinks",
      "abstract": "  We establish an analytic low-energy theory describing higher-order\ntopological insulator (HOTI) phases in quasicrystalline systems. We apply this\nto a model consisting of two stacked Haldane models with oppositely propagating\nedge modes, analogous to the Kane-Mele model, and with a $30^\\circ$ twist. We\nshow that the resulting localized modes at corners, characteristic of a HOTI,\nare not associated with conventional mass inversions but are instead associated\nwith what we dub \"fractional mass kinks\". By generalizing the low-energy\ntheory, we establish a classification for arbitrary $ n $-fold rotational\nsymmetries. We also derive a relationship between corner modes in a bilayer and\ndisclination modes in a single layer. By using numerics to go beyond the\nweak-coupling limit, we show that a hierarchy of additional gaps occurs due to\nthe quasiperiodicity, which also harbor corner-localized modes.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217751X20500591",
      "title": "On the Universal Texture in the PA-2HDM for the V-SPIN case",
      "abstract": "  In a Partially Aligned Two Higgs Doublet Model, where only is allowed flavor\nviolation between third and second generation of fermions, we propose a\nmechanism to generate the second Yukawa matrix through a Unitary V-Spin flavor\ntransformation on the mass matrix for quarks and leptons. Also we assume that\nthis flavor transformation is universal, this is, we use the same parameters to\ngenerate Yukawa matrix elements in both sectors, reducing drastically the\nnumber of free parameters. As consequence we obtained a serie of relations\nbetween Yukawa matrix elements, that we called the Universality Constraint.\nAlso, we obtained an interval of values for the second Yukawa matrix elements,\nexpressed in terms of the Cheng and Sher ansatz, for $\\tau\\to\\ mu\\mu^+\\mu^-$\nand $\\tau\\to\\gamma\\mu$ coming from the Universality Constraint and experimental\nbounds for light scalar masses. Finally, we show the allowed region of\nparameters for the flavor transformation from $B_s\\to\\mu\\mu$ decays,\n$B_s^0-\\bar{B}_s^0$ mixing, $\\tau\\to\\mu\\mu^+\\mu^-$ and $\\tau\\to\\gamma\\mu$\nexperimental bounds.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Aliasing error of the exp$(\\beta \\sqrt{1-z^2})$ kernel in the nonuniform\n  fast Fourier transform",
      "abstract": "  The most popular algorithm for the nonuniform fast Fourier transform (NUFFT)\nuses the dilation of a kernel $\\phi$ to spread (or interpolate) between given\nnonuniform points and a uniform upsampled grid, combined with an FFT and\ndiagonal scaling (deconvolution) in frequency space. The high performance of\nthe recent FINUFFT library is in part due to its use of a new \"exponential of\nsemicircle\" kernel $\\phi(z)=e^{\\beta \\sqrt{1-z^2}}$, for $z\\in[-1,1]$, zero\notherwise, whose Fourier transform $\\hat\\phi$ is unknown analytically. We place\nthis kernel on a rigorous footing by proving an aliasing error estimate which\nbounds the error of the one-dimensional NUFFT of types 1 and 2 in exact\narithmetic. Asymptotically in the kernel width measured in upsampled grid\npoints, the error is shown to decrease with an exponential rate arbitrarily\nclose to that of the popular Kaiser--Bessel kernel. This requires controlling a\nconditionally-convergent sum over the tails of $\\hat\\phi$, using steepest\ndescent, other classical estimates on contour integrals, and a phased sinc sum.\nWe also draw new connections between the above kernel, Kaiser--Bessel, and\nprolate spheroidal wavefunctions of order zero, which all appear to share an\noptimal exponential convergence rate.\n",
      "subjects": [
        "math.NA",
        "cs.NA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "pSPICE: Partial Match Shedding for Complex Event Processing",
      "abstract": "  Complex event processing (CEP) systems continuously process input event\nstreams to detect patterns. Over time, the input event rate might fluctuate and\novershoot the system's capabilities. One way to reduce the overload on the\nsystem is to use load shedding. In this paper, we propose a load shedding\nstrategy for CEP systems which drops a portion of the CEP operator's internal\nstate (a.k.a. partial matches) to maintain a given latency bound. The crucial\nquestion here is how many and which partial matches to drop so that a given\nlatency bound is maintained while minimizing the degradation in the quality of\nresults. In the stream processing domain, different load shedding strategies\nhave been proposed that mainly depend on the importance of individual tuples.\nHowever, as CEP systems perform pattern detection, the importance of events is\nalso influenced by other events in the stream. Our load shedding strategy uses\nMarkov chain and Markov reward process to predict the utility/importance of\npartial matches to determine the ones to be dropped. In addition, we represent\nthe utility in a way that minimizes the overhead of load shedding. Furthermore,\nwe provide algorithms to decide when to start dropping partial matches and how\nmany partial matches to drop. By extensively evaluating our approach on three\nreal-world datasets and several representative queries, we show that the\nadverse impact of our load shedding strategy on the quality of results is\nconsiderably less than the impact of state-of-the-art load shedding strategies.\n",
      "subjects": [
        "cs.DC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1361-648X/ab757b",
      "title": "Hyperfine and quadrupole interactions for Dy isotopes in DyPc$_2$\n  molecules",
      "abstract": "  Nuclear spin levels play an important role in understanding magnetization\ndynamics and implementation and control of quantum bits in lanthanide-based\nsingle-molecule magnets. We investigate the hyperfine and nuclear quadrupole\ninteractions for $^{161}$Dy and $^{163}$Dy nucleus in anionic DyPc$_2$\n(Pc=phthalocyanine) single-molecule magnets, using multiconfigurational\nab-initio methods (beyond density-functional theory) including spin-orbit\ninteraction. The two isotopes of Dy are chosen because the others have zero\nnuclear spin. Both isotopes have the nuclear spin $I=5/2$, although the\nmagnitude and sign of the nuclear magnetic moment differ from each other. The\nlarge energy gap between the electronic ground and first-excited Kramers\ndoublets, allows us to map the microscopic hyperfine and quadrupole interaction\nHamiltonian onto an effective Hamiltonian with an electronic pseudo-spin\n$S_{\\rm eff}=1/2$ that corresponds to the ground Kramers doublet. Our ab-initio\ncalculations show that the coupling between the nuclear spin and electronic\norbital angular momentum contributes the most to the hyperfine interaction and\nthat both the hyperfine and nuclear quadrupole interactions for $^{161}$Dy and\n$^{163}$Dy nucleus are much smaller than those for $^{159}$Tb nucleus in\nTbPc$_2$ single-molecule magnets. The calculated separations of the\nelectronic-nuclear levels are comparable to experimental data reported for\n$^{163}$DyPc$_2$. We demonstrate that hyperfine interaction for Dy Kramers ion\nleads to tunnel splitting (or quantum tunneling of magnetization) at zero\nfield. This effect does not occur for TbPc$_2$ single-molecule magnets. The\nmagnetic field values of the avoided level crossings for $^{161}$DyPc$_2$ and\n$^{163}$DyPc$_2$ are found to be noticeably different, which can be observed\nfrom experiment.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "physics.chem-ph",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On decompositions of the real line",
      "abstract": "  Let X_t be a totally disconnected subset of the real line R for each t in R.\nWe construct a partition {Y_t | t in R} of R into nowhere dense Lebesgue null\nsets Y_t such that for every t in R there exists an increasing homeomorphism\nfrom X_t onto Y_t. In particular, the real line can be partitioned into\n2^{aleph_0} Cantor sets and also into 2^{aleph_0} mutually non-homeomorphic\ncompact subspaces. Furthermore we prove that for every cardinal number k with 2\n\\leq k \\leq 2^{aleph_0} the real line (as well as the Baire space R\\Q) can be\npartitioned into exactly k homeomorphic Bernstein sets and also into exactly k\nmutually non-homeomorphic Bernstein sets. We also investigate partitions of R\ninto Marczewski sets, including the possibility that they are Luzin sets or\nSierpinski sets.\n",
      "subjects": [
        "math.GN"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Adversarial Detection and Correction by Matching Prediction\n  Distributions",
      "abstract": "  We present a novel adversarial detection and correction method for machine\nlearning classifiers.The detector consists of an autoencoder trained with a\ncustom loss function based on the Kullback-Leibler divergence between the\nclassifier predictions on the original and reconstructed instances.The method\nis unsupervised, easy to train and does not require any knowledge about the\nunderlying attack. The detector almost completely neutralises powerful attacks\nlike Carlini-Wagner or SLIDE on MNIST and Fashion-MNIST, and remains very\neffective on CIFAR-10 when the attack is granted full access to the\nclassification model but not the defence. We show that our method is still able\nto detect the adversarial examples in the case of a white-box attack where the\nattacker has full knowledge of both the model and the defence and investigate\nthe robustness of the attack. The method is very flexible and can also be used\nto detect common data corruptions and perturbations which negatively impact the\nmodel performance. We illustrate this capability on the CIFAR-10-C dataset.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Towards Robust and Reproducible Active Learning Using Neural Networks",
      "abstract": "  Active learning (AL) is a promising ML paradigm that has the potential to\nparse through large unlabeled data and help reduce annotation cost in domains\nwhere labeling data can be prohibitive. Recently proposed neural network based\nAL methods use different heuristics to accomplish this goal. In this study, we\ndemonstrate that under identical experimental settings, different types of AL\nalgorithms (uncertainty based, diversity based, and committee based) produce an\ninconsistent gain over random sampling baseline. Through a variety of\nexperiments, controlling for sources of stochasticity, we show that variance in\nperformance metrics achieved by AL algorithms can lead to results that are not\nconsistent with the previously reported results. We also found that under\nstrong regularization, AL methods show marginal or no advantage over the random\nsampling baseline under a variety of experimental conditions. Finally, we\nconclude with a set of recommendations on how to assess the results using a new\nAL algorithm to ensure results are reproducible and robust under changes in\nexperimental conditions. We share our codes to facilitate AL evaluations. We\nbelieve our findings and recommendations will help advance reproducible\nresearch in AL using neural networks. We open source our code at\nhttps://github.com/PrateekMunjal/TorchAL\n",
      "subjects": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Angular momentum and rotational energy of meanflows in toroidal magnetic\n  fields",
      "abstract": "  We derive the balance equation for the Favre averaged angular momentum in\ntoroidal not necessarily axisymmetric magnetic field equilibria. We find that\nthe components of angular momentum are given by the covariant poloidal and\ntoroidal components of ExB and parallel flow velocities and we separately\nidentify all relevant stress tensors, torques and source terms for each of\nthese components. Our results feature the Favre stress generalisations of\npreviously found Reynolds stresses like the diamagnetic or parallel ExB stress,\nas well as the density gradient drive term. Further, we identify the magnetic\nshear as a source of poloidal ExB angular momentum and discuss the mirror and\nthe Lorentz force. Here, we find that the geodesic transfer term, the\nStringer-Winsor spin-up term and the ion-orbit loss term are all part of the\nLorentz force and are in fact one and the same term.\n  Discussing the relation to angular velocity we build the inertia tensor with\nthe help of the first fundamental form of a flux-surface. In turn, the inertia\ntensor is used to construct a flux-surface averaged rotational energy for \\ExB\nsurface flows of the plasma. The evolution of this rotational energy features a\ncorrection of previous results due to the inertia tensor. In particular, this\ncorrection suggests that density sources on the high-field side contribute much\nmore to zonal flow energy generation than on the low field side.\n",
      "subjects": [
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Willmore spheres in the 3-sphere revisited",
      "abstract": "  Bryant \\cite{Bryant84} classified all Willmore spheres in $3$-space to be\ngiven by minimal surfaces in $\\mathbb R^3$ with embedded planar ends. This note\nprovides new explicit formulas for genus 0 minimal surfaces in $\\mathbb R^3$\nwith $2k+1$ embedded planar ends for all $k\\geq4.$ Peng and Xiao claimed these\nexamples to exist in \\cite{PengXiao2000}, but in the same paper they also\nclaimed the existence of a minimal surface with 7 embedded planar ends, which\nwas falsified by Bryant \\cite{Bryant88}.\n",
      "subjects": [
        "math.DG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Augmented reality as a tool for open science platform by research\n  collaboration in virtual teams",
      "abstract": "  The provision of open science is defined as a general policy aimed at\novercoming the barriers that hinder the implementation of the European Research\nArea (ERA). An open science foundation seeks to capture all the elements needed\nfor the functioning of ERA: research data, scientific instruments, ICT services\n(connections, calculations, platforms, and specific studies such as portals).\nManaging shared resources for the community of scholars maximizes the benefits\nto society. In the field of digital infrastructure, this has already\ndemonstrated great benefits. It is expected that applying this principle to an\nopen science process will improve management by funding organizations in\ncollaboration with stakeholders through mechanisms such as public consultation.\nThis will increase the perception of joint ownership of the infrastructure. It\nwill also create clear and non-discriminatory access rules, along with a sense\nof joint ownership that stimulates a higher level of participation,\ncollaboration and social reciprocity. The article deals with the concept of\nopen science. The concept of the European cloud of open science and its\nstructure are presented. According to the study, it has been shown that the\nstructure of the cloud of open science includes an augmented reality as an\nopen-science platform. An example of the practical application of this tool is\nthe general description of MaxWhere, developed by Hungarian scientists, and is\na platform of aggregates of individual 3D spaces.\n",
      "subjects": [
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1367-2630/abb54b",
      "title": "Quasi-nondegenerate pump-probe magnetooptical experiment in GaAs/AlGaAs\n  heterostructure based on spectral filtration",
      "abstract": "  We report on a quasi-nondegenerate pump-probe technique that is based on\nspectral-filtration of femtosecond laser pulses by a pair of\nmutually-spectrally-disjunctive interference filters. This cost- and\nspace-efficient approach can be used even in pump-probe microscopy where\ncollinear propagation of pump and probe pulses is dictated by utilization of a\nmicroscopic objective. This technique solves the contradictory requirements on\nan efficient removal of pump photons from the probe beam, to achieve a good\nsignal-to-noise ratio, simultaneously with a needed spectral proximity of the\nexcitation and probing, which is essential for magnetooptical study of many\nmaterial systems. Importantly, this spectral-filtration of 100 fs long laser\npulses does not affect considerably the resulting time-resolution, which\nremains well below 500 fs. We demonstrate the practical applicability of this\ntechnique with close but distinct wavelengths of pump and probe pulses in\nspatially- and time-resolved spin-sensitive magnetooptical Kerr effect (MOKE)\nexperiment in GaAs/AlGaAs heterostructure, where a high-mobility spin system is\nformed after optical injection of electrons at wavelengths close to MOKE\nresonance. In particular, we studied the time- and spatial-evolutions of\ncharge-related (reflectivity) and spin-related (MOKE) signals. We revealed that\nthey evolve in a similar but not exactly the same way which we attributed to\ninterplay of several electron many-body effects in GaAs.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.ensm.2021.01.009",
      "title": "Tunable capacitance in all-inkjet-printed nanosheet heterostructures",
      "abstract": "  Heterostructures constructed from two-dimensional building blocks have shown\npromise for field-effect transistors, memory devices, photosensors and other\nelectronic applications1,2. 2D nanosheet crystals can be constructed into\nmultilayer heterostructures using layer-by-layer methods3, but that method\ncannot be used to fabricate large-scale and thick heterostructures, due to the\ntime-consuming nature and low efficiency of the process. An alternative\napproach to deposit different two-dimensional materials is by inkjet\nprinting4-7. Here we show the fabrication of a nanosheet supercapacitor by\ninkjet printing Ti3C2Tx MXene nanosheets as electrodes, and graphene oxide\nnanosheets as solid-state electrolyte. The free water molecules trapped between\ngraphene oxide sheets facilitate proton movement through the layered solid\nelectrolyte8. The as-made supercapacitor shows high areal capacitance, good\ncycling stability and high areal energy and power densities comparable with\nexisting printed supercapacitors. Moreover, the specific capacitance can be\nincreased further by addition of liquid electrolytes.\n",
      "subjects": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP12(2020)115",
      "title": "Higgs self-coupling measurements using deep learning in the\n  $b\\bar{b}b\\bar{b}$ final state",
      "abstract": "  Measuring the Higgs trilinear self-coupling $\\lambda_{hhh}$ is experimentally\ndemanding but fundamental for understanding the shape of the Higgs potential.\nWe present a comprehensive analysis strategy for the HL-LHC using di-Higgs\nevents in the four $b$-quark channel ($hh \\to 4b$), extending current methods\nin several directions. We perform deep learning to suppress the formidable\nmultijet background with dedicated optimisation for BSM $\\lambda_{hhh}$\nscenarios. We compare the $\\lambda_{hhh}$ constraining power of events using\ndifferent multiplicities of large radius jets with a two-prong structure that\nreconstruct boosted $h \\to bb$ decays. We show that current uncertainties in\nthe SM top Yukawa coupling $y_t$ can modify $\\lambda_{hhh}$ constraints by\n$\\sim 20\\%$. For SM $y_t$, we find prospects of $-0.8 < \\lambda_{hhh} /\n\\lambda_{hhh}^\\text{SM} < 6.6$ at 68% CL under simplified assumptions for\n3000~fb$^{-1}$ of HL-LHC data. Our results provide a careful assessment of\ndi-Higgs identification and machine learning techniques for all-hadronic\nmeasurements of the Higgs self-coupling and sharpens the requirements for\nfuture improvement.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1017/S0960129521000116",
      "title": "Computing with Continuous Objects: A Uniform Co-inductive Approach",
      "abstract": "  A uniform approach to computing with infinite objects like real numbers,\ntuples of these, compacts sets, and uniformly continuous maps is presented. In\nwork of Berger it was shown how to extract certified algorithms working with\nthe signed digit representation from constructive proofs. Berger and the\npresent author generalised this approach to complete metric spaces and showed\nhow to deal with compact sets. Here, we unify this work and lay the foundations\nfor doing a similar thing for the much more comprehensive class of compact\nHausdorff spaces occurring in applications. The approach is of the same\ncomputational power as Weihrauch's Type-Two Theory of Effectivity.\n",
      "subjects": [
        "cs.LO",
        "math.DS",
        "math.GN"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP08(2020)036",
      "title": "Constraining New Physics with Single Top production at LHC",
      "abstract": "  We study effects of beyond the Standard Model physics coupling third\ngeneration quarks to leptons of the first two generations. We parametrize these\neffects by dimension-six effective operators, and we also consider related\nsimplified UV completions: scalar leptoquark and $W'$ models. We derive new\nconstraints on these scenarios by using recent ATLAS measurements of\ndifferential cross sections of single top production in association with a $W$\nboson, and also show how these limits will evolve with future data. We also\ndescribe how the limits can be significantly improved by using ratios of\ndifferential distributions with different flavors of leptons.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.101.033620",
      "title": "Fermionic versus bosonic behavior of confined Wigner molecules",
      "abstract": "  We assess whether a confined Wigner molecule constituted by $2N$ fermions\nbehaves as $N$ bosons or $2N$ fermions. Following the work by C. K. Law [Phys.\nRev. A \\textbf{71}, 034306 (2005)] and Chudzicki et al. [Phys. Rev. Lett.\n\\textbf{104}, 070402 (2010)] we discuss the physical meaning and the reason why\na large amount of entanglement is needed in order to ensure a bosonic composite\nbehavior. By applying a composite boson ansatz, we found that a Wigner molecule\nconfined in two dimensional traps presents a bosonic behavior induced by\nsymmetry. The two-particle Wigner molecule ground state required by the\ncomposite boson ansatz was obtained within the harmonic approximation in the\nstrong interacting regime. Our approach allows us to address few-particle\nstates (widely studied within a variety of theoretical and numerical\ntechniques) as well as a large number of particles (difficult to address due to\ncomputational costs). For a large number of particles, we found strong\nfermionic correlations exposed by the suppression of particle fluctuations. For\na small number of particles, we show that the wave function calculated within\nthe composite boson ansatz captures the Friedel-Wigner transition. The latter\nis shown in a regime in which strong correlations due to the Pauli exclusion\nprinciple arise, therefore, we conclude that the coboson ansatz reproduces the\nmany particle physics of a confined Wigner molecule, even in the presence of\nstrong deviations of the ideal bosonic behavior due to fermionic correlations.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Quantum Twistor Bundle",
      "abstract": "  We investigate the quantum twistor bundle constructed as a $U(1)$-quotient of\nthe quantum instanton bundle of Bonechi, Ciccoli and Tarlini. It is an example\nof a locally trivial noncommutative bundle fulfilling conditions of the\nframework recently proposed by Brzezi\\'nski and Szyma\\'nski. In particular, we\ngive a detailed description of the corresponding $C^*$-algebra of 'continuous\nfunctions' on its noncommutative total space. Furthermore, we analyse a\ndifferent construction of a quantum instanton bundle due to Landi, Pagani and\nReina, find a basis of its polynomial algebra and discover an intriguing and\nunexpected feature of its enveloping $C^*$-algebra.\n",
      "subjects": [
        "math.QA",
        "math.OA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Multi-Winner Election Control via Social Influence",
      "abstract": "  In an election, we are given a set of voters, each having a preference list\nover a set of candidates, that are distributed on a social network. We consider\na scenario where voters may change their preference lists as a consequence of\nthe messages received by their neighbors in a social network. Specifically, we\nconsider a political campaign that spreads messages in a social network in\nsupport or against a given candidate and the spreading follows a dynamic model\nfor information diffusion. When a message reaches a voter, this latter changes\nits preference list according to an update rule. The election control problem\nasks to find a bounded set of nodes to be the starter of a political campaign\nin support (constructive problem) or against (destructive problem) a given\ntarget candidate $c$, in such a way that the margin of victory of $c$ w.r.t.\nits most voted opponents is maximized. It has been shown that several variants\nof the problem can be solved within a constant factor approximation of the\noptimum, which shows that controlling elections by means of social networks is\ndoable and constitutes a real problem for modern democracies. Most of the\nliterature, however, focuses on the case of single-winner elections. In this\npaper, we define the election control problem in social networks for\n\"multi-winner elections\" with the aim of modeling parliamentarian elections.\nDifferently from the single-winner case, we show that the multi-winner election\ncontrol problem is NP-hard to approximate within any factor in both\nconstructive and destructive cases. We then study a relaxation of the problem\nwhere votes are aggregated on the basis of parties (instead of single\ncandidates), which is a variation of the so-called \"straight-party voting\" used\nin some real parliamentarian elections. We show that the latter problem remains\nNP-hard but can be approximated within a constant factor.\n",
      "subjects": [
        "cs.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/PRJ.419886",
      "title": "Non-iterative complex wave-field reconstruction based on Kramers-Kronig\n  relations",
      "abstract": "  A new computational imaging method to reconstruct the complex wave-field is\nreported. Due to the existence of zero frequency component, the measured signal\nby amplitude modulation of pupil has a spectrum similar to the one of off-axis\nhologram. The mathematical analogy between them is established in this paper.\nBased on this observation and analyticity of band-limited signal under any\ndiffraction-limited system, an algorithm from Kramers-Kronig (KK) relations is\nutilized to recover the phase information only from the intensity patterns.\nFrom the sensing side, only two measurements are required at least. From the\nreconstruction algorithm side, our method is iteration-free and parameter-free,\nalso without any assumption on sample characteristics. It owns several\nadvantages over existing phase imaging methods and could provide a unique\nperspective to understand current computational imaging methods.\n",
      "subjects": [
        "physics.optics",
        "eess.IV",
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Geometry and Algebra of the Deltoid Map",
      "abstract": "  The geometry of the deltoid curve gives rise to a self-map of $\\mathbb{C}^2$\nthat is expressed in coordinates by $f(x,y) = (y^2 - 2x, x^2 - 2y)$. This is\none in a family of maps that generalize Chebyshev polynomials to several\nvariables. We use this example to illustrate two important objects in complex\ndynamics: the Julia set and the iterated monodromy group.\n",
      "subjects": [
        "math.GT",
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1741-4326/abb14b",
      "title": "Nonlinear dynamics of the fishbone-induced alpha transport on ITER",
      "abstract": "  The fishbone-induced transport of alpha particles is computed for the ITER 15\nMA baseline scenario, using the nonlinear hybrid Kinetic-MHD code XTOR-K. Two\nlimit cases have been studied, in order to analyse the characteristic regimes\nof the fishbone instability : the weak kinetic drive limit and the strong\nkinetic drive limit. In both those regimes, characteristic features of the n =\nm = 1 fishbone instability are recovered, such as a strong up/down-chirping of\nthe mode frequency, associated with a resonant transport of trapped and passing\nalpha particles. The effects of the n = m = 0 sheared poloidal and toroidal\nplasma rotation are taken into account in the simulations. The shear is not\nnegligible, which implies that the fishbone mode frequency has a radial\ndependency, impacting the wave-particle resonance condition. Phase space hole\nand clump structures are observed in both nonlinear regimes, centered around\nthe precessional and passing resonances. These structures remains attached to\nthe resonances as the different mode frequencies chirp up and down. In the\nnonlinear phase, the transport of individual resonant trapped particles is\nidentified to be linked to mode-particle synchronization. On this basis, a\npartial mechanism for the nonlinear coupling between particle transport and\nmode dominant down-chirping is proposed. The overall transport of alpha\nparticles inside out the q = 1 surface is of order 2-5% of the initial\npopulation between the simulations. The loss of alpha power is found to be\ndirectly equal to the loss of alpha particles.\n",
      "subjects": [
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Necessary and Sufficient Conditions for Unique Solution to Functional\n  Equations of Poincare Type",
      "abstract": "  Distributional equation is an important tool in the characterization theory\nbecause many characteristic properties of distributions can be transferred to\nsuch equations. Using a novel and natural approach, we retreat a remarkable\ndistributional equation whose corresponding functional equation in terms of\nLaplace-Stieltjes transform is of the Poincare type. The necessary and\nsufficient conditions for the equation to have a unique distributional solution\nwith finite variance are provided. This complements the previous results which\ninvolve at most the mean of the distributional solution. Besides, more general\ndistributional (or functional) equations are investigated as well.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.asr.2020.07.045",
      "title": "Optimal Stereoscopic Angle for Reconstructing Solar Wind Inhomogeneous\n  Structures",
      "abstract": "  This paper is aimed at finding the best separation angle between spacecraft\nfor the three-dimensional reconstruction of solar-wind inhomogeneous structures\nby the CORrelation-Aided Reconstruction(CORAR) method. The analysis is based on\nthe dual-point heliospheric observations from the STEREO HI-1 cameras. We\nproduced synthetic HI-1 white-light images containing artificial blob-like\nstructures in different positions in the common field of view of the two HI-1\ncameras and reconstruct the structures with CORAR method. The distributions of\nperformance levels of the reconstruction for spacecraft separation of\n$60^{\\circ}$, $90^{\\circ}$, $120^{\\circ}$ and $150^{\\circ}$ are obtained. It is\nfound that when the separation angle is $120^{\\circ}$, the performance of the\nreconstruction is the best and the separation angle of $90^{\\circ}$ is the\nnext. A brief discussion of the results are given as well. Based on this study,\nwe suggest the optimal layout scheme of the recently proposed Solar Ring\nmission, which is designed to routinely observe the Sun and the inner\nheliosphere from multiple perspectives in the ecliptic plane.\n",
      "subjects": [
        "astro-ph.SR",
        "physics.space-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jcta.2022.105699",
      "title": "Classical and consecutive pattern avoidance in rooted forests",
      "abstract": "  Following Anders and Archer, we say that an unordered rooted labeled forest\navoids the pattern $\\sigma\\in\\mathcal{S}_k$ if in each tree, each sequence of\nlabels along the shortest path from the root to a vertex does not contain a\nsubsequence with the same relative order as $\\sigma$. For each permutation\n$\\sigma\\in\\mathcal{S}_{k-2}$, we construct a bijection between $n$-vertex\nforests avoiding $(\\sigma)(k-1)k:=\\sigma(1)\\cdots\\sigma(k-2)(k-1)k$ and\n$n$-vertex forests avoiding $(\\sigma)k(k-1):=\\sigma(1)\\cdots\\sigma(k-2)k(k-1)$,\ngiving a common generalization of results of West on permutations and\nAnders--Archer on forests. We further define a new object, the forest-Young\ndiagram, which we use to extend the notion of shape-Wilf equivalence to\nforests. In particular, this allows us to generalize the above result to a\nbijection between forests avoiding $\\{(\\sigma_1)k(k-1), (\\sigma_2)k(k-1),\n\\dots, (\\sigma_\\ell)k(k-1)\\}$ and forests avoiding $\\{(\\sigma_1)(k-1)k,\n(\\sigma_2)(k-1)k, \\dots, (\\sigma_\\ell)(k-1)k\\}$ for $\\sigma_1, \\dots,\n\\sigma_\\ell \\in \\mathcal{S}_{k-2}$. Furthermore, we give recurrences\nenumerating the forests avoiding $\\{123\\cdots k\\}$, $\\{213\\}$, and other sets\nof patterns. Finally, we extend the Goulden--Jackson cluster method to study\nconsecutive pattern avoidance in rooted trees as defined by Anders and Archer.\nUsing the generalized cluster method, we prove that if two length-$k$ patterns\nare strong-c-forest-Wilf equivalent, then up to complementation, the two\npatterns must start with the same number. We also prove the surprising result\nthat the patterns $1324$ and $1423$ are strong-c-forest-Wilf equivalent, even\nthough they are not c-Wilf equivalent with respect to permutations.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Solutions of diophantine equations as periodic points of $p$-adic\n  algebraic functions, III",
      "abstract": "  All the periodic points of a certain algebraic function related to the\nRogers-Ramanujan continued fraction $r(\\tau)$ are determined. They turn out to\nbe $0, \\frac{-1 \\pm \\sqrt{5}}{2}$, and the conjugates over $\\mathbb{Q}$ of the\nvalues $r(w_d/5)$, where $w_d$ is one of a specific set of algebraic integers,\ndivisible by the square of a prime divisor of 5, in the field\n$K_d=\\mathbb{Q}(\\sqrt{-d})$, as $-d$ ranges over all negative quadratic\ndiscriminants for which $\\left(\\frac{-d}{5}\\right) = +1$. This yields new\ninsights on class numbers of orders in the fields $K_d$. Conjecture 1 of Part I\nis proved for the prime $p=5$, showing that the ring class fields over fields\nof type $K_d$ whose conductors are relatively prime to $5$ coincide with the\nfields generated over $\\mathbb{Q}$ by the periodic points (excluding -1) of a\nfixed $5$-adic algebraic function.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP11(2020)097",
      "title": "The Cosmological Phonon: Symmetries and Amplitudes on Sub-Horizon Scales",
      "abstract": "  In contrast to massless spinning particles, scalars are not heavily\nconstrained by unitarity and locality. Off-shell, no gauge symmetries are\nrequired to write down manifestly local theories, while on-shell consistent\nfactorisation is trivial. Instead a useful classification scheme for scalars is\nbased on the symmetries they can non-linearly realise. Motivated by the\nbreaking of Lorentz boosts in cosmology, in this paper we classify the possible\nsymmetries of a shift-symmetric scalar that is assumed to non-linearly realise\nLorentz boosts as, for example, in the EFT of inflation. Our classification\nmethod is algebraic; guided by the coset construction and inverse Higgs\nconstraints. We rediscover some known phonon theories within the superfluid and\ngalileid classes, and discover a new galileid theory which we call the\n$\\textit{extended galileid}$. Generic galileids correspond to the broken phase\nof galileon scalar EFTs and our extended galileids correspond to special\nsubsets where each galileon coupling is fixed by an additional symmetry. We\ndiscuss the broken phase of theories that also admit a perturbation theory\naround Poincar\\'{e} invariant vacua and we show that the so-called exceptional\nEFTs, the DBI scalar and special galileon, do not admit such a broken phase.\nConcentrating on DBI we provide a detailed account of this showing that the\nscattering amplitudes are secretly Poincar\\'{e} invariant when the theory is\nexpanded around the superfluid background used in the EFT of inflation. We\npoint out that DBI is an exception to the common lore that the residue of the\ntotal energy pole of cosmological correlators is proportional to the amplitude.\nWe also discuss the inevitability of poles in $2 \\rightarrow 2$ scattering\namplitudes when boost are spontaneously broken meaning that such theories do\nnot admit Adler zeros and generalisations even in the presence of a shift\nsymmetry.\n",
      "subjects": [
        "hep-th",
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/202038531",
      "title": "Spectral evolution of X-ray pulsar 4U 1901+03 during the 2019 outburst\n  based on Insight-HXMT and NuSTAR observations",
      "abstract": "  We report on a detailed spectral analysis of emission from X-ray pulsar 4U\n1901+03 using data obtained by the Insight-HXMT and NuSTAR observatories during\nthe 2019 outburst of the source. Thanks to the extensive coverage of the\noutburst by Insight-HXMT, we were able to investigate the spectral evolution of\nthe source as a function of flux, and compare these results to the previous\nreports, focusing on the properties of a putative absorption feature at around\n10 keV. In particular, we demonstrate that the broadband X-ray continuum of 4U\n1901+03 can be well described with a two-component continuum model without an\nabsorption line at 10 keV, which casts doubt on its interpretation as a\ncyclotron line. The high quality of the data also allowed us to perform both\nphase-averaged and phase-resolved spectral analyses as a function of\nluminosity. Finally, we performed a detailed investigation of another\nabsorption feature in the spectrum of the source around 30 keV recently\nreported in the NuSTAR data. We show that this feature appears to be\nsignificantly detected both in phase-averaged and phase-resolved spectra\nirrespective of the continuum model.\n",
      "subjects": [
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3842/SIGMA.2020.120",
      "title": "Gauss Coordinates vs Currents for the Yangian Doubles of the Classical\n  Types",
      "abstract": "  We consider relations between Gauss coordinates of $T$-operators for the\nYangian doubles of the classical types corresponding to the algebras\n$\\mathfrak{g}$ of $A$, $B$, $C$ and $D$ series and the current generators of\nthese algebras. These relations are important for the applications in the\nquantum integrable models related to $\\mathfrak{g}$-invariant $R$-matrices and\nconstruction of the Bethe vectors in these models.\n",
      "subjects": [
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/B978-0-12-409547-2.14642-6",
      "title": "Robust multivariate methods in Chemometrics",
      "abstract": "  This chapter presents an introduction to robust statistics with applications\nof a chemometric nature. Following a description of the basic ideas and\nconcepts behind robust statistics, including how robust estimators can be\nconceived, the chapter builds up to the construction (and use) of robust\nalternatives for some methods for multivariate analysis frequently used in\nchemometrics, such as principal component analysis and partial least squares.\nThe chapter then provides an insight into how these robust methods can be used\nor extended to classification. To conclude, the issue of validation of the\nresults is being addressed: it is shown how uncertainty statements associated\nwith robust estimates, can be obtained.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Extending XACC for Quantum Optimal Control",
      "abstract": "  Quantum computing vendors are beginning to open up application programming\ninterfaces for direct pulse-level quantum control. With this, programmers can\nbegin to describe quantum kernels of execution via sequences of arbitrary pulse\nshapes. This opens new avenues of research and development with regards to\nsmart quantum compilation routines that enable direct translation of\nhigher-level digital assembly representations to these native pulse\ninstructions. In this work, we present an extension to the XACC system-level\nquantum-classical software framework that directly enables this compilation\nlowering phase via user-specified quantum optimal control techniques. This\nextension enables the translation of digital quantum circuit representations to\nequivalent pulse sequences that are optimal with respect to the backend system\ndynamics. Our work is modular and extensible, enabling third party optimal\ncontrol techniques and strategies in both C++ and Python. We demonstrate this\nextension with familiar gradient-based methods like gradient ascent pulse\nengineering (GRAPE), gradient optimization of analytic controls (GOAT), and\nKrotov's method. Our work serves as a foundational component of future\nquantum-classical compiler designs that lower high-level programmatic\nrepresentations to low-level machine instructions.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1098/rstb.2019.0547",
      "title": "Anthropogenic Hybridization at Sea: three evolutionary questions\n  relevant to invasive species",
      "abstract": "  Species introductions promote secondary contacts between taxa with long\nhistories of allopatric divergence. Anthropogenic contact zones thus offer\nvaluable contrasts to speciation studies in natural systems where past spatial\nisolations may have been brief or intermittent. Investigations of anthropogenic\nhybridization are rare for marine animals, which have high fecundity and high\ndispersal ability, characteristics that contrast to most terrestrial animals.\nGenomic studies indicate that gene flow can still occur after millions of years\nof divergence, as illustrated by invasive mussels and tunicates. In this\ncontext, we highlight three issues: 1) the effects of high propagule pressure\nand demographic asymmetries on introgression directionality, 2) the role of\nhybridization in preventing introduced species spread, and 3) the importance of\npostzygotic barriers in maintaining reproductive isolation. Anthropogenic\ncontact zones offer evolutionary biologists unprecedented large scale\nhybridization experiments. In addition to breaking the highly effective\nreproductive isolating barrier of spatial segregation, they allow researchers\nto explore unusual demographic contexts with strong asymmetries. The outcomes\nare diverse from introgression swamping to strong barriers to gene flow, and\nlead to local containment or widespread invasion. These outcomes should not be\nneglected in management policies of marine invasive species.\n",
      "subjects": [
        "q-bio.PE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Actor-Context-Actor Relation Network for Spatio-Temporal Action\n  Localization",
      "abstract": "  Localizing persons and recognizing their actions from videos is a challenging\ntask towards high-level video understanding. Recent advances have been achieved\nby modeling direct pairwise relations between entities. In this paper, we take\none step further, not only model direct relations between pairs but also take\ninto account indirect higher-order relations established upon multiple\nelements. We propose to explicitly model the Actor-Context-Actor Relation,\nwhich is the relation between two actors based on their interactions with the\ncontext. To this end, we design an Actor-Context-Actor Relation Network\n(ACAR-Net) which builds upon a novel High-order Relation Reasoning Operator and\nan Actor-Context Feature Bank to enable indirect relation reasoning for\nspatio-temporal action localization. Experiments on AVA and UCF101-24 datasets\nshow the advantages of modeling actor-context-actor relations, and\nvisualization of attention maps further verifies that our model is capable of\nfinding relevant higher-order relations to support action detection. Notably,\nour method ranks first in the AVA-Kineticsaction localization task of\nActivityNet Challenge 2020, out-performing other entries by a significant\nmargin (+6.71mAP). Training code and models will be available at\nhttps://github.com/Siyu-C/ACAR-Net.\n",
      "subjects": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10701-021-00445-w",
      "title": "Appearance of Thermal Time",
      "abstract": "  In this paper a viewpoint that time is an informational and thermal entity is\nshown. We consider a model for a simple relaxation process for which a\nrelationship among event, time and temperature is mathematically formulated. It\nis then explicitly illustrated that temperature and time are statistically\ninferred through measurement of events. The probability distribution of the\nevents thus provides a mutual regulation between temperature and time, which\ncan relevantly be expressed in terms of the Fisher information metric. The\ntwo-dimensional differential geometry of temperature and time then leads us to\na finding of a simple equation for the scalar curvature, R = -1, in this case\nof relaxation process. This basic equation, in turn, may be regarded as\ncharacterizing the nonequilibrium dynamical process and having a solution given\nby the Fisher information metric. The time can then be interpreted so as to\nappear in a thermal way.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Convolutional Gaussian Embeddings for Personalized Recommendation with\n  Uncertainty",
      "abstract": "  Most of existing embedding based recommendation models use embeddings\n(vectors) corresponding to a single fixed point in low-dimensional space, to\nrepresent users and items. Such embeddings fail to precisely represent the\nusers/items with uncertainty often observed in recommender systems. Addressing\nthis problem, we propose a unified deep recommendation framework employing\nGaussian embeddings, which are proven adaptive to uncertain preferences\nexhibited by some users, resulting in better user representations and\nrecommendation performance. Furthermore, our framework adopts Monte-Carlo\nsampling and convolutional neural networks to compute the correlation between\nthe objective user and the candidate item, based on which precise\nrecommendations are achieved. Our extensive experiments on two benchmark\ndatasets not only justify that our proposed Gaussian embeddings capture the\nuncertainty of users very well, but also demonstrate its superior performance\nover the state-of-the-art recommendation models.\n",
      "subjects": [
        "cs.IR",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1361-6455/abc7ff",
      "title": "Absorption spectroscopy and Stokes polarimetry in a $^{87}$Rb vapour in\n  the Voigt geometry with a 1.5 T external magnetic field",
      "abstract": "  We present a detailed spectroscopic investigation of a thermal $^{87}$Rb\natomic vapour in a magnetic field of 1.5~T in the Voigt geometry. We fit\nexperimental spectra for all Stokes parameters with our theoretical model\n\\textit{ElecSus} and find very good quantitative agreement, with RMS errors of\n$\\sim 1.5$\\% in all cases. We extract the magnetic field strength and the angle\nbetween the polarisation of the light and the magnetic field from the atomic\nsignal, and we measure the birefringence effects of the cell windows on the\noptical rotation signals. This allows us to carry out precise measurements at a\nhigh field strength and arbitrary geometries, allowing further development of\npossible areas of application for atomic magnetometers.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Sharp Statistical Guarantees for Adversarially Robust Gaussian\n  Classification",
      "abstract": "  Adversarial robustness has become a fundamental requirement in modern machine\nlearning applications. Yet, there has been surprisingly little statistical\nunderstanding so far. In this paper, we provide the first result of the optimal\nminimax guarantees for the excess risk for adversarially robust classification,\nunder Gaussian mixture model proposed by \\cite{schmidt2018adversarially}. The\nresults are stated in terms of the Adversarial Signal-to-Noise Ratio (AdvSNR),\nwhich generalizes a similar notion for standard linear classification to the\nadversarial setting. For the Gaussian mixtures with AdvSNR value of $r$, we\nestablish an excess risk lower bound of order $\\Theta(e^{-(\\frac{1}{8}+o(1))\nr^2} \\frac{d}{n})$ and design a computationally efficient estimator that\nachieves this optimal rate. Our results built upon minimal set of assumptions\nwhile cover a wide spectrum of adversarial perturbations including $\\ell_p$\nballs for any $p \\ge 1$.\n",
      "subjects": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A $d$-dimensional Analyst's Travelling Salesman Theorem for general sets\n  in $\\mathbb{R}^n$",
      "abstract": "  In his 1990 paper, Jones proved the following: given $E \\subseteq\n\\mathbb{R}^2$, there exists a curve $\\Gamma$ such that $E \\subseteq \\Gamma$ and\n\\[ \\mathscr{H}^1(\\Gamma) \\sim \\text{diam}\\, E + \\sum_{Q}\n\\beta_{E}(3Q)^2\\ell(Q).\\] Here, $\\beta_E(Q)$ measures how far $E$ deviates from\na straight line inside $Q$. This was extended by Okikiolu to subsets of\n$\\mathbb{R}^n$ and by Schul to subsets of a Hilbert space.\n  In 2018, Azzam and Schul introduced a variant of the Jones $\\beta$-number.\nWith this, they, and separately Villa, proved similar results for lower regular\nsubsets of $\\mathbb{R}^n.$ In particular, Villa proved that, given $E \\subseteq\n\\mathbb{R}^n$ which is lower content regular, there exists a `nice'\n$d$-dimensional surface $F$ such that $E \\subseteq F$ and \\begin{align}\n\\mathscr{H}^d(F) \\sim \\text{diam}( E)^d + \\sum_{Q} \\beta_{E}(3Q)^2\\ell(Q)^d.\n\\end{align} In this context, a set $F$ is `nice' if it satisfies a certain\ntopological non degeneracy condition, first introduced in a 2004 paper of\nDavid.\n  In this paper we drop the lower regularity condition and prove an analogous\nresult for general $d$-dimensional subsets of $\\mathbb{R}^n.$ To do this, we\nintroduce a new $d$-dimensional variant of the Jones $\\beta$-number that is\ndefined for any set in $\\mathbb{R}^n.$\n",
      "subjects": [
        "math.CA",
        "math.MG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.102.104308",
      "title": "The role of intraband dynamics in the generation of circularly polarized\n  high harmonics from solids",
      "abstract": "  Recent studies have demonstrated that the polarization states of high\nharmonics from solids can differ from those of the driving pulses. To gain\ninsights on the microscopic origin of this behavior, we perform one-particle\nintraband-only calculations and reproduce some of the most striking\nobservations. For instance, our calculations yield circularly polarized\nharmonics from elliptically polarized pulses that sensitively depend on the\ndriving conditions. Furthermore, we perform experiments on ZnS and find partly\nsimilar characteristics as reported from silicon. Comparison to our\nintraband-only calculations shows reasonable qualitative agreement for a\nbelow-band-gap harmonic. We show that intraband dynamics predict depolarization\neffects for higher field strengths. For harmonics above the band gap, interband\ndynamics become important and the high-harmonic response to elliptical\nexcitation looks systematically different. Our work proposes a method to\ndistinguish between different high-harmonic generation mechanisms and it could\npave the way to compact solid-state high-harmonic sources with controllable\npolarization states.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Personalized Dynamic Treatment Regimes in Continuous Time: A Bayesian\n  Approach for Optimizing Clinical Decisions with Timing",
      "abstract": "  Accurate models of clinical actions and their impacts on disease progression\nare critical for estimating personalized optimal dynamic treatment regimes\n(DTRs) in medical/health research, especially in managing chronic conditions.\nTraditional statistical methods for DTRs usually focus on estimating the\noptimal treatment or dosage at each given medical intervention, but overlook\nthe important question of \"when this intervention should happen.\" We fill this\ngap by developing a two-step Bayesian approach to optimize clinical decisions\nwith timing. In the first step, we build a generative model for a sequence of\nmedical interventions-which are discrete events in continuous time-with a\nmarked temporal point process (MTPP) where the mark is the assigned treatment\nor dosage. Then this clinical action model is embedded into a Bayesian joint\nframework where the other components model clinical observations including\nlongitudinal medical measurements and time-to-event data conditional on\ntreatment histories. In the second step, we propose a policy gradient method to\nlearn the personalized optimal clinical decision that maximizes the patient\nsurvival by interacting the MTPP with the model on clinical observations while\naccounting for uncertainties in clinical observations learned from the\nposterior inference of the Bayesian joint model in the first step. A signature\napplication of the proposed approach is to schedule follow-up visitations and\nassign a dosage at each visitation for patients after kidney transplantation.\nWe evaluate our approach with comparison to alternative methods on both\nsimulated and real-world datasets. In our experiments, the personalized\ndecisions made by the proposed method are clinically useful: they are\ninterpretable and successfully help improve patient survival.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Feedback Enhanced Motion Planning for Autonomous Vehicles",
      "abstract": "  In this work, we address the motion planning problem for autonomous vehicles\nthrough a new lattice planning approach, called Feedback Enhanced Lattice\nPlanner (FELP). Existing lattice planners have two major limitations, namely\nthe high dimensionality of the lattice and the lack of modeling of agent\nvehicle behaviors. We propose to apply the Intelligent Driver Model (IDM) as a\nspeed feedback policy to address both of these limitations. IDM both enables\nthe responsive behavior of the agents, and uniquely determines the acceleration\nand speed profile of the ego vehicle on a given path. Therefore, only a spatial\nlattice is needed, while discretization of higher order dimensions is no longer\nrequired. Additionally, we propose a directed-graph map representation to\nsupport the implementation and execution of lattice planners. The map can\nreflect local geometric structure, embed the traffic rules adhering to the\nroad, and is efficient to construct and update. We show that FELP is more\nefficient compared to other existing lattice planners through runtime\ncomplexity analysis, and we propose two variants of FELP to further reduce the\ncomplexity to polynomial time. We demonstrate the improvement by comparing FELP\nwith an existing spatiotemporal lattice planner using simulations of a merging\nscenario and continuous highway traffic. We also study the performance of FELP\nunder different traffic densities.\n",
      "subjects": [
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.102.195152",
      "title": "Mesoscopic conductance fluctuations and noise in disordered Majorana\n  wires",
      "abstract": "  Superconducting wires with broken time-reversal and spin-rotational\nsymmetries can exhibit two distinct topological gapped phases and host bound\nMajorana states at the phase boundaries. When the wire is tuned to the\ntransition between these two phases and the gap is closed, Majorana states\nbecome delocalized leading to a peculiar critical state of the system. We study\ntransport properties of this critical state as a function of the length $L$ of\na disordered multichannel wire. Applying a non-linear supersymmetric sigma\nmodel of symmetry class D with two replicas, we identify the average\nconductance, its variance and the third cumulant in the whole range of $L$ from\nthe Ohmic limit of short wires to the regime of a broad conductance\ndistribution when $L$ exceeds the correlation length of the system. In\naddition, we calculate the average shot noise power and variance of the\ntopological index for arbitrary $L$. The general approach developed in the\npaper can also be applied to study combined effects of disorder and topology in\nwires of other symmetries.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.dis-nn",
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1155/2020/6573219",
      "title": "Weak solutions and optimal control of hemivariational evolutionary\n  Navier-Stokes equations under Rauch condition",
      "abstract": "  In this paper we consider evolutionary Navier-Stokes equations subject to the\nnonslip boundary condition together with a Clarke subdifferential relation\nbetween the dynamic pressure and the normal component of the velocity. Under\nRauch condition, we use the Galerkin approximation method and a weak\nprecompactness criteria to ensure the convergence to a desired solution.\nMoreover a control problem associated with such system of equations is studied\nwith the help of a stability result with respect to the external forces. In the\nend of this paper, a more general condition due to Z. Naniewicz, namely the\ndirectional growth condition, is considered and all the results are reexamined.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Learning-based Computer-aided Prescription Model for Parkinson's\n  Disease: A Data-driven Perspective",
      "abstract": "  In this paper, we study a novel problem: \"automatic prescription\nrecommendation for PD patients.\" To realize this goal, we first build a dataset\nby collecting 1) symptoms of PD patients, and 2) their prescription drug\nprovided by neurologists. Then, we build a novel computer-aided prescription\nmodel by learning the relation between observed symptoms and prescription drug.\nFinally, for the new coming patients, we could recommend (predict) suitable\nprescription drug on their observed symptoms by our prescription model. From\nthe methodology part, our proposed model, namely Prescription viA Learning\nlAtent Symptoms (PALAS), could recommend prescription using the multi-modality\nrepresentation of the data. In PALAS, a latent symptom space is learned to\nbetter model the relationship between symptoms and prescription drug, as there\nis a large semantic gap between them. Moreover, we present an efficient\nalternating optimization method for PALAS. We evaluated our method using the\ndata collected from 136 PD patients at Nanjing Brain Hospital, which can be\nregarded as a large dataset in PD research community. The experimental results\ndemonstrate the effectiveness and clinical potential of our method in this\nrecommendation task, if compared with other competing methods.\n",
      "subjects": [
        "cs.LG",
        "cs.CV",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Structure-Aware Network for Lane Marker Extraction with Dynamic Vision\n  Sensor",
      "abstract": "  Lane marker extraction is a basic yet necessary task for autonomous driving.\nAlthough past years have witnessed major advances in lane marker extraction\nwith deep learning models, they all aim at ordinary RGB images generated by\nframe-based cameras, which limits their performance in extreme cases, like huge\nillumination change. To tackle this problem, we introduce Dynamic Vision Sensor\n(DVS), a type of event-based sensor to lane marker extraction task and build a\nhigh-resolution DVS dataset for lane marker extraction. We collect the raw\nevent data and generate 5,424 DVS images with a resolution of 1280$\\times$800\npixels, the highest one among all DVS datasets available now. All images are\nannotated with multi-class semantic segmentation format. We then propose a\nstructure-aware network for lane marker extraction in DVS images. It can\ncapture directional information comprehensively with multidirectional slice\nconvolution. We evaluate our proposed network with other state-of-the-art lane\nmarker extraction models on this dataset. Experimental results demonstrate that\nour method outperforms other competitors. The dataset is made publicly\navailable, including the raw event data, accumulated images and labels.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Robotic Line Scan System with Adaptive ROI for Inspection of Defects\n  over Convex Free-form Specular Surfaces",
      "abstract": "  In this paper, we present a new robotic system to perform defect inspection\ntasks over free-form specular surfaces. The autonomous procedure is achieved by\na six-DOF manipulator, equipped with a line scan camera and a high-intensity\nlighting system. Our method first uses the object's CAD mesh model to implement\na K-means unsupervised learning algorithm that segments the object's surface\ninto areas with similar curvature. Then, the scanning path is computed by using\nan adaptive algorithm that adjusts the camera's ROI to observe regions with\nirregular shapes properly. A novel iterative closest point-based projection\nregistration method that robustly localizes the object in the robot's\ncoordinate frame system is proposed to deal with the blind spot problem of\nspecular objects captured by depth sensors. Finally, an image processing\npipeline automatically detects surface defects in the captured high-resolution\nimages. A detailed experimental study with a vision-guided robotic scanning\nsystem is reported to validate the proposed methodology.\n",
      "subjects": [
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s11207-020-01699-9",
      "title": "FLUKA Simulations of Pion Decay Gamma-radiation from Energetic Flare\n  Ions",
      "abstract": "  Gamma-ray continuum at > 10 MeV photon energy yields information on > 0.2 -\n0.3 GeV/nucleon ions at the Sun. We use the general-purpose Monte Carlo code\nFLUKA (FLUktuierende KAskade) to model the transport of ions injected into\nthick and thin target sources, the nuclear processes that give rise to pions\nand other secondaries and the escape of the resulting photons from the\natmosphere. We give examples of photon spectra calculated with a range of\ndifferent assumptions about the primary ion velocity distribution and the\nsource region. We show that FLUKA gives results for pion decay photon\nemissivity in agreement with previous treatments. Through the directionality of\nsecondary products, as well as Compton scattering and pair production of\nphotons prior to escaping the Sun, the predicted spectrum depends significantly\non the viewing angle. Details of the photon spectrum in the 100 MeV range may\nconstrain the angular distribution of primary ions and the depths at which they\ninteract. We display a set of thick-target spectra produced making various\nassumptions about the incident ion energy and angular distribution and the\nviewing angle. If ions are very strongly beamed downward, or ion energies do\nnot extend much above 1 GeV/nucleon, the photon spectrum is highly insensitive\nto details of the ion distribution. Under the simplest assumptions, flares\nobserved near disc centre should not display significant radiation above 1 GeV\nphoton energy. We give an example application to Fermi Large Area Telescope\ndata from the flare of 12 June 2010.\n",
      "subjects": [
        "astro-ph.HE",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Corrosion Resistance of Sulfur-Selenium Alloy Coatings",
      "abstract": "  Despite decades of research, metallic corrosion remains a long-standing\nchallenge in many engineering applications. Specifically, designing a material\nthat can resist corrosion both in abiotic as well as biotic environments\nremains elusive. Here we design a lightweight sulfur-selenium (S-Se) alloy with\nhigh stiffness and ductility that can serve as a universal corrosion-resistant\ncoating with protection efficiency of ~99.9% for steel in a wide range of\ndiverse environments. S-Se coated mild steel shows a corrosion rate that is 6-7\norders of magnitude lower than bare metal in abiotic (simulated seawater and\nsodium sulfate solution) and biotic (sulfate-reducing bacterial medium)\nenvironments. The coating is strongly adhesive and mechanically robust. We\nattribute the high corrosion resistance of the alloy in diverse environments to\nits semi-crystalline, non-porous, anti-microbial, and viscoelastic nature with\nsuperior mechanical performance, enabling it to successfully block a variety of\ndiffusing species.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.5194/npg-28-295-2021",
      "title": "Ensemble Riemannian Data Assimilation over the Wasserstein Space",
      "abstract": "  In this paper, we present an ensemble data assimilation paradigm over a\nRiemannian manifold equipped with the Wasserstein metric. Unlike the Eulerian\npenalization of error in the Euclidean space, the Wasserstein metric can\ncapture translation and difference between the shapes of square-integrable\nprobability distributions of the background state and observations -- enabling\nto formally penalize geophysical biases in state-space with non-Gaussian\ndistributions. The new approach is applied to dissipative and chaotic\nevolutionary dynamics and its potential advantages and limitations are\nhighlighted compared to the classic variational and filtering data assimilation\napproaches under systematic and random errors.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Data Requests and Scenarios for Data Design of Unobserved Events in\n  Corona-related Confusion Using TEEDA",
      "abstract": "  Due to the global violence of the novel coronavirus, various industries have\nbeen affected and the breakdown between systems has been apparent. To\nunderstand and overcome the phenomenon related to this unprecedented crisis\ncaused by the coronavirus infectious disease (COVID-19), the importance of data\nexchange and sharing across fields has gained social attention. In this study,\nwe use the interactive platform called treasuring every encounter of data\naffairs (TEEDA) to externalize data requests from data users, which is a tool\nto exchange not only the information on data that can be provided but also the\ncall for data, what data users want and for what purpose. Further, we analyze\nthe characteristics of missing data in the corona-related confusion stemming\nfrom both the data requests and the providable data obtained in the workshop.\nWe also create three scenarios for the data design of unobserved events\nfocusing on variables.\n",
      "subjects": [
        "cs.HC",
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Revealing Secrets in SPARQL Session Level",
      "abstract": "  Based on Semantic Web technologies, knowledge graphs help users to discover\ninformation of interest by using live SPARQL services. Answer-seekers often\nexamine intermediate results iteratively and modify SPARQL queries repeatedly\nin a search session. In this context, understanding user behaviors is critical\nfor effective intention prediction and query optimization. However, these\nbehaviors have not yet been researched systematically at the SPARQL session\nlevel. This paper reveals secrets of session-level user search behaviors by\nconducting a comprehensive investigation over massive real-world SPARQL query\nlogs. In particular, we thoroughly assess query changes made by users w.r.t.\nstructural and data-driven features of SPARQL queries. To illustrate the\npotentiality of our findings, we employ an application example of how to use\nour findings, which might be valuable to devise efficient SPARQL caching,\nauto-completion, query suggestion, approximation, and relaxation techniques in\nthe future.\n",
      "subjects": [
        "cs.DB",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Optimality of short-term synaptic plasticity in modelling certain\n  dynamic environments",
      "abstract": "  Biological neurons and their in-silico emulations for neuromorphic artificial\nintelligence (AI) use extraordinarily energy-efficient mechanisms, such as\nspike-based communication and local synaptic plasticity. It remains unclear\nwhether these neuronal mechanisms only offer efficiency or also underlie the\nsuperiority of biological intelligence. Here, we prove rigorously that, indeed,\nthe Bayes-optimal prediction and inference of randomly but continuously\ntransforming environments, a common natural setting, relies on short-term\nspike-timing-dependent plasticity, a hallmark of biological synapses. Further,\nthis dynamic Bayesian inference through plasticity enables circuits of the\ncerebral cortex in simulations to recognize previously unseen, highly distorted\ndynamic stimuli. Strikingly, this also introduces a biologically-modelled AI,\nthe first to overcome multiple limitations of deep learning and outperform\nartificial neural networks in a visual task. The cortical-like network is\nspiking and event-based, trained only with unsupervised and local plasticity,\non a small, narrow, and static training dataset, but achieves recognition of\nunseen, transformed, and dynamic data better than deep neural networks with\ncontinuous activations, trained with supervised backpropagation on the\ntransforming data. These results link short-term plasticity to high-level\ncortical function, suggest optimality of natural intelligence for natural\nenvironments, and repurpose neuromorphic AI from mere efficiency to\ncomputational supremacy altogether.\n",
      "subjects": [
        "cs.NE",
        "cs.CV",
        "cs.LG",
        "q-bio.NC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Categorical large cardinals and the tension between categoricity and\n  set-theoretic reflection",
      "abstract": "  Inspired by Zermelo's quasi-categoricity result characterizing the models of\nsecond-order Zermelo-Fraenkel set theory $\\text{ZFC}_2$, we investigate when\nthose models are fully categorical, characterized by the addition to\n$\\text{ZFC}_2$ either of a first-order sentence, a first-order theory, a\nsecond-order sentence or a second-order theory. Thus we mount an analysis of\nthe categorical large cardinals. This mathematical analysis leads naturally to\nphilosophical issues concerning structuralism and realism, including especially\nthe tension between categoricity and reflection. Ultimately we identify grounds\nfor the preference of noncategoricity in one's foundations.\n",
      "subjects": [
        "math.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.126.187601",
      "title": "Cooperative cluster-Jahn-Teller effect as a possible route to\n  antiferroelectricity",
      "abstract": "  We report the observation of an antipolar phase in cubic GaNb$_4$S$_8$ driven\nby an unconventional microscopic mechanism, the cooperative Jahn-Teller effect\nof Nb$_4$S$_4$ molecular clusters. The assignment of the antipolar nature is\nbased on sudden changes in the crystal structure and a strong drop of the\ndielectric constant at $T_\\mathrm{JT}=31$\\,K, also indicating the first-order\nnature of the transition. In addition, we found that local symmetry lowering\nprecedes long-range orbital ordering, implying the presence of a dynamic\nJahn-Teller effect in the cubic phase above $T_\\mathrm{JT}$. Based on the\nvariety of structural polymorphs reported in lacunar spinels, also including\nferroelectric phases, we argue that GaNb$_4$S$_8$ may be transformable to a\nferroelectric state, which would further classify the observed antipolar phase\nas antiferrolectric.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Construction of Hecke Characters for Three-dimensional CM Abelian\n  Varieties",
      "abstract": "  It is well-known for an elliptic curve with complex multiplication that the\nexistence of a $\\mathbb{Q}$-rational model is equivalent to its field of moduli\nbeing equal to $\\mathbb{Q}$, or its endomorphism ring being the ring of\nintegers of 9 possible fields ($\\ast$). Murabayashi and Umegaki proved\nanalogous results for abelian surfaces. For three dimensional CM abelian\nvarieties with rational fields of moduli, Chun narrowed down to a list of 37\npossible CM fields. In this paper, we show that his list is exact. By\nconstructing certain Hecke characters that satisfy a theorem of Shimura, we\nprove that precisely 28 isogeny classes of these abelian varieties have\n$\\mathbb{Q}$-models. Therefore the complete analogy to $(\\ast)$ fails here.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s00023-021-01079-4",
      "title": "Time-slicing approximation of Feynman path integrals on compact\n  manifolds",
      "abstract": "  We construct fundamental solutions to the time-dependent Schr\\\"odinger\nequations on compact manifolds by the time-slicing approximation of the Feynman\npath integral. We show that the iteration of short-time approximate solutions\nconverges to the fundamental solutions to the Schr\\\"odinger equations modified\nby the scalar curvature in the uniform operator topology from the Sobolev space\nto the space of square integrable functions. In order to construct the\ntime-slicing approximation by our method, we only need to consider broken paths\nconsisting of sufficiently short classical paths. We prove the convergence to\nfundamental solutions by proving two important properties of the short-time\napproximate solution, the stability and the consistency.\n",
      "subjects": [
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP01(2021)076",
      "title": "Phenomenology of vector-like leptons with Deep Learning at the Large\n  Hadron Collider",
      "abstract": "  In this paper, a model inspired by Grand Unification principles featuring\nthree generations of vector-like fermions, new Higgs doublets and a rich\nneutrino sector at the low scale is presented. Using the state-of-the-art Deep\nLearning techniques we perform the first phenomenological analysis of this\nmodel focusing on the study of new charged vector-like leptons (VLLs) and their\npossible signatures at CERN's Large Hadron Collider (LHC). In our numerical\nanalysis we consider signal events for vector-boson fusion and VLL pair\nproduction topologies, both involving a final state containing a pair of\ncharged leptons of different flavor and two sterile neutrinos that provide a\nmissing energy. We also consider the case of VLL single production where, in\naddition to a pair of sterile neutrinos, the final state contains only one\ncharged lepton. All calculated observables are provided as data sets for Deep\nLearning analysis, where a neural network is constructed, based on results\nobtained via an evolutive algorithm, whose objective is to maximise either the\naccuracy metric or the Asimov significance for different masses of the VLL.\nTaking into account the effect of the three analysed topologies, we have found\nthat the combined significance for the observation of new VLLs at the\nhigh-luminosity LHC can range from $5.7\\sigma$, for a mass of\n$1.25~\\mathrm{TeV}$, all the way up to $28\\sigma$ if the VLL mass is\n$200~\\mathrm{GeV}$. We have also shown that by the end of the LHC Run-III a\n$200~\\mathrm{GeV}$ VLL can be excluded with a confidence of $8.8$ standard\ndeviations. The results obtained show that our model can be probed well before\nthe end of the LHC operations and, in particular, providing important\nphenomenological information to constrain the energy scale at which new gauge\nsymmetries emergent from the considered Grand Unification picture can be\nmanifest.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.103.032135",
      "title": "Derivative expansion for computing critical exponents of O(N) symmetric\n  models at NNLO",
      "abstract": "  We apply the derivative expansion of the effective action in the exact\nrenormalization group equation up to fourth order to the $Z_2$ and $O(N)$\nsymmetric scalar models in $d=3$ Euclidean dimensions. We compute the critical\nexponents $\\nu$, $\\eta$ and $\\omega$ using polynomial expansion in the field.\nWe obtain our predictions for the exponents employing two regulators widely\nused in ERG computations. We apply Wynn's epsilon algorithm to improve the\npredictions for the critical exponents, extrapolating beyond the\nnext-to-next-to-leading order prediction of the derivative expansion.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Deep Sequence Learning for Video Anticipation: From Discrete and\n  Deterministic to Continuous and Stochastic",
      "abstract": "  Video anticipation is the task of predicting one/multiple future\nrepresentation(s) given limited, partial observation. This is a challenging\ntask due to the fact that given limited observation, the future representation\ncan be highly ambiguous. Based on the nature of the task, video anticipation\ncan be considered from two viewpoints: the level of details and the level of\ndeterminism in the predicted future. In this research, we start from\nanticipating a coarse representation of a deterministic future and then move\ntowards predicting continuous and fine-grained future representations of a\nstochastic process. The example of the former is video action anticipation in\nwhich we are interested in predicting one action label given a partially\nobserved video and the example of the latter is forecasting multiple diverse\ncontinuations of human motion given partially observed one. In particular, in\nthis thesis, we make several contributions to the literature of video\nanticipation...\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Survive the Schema Changes: Integration of Unmanaged Data Using Deep\n  Learning",
      "abstract": "  Data is the king in the age of AI. However data integration is often a\nlaborious task that is hard to automate. Schema change is one significant\nobstacle to the automation of the end-to-end data integration process. Although\nthere exist mechanisms such as query discovery and schema modification language\nto handle the problem, these approaches can only work with the assumption that\nthe schema is maintained by a database. However, we observe diversified schema\nchanges in heterogeneous data and open data, most of which has no schema\ndefined. In this work, we propose to use deep learning to automatically deal\nwith schema changes through a super cell representation and automatic injection\nof perturbations to the training data to make the model robust to schema\nchanges. Our experimental results demonstrate that our proposed approach is\neffective for two real-world data integration scenarios: coronavirus data\nintegration, and machine log integration.\n",
      "subjects": [
        "cs.DB",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "AEGIS: A real-time multimodal augmented reality computer vision based\n  system to assist facial expression recognition for individuals with autism\n  spectrum disorder",
      "abstract": "  The ability to interpret social cues comes naturally for most people, but for\nthose living with Autism Spectrum Disorder (ASD), some experience a deficiency\nin this area. This paper presents the development of a multimodal augmented\nreality (AR) system which combines the use of computer vision and deep\nconvolutional neural networks (CNN) in order to assist individuals with the\ndetection and interpretation of facial expressions in social settings. The\nproposed system, which we call AEGIS (Augmented-reality Expression Guided\nInterpretation System), is an assistive technology deployable on a variety of\nuser devices including tablets, smartphones, video conference systems, or\nsmartglasses, showcasing its extreme flexibility and wide range of use cases,\nto allow integration into daily life with ease. Given a streaming video camera\nsource, each real-world frame is passed into AEGIS, processed for facial\nbounding boxes, and then fed into our novel deep convolutional time windowed\nneural network (TimeConvNet). We leverage both spatial and temporal information\nin order to provide an accurate expression prediction, which is then converted\ninto its corresponding visualization and drawn on top of the original video\nframe. The system runs in real-time, requires minimal set up and is simple to\nuse. With the use of AEGIS, we can assist individuals living with ASD to learn\nto better identify expressions and thus improve their social experiences.\n",
      "subjects": [
        "cs.CV",
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stab397",
      "title": "A finite volume method for two-moment cosmic-ray hydrodynamics on a\n  moving mesh",
      "abstract": "  We present a new numerical algorithm to solve the recently derived equations\nof two-moment cosmic ray hydrodynamics (CRHD). The algorithm is implemented as\na module in the moving mesh Arepo code. Therein, the anisotropic transport of\ncosmic rays (CRs) along magnetic field lines is discretised using a\npath-conservative finite volume method on the unstructured time-dependent\nVoronoi mesh of Arepo. The interaction of CRs and gyroresonant Alfv\\'en waves\nis described by short-timescale source terms in the CRHD equations. We employ a\ncustom-made semi-implicit adaptive time stepping source term integrator to\naccurately integrate this interaction on the small light-crossing time of the\nanisotropic transport step. Both the transport and the source term integration\nstep are separated from the evolution of the magneto-hydrodynamical equations\nusing an operator split approach. The new algorithm is tested with a variety of\ntest problems, including shock tubes, a perpendicular magnetised discontinuity,\nthe hydrodynamic response to a CR overpressure, CR acceleration of a warm\ncloud, and a CR blast wave, which demonstrate that the coupling between CR and\nmagneto-hydrodynamics is robust and accurate. We demonstrate the numerical\nconvergence of the presented scheme using new linear and non-linear analytic\nsolutions.\n",
      "subjects": [
        "astro-ph.HE",
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Being Single Has Benefits. Instance Poisoning to Deceive Malware\n  Classifiers",
      "abstract": "  The performance of a machine learning-based malware classifier depends on the\nlarge and updated training set used to induce its model. In order to maintain\nan up-to-date training set, there is a need to continuously collect benign and\nmalicious files from a wide range of sources, providing an exploitable target\nto attackers. In this study, we show how an attacker can launch a sophisticated\nand efficient poisoning attack targeting the dataset used to train a malware\nclassifier. The attacker's ultimate goal is to ensure that the model induced by\nthe poisoned dataset will be unable to detect the attacker's malware yet\ncapable of detecting other malware. As opposed to other poisoning attacks in\nthe malware detection domain, our attack does not focus on malware families but\nrather on specific malware instances that contain an implanted trigger,\nreducing the detection rate from 99.23% to 0% depending on the amount of\npoisoning. We evaluate our attack on the EMBER dataset with a state-of-the-art\nclassifier and malware samples from VirusTotal for end-to-end validation of our\nwork. We propose a comprehensive detection approach that could serve as a\nfuture sophisticated defense against this newly discovered severe threat.\n",
      "subjects": [
        "cs.CR",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Learning Structured Representations of Entity Names using Active\n  Learning and Weak Supervision",
      "abstract": "  Structured representations of entity names are useful for many entity-related\ntasks such as entity normalization and variant generation. Learning the\nimplicit structured representations of entity names without context and\nexternal knowledge is particularly challenging. In this paper, we present a\nnovel learning framework that combines active learning and weak supervision to\nsolve this problem. Our experimental evaluation show that this framework\nenables the learning of high-quality models from merely a dozen or so labeled\nexamples.\n",
      "subjects": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP05(2021)071",
      "title": "The Casimir effect in the presence of infrared transparency",
      "abstract": "  We revisit the Casimir effect perceived by two surfaces in the presence of\ninfrared (IR) transparency. To address this problem, we study a model, where\nsuch a phenomenon naturally arises: the DGP model with two parallel 3-branes,\neach endowed with a localized curvature term. In that model, the UV modes of\nthe 5-dimensional graviton are suppressed on the branes, while the IR modes can\npenetrate them freely. First, we find that the DGP branes act as \"effective\"\n(momentum-dependent) boundary conditions for the gravitational field, so that\nthe (gravitational) Casimir force between them emerges. Second, we discover\nthat the presence of an IR transparency region for the discrete modes modifies\nthe standard Casimir force -- as derived for ideal Dirichlet boundary\nconditions -- in two competing ways: i) The exclusion of soft modes from the\ndiscrete spectrum leads to an increase of the Casimir force. ii) The non-ideal\nnature of the boundary conditions gives rise to a \"leakage\" of hard modes. As a\nresult of i) and ii), the Casimir force becomes weaker. Since the derivation of\nthis result involves only the localized kinetic terms of a quantum field on\nparallel surfaces (with codimension one), the derived Casimir force is expected\nto be present in a variety of setups in arbitrary dimensions.\n",
      "subjects": [
        "hep-th",
        "cond-mat.mes-hall",
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1361-6528/abd8f7",
      "title": "Giant energy storage effect in nanolayer capacitors charged by the field\n  emission tunneling",
      "abstract": "  We fabricate nanolayer alumina capacitor and apply high electric fields,\nclose to 1 GV/m, to inject charges in the dielectric. Asymmetric charge\ndistributions have been achieved due to the selectivity of the quantum\ntunneling process. Namely, the electrons cannot tunnel to a region near\ncathode, where the total energy would be less than the potential energy. This\nmechanism exhibits a strong tendency to populate charge traps located near the\nanode, i.e., the regions where their potential energy is the lowest. This\ncharge injection allows a permanent storage of the bulk charge even if the\ncapacitor plates are short-circuited, provided that the temperature is\nsufficiently low so that the conductivity of the dielectric is negligible. In\nour experiments, the total charge stored in the dielectric was up to seven and\na half times higher than the charge stored on the capacitor plates. Also,\nmeasurements of the breakdown voltage show that the breakdown electric field,\ni.e., the dielectric strength, is independent of the thickness of the\ndielectric.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tracking and Visualizing Signs of Degradation for an Early Failure\n  Prediction of a Rolling Bearing",
      "abstract": "  Predictive maintenance, i.e. predicting failure to be few steps ahead of the\nfault, is one of the pillars of Industry 4.0. An effective method for that is\nto track early signs of degradation before a failure happens. This paper\npresents an innovative failure predictive scheme for machines. The proposed\nscheme combines the use of full spectrum of the vibration data caused by the\nmachines and data visualization technologies. This scheme is featured by no\ntraining data required and by quick start after installation. First, we propose\nto use full spectrum (as high-dimensional data vector) with no cropping and no\ncomplex feature extraction and to visualize data behavior by mapping the high\ndimensional vectors into a 2D map. We then can ensure the simplicity of process\nand less possibility of overlooking of important information as well as\nproviding a human-friendly and human-understandable output. Second, we propose\nReal-Time Data Tracker (RTDT) which predicts the failure at an appropriate time\nwith sufficient time for maintenance by plotting real-time frequency spectrum\ndata of the target machine on the 2D map composed from normal data. Third, we\nshow the test results of our proposal using vibration data of bearings from\nreal-world test-to-failure measurements provided by the public dataset, the IMS\ndataset.\n",
      "subjects": [
        "cs.RO",
        "cs.LG",
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Hop-Constrained Oblivious Routing",
      "abstract": "  We prove the existence of an oblivious routing scheme that is\n$\\mathrm{poly}(\\log n)$-competitive in terms of $(congestion + dilation)$, thus\nresolving a well-known question in oblivious routing.\n  Concretely, consider an undirected network and a set of packets each with its\nown source and destination. The objective is to choose a path for each packet,\nfrom its source to its destination, so as to minimize $(congestion +\ndilation)$, defined as follows: The dilation is the maximum path hop-length,\nand the congestion is the maximum number of paths that include any single edge.\nThe routing scheme obliviously and randomly selects a path for each packet\nindependent of (the existence of) the other packets. Despite this\nobliviousness, the selected paths have $(congestion + dilation)$ within a\n$\\mathrm{poly}(\\log n)$ factor of the best possible value. More precisely, for\nany integer hop-bound $h$, this oblivious routing scheme selects paths of\nlength at most $h \\cdot \\mathrm{poly}(\\log n)$ and is $\\mathrm{poly}(\\log\nn)$-competitive in terms of $congestion$ in comparison to the best possible\n$congestion$ achievable via paths of length at most $h$ hops. These paths can\nbe sampled in polynomial time.\n  This result can be viewed as an analogue of the celebrated oblivious routing\nresults of R\\\"{a}cke [FOCS 2002, STOC 2008], which are $O(\\log n)$-competitive\nin terms of $congestion$, but are not competitive in terms of $dilation$.\n",
      "subjects": [
        "cs.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Towards Mass Adoption of Contact Tracing Apps -- Learning from Users'\n  Preferences to Improve App Design",
      "abstract": "  Contact tracing apps have become one of the main approaches to control and\nslow down the spread of COVID-19 and ease up lockdown measures. While these\napps can be very effective in stopping the transmission chain and saving lives,\ntheir adoption remains under the expected critical mass. The public debate\nabout contact tracing apps emphasizes general privacy reservations and is\nconducted at an expert level, but lacks the user perspective related to actual\ndesigns. To address this gap, we explore user preferences for contact tracing\napps using market research techniques, and specifically conjoint analysis. Our\nmain contributions are empirical insights into individual and group\npreferences, as well as insights for prescriptive design. While our results\nconfirm the privacy-preserving design of most European contact tracing apps,\nthey also provide a more nuanced understanding of acceptable features. Based on\nmarket simulation and variation analysis, we conclude that adding\ngoal-congruent features will play an important role in fostering mass adoption.\n",
      "subjects": [
        "cs.CR",
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.125.225504",
      "title": "Nondestructive Prediction of the Buckling Load of Imperfect Shells",
      "abstract": "  From soda cans to space rockets, thin-walled cylindrical shells are abundant,\noffering exceptional load carrying capacity at relatively low weight. However,\nthe actual load at which any shell buckles and collapses is very sensitive to\nimperceptible defects and can not be predicted, which challenges the reliable\ndesign of such structures. Consequently, probabilistic descriptions in terms of\nempirical design rules are used and reliable design requires to be very\nconservative. We introduce a nonlinear description where finite-amplitude\nperturbations trigger buckling. Drawing from the analogy between imperfect\nshells which buckle and imperfect pipe flow which becomes turbulent, we\nexperimentally show that lateral probing of cylindrical shells reveals their\nstrength non-destructively. A new ridge-tracking method is applied to\ncommercial cylinders with a hole showing that when the location where buckling\nis nucleated is known we can accurately predict the buckling load of each\nindividual shell, within $\\pm 5\\%$. Our study provides a new promising\nframework to understand shell buckling, and more generally,\nimperfection-sensitive instabilities.\n",
      "subjects": [
        "physics.app-ph",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Unified Structure for Efficient RGB and RGB-D Salient Object Detection",
      "abstract": "  Salient object detection (SOD) has been well studied in recent years,\nespecially using deep neural networks. However, SOD with RGB and RGB-D images\nis usually treated as two different tasks with different network structures\nthat need to be designed specifically. In this paper, we proposed a unified and\nefficient structure with a cross-attention context extraction (CRACE) module to\naddress both tasks of SOD efficiently. The proposed CRACE module receives and\nappropriately fuses two (for RGB SOD) or three (for RGB-D SOD) inputs. The\nsimple unified feature pyramid network (FPN)-like structure with CRACE modules\nconveys and refines the results under the multi-level supervisions of saliency\nand boundaries. The proposed structure is simple yet effective; the rich\ncontext information of RGB and depth can be appropriately extracted and fused\nby the proposed structure efficiently. Experimental results show that our\nmethod outperforms other state-of-the-art methods in both RGB and RGB-D SOD\ntasks on various datasets and in terms of most metrics.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.103.022321",
      "title": "Enhanced robustness of single-layer networks with redundant dependencies",
      "abstract": "  Dependency links in single-layer networks offer a convenient way of modeling\nnonlocal percolation effects in networked systems where certain pairs of nodes\nare only able to function together. We study the percolation properties of the\nweak variant of this model: nodes with dependency neighbours may continue to\nfunction if at least one of their dependency neighbours is active. We show that\nthis relaxation of the dependency rule allows for more robust structures and a\nrich variety of critical phenomena, as percolation is not determined strictly\nby finite dependency clusters. We study Erd\\\"os-R\\'enyi and random scale-free\nnetworks with an underlying Erd\\\"os-R\\'enyi network of dependency links. We\nidentify a special \"cusp\" point above which the system is always stable,\nirrespective of the density of dependency links. We find continuous and\ndiscontinuous hybrid percolation transitions, separated by a tricritical point\nfor Erd\\\"os-R\\'enyi networks. For scale-free networks with a finite degree\ncutoff we observe the appearance of a critical point and corresponding double\ntransitions in a certain range of the degree distribution exponent. We show\nthat at a special point in the parameter space, where the critical point\nemerges, the giant viable cluster has the unusual critical singularity $S-S_c\n\\propto (p-p_c)^{1/4}$. We study the robustness of networks where connectivity\ndegrees and dependency degrees are correlated and find that scale-free networks\nare able to retain their high resilience for strong enough positive\ncorrelation, i.e., when hubs are protected by greater redundancy.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Statistical techniques to estimate the SARS-CoV-2 infection fatality\n  rate",
      "abstract": "  The determination of the infection fatality rate (IFR) for the novel\nSARS-CoV-2 coronavirus is a key aim for many of the field studies that are\ncurrently being undertaken in response to the pandemic. The IFR together with\nthe basic reproduction number $R_0$, are the main epidemic parameters\ndescribing severity and transmissibility of the virus, respectively. The IFR\ncan be also used as a basis for estimating and monitoring the number of\ninfected individuals in a population, which may be subsequently used to inform\npolicy decisions relating to public health interventions and lockdown\nstrategies. The interpretation of IFR measurements requires the calculation of\nconfidence intervals. We present a number of statistical methods that are\nrelevant in this context and develop an inverse problem formulation to\ndetermine correction factors to mitigate time-dependent effects that can lead\nto biased IFR estimates. We also review a number of methods to combine IFR\nestimates from multiple independent studies, provide example calculations\nthroughout this note and conclude with a summary and \"best practice\"\nrecommendations. The developed code is available online.\n",
      "subjects": [
        "stat.AP",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Constrained motion design with distinct actuators and motion\n  stabilization",
      "abstract": "  The design of adaptive structures is one method to improve sustainability of\nbuildings. Adaptive structures are able to adapt to different loading and\nenvironmental conditions or to changing requirements by either small or large\nshape changes. In the latter case, also the mechanics and properties of the\ndeformation process play a role for the structure's energy efficiency. The\nmethod of variational motion design, previously developed in the group of the\nauthors, allows to identify deformation paths between two given geometrical\nconfigurations that are optimal with respect to a defined quality function. In\na preliminary, academic setting this method assumes that every single degree of\nfreedom is accessible to arbitrary external actuation forces that realize the\noptimized motion. These (nodal) forces can be recovered a posteriori. The\npresent contribution deals with an extension of the method of motion design by\nthe constraint that the motion is to be realized by a predefined set of\nactuation forces. These can be either external forces or prescribed length\nchances of discrete, internal actuator elements. As an additional constraint,\nstatic stability of each intermediate configuration during the motion is taken\ninto account. It can be accomplished by enforcing a positive determinant of the\nstiffness matrix.\n",
      "subjects": [
        "cs.CE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.103.125011",
      "title": "Two-Loop Scalar Kinks",
      "abstract": "  At one loop, quantum kinks are described by a sum of quantum harmonic\noscillator Hamiltonians, and the ground state is just the product of the\noscillator ground states. Two-loop kink masses are only known in integrable and\nsupersymmetric cases and two-loop states have never been found. We find the\ntwo-loop kink mass and explicitly construct the two-loop kink ground state in a\nscalar field theory with an arbitrary nonderivative potential. We use a\ncoherent state operator which maps the vacuum sector to the kink sector,\nallowing all states to be treated with a single Hamiltonian which needs to be\nrenormalized only once, eliminating the need for regulator matching conditions.\nOur calculation is greatly simplified by a recently introduced alternative to\ncollective coordinates, in which the kink momentum is fixed perturbatively.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.103.063524",
      "title": "The DFSZ axion in the CMB",
      "abstract": "  We perform for the first time a dedicated analysis of cosmological\nconstraints on DFSZ QCD axion models. Such constructions are especially\ninteresting in light of the recent Xenon-1T excess and of hints from stellar\ncooling. In DFSZ models, for $m_a\\gtrsim 0.1$ eV, scatterings of pions and\nmuons can produce a sizable cosmic background of thermal axions, that behave\nsimilarly to massive neutrinos. However, the pion coupling depends on the\nalignment between the vevs of two Higgs doublets, and can be significantly\nsuppressed or enhanced with respect to the KSVZ scenario. Using the latest\nPlanck and BAO data, we find $m_a\\leq 0.2~\\text{eV}$ at $95\\%$ C.L., when the\naxion coupling to pions $c_{a\\pi}$ is maximal. Constraints on $m_a$, instead,\ncan be significantly relaxed when $c_{a\\pi}$ is small. In particular, we point\nout that in the so-called DFSZ-II model, where the axion coupling to leptons\ndoes not vanish simultaneously with $c_{a\\pi}$, production via muons gives\n$m_a\\leq 0.6~\\text{eV}$ at $95\\%$ C.L., whereas in the DFSZ-I model bounds on\n$m_a$ can be fully lifted. We then combine cosmological data with recent hints\nof a DFSZ axion coupled to electrons from the Xenon-1T experiment, finding in\nthis case that the axion mass is constrained to be in the window $0.07\n~\\text{eV} \\lesssim m_a \\lesssim 1.8\\, (0.3)~\\text{eV}$ for the DFSZ-I\n(DFSZ-II) model. A similar analysis with stellar cooling hints gives $3\n~\\text{meV} \\lesssim m_a \\lesssim 0.2 ~\\text{eV}$ for DFSZ-II, while no\nconstraint arises in the DFSZ-I case. Forthcoming CMB Stage 4 experiments will\nbe able to further test such scenarios; for instance the Xenon-1T window should\nbe fully probed at $2\\sigma$ for a DFSZ-I axion.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.103.064034",
      "title": "Thermodynamics of Kerr-AdS black holes in general Poincar\\'e gauge\n  theory",
      "abstract": "  A Hamiltonian variational approach is used to study asymptotic charges and\nentropy of Kerr-AdS black holes in the general Poincar\\'e gauge theory, with\nboth even and odd parity modes. The results turn out to be the same as those\nfound earlier in the sector of parity invariant Lagrangians.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "IFGAN: Missing Value Imputation using Feature-specific Generative\n  Adversarial Networks",
      "abstract": "  Missing value imputation is a challenging and well-researched topic in data\nmining. In this paper, we propose IFGAN, a missing value imputation algorithm\nbased on Feature-specific Generative Adversarial Networks (GAN). Our idea is\nintuitive yet effective: a feature-specific generator is trained to impute\nmissing values, while a discriminator is expected to distinguish the imputed\nvalues from observed ones. The proposed architecture is capable of handling\ndifferent data types, data distributions, missing mechanisms, and missing\nrates. It also improves post-imputation analysis by preserving inter-feature\ncorrelations. We empirically show on several real-life datasets that IFGAN\noutperforms current state-of-the-art algorithm under various missing\nconditions.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification",
      "abstract": "  Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "SoS Degree Reduction with Applications to Clustering and Robust Moment\n  Estimation",
      "abstract": "  We develop a general framework to significantly reduce the degree of\nsum-of-squares proofs by introducing new variables. To illustrate the power of\nthis framework, we use it to speed up previous algorithms based on\nsum-of-squares for two important estimation problems, clustering and robust\nmoment estimation. The resulting algorithms offer the same statistical\nguarantees as the previous best algorithms but have significantly faster\nrunning times. Roughly speaking, given a sample of $n$ points in dimension $d$,\nour algorithms can exploit order-$\\ell$ moments in time $d^{O(\\ell)}\\cdot\nn^{O(1)}$, whereas a naive implementation requires time $(d\\cdot n)^{O(\\ell)}$.\nSince for the aforementioned applications, the typical sample size is\n$d^{\\Theta(\\ell)}$, our framework improves running times from $d^{O(\\ell^2)}$\nto $d^{O(\\ell)}$.\n",
      "subjects": [
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.13140/RG.2.2.29888.35841",
      "title": "A Julia implementation of Algorithm NCL for constrained optimization",
      "abstract": "  Algorithm NCL is designed for general smooth optimization problems where\nfirst and second derivatives are available, including problems whose\nconstraints may not be linearly independent at a solution (i.e., do not satisfy\nthe LICQ). It is equivalent to the LANCELOT augmented Lagrangian method,\nreformulated as a short sequence of nonlinearly constrained subproblems that\ncan be solved efficiently by IPOPT and KNITRO, with warm starts on each\nsubproblem. We give numerical results from a Julia implementation of Algorithm\nNCL on tax policy models that do not satisfy the LICQ, and on nonlinear\nleast-squares problems and general problems from the CUTEst test set.\n",
      "subjects": [
        "math.OC",
        "cs.MS",
        "cs.NA",
        "math.NA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10618-021-00809-w",
      "title": "Synwalk -- Community Detection via Random Walk Modelling",
      "abstract": "  Complex systems, abstractly represented as networks, are ubiquitous in\neveryday life. Analyzing and understanding these systems requires, among\nothers, tools for community detection. As no single best community detection\nalgorithm can exist, robustness across a wide variety of problem settings is\ndesirable. In this work, we present Synwalk, a random walk-based community\ndetection method. Synwalk builds upon a solid theoretical basis and detects\ncommunities by synthesizing the random walk induced by the given network from a\nclass of candidate random walks. We thoroughly validate the effectiveness of\nour approach on synthetic and empirical networks, respectively, and compare\nSynwalk's performance with the performance of Infomap and Walktrap. Our results\nindicate that Synwalk performs robustly on networks with varying mixing\nparameters and degree distributions. We outperform Infomap on networks with\nhigh mixing parameter, and Infomap and Walktrap on networks with many small\ncommunities and low average degree. Our work has a potential to inspire further\ndevelopment of community detection via synthesis of random walks and we provide\nconcrete ideas for future research.\n",
      "subjects": [
        "cs.SI",
        "cs.LG",
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/NCA51143.2020.9306721",
      "title": "Personal Data Access Control Through Distributed Authorization",
      "abstract": "  This paper presents an architecture of a Personal Information Management\nSystem, in which individuals can define the access to their personal data by\nmeans of smart contracts. These smart contracts, running on the Ethereum\nblockchain, implement access control lists and grant immutability, traceability\nand verifiability of the references to personal data, which is stored itself in\na (possibly distributed) file system. A distributed authorization mechanism is\ndevised, where trust from multiple network nodes is necessary to grant the\naccess to the data. To this aim, two possible alternatives are described: a\nSecret Sharing scheme and Threshold Proxy Re-Encryption scheme. The performance\nof these alternatives is experimentally compared in terms of execution time.\nThreshold Proxy Re-Encryption appears to be faster in different scenarios, in\nparticular when increasing message size, number of nodes and the threshold\nvalue, i.e. number of nodes needed to grant the data disclosure.\n",
      "subjects": [
        "cs.CR",
        "cs.DC",
        "cs.NI",
        "cs.PF"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nonparametric Analysis of Delayed Treatment Effects using\n  Single-Crossing Constraints",
      "abstract": "  Clinical trials involving novel immuno-oncology (IO) therapies frequently\nexhibit survival profiles which violate the proportional hazards assumption due\nto a delay in treatment effect, and in such settings, the survival curves in\nthe two treatment arms may have a crossing before the two curves eventually\nseparate. To flexibly model such scenarios, we describe a nonparametric\napproach for estimating the treatment arm-specific survival functions which\nconstrains these two survival functions to cross at most once without making\nany additional assumptions about how the survival curves are related. A main\nadvantage of our approach is that it provides an estimate of a crossing time if\nsuch a crossing exists, and moreover, our method generates interpretable\nmeasures of treatment benefit including crossing-conditional survival\nprobabilities and crossing-conditional estimates of restricted residual mean\nlife. We demonstrate the use and effectiveness of our approach with a large\nsimulation study and an analysis of reconstructed outcomes from a recent\ncombination-therapy trial.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Decentralized Joint Beamforming, User Scheduling and QoS Management in\n  5G and Beyond Systems",
      "abstract": "  Fifth generation cellular systems support a broad range of services,\nincluding mobile broadband, critical and massive Internet of Things and are\nused in a variety of scenarios. In many of these scenarios, the main challenge\nis maintaining high throughput and ensuring proper quality of service (QoS) in\nirregular topologies. In multiple input multiple output systems, this challenge\ntranslates to designing linear transmit and receive beamformers that maximize\nthe system throughput and manage QoS constraints. In this paper, we argue that\nthis basic design task in 5G and beyond systems must be extended such that\nbeamforming design and user scheduling are managed jointly. Specifically, we\npropose a fully decentralized joint beamforming design and user scheduling\nalgorithm that manages QoS. A novel feature of this scheme is its ability to\nreduce the initial rate requirements in case of infeasibility. By means of\nsimulations that model contemporary 5G scenarios, we show that the proposed\ndecentralized scheme outperforms benchmarking algorithms that do not support\nminimum rate requirements and previously proposed algorithms that support QoS\nrequirements.\n",
      "subjects": [
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Decoding Event-related Potential from Ear-EEG Signals based on Ensemble\n  Convolutional Neural Networks in Ambulatory Environment",
      "abstract": "  Recently, practical brain-computer interface is actively carried out,\nespecially, in an ambulatory environment. However, the electroencephalography\n(EEG) signals are distorted by movement artifacts and electromyography signals\nwhen users are moving, which make hard to recognize human intention. In\naddition, as hardware issues are also challenging, ear-EEG has been developed\nfor practical brain-computer interface and has been widely used. In this paper,\nwe proposed ensemble-based convolutional neural networks in ambulatory\nenvironment and analyzed the visual event-related potential responses in scalp-\nand ear-EEG in terms of statistical analysis and brain-computer interface\nperformance. The brain-computer interface performance deteriorated as 3-14%\nwhen walking fast at 1.6 m/s. The proposed methods showed 0.728 in average of\nthe area under the curve. The proposed method shows robust to the ambulatory\nenvironment and imbalanced data as well.\n",
      "subjects": [
        "cs.HC",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Interpretable Artificial Intelligence through the Lens of Feature\n  Interaction",
      "abstract": "  Interpretation of deep learning models is a very challenging problem because\nof their large number of parameters, complex connections between nodes, and\nunintelligible feature representations. Despite this, many view\ninterpretability as a key solution to trustworthiness, fairness, and safety,\nespecially as deep learning is applied to more critical decision tasks like\ncredit approval, job screening, and recidivism prediction. There is an\nabundance of good research providing interpretability to deep learning models;\nhowever, many of the commonly used methods do not consider a phenomenon called\n\"feature interaction.\" This work first explains the historical and modern\nimportance of feature interactions and then surveys the modern interpretability\nmethods which do explicitly consider feature interactions. This survey aims to\nbring to light the importance of feature interactions in the larger context of\nmachine learning interpretability, especially in a modern context where deep\nlearning models heavily rely on feature interactions.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.105.035405",
      "title": "Layer Coherent Phase in Double Layer graphene at $\\nu^{}_1=\\nu^{}_2=0$",
      "abstract": "  In the recent advancement in graphene heterostructures, it is possible to\ncreate a double layer tunnel decoupled graphene system that has a strong\ninterlayer electronic interaction. In this work, we restrict the parameters in\nthe low energy effective Hamiltonian using simple symmetry arguments. Then, we\nstudy the ground state of this system in the Hartree-Fock approximation at\n$\\nu^{}_1=\\nu^{}_2=0$. In addition to the phases found in monolayer graphene,\nwe found an existence of layer coherent phase which breaks the layer $U(1)$\nsymmetry. At non-zero Zeeman coupling strength ($E^{}_z$), this layer coherent\nstate has a small magnetization, that vanishes when $E^{}_z$ tends to zero. We\ndiscuss the bulk gapless modes using the Goldstone theorem. We also comment on\nthe edge structure for the layer coherent phase.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.13140/RG.2.2.18142.15680",
      "title": "Scalable adaptive cubic regularization methods",
      "abstract": "  Adaptive cubic regularization (ARC) methods for unconstrained optimization\ncompute steps from linear systems involving a shifted Hessian in the spirit of\nthe Levenberg-Marquardt and trust-region methods. The standard approach\nconsists in performing an iterative search for the shift akin to solving the\nsecular equation in trust-region methods. Such search requires computing the\nCholesky factorization of a tentative shifted Hessian at each iteration, which\nlimits the size of problems that can be reasonably considered. We propose a\nscalable implementation of ARC named ARCqK in which we solve a set of shifted\nsystems concurrently by way of an appropriate modification of the Lanczos\nformulation of the conjugate gradient (CG) method. At each iteration of ARCqK\nto solve a problem with n variables, a range of m << n shift parameters is\nselected. The computational overhead in CG beyond the Lanczos process is\nthirteen scalar operations to update five vectors of length m and two n-vector\nupdates for each value of the shift. The CG variant only requires one\nHessian-vector product and one dot product per iteration, independently of the\nnumber of shift parameters. Solves corresponding to inadequate shift parameters\nare interrupted early. All shifted systems are solved inexactly. Such modest\ncost makes our implementation scalable and appropriate for large-scale\nproblems. We provide a new analysis of the inexact ARC method including its\nworst case evaluation complexity, global and asymptotic convergence. We\ndescribe our implementation and provide preliminary numerical observations that\nconfirm that for problems of size at least 100, our implementation of ARCqK is\nmore efficient than a classic Steihaug-Toint trust region method. Finally, we\ngeneralize our convergence results to inexact Hessians and nonlinear\nleast-squares problems.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3447818.3460364",
      "title": "FT-BLAS: A High Performance BLAS Implementation With Online Fault\n  Tolerance",
      "abstract": "  Basic Linear Algebra Subprograms (BLAS) is a core library in scientific\ncomputing and machine learning. This paper presents FT-BLAS, a new\nimplementation of BLAS routines that not only tolerates soft errors on the fly,\nbut also provides comparable performance to modern state-of-the-art BLAS\nlibraries on widely-used processors such as Intel Skylake and Cascade Lake. To\naccommodate the features of BLAS, which contains both memory-bound and\ncomputing-bound routines, we propose a hybrid strategy to incorporate fault\ntolerance into our brand-new BLAS implementation: duplicating computing\ninstructions for memory-bound Level-1 and Level-2 BLAS routines and\nincorporating an Algorithm-Based Fault Tolerance mechanism for computing-bound\nLevel-3 BLAS routines. Our high performance and low overhead are obtained from\ndelicate assembly-level optimization and a kernel-fusion approach to the\ncomputing kernels. Experimental results demonstrate that FT-BLAS offers high\nreliability and high performance -- faster than Intel MKL, OpenBLAS, and BLIS\nby up to 3.50%, 22.14% and 21.70%, respectively, for routines spanning all\nthree levels of BLAS we benchmarked, even under hundreds of errors injected per\nminute.\n",
      "subjects": [
        "cs.DC",
        "cs.PF"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/abf5de",
      "title": "The influence of the secular perturbation of an intermediate-mass\n  companion: II. Ejection of hypervelocity stars from the Galactic Center",
      "abstract": "  There is a population of stars with velocities in excess of 500 km s$^{-1}$\nrelative to the Galactic center. Many, perhaps most, of these hyper-velocity\nstars (HVSs) are B stars, similar to the disk and S stars in a nuclear cluster\naround a super-massive black hole (SMBH) near $\\rm Sgr~A^{\\star}$. In the paper\nI of this series, we showed that the eccentricity of the stars emerged from a\nhypothetical disk around the SMBH can be rapidly excited by the secular\nperturbation of its intermediate-mass companion (IMC), and we suggested IRS 13E\nas a potential candidate for the IMC. Here, we show that this process leads to\nan influx of stars on parabolic orbits to the proximity of $\\rm Sgr~A^{\\star}$\non a secular timescale of a few Myr. This timescale is much shorter than the\ndiffusion timescale into the lost cone through either the classical or the\nresonant relaxation. Precession of the highly-eccentric stars' longitude of\nperiastron, relative to that of the IMC, brings them to its proximity within a\nfew Myr. The IMC's gravitational perturbation scatters a fraction of the stars\nfrom nearly parabolic to hyperbolic orbits, with respect to the SMBH. Their\nfollow-up close encounters with the SMBH induce them to escape with\nhyper-velocity. This scenario is a variant of the hypothesis proposed by Hills\nbased on the anticipated breakup of some progenitor binary stars in the\nproximity of the SMBH, and its main objective is to account for the limited\nlifespan of the known HVSs. We generalize our previous numerical simulations of\nthis process with a much wider range of orbital configurations. We demonstrate\nthe robustness and evaluate the efficiency of this channel of HVS formation.\nFrom these numerical simulations, we infer observable kinematic properties for\nthe HVSs.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.automatica.2022.110684",
      "title": "Safe Exploration in Model-based Reinforcement Learning using Control\n  Barrier Functions",
      "abstract": "  This paper develops a model-based reinforcement learning (MBRL) framework for\nlearning online the value function of an infinite-horizon optimal control\nproblem while obeying safety constraints expressed as control barrier functions\n(CBFs). Our approach is facilitated by the development of a novel class of\nCBFs, termed Lyapunov-like CBFs (LCBFs), that retain the beneficial properties\nof CBFs for developing minimally-invasive safe control policies while also\npossessing desirable Lyapunov-like qualities such as positive\nsemi-definiteness. We show how these LCBFs can be used to augment a\nlearning-based control policy to guarantee safety and then leverage this\napproach to develop a safe exploration framework in a MBRL setting. We\ndemonstrate that our approach can handle more general safety constraints than\ncomparative methods via numerical examples.\n",
      "subjects": [
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP06(2021)169",
      "title": "Composing Effective Prediction at Five Points",
      "abstract": "  Color-kinematics duality in the adjoint has proven key to the relationship\nbetween gauge and gravity theory scattering amplitude predictions. In recent\nwork, we demonstrated that at four-point tree-level, a small number of\ncolor-dual EFT building blocks could encode all higher-derivative single-trace\nmassless corrections to gauge and gravity theories compatible with adjoint\ndouble-copy. One critical aspect was the trivialization of building\nhigher-derivative color-weights -- indeed, it is the mixing of kinematics with\nnon-adjoint-type color-weights (like the permutation-invariant d^4) which\npermits description via adjoint double-copy. Here we find that such ideas\nclarify the predictions of local five-point higher-dimensional operators as\nwell. We demonstrate how a single scalar building block can be combined with\ncolor structures to build higher-derivative color factors that generate,\nthrough double copy, the predictions of higher-derivative gauge-theory\noperators. These may then be suitably mapped, through another double-copy, to\nhigher-derivative corrections in gravity.\n",
      "subjects": [
        "hep-th",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Least Squares with Error in Variables",
      "abstract": "  Error-in-variables regression is a common ingredient in treatment effect\nestimators using panel data. This includes synthetic control estimators,\ncounterfactual time series forecasting estimators, and combinations. We study\nhigh-dimensional least squares with correlated error-in-variables with a focus\non these uses. We use our results to derive conditions under which the\nsynthetic control estimator is asymptotically unbiased and normal with\nestimable variance, permitting inference without assuming time-stationarity,\nunit-exchangeability, or the absence of weak factors. These results hold in an\nasymptotic regime in which the number of pre-treatment periods goes to infinity\nand the number of control units can be much larger $(p \\gg n)$.\n",
      "subjects": [
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "General Tail Bounds for Random Tensors Summation: Majorization Approach",
      "abstract": "  In recent years, tensors have been applied to different applications in\nscience and engineering fields. In order to establish theory about tail bounds\nof the tensors summation behavior, this work extends previous work by\nconsidering the tensors summation tail behavior of the top $k$-largest singular\nvalues of a function of the tensors summation, instead of the largest/smallest\nsingular value of the tensors summation directly (identity function) explored\nin Shih Yu's work: Convenient tail bounds for sums of random tensors.\nMajorization and antisymmetric tensor product tools are main techniques\nutilized to establish inequalities for unitarily norms of multivariate tensors.\nThe Laplace transform method is integrated with these inequalities for\nunitarily norms of multivariate tensors to give us tail bounds estimation for\nKy Fan $k$-norm for a function of the tensors summation. By restricting\ndifferent random tensor conditions, we obtain generalized tensor Chernoff and\nBernstein inequalities.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Total Coloring and Total Matching: Polyhedra and Facets",
      "abstract": "  A total coloring of a graph $G = (V, E)$ is an assignment of colors to\nvertices and edges such that neither two adjacent vertices nor two incident\nedges get the same color, and, for each edge, the end-points and the edge\nitself receive different colors. Any valid total coloring induces a partition\nof the elements of $G$ into total matchings, which are defined as subsets of\nvertices and edges that can take the same color. In this paper, we propose\nInteger Linear Programming models for both the Total Coloring and the Total\nMatching problems, and we study the strength of the corresponding Linear\nProgramming relaxations. The total coloring is formulated as the problem of\nfinding the minimum number of total matchings that cover all the graph\nelements. This covering formulation can be solved by a Column Generation\nalgorithm, where the pricing subproblem corresponds to the Weighted Total\nMatching Problem. Hence, we study the Total Matching Polytope. We introduce\nthree families of nontrivial valid inequalities: vertex-clique inequalities\nbased on standard clique inequalities of the Stable Set Polytope,\ncongruent-$2k3$ cycle inequalities based on the parity of the vertex set\ninduced by the cycle, and even-clique inequalities induced by complete\nsubgraphs of even order. We prove that congruent-$2k3$ cycle inequalities are\nfacet-defining only when $k = 4$, while the vertex-clique and even-cliques are\nalways facet-defining. Finally, we present preliminary computational results of\na Column Generation algorithm for the Total Coloring Problem and a Cutting\nPlane algorithm for the Total Matching Problem.\n",
      "subjects": [
        "cs.DM",
        "math.CO",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Optimal system design for energy communities in multi-family buildings:\n  the case of the German Tenant Electricity Law",
      "abstract": "  Involving residential actors in the energy transition is crucial for its\nsuccess. Local energy generation, consumption and trading are identified as\ndesirable forms of involvement, especially in energy communities. The\npotentials for energy communities in the residential building stock are high\nbut are largely untapped in multi-family buildings. In many countries, rapidly\nevolving legal frameworks aim at overcoming related barriers, e.g. ownership\nstructures, principal-agent problems and system complexity. But academic\nliterature is scarce regarding the techno-economic and environmental\nimplications of such complex frameworks. This paper develops a mixed-integer\nlinear program (MILP) optimisation model for assessing the implementation of\nmulti-energy systems in an energy community in multi-family buildings with a\nspecial distinction between investor and user. The model is applied to the\nGerman Tenant Electricity Law. Based on hourly demands from appliances, heating\nand electric vehicles, the optimal energy system layout and dispatch are\ndetermined. The results contain a rich set of performance indicators that\ndemonstrate how the legal framework affects the technologies' interdependencies\nand economic viability of multi-energy system energy communities. Certain\neconomic technology combinations may fail to support national emissions\nmitigation goals and lead to lock-ins in Europe's largest residential building\nstock. The subsidies do not lead to the utilisation of a battery storage.\nDespite this, self-sufficiency ratios of more than 90% are observable for\nsystems with combined heat and power plants and heat pumps. Public CO2\nmitigation costs range between 147.5-272.8 EUR/tCO2. Finally, the results show\nthe strong influence of the heat demand on the system layout.\n",
      "subjects": [
        "econ.GN",
        "q-fin.EC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.104.044324",
      "title": "Evolution of octupole deformation and collectivity in neutron-rich\n  lanthanides",
      "abstract": "  The onset of octupole deformation and its impact on related spectroscopic\nproperties is studied in even-even neutron-rich lanthanide isotopes Xe, Ba, Ce,\nand Nd with neutron number $86\\leqslant N\\leqslant 94$. Microscopic input comes\nfrom the Hartree-Fock-Bogoliubov approximation with constrains on the axially\nsymmetric quadrupole and octupole operators using the Gogny-D1M interaction. At\nthe mean-field level, reflection asymmetric ground states are predicted for\nisotopes with neutron number around $N=88$. Spectroscopic properties are\nstudied by diagonalizing the interacting boson model Hamiltonian, with the\nparameters obtained via the mapping of the mean-field potential energy surface\nonto the expectation value of the Hamiltonian in the $s$, $d$, and $f$ boson\ncondensate state. The results obtained for low-energy positive- and\nnegative-parity excitation spectra as well as the electric dipole, quadrupole,\nand octupole transition probabilities indicate the onset of pronounced\noctupolarity for $Z\\approx 56$ and $N\\approx 88$ nuclei.\n",
      "subjects": [
        "nucl-th",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non Gaussian Denoising Diffusion Models",
      "abstract": "  Generative diffusion processes are an emerging and effective tool for image\nand speech generation. In the existing methods, the underline noise\ndistribution of the diffusion process is Gaussian noise. However, fitting\ndistributions with more degrees of freedom, could help the performance of such\ngenerative models. In this work, we investigate other types of noise\ndistribution for the diffusion process. Specifically, we show that noise from\nGamma distribution provides improved results for image and speech generation.\nMoreover, we show that using a mixture of Gaussian noise variables in the\ndiffusion process improves the performance over a diffusion process that is\nbased on a single distribution. Our approach preserves the ability to\nefficiently sample state in the training diffusion process while using Gamma\nnoise and a mixture of noise.\n",
      "subjects": [
        "cs.LG",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Accumulative Poisoning Attacks on Real-time Data",
      "abstract": "  Collecting training data from untrusted sources exposes machine learning\nservices to poisoning adversaries, who maliciously manipulate training data to\ndegrade the model accuracy. When trained on offline datasets, poisoning\nadversaries have to inject the poisoned data in advance before training, and\nthe order of feeding these poisoned batches into the model is stochastic. In\ncontrast, practical systems are more usually trained/fine-tuned on sequentially\ncaptured real-time data, in which case poisoning adversaries could dynamically\npoison each data batch according to the current model state. In this paper, we\nfocus on the real-time settings and propose a new attacking strategy, which\naffiliates an accumulative phase with poisoning attacks to secretly (i.e.,\nwithout affecting accuracy) magnify the destructive effect of a (poisoned)\ntrigger batch. By mimicking online learning and federated learning on MNIST and\nCIFAR-10, we show that model accuracy significantly drops by a single update\nstep on the trigger batch after the accumulative phase. Our work validates that\na well-designed but straightforward attacking strategy can dramatically amplify\nthe poisoning effects, with no need to explore complex techniques.\n",
      "subjects": [
        "cs.LG",
        "cs.CR",
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "TNT: Text-Conditioned Network with Transductive Inference for Few-Shot\n  Video Classification",
      "abstract": "  Recently, few-shot video classification has received an increasing interest.\nCurrent approaches mostly focus on effectively exploiting the temporal\ndimension in videos to improve learning under low data regimes. However, most\nworks have largely ignored that videos are often accompanied by rich textual\ndescriptions that can also be an essential source of information to handle\nfew-shot recognition cases. In this paper, we propose to leverage these\nhuman-provided textual descriptions as privileged information when training a\nfew-shot video classification model. Specifically, we formulate a text-based\ntask conditioner to adapt video features to the few-shot learning task.\nFurthermore, our model follows a transductive setting to improve the\ntask-adaptation ability of the model by using the support textual descriptions\nand query instances to update a set of class prototypes. Our model achieves\nstate-of-the-art performance on four challenging benchmarks commonly used to\nevaluate few-shot video action classification models.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "SENT: Sentence-level Distant Relation Extraction via Negative Training",
      "abstract": "  Distant supervision for relation extraction provides uniform bag labels for\neach sentence inside the bag, while accurate sentence labels are important for\ndownstream applications that need the exact relation type. Directly using bag\nlabels for sentence-level training will introduce much noise, thus severely\ndegrading performance. In this work, we propose the use of negative training\n(NT), in which a model is trained using complementary labels regarding that\n``the instance does not belong to these complementary labels\". Since the\nprobability of selecting a true label as a complementary label is low, NT\nprovides less noisy information. Furthermore, the model trained with NT is able\nto separate the noisy data from the training data. Based on NT, we propose a\nsentence-level framework, SENT, for distant relation extraction. SENT not only\nfilters the noisy data to construct a cleaner dataset, but also performs a\nre-labeling process to transform the noisy data into useful training data, thus\nfurther benefiting the model's performance. Experimental results show the\nsignificant improvement of the proposed method over previous methods on\nsentence-level evaluation and de-noise effect.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Regularised B-splines projected Gaussian Process priors to estimate\n  time-trends of age-specific COVID-19 deaths related to vaccine roll-out",
      "abstract": "  The COVID-19 pandemic has caused severe public health consequences in the\nUnited States. In this study, we use a hierarchical Bayesian model to estimate\nthe age-specific COVID-19 attributable deaths over time in the United States.\nThe model is specified by a novel non-parametric spatial approach, a low-rank\nGaussian Process (GP) projected by regularised B-splines. We show that this\nprojection defines a new GP with attractive smoothness and computational\nefficiency properties, derive its kernel function, and discuss the penalty\nterms induced by the projected GP. Simulation analyses and benchmark results\nshow that the spatial approach performs better than standard B-splines and\nBayesian P-splines and equivalently well as a standard GP, for considerably\nlower runtimes. The B-splines projected GP priors that we develop are likely an\nappealing addition to the arsenal of Bayesian regularising priors. We apply the\nmodel to weekly, age-stratified COVID-19 attributable deaths reported by the US\nCenters for Disease Control, which are subject to censoring and reporting\nbiases. Using the B-splines projected GP, we can estimate longitudinal trends\nin COVID-19 associated deaths across the US by 1-year age bands. These\nestimates are instrumental to calculate age-specific mortality rates, describe\nvariation in age-specific deaths across the US, and for fitting epidemic\nmodels. Here, we couple the model with age-specific vaccination rates to show\nthat lower vaccination rates in younger adults aged 18-64 are associated with\nsignificantly stronger resurgences in COVID-19 deaths, especially in Florida\nand Texas. These results underscore the critical importance of medically able\nindividuals of all ages to be vaccinated against COVID-19 in order to limit\nfatal outcomes.\n",
      "subjects": [
        "stat.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.105.044146",
      "title": "Martingale-induced local invariance in Progressive Quenching",
      "abstract": "  Progressive quenching (PQ) is a stochastic process during which one fixes,\none after another, the degrees of freedom of a globally coupled Ising spin\nsystem while letting it thermalize through a heat bath. It has previously been\nshown that during PQ, the mean equilibrium spin value follows a martingale\nprocess and this process can characterize the memory of the system. In the\npresent study, we find that the aforementioned martingale implies a local\ninvariance of the path weight for the total quenched magnetization, the\nMarkovian process whose increment is the spin that is fixed last. Consequently,\nPQ lets the probability distribution for the total quenched magnetization\nevolve while keeping the Boltzmann-like factor, or a canonical structure, under\nconstraint, which consists of a path-independent potential and a path-counting\nentropy. Moreover, when the PQ starts from full equilibrium, the probability\ndistribution at each stage of PQ is found to be the limit distribution of what\nwe call recycled quenching, the process in which a randomly chosen quenched\nspin is unquenched after a single step of PQ. The local invariance is a\nconsequence of the martingale property, and not an application of known\ntheorems for the martingale process.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Bi-static Radar Cross Section Test Method by Using Historic Marconi\n  Set-up and Time Gating",
      "abstract": "  In this paper, a low-cost, simple and reliable bi-static Radar Cross Section\n(RCS) measurement method making use a historic Marconi set-up is presented. It\nuses a transmitting (Tx) antenna (located at a constant position, at a\nreference angle of {\\theta} = 0o) and a receiver (Rx) antenna (mounted on a\nmoveable arm calibrated in the azimuthal direction with an accuracy of 0.1o). A\ntime gating method is used to extract the information from the reflection in\nthe time domain; applying time filter allows removing the antenna side lobe\neffects and other ambient noise. In this method, the Rx antenna (on the movable\narm) is used to measure the reflected field in the angular range from 1o to 90o\nof reflection from the structure (printed PCB) and from the reference\nconfiguration represented by a ground (GND) plane of the same dimension. The\ntime gating method is then applied to each pair of PCB / GND measurements to\nextract the bi-static RCS pattern of the structure at a given frequency. Here\ncomparison of measurement results carried out at 18 GHz and 32 GHz with\nsimulation indicates the successful performance of the proposed method. It can\nbe used as a low-cost, reliable and available option in future measurement and\nscientific research.\n",
      "subjects": [
        "eess.SP",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Pedestrian Emergence Estimation and Occlusion-Aware Risk Assessment for\n  Urban Autonomous Driving",
      "abstract": "  Avoiding unseen or partially occluded vulnerable road users (VRUs) is a major\nchallenge for fully autonomous driving in urban scenes. However,\nocclusion-aware risk assessment systems have not been widely studied. Here, we\npropose a pedestrian emergence estimation and occlusion-aware risk assessment\nsystem for urban autonomous driving. First, the proposed system utilizes\navailable contextual information, such as visible cars and pedestrians, to\nestimate pedestrian emergence probabilities in occluded regions. These\nprobabilities are then used in a risk assessment framework, and incorporated\ninto a longitudinal motion controller. The proposed controller is tested\nagainst several baseline controllers that recapitulate some commonly observed\ndriving styles. The simulated test scenarios include randomly placed parked\ncars and pedestrians, most of whom are occluded from the ego vehicle's view and\nemerges randomly. The proposed controller outperformed the baselines in terms\nof safety and comfort measures.\n",
      "subjects": [
        "cs.RO",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Combinatorial mutations of Newton-Okounkov polytopes arising from plabic\n  graphs",
      "abstract": "  It is known that the homogeneous coordinate ring of a Grassmannian has a\ncluster structure, which is induced from the combinatorial structure of a\nplabic graph. A plabic graph is a certain bipartite graph described on the\ndisk, and there is a family of plabic graphs giving a cluster structure of the\nsame Grassmannian. Such plabic graphs are related by the operation called\nsquare move which can be considered as the mutation in cluster theory. By using\na plabic graph, we also obtain the Newton--Okounkov polytope which gives a\ntoric degeneration of the Grassmannian. The purposes of this article is to\nsurvey these phenomena and observe the behavior of Newton--Okounkov polytopes\nunder the operation called the combinatorial mutation of polytopes. In\nparticular, we reinterpret some operations defined for Newton--Okounkov\npolytopes using the combinatorial mutation.\n",
      "subjects": [
        "math.CO",
        "math.AG",
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/s41467-021-24114-8",
      "title": "Visualizing the strongly reshaped skyrmion Hall effect in multilayer\n  wire devices",
      "abstract": "  Magnetic skyrmions are nanoscale spin textures touted as next-generation\ncomputing elements. When subjected to lateral currents, skyrmions move at\nconsiderable speeds. Their topological charge results in an additional\ntransverse deflection known as the skyrmion Hall effect (SkHE). While\npromising, their dynamic phenomenology with current, skyrmion size, geometric\neffects and disorder remain to be established. Here we report on the ensemble\ndynamics of individual skyrmions forming dense arrays in Pt/Co/MgO wires by\nexamining over 20,000 instances of motion across currents and fields. The\nskyrmion speed reaches 24 m/s in the plastic flow regime and is surprisingly\nrobust to positional and size variations. Meanwhile, the SkHE saturates at\n$\\sim 22^\\circ$, is substantially reshaped by the wire edge, and crucially\nincreases weakly with skyrmion size. Particle model simulations suggest that\nthe SkHE size dependence - contrary to analytical predictions - arises from the\ninterplay of intrinsic and pinning-driven effects. These results establish a\nrobust framework to harness SkHE and achieve high-throughput skyrmion motion in\nwire devices.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3460231.3474604",
      "title": "You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a\n  (Mostly) Serverless and Open Stack",
      "abstract": "  We argue that immature data pipelines are preventing a large portion of\nindustry practitioners from leveraging the latest research on recommender\nsystems. We propose our template data stack for machine learning at \"reasonable\nscale\", and show how many challenges are solved by embracing a serverless\nparadigm. Leveraging our experience, we detail how modern open source can\nprovide a pipeline processing terabytes of data with limited infrastructure\nwork.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "One Thousand and One Stories: A Large-Scale Survey of Software\n  Refactoring",
      "abstract": "  Despite the availability of refactoring as a feature in popular IDEs, recent\nstudies revealed that developers are reluctant to use them, and still prefer\nthe manual refactoring of their code. At JetBrains, our goal is to fully\nsupport refactoring features in IntelliJ-based IDEs and improve their adoption\nin practice. Therefore, we start by raising the following main questions. How\nexactly do people refactor code? What refactorings are the most popular? Why do\nsome developers tend not to use convenient IDE refactoring tools?\n  In this paper, we investigate the raised questions through the design and\nimplementation of a survey targeting 1,183 users of IntelliJ-based IDEs. Our\nquantitative and qualitative analysis of the survey results shows that almost\ntwo-thirds of developers spend more than one hour in a single session\nrefactoring their code; that refactoring types vary greatly in popularity; and\nthat a lot of developers would like to know more about IDE refactoring features\nbut lack the means to do so. These results serve us internally to support the\nnext generation of refactoring features, as well as can help our research\ncommunity to establish new directions in the refactoring usability research.\n",
      "subjects": [
        "cs.SE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Generative Pretraining for Paraphrase Evaluation",
      "abstract": "  We introduce ParaBLEU, a paraphrase representation learning model and\nevaluation metric for text generation. Unlike previous approaches, ParaBLEU\nlearns to understand paraphrasis using generative conditioning as a pretraining\nobjective. ParaBLEU correlates more strongly with human judgements than\nexisting metrics, obtaining new state-of-the-art results on the 2017 WMT\nMetrics Shared Task. We show that our model is robust to data scarcity,\nexceeding previous state-of-the-art performance using only $50\\%$ of the\navailable training data and surpassing BLEU, ROUGE and METEOR with only $40$\nlabelled examples. Finally, we demonstrate that ParaBLEU can be used to\nconditionally generate novel paraphrases from a single demonstration, which we\nuse to confirm our hypothesis that it learns abstract, generalized paraphrase\nrepresentations.\n",
      "subjects": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1475-7516/2021/10/078",
      "title": "Well-tempered teleparallel Horndeski cosmology: a teleparallel variation\n  to the cosmological constant problem",
      "abstract": "  Well-tempering is a promising classical method of dynamically screening an\narbitrarily large vacuum energy and generating a late-time, low energy de\nSitter vacuum state. In this paper, we study for the first time self-tuning in\nteleparallel gravity and obtain well-tempered cosmological models in the\nteleparallel gravity analogue of Horndeski theory. This broadens the scope of\nwell-tempered cosmology and teases the potentially far richer cosmological\ndynamics that could be anchored on teleperallel gravity. We expand the\nwell-tempered recipe to its most general form so far and use it to search for\nthe first well-tempered cosmologies in teleparallel gravity. We also study the\ncosmological dynamics in a well-tempered model and demonstrate the dynamical\nstability of the vacuum, the compatibility with a matter era, and the stability\nof the vacuum through a phase transition.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.104.L010201",
      "title": "Detection loophole in quantum causality and its countermeasures",
      "abstract": "  Quantum causality violates classical intuitions of cause and effect and is a\nunique quantum feature different from other quantum phenomena such as\nentanglement and quantum nonlocality. In order to avoid the detection loophole\nin quantum causality, we initiate the study of the detection efficiency\nrequirement for observing quantum causality. We first show that previous\nclassical causal inequalities require detection efficiency at least 95.97%\n(89.44%) to show violation with quantum (nonsignaling) correlations. Next we\nderive a classical causal inequality I_{222} and show that it requires lower\ndetection efficiency to be violated, 92.39% for quantum correlations and 81.65%\nfor nonsignaling correlations, hence substantially reducing the requirement on\ndetection. Then we extend this causal inequality to the case of multiple\nmeasurement settings and analyze the corresponding detection efficiency. After\nthat, we show that previous quantum causal inequalities require detection\nefficiency at least 94.29% to violate with nonsignaling correlations. We\nsubsequently derive a quantum causal bound J_{222} that has a lower detection\nefficiency requirement of 91.02% for violation with nonsignaling correlations.\nOur work paves the way towards an experimental demonstration of quantum\ncausality and shows that causal inequalities significantly differ from Bell\ninequalities in terms of the detection efficiency requirement.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Enumeration of Polyominoes & Polycubes Composed of Magnetic Cubes",
      "abstract": "  This paper examines a family of designs for magnetic cubes and counts how\nmany configurations are possible for each design as a function of the number of\nmodules.\n  Magnetic modular cubes are cubes with magnets arranged on their faces. The\nmagnets are positioned so that each face has either magnetic south or north\npole outward. Moreover, we require that the net magnetic moment of the cube\npasses through the center of opposing faces. These magnetic arrangements enable\ncoupling when cube faces with opposite polarity are brought in close proximity\nand enable moving the cubes by controlling the orientation of a global magnetic\nfield. This paper investigates the 2D and 3D shapes that can be constructed by\nmagnetic modular cubes, and describes all possible magnet arrangements that\nobey these rules. We select ten magnetic arrangements and assign a \"colo\"' to\neach of them for ease of visualization and reference. We provide a method to\nenumerate the number of unique polyominoes and polycubes that can be\nconstructed from a given set of colored cubes. We use this method to enumerate\nall arrangements for up to 20 modules in 2D and 16 modules in 3D. We provide a\nmotion planner for 2D assembly and through simulations compare which\narrangements require fewer movements to generate and which arrangements are\nmore common. Hardware demonstrations explore the self-assembly and disassembly\nof these modules in 2D and 3D.\n",
      "subjects": [
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Role of Functional Programming in Management and Orchestration of\n  Virtualized Network Resources Part II. Network Evolution and Design\n  Principles",
      "abstract": "  This is part II of the follow-up lecture notes of the lectures given by the\nauthors at the Three \\CO\" (Composability, Comprehensibility, Correctness)\nWinter School held in Kov{s}ice, Slovakia, in January 2018, and Summer School\nheld in Budapest, Hungary, in June 2019. In this part we explain the recent\nnetwork evolution and the concept of virtualization, focusing on the management\nand orchestration of virtualized network resources. Network Functions\nVirtualization (NFV) is a new paradigm for changing the way networks are built\nand operated. Decoupling software implementation from network resources through\na virtualization layer introduces a need for developing sets of NFV management\nand orchestration (MANO) functions. We discuss how this new point of view is\nhighly inspired by the functional programming concepts. We provide examples and\nexercises on Open Stack virtual technology, and also discuss the challenges and\nproblems inspired by telecommunication industry. Focus is on Reliable operation\nof Management and Orchestration functions of Virtualized resources.\n  These notes provide an introduction to the subject, with the goal of\nexplaining the necessity for new knowledge and skills in area of network\nprogramming. We introduce students with main problems and the network design\nprinciples, methods and techniques used for their solution. The worked examples\nand exercises serve students as the teaching material, from which they can\nlearn how to use functional programming to effectively and efficiently\ncoordinate management and orchestration functions in distributed complex\nsystems using NFV.\n",
      "subjects": [
        "cs.SE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An induced subgraph of the Hamming graph with maximum degree 1",
      "abstract": "  For every graph $G$, let $\\alpha(G)$ denote its independence number. What is\nthe minimum of the maximum degree of an induced subgraph of $G$ with\n$\\alpha(G)+1$ vertices? We study this question for the $n$-dimensional Hamming\ngraph over an alphabet of size $k$. In this paper, we give a construction to\nprove that the answer is $1$ for all $n$ and $k$ with $k \\geq 3$. This is an\nimprovement over an earlier work showing that the answer is at most $\\lceil\n\\sqrt{n} \\, \\rceil$.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Optimizing Cost per Click for Digital Advertising Campaigns",
      "abstract": "  Cost per click is a common metric to judge digital advertising campaign\nperformance. In this paper we discuss an approach that generates a feature\ntargeting recommendation to optimise cost per click. We also discuss a\ntechnique to assign bid prices to features without compromising on the number\nof features recommended.\n  Our approach utilises impression and click stream data sets corresponding to\nreal time auctions that we have won. The data contains information about device\ntype, website, RTB Exchange ID. We leverage data across all campaigns that we\nhave access to while ensuring that recommendations are sensitive to both\nindividual campaign level features and globally well performing features as\nwell. We model Bid recommendation around the hypothesis that a click is a\nBernoulli trial and click stream follows Binomial distribution which is then\nupdated based on live performance ensuring week over week improvement.\n  This approach has been live tested over 10 weeks across 5 campaigns. We see\nCost per click gains of 16-60% and click through rate improvement of 42-137%.\nAt the same time, the campaign delivery was competitive.\n",
      "subjects": [
        "stat.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "JOET: Sustainable Vehicle-assisted Edge Computing for Internet of\n  Vehicles",
      "abstract": "  Task offloading in Internet of Vehicles (IoV) involves numerous steps and\noptimization variables such as: where to offload tasks, how to allocate\ncomputation resources, how to adjust offloading ratio and transmit power for\noffloading, and such optimization variables and hybrid combination features are\nhighly coupled with each other. Thus, this is a fully challenge issue to\noptimize these variables for task offloading to sustainably reduce energy\nconsumption with load balancing while ensuring that a task is completed before\nits deadline. In this paper, we first provide a Mixed Integer Nonlinear\nProgramming Problem (MINLP) formulation for such task offloading under energy\nand deadline constraints in IoV. Furthermore, in order to efficiently solve the\nformulated MINLP, we decompose it into two subproblems, and design a\nlow-complexity Joint Optimization for Energy Consumption and Task Processing\nDelay (JOET) algorithm to optimize selection decisions, resource allocation,\noffloading ratio and transmit power adjustment. We carry out extensive\nsimulation experiments to validate JOET. Simulation results demonstrate that\nJOET outperforms many representative existing approaches in quickly converge\nand effectively reduce energy consumption and delay. Specifically, average\nenergy consumption and task processing delay have been reduced by 15.93% and\n15.78%, respectively, and load balancing efficiency has increased by 10.20%.\n",
      "subjects": [
        "cs.OH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1112/jlms.12872",
      "title": "One-sided sharp thresholds for homology of random flag complexes",
      "abstract": "  We prove that the random flag complex has a probability regime where the\nprobability of nonvanishing homology is asymptotically bounded away from zero\nand away from one. Related to this main result we also establish new bounds on\na sharp threshold for the fundamental group of a random flag complex to be a\nfree group. In doing so we show that there is an intermediate probability\nregime in which the random flag complex has fundamental group which is neither\nfree nor has Kazhdan's property (T).\n",
      "subjects": [
        "math.AT",
        "math.CO",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nonlinear Controllability Assessment of Aerial Manipulator Systems using\n  Lagrangian Reduction",
      "abstract": "  This paper analyzes the nonlinear Small-Time Local Controllability (STLC) of\na class of underatuated aerial manipulator robots. We apply methods of\nLagrangian reduction to obtain their lowest dimensional equations of motion\n(EOM). The symmetry-breaking potential energy terms are resolved using advected\nparameters, allowing full $SE(3)$ reduction at the cost of additional advection\nequations. The reduced EOM highlights the shifting center of gravity due to\nmanipulation and is readily in control-affine form, simplifying the nonlinear\ncontrollability analysis. Using Sussmann's sufficient condition, we conclude\nthat the aerial manipulator robots are STLC near equilibrium condition,\nrequiring Lie bracket motions up to degree three.\n",
      "subjects": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/TITS.2022.3208829",
      "title": "OpenStreetMap-based Autonomous Navigation With LiDAR Naive-Valley-Path\n  Obstacle Avoidance",
      "abstract": "  OpenStreetMaps (OSM) is currently studied as the environment representation\nfor autonomous navigation. It provides advantages such as global consistency, a\nheavy-less map construction process, and a wide variety of road information\npublicly available. However, the location of this information is usually not\nvery accurate locally.\n  In this paper, we present a complete autonomous navigation pipeline using OSM\ninformation as environment representation for global planning. To avoid the\nflaw of local low-accuracy, we offer the novel LiDAR-based Naive-Valley-Path\n(NVP) method that exploits the concept of \"valley\" areas to infer the local\npath always furthest from obstacles. This behavior allows navigation always\nthrough the center of trafficable areas following the road's shape\nindependently of OSM error. Furthermore, NVP is a naive method that is highly\nsample-time-efficient. This time efficiency also enables obstacle avoidance,\neven for dynamic objects.\n  We demonstrate the system's robustness in our research platform BLUE, driving\nautonomously across the University of Alicante Scientific Park for more than 20\nkm with 0.24 meters of average error against the road's center with a 19.8 ms\nof average sample time. Our vehicle avoids static obstacles in the road and\neven dynamic ones, such as vehicles and pedestrians.\n",
      "subjects": [
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Zoom, Enhance! Measuring Surveillance GAN Up-sampling",
      "abstract": "  Deep Neural Networks have been very successfully used for many computer\nvision and pattern recognition applications. While Convolutional Neural\nNetworks(CNNs) have shown the path to state of art image classifications,\nGenerative Adversarial Networks or GANs have provided state of art capabilities\nin image generation. In this paper we extend the applications of CNNs and GANs\nto experiment with up-sampling techniques in the domains of security and\nsurveillance. Through this work we evaluate, compare and contrast the state of\nart techniques in both CNN and GAN based image and video up-sampling in the\nsurveillance domain. As a result of this study we also provide experimental\nevidence to establish DISTS as a stronger Image Quality Assessment(IQA) metric\nfor comparing GAN Based Image Up-sampling in the surveillance domain.\n",
      "subjects": [
        "cs.CV",
        "eess.IV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "State estimation for aoristic models",
      "abstract": "  Aoristic data can be described by a marked point process in time in which the\npoints cannot be observed directly but are known to lie in observable\nintervals, the marks. We consider Bayesian state estimation for the latent\npoints when the marks are modelled in terms of an alternating renewal process\nin equilibrium and the prior is a Markov point point process. We derive the\nposterior distribution, estimate its parameters and present some examples that\nillustrate the influence of the prior distribution.\n",
      "subjects": [
        "math.ST",
        "stat.ME",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the linear complexity of feedforward clock-controlled sequence",
      "abstract": "  As a research field of stream ciphers, the pursuit of a balance of security\nand practicality is the focus. The conditions for security usually have to\nsatisfy at least high period and high linear complexity. Because the\nfeedforward clock-controlled structure can provide quite a high period and\nutility, many sequence ciphers are constructed based on this structure.\nHowever, the past study of its linear complexity only works when the controlled\nsequence is an m-sequence. Using the theory of matrix over the ring and block\nmatrix in this paper, we construct a more helpful method. It can estimate the\nlower bound of the linear complexity of the feedforward clock-controlled\nsequence. Even the controlled sequence has great linear complexity.\n",
      "subjects": [
        "cs.CR",
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The unitary Master Ward Identity: Time slice axiom, Noether's Theorem\n  and Anomalies",
      "abstract": "  The C*-algebraic formulation of generic interacting quantum field theories,\nrecently presented by Detlev Buchholz and one of the authors (KF), is enriched\nby a unitary version of the Master Ward Identity, which was postulated some\ntime ago by Franz Marc Boas, Ferdinand Brennecke and two of us (MD,KF). It is\nshown that the corresponding axiom implies the validity of the time slice\naxiom. Moreover, it opens the way for a new approach to Noether's Theorem where\nit yields directly the unitaries implementing the symmetries. It also unravels\ninteresting aspects of the role of anomalies in quantum field theory.\n",
      "subjects": [
        "math-ph",
        "hep-th",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Arboreal Topological and Fracton Phases",
      "abstract": "  We describe topologically ordered and fracton ordered states on novel\ngeometries which do not have an underlying manifold structure. Using tree\ngraphs such as the $k$-coordinated Bethe lattice ${\\cal B}(k)$ and a hypertree\ncalled the $(k,n)$-hyper-Bethe lattice ${\\cal HB}(k,n)$ consisting of\n$k$-coordinated hyperlinks (defined by $n$ sites), we construct\nmultidimensional arboreal arenas such as ${\\cal B}(k_1) \\square {\\cal B}(k_2)$\nby the notion of a graph Cartesian product $\\square$. We study various quantum\nsystems such as the ${\\mathbb Z}_2$ gauge theory, generalized quantum Ising\nmodels (GQIM), the fractonic X-cube model, and related X-cube gauge theory\ndefined on these arenas. Even the simplest ${\\mathbb Z}_2$ gauge theory on a 2d\narboreal arena is fractonic -- the monopole excitation is immobile. The X-cube\nmodel on a 3d arboreal arena is fully fractonic, all multipoles are rendered\nimmobile. We obtain variational ground state phase diagrams of these gauge\ntheories. Further, we find an intriguing class of dualities in arboreal arenas\nas illustrated by the ${\\mathbb Z}_2$ gauge theory defined on ${\\cal B}(k_1)\n\\square {\\cal B}(k_2)$ being dual to a GQIM defined on ${\\cal HB}(2,k_1)\n\\square {\\cal HB}(2,k_2)$. Finally, we discuss different classes of topological\nand fracton orders on arboreal arenas. We find three distinct classes of\narboreal toric code orders on 2d arboreal arenas, those that occur on ${\\cal\nB}(2) \\square {\\cal B}(2)$, ${\\cal B}(k) \\square {\\cal B}(2), k >2$, and ${\\cal\nB}(k_1) \\square {\\cal B}(k_2)$, $k_1,k_2>2$. Likewise, four classes of X-cube\nfracton orders are found in 3d arboreal arenas -- those on ${\\cal\nB}(2)\\square{\\cal B}(2)\\square {\\cal B}(2)$, ${\\cal B}(k) \\square {\\cal\nB}(2)\\square {\\cal B}(2), k>2$, ${\\cal B}(k_1) \\square {\\cal B}(k_2) \\square\n{\\cal B}(2), k_1,k_2 >2$, and ${\\cal B}(k_1) \\square {\\cal B}(k_2) \\square\n{\\cal B}(k_3), k_1,k_2,k_3 >2$.\n",
      "subjects": [
        "cond-mat.str-el",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The fate of Landau levels under $\\delta$-interactions",
      "abstract": "  We consider the self-adjoint Landau Hamiltonian $H_0$ in $L^2(\\mathbb{R}^2)$\nwhose spectrum consists of infinitely degenerate eigenvalues $\\Lambda_q$, $q\n\\in \\mathbb{Z}_+$, and the perturbed operator $H_\\upsilon = H_0 +\n\\upsilon\\delta_\\Gamma$, where $\\Gamma \\subset \\mathbb{R}^2$ is a regular Jordan\n$C^{1,1}$-curve, and $\\upsilon \\in L^p(\\Gamma;\\mathbb{R})$, $p>1$, has a\nconstant sign. We investigate ${\\rm Ker}(H_\\upsilon -\\Lambda_q)$, $q \\in\n\\mathbb{Z}_+$, and show that generically $$0 \\leq {\\rm dim \\, Ker}(H_\\upsilon\n-\\Lambda_q) - {\\rm dim \\, Ker}(T_q(\\upsilon \\delta_\\Gamma)) < \\infty,$$ where\n$T_q(\\upsilon \\delta_\\Gamma) = p_q (\\upsilon \\delta_\\Gamma)p_q$, is an operator\nof Berezin-Toeplitz type, acting in $p_q L^2(\\mathbb{R}^2)$, and $p_q$ is the\northogonal projection on ${\\rm Ker}\\,(H_0 -\\Lambda_q)$. If $\\upsilon \\neq 0$\nand $q = 0$, we prove that ${\\rm Ker}\\,(T_0(\\upsilon \\delta_\\Gamma)) = \\{0\\}$.\nIf $q \\geq 1$, and $\\Gamma = \\mathcal{C}_r$ is a circle of radius $r$, we show\nthat ${\\rm dim \\, Ker} (T_q(\\delta_{\\mathcal{C}_r})) \\leq q$, and the set of $r\n\\in (0,\\infty)$ for which ${\\rm dim \\, Ker}(T_q(\\delta_{\\mathcal{C}_r})) \\geq\n1$, is infinite and discrete.\n",
      "subjects": [
        "math.SP",
        "math-ph",
        "math.AP",
        "math.FA",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Multimodal Incremental Transformer with Visual Grounding for Visual\n  Dialogue Generation",
      "abstract": "  Visual dialogue is a challenging task since it needs to answer a series of\ncoherent questions on the basis of understanding the visual environment.\nPrevious studies focus on the implicit exploration of multimodal co-reference\nby implicitly attending to spatial image features or object-level image\nfeatures but neglect the importance of locating the objects explicitly in the\nvisual content, which is associated with entities in the textual content.\nTherefore, in this paper we propose a {\\bf M}ultimodal {\\bf I}ncremental {\\bf\nT}ransformer with {\\bf V}isual {\\bf G}rounding, named MITVG, which consists of\ntwo key parts: visual grounding and multimodal incremental transformer. Visual\ngrounding aims to explicitly locate related objects in the image guided by\ntextual entities, which helps the model exclude the visual content that does\nnot need attention. On the basis of visual grounding, the multimodal\nincremental transformer encodes the multi-turn dialogue history combined with\nvisual scene step by step according to the order of the dialogue and then\ngenerates a contextually and visually coherent response. Experimental results\non the VisDial v0.9 and v1.0 datasets demonstrate the superiority of the\nproposed model, which achieves comparable performance.\n",
      "subjects": [
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.22331/q-2023-06-12-1039",
      "title": "Deep recurrent networks predicting the gap evolution in adiabatic\n  quantum computing",
      "abstract": "  In adiabatic quantum computing finding the dependence of the gap of the\nHamiltonian as a function of the parameter varied during the adiabatic sweep is\ncrucial in order to optimize the speed of the computation. Inspired by this\nchallenge, in this work, we explore the potential of deep learning for\ndiscovering a mapping from the parameters that fully identify a problem\nHamiltonian to the aforementioned parametric dependence of the gap applying\ndifferent network architectures. Through this example, we conjecture that a\nlimiting factor for the learnability of such problems is the size of the input,\nthat is, how the number of parameters needed to identify the Hamiltonian scales\nwith the system size. We show that a long short-term memory network succeeds in\npredicting the gap when the parameter space scales linearly with system size.\nRemarkably, we show that once this architecture is combined with a\nconvolutional neural network to deal with the spatial structure of the model,\nthe gap evolution can even be predicted for system sizes larger than the ones\nseen by the neural network during training. This provides a significant speedup\nin comparison with the existing exact and approximate algorithms in calculating\nthe gap.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4365/ac3baf",
      "title": "The Impact of Observing Strategy on Reliable Classification of Standard\n  Candle Stars: Detection of Amplitude, Period, and Phase Modulation (Blazhko\n  Effect) of RR Lyrae Stars with LSST",
      "abstract": "  The Vera C. Rubin Observatory will carry out its Legacy Survey of Space and\nTime (LSST) with a single-exposure depth of $r{\\sim}24.7$ and an anticipated\nbaseline of 10 years, allowing to access the Milky Way's old halo not only\ndeeper, but also with a longer baseline and better cadence than e.g. PS1 3$\\pi$\n(Chambers et al. 2016). This will make LSST ideal to study populations of\nvariable stars such as RR Lyrae stars (RRL). Here, we address the question of\nobserving strategy optimization of LSST, as survey footprint definition, single\nvisit exposure time as well as the cadence of repeat visits in different\nfilters are yet to be finalized. We present metrics used to assess the impact\nof different observing strategies on the reliable detectability and\nclassification of standard-candle variable stars, including detection of\namplitude period, phase modulation effects of RR Lyrae stars, the so-called\nBlazhko effect (Blazhko 1907, Kollath et al. 2011), by evaluating metrics for\nsimulated potential survey designs. So far, due to depth and cadence of typical\nall-sky surveys, it was nearly impossible to study this effect on a larger\nsample. All-sky surveys with relatively few observations over a moderately long\nbaseline allow only for fitting phase-folded RRL light curves, thus integrating\nover the complete survey length and hiding any information regarding possible\nperiod or phase modulation during the survey. On the other hand, surveys with a\ncadence to detect slightly changing light curves usually have a relatively\nsmall footprint. LSST's survey strategy, however, will allow for studying\nvariable stars in a way that makes population studies possible.\n",
      "subjects": [
        "astro-ph.SR",
        "astro-ph.GA",
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Representations by ordered Bell and degenerate ordered Bell polynomials",
      "abstract": "  In this paper, we consider the problem of representing any polynomial in\nterms of the ordered Bell and degenerate ordered Bell polynomials, and more\ngenerally of the higher-order ordered Bell and higher-order degenerate ordered\nBell polynomials. We derive explicit formulas with the help of umbral calculus\nand illustrate our results with some examples.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3842/SIGMA.2022.034",
      "title": "Witten-Reshetikhin-Turaev Invariants, Homological Blocks, and Quantum\n  Modular Forms for Unimodular Plumbing H-Graphs",
      "abstract": "  Gukov-Pei-Putrov-Vafa constructed $q$-series invariants called homological\nblocks in a physical way in order to categorify Witten-Reshetikhin-Turaev (WRT)\ninvariants and conjectured that radial limits of homological blocks are WRT\ninvariants. In this paper, we prove their conjecture for unimodular H-graphs.\nAs a consequence, it turns out that the WRT invariants of H-graphs yield\nquantum modular forms of depth two and of weight one with the quantum set\n$\\mathbb{Q}$. In the course of the proof of our main theorem, we first write\nthe invariants as finite sums of rational functions. We second carry out a\nsystematic study of weighted Gauss sums in order to give new vanishing results\nfor them. Combining these results, we finally prove that the above conjecture\nholds for H-graphs.\n",
      "subjects": [
        "math.GT",
        "hep-th",
        "math-ph",
        "math.MP",
        "math.NT",
        "math.QA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1364/OE.446740",
      "title": "High-fidelity glass micro-axicons fabricated by laser-assisted wet\n  etching",
      "abstract": "  We report on the fabrication of micro-axicons made of glass by laser-assisted\nwet etching (LAE) and laser polishing. The employed technique, relying on an\nefficient direct-writing process by femtosecond laser, allows revealing high\nfidelity profiles while etched in a heated potassium hydroxide (KOH) solution.\nThe remaining surface roughness is then smoothened by carbon dioxide (CO2)\nlaser polishing. Such polishing is limited to the skin of the component so that\nthe tip is only slightly rounded, with a radius of curvature of nearly 200\n{\\mu}m. It is then shown with 500 {\\mu}m-diameter axicons that the quasi-Bessel\nbeam is generated closely after the tip, and features a 5.3 {\\mu}m diameter\nmaintained over a propagation distance of almost 3.5 mm.\n",
      "subjects": [
        "physics.optics",
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Simplicial complexes from finite projective planes and colored\n  configurations",
      "abstract": "  In the 7-vertex triangulation of the torus, the 14 triangles can be\npartitioned as $T_{1} \\sqcup T_{2}$, such that each $T_{i}$ represents the\nlines of a copy of the Fano plane $PG(2, \\mathbb{F}_{2})$. We generalize this\nobservation by constructing, for each prime power $q$, a simplicial complex\n$X_{q}$ with $q^{2} + q + 1$ vertices and $2(q^{2} + q + 1)$ facets consisting\nof two copies of $PG(2, \\mathbb{F}_{q})$.\n  Our construction works for any colored $k$-configuration, defined as a\n$k$-configuration whose associated bipartite graph $G$ is connected and has a\n$k$-edge coloring $\\chi \\colon E(G) \\to [k]$, such that for all $v \\in V(G)$,\n$a, b, c \\in [k]$, following edges of colors $a, b, c, a, b, c$ from $v$ brings\nus back to $v$. We give one-to-one correspondences between (1) Sidon sets of\norder 2 and size $k + 1$ in groups with order $n$, (2) linear codes with radius\n1 and index $n$ in the lattice $A_{k}$, and (3) colored $(k +\n1)$-configurations with $n$ points and $n$ lines. (The correspondence between\n(1) and (2) is known.) As a result, we suggest possible topological\nobstructions to the existence of Sidon sets, and in particular, planar\ndifference sets.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/PESGM48719.2022.9917119",
      "title": "Spatiotemporal Impact Assessment of Hurricanes on Electric Power Systems",
      "abstract": "  Almost 90% of the major power outages in the US are caused due to hurricanes.\nDue to the highly uncertain nature of hurricanes in both spatial and temporal\ndimensions, it is essential to quantify the effect of such hurricanes on a\npower grid. In this paper, we provide a Monte-Carlo-based framework in which\nseveral hurricane scenarios and their impact on a power grid are analyzed in\nspatiotemporal dimensions. The hurricane simulations are performed using\nsamples from previously occurred hurricanes in the US whereas probabilistic\nassessment of the transmission lines is performed through line fragility model.\nFinally, a loss metric based on the amount of load disconnected due to\nhurricanes traveling inland is calculated for each time step. The simulation is\nperformed on ACTIVSg2000: 2000-bus synthetic Texas grid while mapping the\ntransmission lines of the test case on the geographical footprint of Texas. The\nsimulation results show that the loss increases significantly for a few time\nsteps when the wind field of a hurricane is intense and almost saturates when\nthe intensity of the hurricane decays while traversing further. The proposed\nanalysis can provide some insights for proactive planning strategies on\nimproving the resilience of the power grid.\n",
      "subjects": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.21883/FTT.2022.02.51930.223",
      "title": "Nuclear spin dynamics and noise in anisotropic large box model",
      "abstract": "  We consider the central spin model in the box approximation taking into\naccount external magnetic field and anisotropy of the hyperfine interaction.\nFrom the exact Hamiltonian diagonalization we obtain analytical expressions for\nthe nuclear spin dynamics in the limit of many nuclear spins. We predict the\nnuclear spin precession in zero magnetic field for the case of anisotropic\ninteraction between electron and nuclear spins. We calculate and describe the\nnuclear spin noise spectra in the thermodynamic equilibrium. The obtained\nresults can be used for the analysis of the nuclear spin induced current\nfluctuations in organic semiconductors.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.105.155124",
      "title": "Inner workings of fractional quantum Hall parent Hamiltonians: A matrix\n  product state point of view",
      "abstract": "  We study frustration-free Hamiltonians of fractional quantum Hall (FQH)\nstates from the point of view of the matrix product state (MPS) representation\nof their ground and excited states. There is a wealth of solvable models\nrelating to FQH physics, which, however, is mostly derived and analyzed from\nthe vantage point of first-quantized \"analytic clustering properties\". In\ncontrast, one obtains long-ranged frustration-free lattice models when these\nHamiltonians are studied in an orbital basis, which is the natural basis for\nthe MPS representation of FQH states. The connection between MPS-like states\nand frustration-free parent Hamiltonians is the central guiding principle in\nthe construction of solvable lattice models, but thus far, only for short-range\nHamiltonians and MPSs of finite bond dimension. The situation in the FQH\ncontext is fundamentally different. Here we expose the direct link between the\ninfinite-bond-dimension MPS structure of Laughlin-conformal field theory (CFT)\nstates and their parent Hamiltonians. While focusing on the Laughlin state,\ngeneralizations to other CFT-MPSs will become transparent.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.104.053319",
      "title": "Rotation-driven transition into coexistent Josephson modes in an\n  atomtronic dc-SQUID",
      "abstract": "  By means of a two-mode model, we show that transitions to different arrays of\ncoexistent regimes in the phase space can be attained by rotating a double-well\nsystem, which consists of a toroidal condensate with two diametrically placed\nbarriers. Such a configuration corresponds to the atomtronic counterpart of the\nwell-known direct-current superconducting quantum interference device. Due to\nthe phase gradient experimented by the on-site localized functions when the\nsystem is subject to rotation, a phase difference appears on each junction in\norder to satisfy the quantization of the velocity field around the torus. We\ndemonstrate that such a phase can produce a significant change on the relative\nvalues of different types of hopping parameters. In particular, we show that\nwithin a determined rotation frequency interval, a hopping parameter, usually\ndisregarded in nonrotating systems, turns out to rule the dynamics. At the\nlimits of such a frequency interval, bifurcations of the stationary points\noccur, which substantially change the phase space portrait that describes the\norbits of the macroscopic canonical conjugate variables. We analyze the\nemerging dynamics that combines the $0$ and $\\pi$ Josephson modes, and evaluate\nthe small-oscillation time-periods of such orbits at the frequency range where\neach mode survives. All the findings predicted by the model are confirmed by\nGross-Pitaevskii simulations.\n",
      "subjects": [
        "cond-mat.quant-gas",
        "physics.atom-ph",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.105.084006",
      "title": "Series expansion of the overlap reduction function for scalar and vector\n  polarizations for gravitational wave search with pulsar timing arrays",
      "abstract": "  In our previous work \\cite{PTA2} we calculated the overlap reduction function\nfor the tensor polarization without employing the short wavelength\napproximation, this was done by obtaining a power series of nested sums which\nis valid for all gravitational wave frequencies and pulsar distances. In this\nwork we generalize the power-series expansion method to vector and scalar\npolarizations. We have compared our expression for the breathing and vector\nmodes with previous literature. We present for the first time analytic\nexpressions for the overlap reduction function of the longitudinal mode for all\nangles between the pulsar pairs.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Group equivariant neural posterior estimation",
      "abstract": "  Simulation-based inference with conditional neural density estimators is a\npowerful approach to solving inverse problems in science. However, these\nmethods typically treat the underlying forward model as a black box, with no\nway to exploit geometric properties such as equivariances. Equivariances are\ncommon in scientific models, however integrating them directly into expressive\ninference networks (such as normalizing flows) is not straightforward. We here\ndescribe an alternative method to incorporate equivariances under joint\ntransformations of parameters and data. Our method -- called group equivariant\nneural posterior estimation (GNPE) -- is based on self-consistently\nstandardizing the \"pose\" of the data while estimating the posterior over\nparameters. It is architecture-independent, and applies both to exact and\napproximate equivariances. As a real-world application, we use GNPE for\namortized inference of astrophysical binary black hole systems from\ngravitational-wave observations. We show that GNPE achieves state-of-the-art\naccuracy while reducing inference times by three orders of magnitude.\n",
      "subjects": [
        "cs.LG",
        "astro-ph.IM",
        "gr-qc",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions\n  for Evaluating the Robustness of Question Matching Models",
      "abstract": "  In this paper, we focus on studying robustness evaluation of Chinese question\nmatching. Most of the previous work on analyzing robustness issue focus on just\none or a few types of artificial adversarial examples. Instead, we argue that\nit is necessary to formulate a comprehensive evaluation about the linguistic\ncapabilities of models on natural texts. For this purpose, we create a Chinese\ndataset namely DuQM which contains natural questions with linguistic\nperturbations to evaluate the robustness of question matching models. DuQM\ncontains 3 categories and 13 subcategories with 32 linguistic perturbations.\nThe extensive experiments demonstrate that DuQM has a better ability to\ndistinguish different models. Importantly, the detailed breakdown of evaluation\nby linguistic phenomenon in DuQM helps us easily diagnose the strength and\nweakness of different models. Additionally, our experiment results show that\nthe effect of artificial adversarial examples does not work on the natural\ntexts.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Exploration-exploitation trade-off for continuous-time episodic\n  reinforcement learning with linear-convex models",
      "abstract": "  We develop a probabilistic framework for analysing model-based reinforcement\nlearning in the episodic setting. We then apply it to study finite-time horizon\nstochastic control problems with linear dynamics but unknown coefficients and\nconvex, but possibly irregular, objective function. Using probabilistic\nrepresentations, we study regularity of the associated cost functions and\nestablish precise estimates for the performance gap between applying optimal\nfeedback control derived from estimated and true model parameters. We identify\nconditions under which this performance gap is quadratic, improving the linear\nperformance gap in recent work [X. Guo, A. Hu, and Y. Zhang, arXiv preprint,\narXiv:2104.09311, (2021)], which matches the results obtained for stochastic\nlinear-quadratic problems. Next, we propose a phase-based learning algorithm\nfor which we show how to optimise exploration-exploitation trade-off and\nachieve sublinear regrets in high probability and expectation. When assumptions\nneeded for the quadratic performance gap hold, the algorithm achieves an order\n$\\mathcal{O}(\\sqrt{N} \\ln N)$ high probability regret, in the general case, and\nan order $\\mathcal{O}((\\ln N)^2)$ expected regret, in self-exploration case,\nover $N$ episodes, matching the best possible results from the literature. The\nanalysis requires novel concentration inequalities for correlated\ncontinuous-time observations, which we derive.\n",
      "subjects": [
        "cs.LG",
        "math.OC",
        "math.PR",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Cyclic Lattices, Ideal Lattices and Bounds for the Smoothing Parameter",
      "abstract": "  Cyclic lattices and ideal lattices were introduced by Micciancio in\n\\cite{D2}, Lyubashevsky and Micciancio in \\cite{L1} respectively, which play an\nefficient role in Ajtai's construction of a collision resistant Hash function\n(see \\cite{M1} and \\cite{M2}) and in Gentry's construction of fully homomorphic\nencryption (see \\cite{G}). Let $R=Z[x]/\\langle \\phi(x)\\rangle$ be a quotient\nring of the integer coefficients polynomials ring, Lyubashevsky and Micciancio\nregarded an ideal lattice as the correspondence of an ideal of $R$, but they\nneither explain how to extend this definition to whole Euclidean space\n$\\mathbb{R}^n$, nor exhibit the relationship of cyclic lattices and ideal\nlattices.\n  In this paper, we regard the cyclic lattices and ideal lattices as the\ncorrespondences of finitely generated $R$-modules, so that we may show that\nideal lattices are actually a special subclass of cyclic lattices, namely,\ncyclic integer lattices. In fact, there is a one to one correspondence between\ncyclic lattices in $\\mathbb{R}^n$ and finitely generated $R$-modules (see\nTheorem \\ref{th4} below). On the other hand, since $R$ is a Noether ring, each\nideal of $R$ is a finitely generated $R$-module, so it is natural and\nreasonable to regard ideal lattices as a special subclass of cyclic lattices\n(see corollary \\ref{co3.4} below). It is worth noting that we use more general\nrotation matrix here, so our definition and results on cyclic lattices and\nideal lattices are more general forms. As application, we provide cyclic\nlattice with an explicit and countable upper bound for the smoothing parameter\n(see Theorem \\ref{th5} below). It is an open problem that is the shortest\nvector problem on cyclic lattice NP-hard? (see \\cite{D2}). Our results may be\nviewed as a substantial progress in this direction.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the intersection ideal graph of semigroups",
      "abstract": "  The intersection ideal graph $\\Gamma(S)$ of a semigroup $S$ is a simple\nundirected graph whose vertices are all nontrivial left ideals of $S$ and two\ndistinct left ideals $I, J$ are adjacent if and only if their intersection is\nnontrivial. In this paper, we investigate the connectedness of $\\Gamma(S)$. We\nshow that if $\\Gamma(S)$ is connected then $diam(\\Gamma(S)) \\leq 2$. Further we\nclassify the semigroups such that the diameter of their intersection graph is\ntwo. Other graph invariants, namely perfectness, planarity, girth, dominance\nnumber, clique number, independence number etc. are also discussed. Finally, if\n$S$ is union of $n$ minimal left ideals then we obtain the automorphism group\nof $\\Gamma(S)$.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1098/rspa.2022.0040",
      "title": "Highly coordinated nationwide massive travel restrictions are central to\n  effective mitigation and control of COVID-19 outbreaks in China",
      "abstract": "  The COVID-19, the disease caused by the novel coronavirus 2019 (SARS-CoV-2),\nhas caused graving woes across the globe since first reported in the epicenter\nWuhan, Hubei, China, December 2019. The spread of COVID-19 in China has been\nsuccessfully curtailed by massive travel restrictions that put more than 900\nmillion people housebound for more than two months since the lockdown of Wuhan\non 23 January 2020 when other provinces in China followed suit. Here, we assess\nthe impact of China's massive lockdowns and travel restrictions reflected by\nthe changes in mobility patterns before and during the lockdown period. We\nquantify the synchrony of mobility patterns across provinces and within\nprovinces. Using these mobility data, we calibrate movement flow between\nprovinces in combination with an epidemiological compartment model to quantify\nthe effectiveness of lockdowns and reductions in disease transmission. Our\nanalysis demonstrates that the onset and phase of local community transmission\nin other provinces depends on the cumulative population outflow received from\nthe epicenter Hubei. As such, infections can propagate further into other\ninterconnected places both near and far, thereby necessitating synchronous\nlockdowns. Moreover, our data-driven modeling analysis shows that lockdowns and\nconsequently reduced mobility lag a certain time to elicit an actual impact on\nslowing down the spreading and ultimately putting the epidemic under check. In\nspite of the vastly heterogeneous demographics and epidemiological\ncharacteristics across China, mobility data shows that massive travel\nrestrictions have been applied consistently via a top-down approach along with\nhigh levels of compliance from the bottom up.\n",
      "subjects": [
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Impact of Bidding and Dispatch Models over Energy Storage Utilization in\n  Bulk Power Systems",
      "abstract": "  Energy storage is a key enabler towards a low-emission electricity system,\nbut requires appropriate dispatch models to be economically coordinated with\nother generation resources in bulk power systems. This paper analyzes how\ndifferent dispatch models and bidding strategies would affect the utilization\nof storage with various durations in deregulated power systems. We use a\ndynamic programming model to calculate the operation opportunity value of\nstorage from price predictions, and use the opportunity value result as a base\nfor designing market bids. We compare two market bidding and dispatch models in\nsingle-period economic dispatch: one without state of charge (SoC) constraints\nand one with SoC constraints. We test the two storage dispatch models, combined\nwith different price predictions and storage durations, using historical\nreal-time price data from New York Independent System Operator. We compare the\nutilization rate with respect to results from perfect price forecast cases. Our\nresult shows that while price prediction accuracy is critical for short\nduration storage with a less than four hours capacity, storage with a duration\nlonger than twelve hours can easily achieve a utilization rate higher than 80\\%\neven with naive day-ahead price predictions. Modeling storage bids as dependent\nof SoC in single-period real-time dispatch will provide around 5% of\nimprovement in storage utilization over all duration cases and bidding\nstrategies, and higher renewable share will likely improve storage utilization\nrate due to higher occurrence of negative prices.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Mass and radius of balls in Gromov-Hausdorff-Prokhorov convergent\n  sequences",
      "abstract": "  We survey some properties of Gromov--Hausdorff--Prokhorov convergent\nsequences $(\\mathsf{X}_n, d_{\\mathsf{X}_n}, \\nu_{\\mathsf{X}_n})_{n \\ge 1}$ of\nrandom compact metric spaces equipped with Borel probability measures. We\nformalize that if the limit is almost surely non-atomic, then for large $n$\neach open ball in $\\mathsf{X}_n$ with small radius must have small mass.\nConversely, if the limit is almost surely fully supported, then each closed\nball in $\\mathsf{X}_n$ with small mass must have small radius. We do not claim\nany new results, but justifications are provided for properties for which we\ncould not find explicit references.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fair ranking: a critical review, challenges, and future directions",
      "abstract": "  Ranking, recommendation, and retrieval systems are widely used in online\nplatforms and other societal systems, including e-commerce, media-streaming,\nadmissions, gig platforms, and hiring. In the recent past, a large \"fair\nranking\" research literature has been developed around making these systems\nfair to the individuals, providers, or content that are being ranked. Most of\nthis literature defines fairness for a single instance of retrieval, or as a\nsimple additive notion for multiple instances of retrievals over time. This\nwork provides a critical overview of this literature, detailing the often\ncontext-specific concerns that such an approach misses: the gap between high\nranking placements and true provider utility, spillovers and compounding\neffects over time, induced strategic incentives, and the effect of statistical\nuncertainty. We then provide a path forward for a more holistic and\nimpact-oriented fair ranking research agenda, including methodological lessons\nfrom other fields and the role of the broader stakeholder community in\novercoming data bottlenecks and designing effective regulatory environments.\n",
      "subjects": [
        "cs.IR",
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Reinforcement Learning with Heterogeneous Data: Estimation and Inference",
      "abstract": "  Reinforcement Learning (RL) has the promise of providing data-driven support\nfor decision-making in a wide range of problems in healthcare, education,\nbusiness, and other domains. Classical RL methods focus on the mean of the\ntotal return and, thus, may provide misleading results in the setting of the\nheterogeneous populations that commonly underlie large-scale datasets. We\nintroduce the K-Heterogeneous Markov Decision Process (K-Hetero MDP) to address\nsequential decision problems with population heterogeneity. We propose the\nAuto-Clustered Policy Evaluation (ACPE) for estimating the value of a given\npolicy, and the Auto-Clustered Policy Iteration (ACPI) for estimating the\noptimal policy in a given policy class. Our auto-clustered algorithms can\nautomatically detect and identify homogeneous sub-populations, while estimating\nthe Q function and the optimal policy for each sub-population. We establish\nconvergence rates and construct confidence intervals for the estimators\nobtained by the ACPE and ACPI. We present simulations to support our\ntheoretical findings, and we conduct an empirical study on the standard\nMIMIC-III dataset. The latter analysis shows evidence of value heterogeneity\nand confirms the advantages of our new method.\n",
      "subjects": [
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training",
      "abstract": "  We introduce Corrupted Image Modeling (CIM) for self-supervised visual\npre-training. CIM uses an auxiliary generator with a small trainable BEiT to\ncorrupt the input image instead of using artificial [MASK] tokens, where some\npatches are randomly selected and replaced with plausible alternatives sampled\nfrom the BEiT output distribution. Given this corrupted image, an enhancer\nnetwork learns to either recover all the original image pixels, or predict\nwhether each visual token is replaced by a generator sample or not. The\ngenerator and the enhancer are simultaneously trained and synergistically\nupdated. After pre-training, the enhancer can be used as a high-capacity visual\nencoder for downstream tasks. CIM is a general and flexible visual pre-training\nframework that is suitable for various network architectures. For the first\ntime, CIM demonstrates that both ViT and CNN can learn rich visual\nrepresentations using a unified, non-Siamese framework. Experimental results\nshow that our approach achieves compelling results in vision benchmarks, such\nas ImageNet classification and ADE20K semantic segmentation.\n",
      "subjects": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1748-0221/5/12/C12045",
      "title": "A 4.9-GHz Low Power, Low Jitter, LC Phase Locked Loop",
      "abstract": "  This paper presents a low power, low jitter LC phase locked loop (PLL) which\nhas been designed and fabricated in a commercial 0.25-um Silicon-on-Sapphire\nCMOS technology. Random jitter and deterministic jitter of the PLL are 1.3 ps\nand 7.5 ps, respectively. The measured tuning range, from 4.6 to 5.0 GHz, is\nnarrower than the expected one, from 3.8 to 5.0 GHz. The narrow tuning range\nissue has been investigated and traced to the first stage of the divider chain.\nThe power consumption at the central frequency is 111 mW.\n",
      "subjects": [
        "physics.ins-det"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3495211",
      "title": "When Did It Happen? Duration-informed Temporal Localization of Narrated\n  Actions in Vlogs",
      "abstract": "  We consider the task of temporal human action localization in lifestyle\nvlogs. We introduce a novel dataset consisting of manual annotations of\ntemporal localization for 13,000 narrated actions in 1,200 video clips. We\npresent an extensive analysis of this data, which allows us to better\nunderstand how the language and visual modalities interact throughout the\nvideos. We propose a simple yet effective method to localize the narrated\nactions based on their expected duration. Through several experiments and\nanalyses, we show that our method brings complementary information with respect\nto previous methods, and leads to improvements over previous work for the task\nof temporal action localization.\n",
      "subjects": [
        "cs.CV",
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Complete minors and average degree -- a short proof",
      "abstract": "  We provide a short and self-contained proof of the classical result of\nKostochka and of Thomason, ensuring that every graph of average degree $d$ has\na complete minor of order $d/\\sqrt{\\log d}$.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Optimization flows landing on the Stiefel manifold",
      "abstract": "  We study a continuous-time system that solves optimization problems over the\nset of orthonormal matrices, which is also known as the Stiefel manifold. The\nresulting optimization flow follows a path that is not always on the manifold\nbut asymptotically lands on the manifold. We introduce a generalized Stiefel\nmanifold to which we extend the canonical metric of the Stiefel manifold. We\nshow that the vector field of the proposed flow can be interpreted as the sum\nof a Riemannian gradient on a generalized Stiefel manifold and a normal vector.\nMoreover, we prove that the proposed flow globally converges to the set of\ncritical points, and any local minimum and isolated critical point is\nasymptotically stable.\n",
      "subjects": [
        "math.OC",
        "math.DS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.18653/v1/2023.eacl-main.27",
      "title": "USCORE: An Effective Approach to Fully Unsupervised Evaluation Metrics\n  for Machine Translation",
      "abstract": "  The vast majority of evaluation metrics for machine translation are\nsupervised, i.e., (i) are trained on human scores, (ii) assume the existence of\nreference translations, or (iii) leverage parallel data. This hinders their\napplicability to cases where such supervision signals are not available. In\nthis work, we develop fully unsupervised evaluation metrics. To do so, we\nleverage similarities and synergies between evaluation metric induction,\nparallel corpus mining, and MT systems. In particular, we use an unsupervised\nevaluation metric to mine pseudo-parallel data, which we use to remap deficient\nunderlying vector spaces (in an iterative manner) and to induce an unsupervised\nMT system, which then provides pseudo-references as an additional component in\nthe metric. Finally, we also induce unsupervised multilingual sentence\nembeddings from pseudo-parallel data. We show that our fully unsupervised\nmetrics are effective, i.e., they beat supervised competitors on 4 out of our 5\nevaluation datasets. We make our code publicly available.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Topological portals from matter to antimatter",
      "abstract": "  We discuss possibilities of generating a Majorana mass for the neutron from\ntopological quantum gravity effects which survive at mesoscopic scales from\ndecoherence. We show how virtual micro-black hole (BH) pairs with skyrme/baryon\nhairs induce a neutron-antineutron transition which can be tested in next\ngeneration of experiments. Such effects do not destabilize the proton. We also\ndiscuss how BHs with mix ordinary and mirror baryon hairs can mediate\nneutron-mirror neutron mixings.\n",
      "subjects": [
        "hep-ph",
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.14445/22315373/IJMTT-V68I2P501",
      "title": "Application of Tikhonov Regularization in Generalized Inverse of\n  Adjacency Matrix of Undirected Graph",
      "abstract": "  In this paper, we found the Moore-Penrose generalized inverse of adjacency\nmatrix of an undirected graph, explicitly. We proved that the matrix\n$R_\\lambda= [r_{ij}]$ is nonsingular where $r_{ii}=\\frac{1}{\\lambda}+ \\deg v_i$\nand $r_{ij}=\\mid N_G(V_i)\\cap N_G(V_j)\\mid$ for $i\\neq j$, and we proved that\n$A^{\\dagger}_G=[s_{ij}]_{1\\leq i, j \\leq n}$ where\n$\\displaystyle{s_{ij}=s_{ji}=\\lim_{\\lambda \\rightarrow +\\infty} \\langle\nR^{-1}_{\\lambda}e_j, f_i \\rangle }$. The proof of the main result was based on\nthe Tikhonov regularization.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.105.084043",
      "title": "Bardeen-Kiselev black hole with cosmological constant",
      "abstract": "  In this work we analyze a solution that mimics the Bardeen solution with a\ncosmological constant surrounded by quintessence. We show that this solution\ncan be obtained by Einstein equations coupled with nonlinear electrodynamics.\nWe also show that the solution is not always regular and what the conditions\nfor regularity are. We analyze the thermodynamics associated with this type of\nsolution by establishing the form of the Smarr formula and the first law of\nthermodynamics. We obtain some thermodynamic quantities such as pressure,\ntemperature, heat capacity and isothermal compressibility. Once we have these\nthermodynamic quantities, we check if this solution has phase transitions and\nhow it behaves at the points where the transitions occur. For some values of\nthe parameters, we find that the solution exhibits a first-order phase\ntransition, like a van der Waals fluid.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1098/rsta.2021.0385",
      "title": "Edge Waves and Transmissions for Temporal Laminates and Imperfect Chiral\n  Interfaces",
      "abstract": "  The analysis of wave patterns in a structure which possesses periodicity in\nthe spatial and temporal dimensions is presented. The topic of imperfect chiral\ninterfaces is also considered. Although causality is fundamental for physical\nprocesses, natural wave phenomena can be observed when a wave is split at a\ntemporal interface. A wave split at a spatial interface is a more common\noccurrence; however when the coefficients of the governing equations are\ntime-dependent, the temporal interface becomes important. Here, the associated\nedge waves are studied, and regimes are analysed where the growth of the\nsolution in time is found. Imperfect interfaces, across which the displacements\nare discontinuous, are also considered in the vector case of chiral elastic\nsystems. Analytical study and asymptotic approximations are supplied with\nillustrative numerical examples.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Symmetry-Based Representations for Artificial and Biological General\n  Intelligence",
      "abstract": "  Biological intelligence is remarkable in its ability to produce complex\nbehaviour in many diverse situations through data efficient, generalisable and\ntransferable skill acquisition. It is believed that learning \"good\" sensory\nrepresentations is important for enabling this, however there is little\nagreement as to what a good representation should look like. In this review\narticle we are going to argue that symmetry transformations are a fundamental\nprinciple that can guide our search for what makes a good representation. The\nidea that there exist transformations (symmetries) that affect some aspects of\nthe system but not others, and their relationship to conserved quantities has\nbecome central in modern physics, resulting in a more unified theoretical\nframework and even ability to predict the existence of new particles. Recently,\nsymmetries have started to gain prominence in machine learning too, resulting\nin more data efficient and generalisable algorithms that can mimic some of the\ncomplex behaviours produced by biological intelligence. Finally, first\ndemonstrations of the importance of symmetry transformations for representation\nlearning in the brain are starting to arise in neuroscience. Taken together,\nthe overwhelming positive effect that symmetries bring to these disciplines\nsuggest that they may be an important general framework that determines the\nstructure of the universe, constrains the nature of natural tasks and\nconsequently shapes both biological and artificial intelligence.\n",
      "subjects": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Minimum Variance Unbiased N:M Sparsity for the Neural Gradients",
      "abstract": "  In deep learning, fine-grained N:M sparsity reduces the data footprint and\nbandwidth of a General Matrix multiply (GEMM) up to x2, and doubles throughput\nby skipping computation of zero values. So far, it was mainly only used to\nprune weights to accelerate the forward and backward phases. We examine how\nthis method can be used also for the neural gradients (i.e., loss gradients\nwith respect to the intermediate neural layer outputs). To this end, we first\nestablish a tensor-level optimality criteria. Previous works aimed to minimize\nthe mean-square-error (MSE) of each pruned block. We show that while\nminimization of the MSE works fine for pruning the weights and activations, it\ncatastrophically fails for the neural gradients. Instead, we show that accurate\npruning of the neural gradients requires an unbiased minimum-variance pruning\nmask. We design such specialized masks, and find that in most cases, 1:2\nsparsity is sufficient for training, and 2:4 sparsity is usually enough when\nthis is not the case. Further, we suggest combining several such methods\ntogether in order to potentially speed up training even more.\n",
      "subjects": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Quantization for the mixtures of uniform distributions on connected and\n  disconnected line segments",
      "abstract": "  In this paper, we have considered different mixed distributions which are\ngenerated by two uniform distributions: first supported by two connected line\nsegments, and then supported by two disconnected line segments. For these mixed\ndistributions, we have determined the optimal sets of $n$-means and the $n$th\nquantization errors for all positive integers $n$. The technique of this paper\ncan be utilized to investigate the optimal quantization for any mixed\ndistributions $P:=pP_1+(1-p)P_2$, generated by any two probability\ndistributions $P_1$ and $P_2$ associated with any probability vector $(p, 1-p)$\nfor $0<p<1$ with support a connected or the union of disconnected line\nsegments.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.106.092002",
      "title": "Xenon-Doped Liquid Argon TPCs as a Neutrinoless Double Beta Decay\n  Platform",
      "abstract": "  Searches for neutrinoless double-beta decay continue to expand our\nunderstanding of the lepton sector, with experiments now pursuing ton-scale\ntarget masses with sensitivity to $m_{\\beta\\beta}$ covering the allowed\nparameter space for the inverted neutrino mass ordering. Continued searches for\nthis rare decay will require scalable detector technologies to achieve\nsignificant increases in the target mass beyond the ton scale, in order to\nprobe the normal ordering region. This work explores the concept of searching\nfor neutrinoless double-beta decay in a 10 kton scale liquid argon time\nprojection chamber (LArTPC) located deep underground and doped with\npercent-level quantities of xenon. We discuss the design requirements,\nbackground mitigation and detector R&D needs, and considerations for deployment\nin a modified DUNE far detector module. We find that such a detector could\nreach $m_{\\beta\\beta}$ sensitivity at the 2-4 meV range with xenon doping at 2%\nif significant background reductions can be achieved.\n",
      "subjects": [
        "hep-ex",
        "nucl-ex",
        "physics.ins-det"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.106.085127",
      "title": "Chirality-dependent second-order spin current in systems with\n  time-reversal symmetry",
      "abstract": "  Spin currents proportional to the first- and second-order of the electric\nfield are calculated in a specific tight-binding model with time-reversal\nsymmetry. Specifically, a tight-binding model with time-reversal symmetry is\nconstructed with chiral hopping and spin-orbit coupling. The spin conductivity\nof the model is calculated using the Boltzmann equation. As a result, it is\nclarified that the first-order spin current of the electric field vanishes,\nwhile the second-order spin current can be finite. Furthermore, the spin\ncurrent changes its sign by reversing the chirality of the model. The present\nresults reveal the existence of spin currents in systems with time-reversal\nsymmetry depending on the chirality of the system. They may provide useful\ninformation for understanding the chirality-dependent spin polarization\nphenomena in systems with time-reversal symmetry.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/TPAMI.2022.3159811",
      "title": "On Distinctive Image Captioning via Comparing and Reweighting",
      "abstract": "  Recent image captioning models are achieving impressive results based on\npopular metrics, i.e., BLEU, CIDEr, and SPICE. However, focusing on the most\npopular metrics that only consider the overlap between the generated captions\nand human annotation could result in using common words and phrases, which\nlacks distinctiveness, i.e., many similar images have the same caption. In this\npaper, we aim to improve the distinctiveness of image captions via comparing\nand reweighting with a set of similar images. First, we propose a\ndistinctiveness metric -- between-set CIDEr (CIDErBtw) to evaluate the\ndistinctiveness of a caption with respect to those of similar images. Our\nmetric reveals that the human annotations of each image in the MSCOCO dataset\nare not equivalent based on distinctiveness; however, previous works normally\ntreat the human annotations equally during training, which could be a reason\nfor generating less distinctive captions. In contrast, we reweight each\nground-truth caption according to its distinctiveness during training. We\nfurther integrate a long-tailed weight strategy to highlight the rare words\nthat contain more information, and captions from the similar image set are\nsampled as negative examples to encourage the generated sentence to be unique.\nFinally, extensive experiments are conducted, showing that our proposed\napproach significantly improves both distinctiveness (as measured by CIDErBtw\nand retrieval metrics) and accuracy (e.g., as measured by CIDEr) for a wide\nvariety of image captioning baselines. These results are further confirmed\nthrough a user study.\n",
      "subjects": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.105.063514",
      "title": "Manipulating the transverse spin angular momentum and Belinfante\n  momentum of spin-polarized light by a tilted stratified medium in optical\n  tweezers",
      "abstract": "  In the recent past, optical tweezers incorporating a stratified medium have\nbeen exploited to generate complex translational and rotational dynamics in\nmesoscopic particles due to the coupling between the spin and orbital angular\nmomentum of the light, generated as a consequence of the tight focusing of\nlight by a high numerical aperture objective lens into the stratified medium.\nHere, we consider an optical tweezers system with a tilted stratified medium\n(direction of stratification at an angle with the axis of the incident beam),\nand show that for input circularly polarized Gaussian beams, the resulting\nspin-orbit interaction deeply influences the generation of transverse spin\nangular momentum (TSAM) and Belinfante momentum of light, and allows additional\ncontrol on their magnitude. Importantly, the TSAM generated in our system\nconsists of both the orthogonal components, which is in sharp contrast to the\ncase of evanescent waves and surface plasmons, where only one of the TSAM\ncomponents are generated. The broken symmetry due to the tilt ensures that,\ndepending upon the helicity of the input beam, the magnitude of the mutually\northogonal components of the TSAM depend entirely on the tilt angle. This may\nprove to be an effective handle in exotic spin-controlled manipulation of\nparticles in experiments.\n",
      "subjects": [
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Breakdown voltage and linear temperature drift in a single-molecule\n  junction",
      "abstract": "  Using first-principles calculations based on density functional theory\ncombined with the non-equilibrium Green's function approach, the transport\nbehaviors of a single-molecule junction formed by benzenedithiol connected to\ngold electrodes are investigated. The breakdown voltage for the model of\nbenzenedithiol plus gold electrodes is 0.7 V, which is close to the\nexperimental value. A linear response between the conductance and temperature\n(known as linear temperature drift) is found in the molecular device, which\nindicates that it could be used to maintain the stability of molecular\ncircuits. Meanwhile, input and output with the same accuracies would be useful\nfor designing multi-level circuits, which would be used to improve the\nresolution ratio in analog-to-digital converters. The present findings indicate\nthat benzenedithiol-based single-molecule junctions would be promising\nfunctional units for molecular sensors.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "physics.comp-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Differentially Private Distributed Mismatch Tracking Algorithm for\n  Constraint-Coupled Resource Allocation Problems",
      "abstract": "  This paper considers privacy-concerned distributed constraint-coupled\nresource allocation problems over an undirected network, where each agent holds\na private cost function and obtains the solution via only local communication.\nWith privacy concerns, we mask the exchanged information with independent\nLaplace noise against a potential attacker with potential access to all network\ncommunications. We propose a differentially private distributed mismatch\ntracking algorithm (diff-DMAC) to achieve cost-optimal distribution of\nresources while preserving privacy. Adopting constant stepsizes, the linear\nconvergence property of diff-DMAC in mean square is established under the\nstandard assumptions of Lipschitz gradients and strong convexity. Moreover, it\nis theoretically proven that the proposed algorithm is\n{\\epsilon}-differentially private.And we also show the trade-off between\nconvergence accuracy and privacy level. Finally, a numerical example is\nprovided for verification.\n",
      "subjects": [
        "math.OC",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Interactiveness Field in Human-Object Interactions",
      "abstract": "  Human-Object Interaction (HOI) detection plays a core role in activity\nunderstanding. Though recent two/one-stage methods have achieved impressive\nresults, as an essential step, discovering interactive human-object pairs\nremains challenging. Both one/two-stage methods fail to effectively extract\ninteractive pairs instead of generating redundant negative pairs. In this work,\nwe introduce a previously overlooked interactiveness bimodal prior: given an\nobject in an image, after pairing it with the humans, the generated pairs are\neither mostly non-interactive, or mostly interactive, with the former more\nfrequent than the latter. Based on this interactiveness bimodal prior we\npropose the \"interactiveness field\". To make the learned field compatible with\nreal HOI image considerations, we propose new energy constraints based on the\ncardinality and difference in the inherent \"interactiveness field\" underlying\ninteractive versus non-interactive pairs. Consequently, our method can detect\nmore precise pairs and thus significantly boost HOI detection performance,\nwhich is validated on widely-used benchmarks where we achieve decent\nimprovements over state-of-the-arts. Our code is available at\nhttps://github.com/Foruck/Interactiveness-Field.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "SmartSales: Sales Script Extraction and Analysis from Sales Chatlog",
      "abstract": "  In modern sales applications, automatic script extraction and management\ngreatly decrease the need for human labor to collect the winning sales scripts,\nwhich largely boost the success rate for sales and can be shared across the\nsales teams. In this work, we present the SmartSales system to serve both the\nsales representatives and managers to attain the sales insights from the\nlarge-scale sales chatlog. SmartSales consists of three modules: 1) Customer\nfrequently asked questions (FAQ) extraction aims to enrich the FAQ knowledge\nbase by harvesting high quality customer question-answer pairs from the\nchatlog. 2) Customer objection response assists the salespeople to figure out\nthe typical customer objections and corresponding winning sales scripts, as\nwell as search for proper sales responses for a certain customer objection. 3)\nSales manager dashboard helps sales managers to monitor whether a specific\nsales representative or team follows the sales standard operating procedures\n(SOP). The proposed prototype system is empowered by the state-of-the-art\nconversational intelligence techniques and has been running on the Tencent\nCloud to serve the sales teams from several different areas.\n",
      "subjects": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Assembly Planning from Observations under Physical Constraints",
      "abstract": "  This paper addresses the problem of copying an unknown assembly of primitives\nwith known shape and appearance using information extracted from a single\nphotograph by an off-the-shelf procedure for object detection and pose\nestimation. The proposed algorithm uses a simple combination of physical\nstability constraints, convex optimization and Monte Carlo tree search to plan\nassemblies as sequences of pick-and-place operations represented by STRIPS\noperators. It is efficient and, most importantly, robust to the errors in\nobject detection and pose estimation unavoidable in any real robotic system.\nThe proposed approach is demonstrated with thorough experiments on a UR5\nmanipulator.\n",
      "subjects": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.129.230403",
      "title": "Exponentially decreasing critical detection efficiency for any Bell\n  inequality",
      "abstract": "  We address the problem of closing the detection efficiency loophole in Bell\nexperiments, which is crucial for real-world applications. Every Bell\ninequality has a critical detection efficiency $\\eta$ that must be surpassed to\navoid the detection loophole. Here, we propose a general method for reducing\nthe critical detection efficiency of any Bell inequality to arbitrary low\nvalues. This is accomplished by entangling two particles in $N$ orthogonal\nsubspaces (e.g., $N$ degrees of freedom) and conducting $N$ Bell tests in\nparallel. Furthermore, the proposed method is based on the introduction of\npenalized $N$-product (PNP) Bell inequalities, for which the so-called\nsimultaneous measurement loophole is closed, and the maximum value for local\nhidden-variable theories is simply the $N$th power of the one of the Bell\ninequality initially considered. We show that, for the PNP Bell inequalities,\nthe critical detection efficiency decays exponentially with $N$. The strength\nof our method is illustrated with a detailed study of the PNP Bell inequalities\nresulting from the Clauser-Horne-Shimony-Holt inequality.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1080/19427867.2022.2050493",
      "title": "Adaptive Traffic Signal Control for Developing Countries Using Fused\n  Parameters Derived from Crowd-Source Data",
      "abstract": "  Advancement of mobile technologies has enabled economical collection,\nstorage, processing, and sharing of traffic data. These data are made\naccessible to intended users through various application program interfaces\n(API) and can be used to recognize and mitigate congestion in real time. In\nthis paper, quantitative (time of arrival) and qualitative (color-coded\ncongestion levels) data were acquired from the Google traffic APIs. New\nparameters that reflect heterogeneous traffic conditions were defined and\nutilized for real-time control of traffic signals while maintaining the\ngreen-to-red time ratio. The proposed method utilizes a congestion-avoiding\nprinciple commonly used in computer networking. Adaptive congestion levels were\nobserved on three different intersections of Delhi (India), in peak hours. It\nshowed good variation, hence sensitive for the control algorithm to act\nefficiently. Also, simulation study establishes that proposed control algorithm\ndecreases waiting time and congestion. The proposed method provides an\ninexpensive alternative for traffic sensing and tracking technologies.\n",
      "subjects": [
        "physics.soc-ph",
        "cs.SY",
        "eess.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Graph Convolutional Reinforcement Learning for Collaborative Queuing\n  Agents",
      "abstract": "  In this paper, we explore the use of multi-agent deep learning as well as\nlearning to cooperate principles to meet stringent service level agreements, in\nterms of throughput and end-to-end delay, for a set of classified network\nflows. We consider agents built on top of a weighted fair queuing algorithm\nthat continuously set weights for three flow groups: gold, silver, and bronze.\nWe rely on a novel graph-convolution based, multi-agent reinforcement learning\napproach known as DGN. As benchmarks, we propose centralized and distributed\ndeep Q-network approaches and evaluate their performances in different network,\ntraffic, and routing scenarios, highlighting the effectiveness of our proposals\nand the importance of agent cooperation. We show that our DGN-based approach\nmeets stringent throughput and delay requirements across all scenarios.\n",
      "subjects": [
        "cs.NI",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "$2 n^2$-inequality for $cA_1$ points and applications to birational\n  rigidity",
      "abstract": "  The $4 n^2$-inequality for smooth points plays an important role in the\nproofs of birational (super)rigidity. The main aim of this paper is to\ngeneralize such an inequality to terminal singular points of type $cA_1$, and\nobtain a $2 n^2$-inequality for $cA_1$ points. As applications, we prove\nbirational (super)rigidity of sextic double solids, many other prime Fano\n3-fold weighted complete intersections, and del Pezzo fibrations of degree $1$\nover $\\mathbb{P}^1$ satisfying the $K^2$-condition, all of which have at most\nterminal $cA_1$ singularities and terminal quotient singularities. These give\nfirst examples of birationally (super)rigid Fano 3-folds and del Pezzo\nfibrations admitting a $cA_1$ point which is not an ordinary double point.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stad266",
      "title": "ALMA Confirmation of an Obscured Hyperluminous Radio-Loud AGN at\n  $z=6.853$ Associated with a Dusty Starburst in the 1.5 deg$^2$ COSMOS Field",
      "abstract": "  We present band 6 ALMA observations of a heavily-obscured radio-loud\n($L_{1.4\\ \\mathrm{GHz}}=10^{25.4}$ W Hz$^{-1}$) AGN candidate at\n$z_\\mathrm{phot}=6.83\\pm0.06$ found in the 1.5 deg$^2$ COSMOS field. The ALMA\ndata reveal detections of exceptionally strong [CII]158$\\mu$m\n($z_\\mathrm{[CII]}=6.8532$) and underlying dust continuum emission from this\nobject (COS-87259), where the [CII] line luminosity, line width, and 158$\\mu$m\ncontinuum luminosity are comparable to that seen from $z\\sim7$ sub-mm galaxies\nand quasar hosts. The 158$\\mu$m continuum detection suggests a total infrared\nluminosity of $9\\times10^{12}$ $L_\\odot$ with corresponding very large obscured\nstar formation rate (1300 $M_\\odot$/yr) and dust mass ($2\\times10^9$\n$M_\\odot$). The strong break seen between the VIRCam and IRAC photometry\nperhaps suggests that COS-87259 is an extremely massive reionization era galaxy\nwith $M_\\ast\\approx1.7\\times10^{11}$ $M_\\odot$. Moreover, the MIPS, PACS, and\nSPIRE detections imply that this object harbors an AGN that is heavily obscured\n($\\tau_{_{\\mathrm{9.7\\mu m}}}=2.3$) with a bolometric luminosity of\napproximately $5\\times10^{13}$ $L_\\odot$. Such a very high AGN luminosity\nsuggests this object is powered by an $\\approx$1.6 $\\times$ 10$^9$ $M_\\odot$\nblack hole if accreting near the Eddington limit, and is effectively a\nhighly-obscured version of an extremely UV-luminous ($M_{1450}\\approx-27.3$)\n$z\\sim7$ quasar. Notably, these $z\\sim7$ quasars are an exceedingly rare\npopulation ($\\sim$0.001 deg$^{-2}$) while COS-87259 was identified over a\nrelatively small field. Future very wide-area surveys with, e.g., Roman and\nEuclid have the potential to identify many more extremely red yet UV-bright\n$z\\gtrsim7$ objects similar to COS-87259, providing richer insight into the\noccurrence of intense obscured star formation and supermassive black hole\ngrowth among this population.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Meta-SysId: A Meta-Learning Approach for Simultaneous Identification and\n  Prediction",
      "abstract": "  In this paper, we propose Meta-SysId, a meta-learning approach to model sets\nof systems that have behavior governed by common but unknown laws and that\ndifferentiate themselves by their context. Inspired by classical\nmodeling-and-identification approaches, Meta-SysId learns to represent the\ncommon law through shared parameters and relies on online optimization to\ncompute system-specific context. Compared to optimization-based meta-learning\nmethods, the separation between class parameters and context variables reduces\nthe computational burden while allowing batch computations and a simple\ntraining scheme. We test Meta-SysId on polynomial regression, time-series\nprediction, model-based control, and real-world traffic prediction domains,\nempirically finding it outperforms or is competitive with meta-learning\nbaselines.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "MSR: Making Self-supervised learning Robust to Aggressive Augmentations",
      "abstract": "  Most recent self-supervised learning methods learn visual representation by\ncontrasting different augmented views of images. Compared with supervised\nlearning, more aggressive augmentations have been introduced to further improve\nthe diversity of training pairs. However, aggressive augmentations may distort\nimages' structures leading to a severe semantic shift problem that augmented\nviews of the same image may not share the same semantics, thus degrading the\ntransfer performance. To address this problem, we propose a new SSL paradigm,\nwhich counteracts the impact of semantic shift by balancing the role of weak\nand aggressively augmented pairs. Specifically, semantically inconsistent pairs\nare of minority and we treat them as noisy pairs. Note that deep neural\nnetworks (DNNs) have a crucial memorization effect that DNNs tend to first\nmemorize clean (majority) examples before overfitting to noisy (minority)\nexamples. Therefore, we set a relatively large weight for aggressively\naugmented data pairs at the early learning stage. With the training going on,\nthe model begins to overfit noisy pairs. Accordingly, we gradually reduce the\nweights of aggressively augmented pairs. In doing so, our method can better\nembrace the aggressive augmentations and neutralize the semantic shift problem.\nExperiments show that our model achieves 73.1% top-1 accuracy on ImageNet-1K\nwith ResNet-50 for 200 epochs, which is a 2.5% improvement over BYOL. Moreover,\nexperiments also demonstrate that the learned representations can transfer well\nfor various downstream tasks.\n",
      "subjects": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Which models are innately best at uncertainty estimation?",
      "abstract": "  Due to the comprehensive nature of this paper, it has been updated and split\ninto two separate papers: \"A Framework For Benchmarking\nClass-out-of-distribution Detection And Its Application To ImageNet\" and \"What\nCan We Learn From The Selective Prediction And Uncertainty Estimation\nPerformance Of 523 Imagenet Classifiers\". We recommend reading them instead.\n  Deep neural networks must be equipped with an uncertainty estimation\nmechanism when deployed for risk-sensitive tasks. This paper studies the\nrelationship between deep architectures and their training regimes with their\ncorresponding selective prediction and uncertainty estimation performance. We\nconsider both in-distribution uncertainties and class-out-of-distribution ones.\nMoreover, we consider some of the most popular estimation performance metrics\npreviously proposed including AUROC, ECE, AURC, and coverage for selective\naccuracy constraint. We present a novel and comprehensive study of selective\nprediction and the uncertainty estimation performance of 484 existing\npretrained deep ImageNet classifiers that are available at popular\nrepositories. We identify numerous and previously unknown factors that affect\nuncertainty estimation and examine the relationships between the different\nmetrics. We find that distillation-based training regimes consistently yield\nbetter uncertainty estimations than other training schemes such as vanilla\ntraining, pretraining on a larger dataset and adversarial training. We also\nprovide strong empirical evidence showing that ViT is by far the most superior\narchitecture in terms of uncertainty estimation performance, judging by any\naspect, in both in-distribution and class-out-of-distribution scenarios.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A directed walk in probability space that locates mean field solutions\n  to spin models",
      "abstract": "  Despite their formal simplicity, most lattice spin models cannot be easily\nsolved, even under the simplifying assumptions of mean field theory. In this\nmanuscript, we present a method for generating mean field solutions to\nclassical continuous spins. We focus our attention on systems with non-local\ninteractions and non-periodic boundaries, which require careful handling with\nexisting approaches, such as Monte Carlo sampling. Our approach utilizes\nfunctional optimization to derive a closed-form optimality condition and arrive\nat self-consistent mean field equations. We show that this approach\nsignificantly outperforms conventional Monte Carlo sampling in convergence\nspeed and accuracy. To convey the general concept behind the approach, we first\ndemonstrate its application to a simple system - a finite one-dimensional\ndipolar chain in an external electric field. We then describe how the approach\nnaturally extends to more complicated spin systems and to continuum field\ntheories. Furthermore, we numerically illustrate the efficacy of our approach\nby highlighting its utility on nonperiodic spin models of various\ndimensionality.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevX.12.041031",
      "title": "Phonon Thermal Hall Conductivity from Scattering with Collective\n  Fluctuations",
      "abstract": "  Because electrons and ions form a coupled system, it is a priori clear that\nthe dynamics of the lattice should reflect symmetry breaking within the\nelectronic degrees of freedom. This has been recently clearly evidenced for the\ncase of time-reversal and mirror symmetry breakings by observations of a large\nphononic thermal Hall effect in many strongly correlated electronic materials.\nThe mechanism by which time-reversal breaking and chirality is communicated to\nthe lattice is, however, far from evident. In this paper we discuss how this\noccurs via many-body scattering of phonons by collective modes: a consequence\nof non-Gaussian correlations of the latter modes. We derive fundamental new\nresults for such skew (i.e. chiral) scattering and the consequent thermal Hall\nconductivity. From this we also obtain general formulae for these quantities\nfor ordered antiferromagnets. From the latter we obtain the scaling behavior of\nthe phonon thermal Hall effect in clean antiferromagnets. The calculations show\nseveral different regimes and give quantitative estimates of similar order to\nthat seen in recent experiments.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tight bounds for the learning of homotopy \\`a la Niyogi, Smale, and\n  Weinberger for subsets of Euclidean spaces and of Riemannian manifolds",
      "abstract": "  In this article we extend and strengthen the seminal work by Niyogi, Smale,\nand Weinberger on the learning of the homotopy type from a sample of an\nunderlying space. In their work, Niyogi, Smale, and Weinberger studied samples\nof $C^2$ manifolds with positive reach embedded in $\\mathbb{R}^d$. We extend\ntheir results in the following ways: In the first part of our paper we consider\nboth manifolds of positive reach -- a more general setting than $C^2$ manifolds\n-- and sets of positive reach embedded in $\\mathbb{R}^d$. The sample $P$ of\nsuch a set $\\mathcal{S}$ does not have to lie directly on it. Instead, we\nassume that the two one-sided Hausdorff distances -- $\\varepsilon$ and $\\delta$\n-- between $P$ and $\\mathcal{S}$ are bounded. We provide explicit bounds in\nterms of $\\varepsilon$ and $ \\delta$, that guarantee that there exists a\nparameter $r$ such that the union of balls of radius $r$ centred at the sample\n$P$ deformation-retracts to $\\mathcal{S}$.\n  In the second part of our paper we study homotopy learning in a significantly\nmore general setting -- we investigate sets of positive reach and submanifolds\nof positive reach embedded in a \\emph{Riemannian manifold with bounded\nsectional curvature}. To this end we introduce a new version of the reach in\nthe Riemannian setting inspired by the cut locus. Yet again, we provide tight\nbounds on $\\varepsilon$ and $\\delta$ for both cases (submanifolds as well as\nsets of positive reach), exhibiting the tightness by an explicit construction.\n",
      "subjects": [
        "cs.CG",
        "math.AT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Marginal Interventional Effects",
      "abstract": "  Conventional causal estimands, such as the average treatment effect (ATE),\nreflect how the mean outcome in a population or subpopulation would change if\nall units received treatment versus control. Real-world policy changes,\nhowever, are often incremental, changing the treatment status for only a small\nsegment of the population who are at or near \"the margin of participation.\" To\ncapture this notion, two parallel lines of inquiry have developed in economics\nand in statistics and epidemiology that define, identify, and estimate what we\ncall interventional effects. In this article, we bridge these two strands of\nliterature by defining interventional effect (IE) as the per capita effect of a\ntreatment intervention on an outcome of interest, and marginal interventional\neffect (MIE) as its limit when the size of the intervention approaches zero.\nThe IE and MIE can be viewed as the unconditional counterparts of the\npolicy-relevant treatment effect (PRTE) and marginal PRTE (MPRTE) proposed in\nthe economics literature. However, different from PRTE and MPRTE, IE and MIE\nare defined without reference to a latent index model, and, as we show, can be\nidentified either under unconfoundedness or through the use of instrumental\nvariables. For both scenarios, we show that MIEs are typically identified\nwithout the strong positivity assumption required of the ATE, highlight several\n\"stylized interventions\" that may be of particular interest in policy analysis,\ndiscuss several parametric and semiparametric estimation strategies, and\nillustrate the proposed methods with an empirical example.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.jssc.2017.01.014",
      "title": "Conditions for the formation of pure birnessite during the oxidation of\n  Mn(II) cations in aqueous alkaline medium",
      "abstract": "  Birnessite was synthetized through redox reaction by mixing MnO4-, Mn2+ and\nOH- solutions. The Mn(VII): Mn(II) ratio of 0.33 was chosen and three methods\nwere used consisting in a quick mixing under vigorous stirring of two of the\nthree reagents and then on the dropwise addition of the third one. The obtained\nsolids were characterized by XRD, FTIR and XPS spectroscopies. Their average\noxidation states were determined from ICP and CEC measurements while their\nsurface properties were investigated by XPS. This study provides an increased\nunderstanding of the importance of dissolved oxygen in the formation of\nbirnessite and hausmannite and shows the ways to obtain pure birnessite. The\nrole of counter-ion ie. Na+ or K+ was also examined.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "More Than a Wife and a Mom: A Study of Mom Vlogging Practices in China",
      "abstract": "  Mom vloggers are stay-at-home moms who record and share their daily life\nthrough short videos. In this exploratory study, we aspire to understand mom\nvloggers' motivations, practices, and challenges. Our mixed-methods inspection\ncontained interviews with 4 mom vloggers in China and a content analysis of mom\nvlogs of 5 other mom vloggers. Mom vloggers' primary motivations are to make\nmoney, record daily life, and seek their individual identities and values, well\nmeeting their financial and social needs after leaving their paid employment.\nWhen creating vlog content, mom bloggers encounter various challenges, such as\na lack of video visibility, being stretched by both intensive motherhood and\nheavy digital work, privacy and self-presentation concerns, and so on. Based on\nthe findings, we propose design implications toward resolving these challenges\nand benefiting mom vloggers' experiences.\n",
      "subjects": [
        "cs.HC",
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.106.083522",
      "title": "Constraints on extended Bekenstein models from cosmological,\n  astrophysical, and local data",
      "abstract": "  Searching for variations of nature's fundamental constants is a crucial step\nin our quest to go beyond our current standard model of fundamental physics. If\nthey exist, such variations will be very likely driven by the existence of a\nnew fundamental field. The Bekenstein model and its extensions introduce such a\nscalar field in a purely phenomenological way, inducing a variation of the\nfine-structure constant on cosmological scales. This theoretical framework is\nas simple and general as possible while still preserving all the symmetries of\nstandard quantum electrodynamics. When allowing for couplings to the other\nsectors of the Universe, such as baryons, dark matter, and the cosmological\nconstant, the Bekenstein model is expected to reproduce the low energy limits\nof several grand unification, quantum gravity, and higher dimensional theories.\nIn this work, we constrain different versions of the Bekenstein model by\nconfronting the full cosmological evolution of the field with an extensive set\nof astrophysical, cosmological, and local measurements. We show that couplings\nof the order of parts per million (ppm) are excluded for all the cases\nconsidered, imposing strong restrictions on theoretical frameworks aiming to\ndeal with variations of the fine-structure constant.\n",
      "subjects": [
        "astro-ph.CO",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Electron Sources for Accelerators",
      "abstract": "  Electron sources are essential to an array of electron accelerator supporting\nresearch in high-energy physics and beyond. This report summarizes the\n\"Snowmass 2021 Electron Source Workshop\" which reviewed the current\nstate-of-the art research and identified some possible research directions.\n",
      "subjects": [
        "physics.acc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1098/rspa.2023.0048",
      "title": "Law of elasticity and fracture limit of magnetic forcelines under their\n  gravitational deformation",
      "abstract": "  Magnetic fields are a very special form of elastic medium. Within\nastrophysical environments (magnetised stars and protogalaxies) they counteract\nshear and rotational distortions as well as gravitational collapse. Their\nvector nature allows for their extraordinary coupling with spacetime curvature\nin the framework of general relativity. This particular coupling points out the\nway to study magnetic elasticity under gravitational deformation. In this\ncontext, we reveal their law of elasticity, calculate their fracture limit and\nsubsequently argue that they ultimately lose the battle against gravitational\ncontraction of magnetised matter. Two illustrative applications, in a neutron\nstar and a white dwarf, accompany the results.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Theia : science cases and mission profiles for high precision astrometry\n  in the future",
      "abstract": "  High-precision astrometry well beyond the capacities of Gaia will provide a\nunique way to achieve astrophysical breakthroughs, in particular on the nature\nof dark matter, and a complete survey of nearby habitable exoplanets. In this\ncontribution, we present the scientific cases that require a flexibly-pointing\ninstrument capable of high astrometric accuracy and we review the best mission\nprofiles that can achieve such observations with the current space technology\nas well as within the boundary conditions defined by space agencies. We also\ndescribe the way the differential astrometric measurement is made using\nreference stars within the field. We show that the ultimate accuracy can be met\nwithout drastic constrains on the telescope stability.\n",
      "subjects": [
        "astro-ph.IM",
        "astro-ph.CO",
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On spectra of Hankel operators on the polydisc",
      "abstract": "  We give sufficient conditions for the essential spectrum of the Hermitian\nsquare of a class of Hankel operators on the Bergman space of the polydisc to\ncontain intervals. We also compute the spectrum in case the symbol is a\nmonomial.\n",
      "subjects": [
        "math.FA",
        "math.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Stochastic modeling using Adomian method and fractionnal differential\n  equations",
      "abstract": "  In this paper, we propose a fractional differential equation of order\none-half, to model the evolution through time of the dynamics of accumulation\nand elimination of the contaminant in human organism with a deficient immune\nsystem, during consecutive intakes of contaminated food. This process\nquantifies the exposure to toxins of subjects living with comorbidity (children\nnot breast-fed, the elderly, pregnant women) to food-born diseases. The Adomian\nDecomposition Method and the fractional integration of Riemann Liouville are\nused in the modeling processes.\n",
      "subjects": [
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tensor product indecomposability results for existentially closed\n  factors",
      "abstract": "  In the first part of the paper we survey several results from Popa's\ndeformation/rigidity theory on the classification of tensor product\ndecompositions of large natural classes of II$_1$ factors. Using a m\\'elange of\ntechniques from deformation/rigidity theory, model theory, and the recent works\n\\cite{CIOS21,CDI22} we highlight an uncountable family of existentially closed\nII$_1$ factors $M$ which do not admit tensor product decompositions $M= P\\bar\n\\otimes Q$ into diffuse factors where $Q$ is full. In the last section we\ndiscuss several open problems regarding the structural theory of existentially\nclosed factors.\n",
      "subjects": [
        "math.OA",
        "math.GR",
        "math.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.cmpb.2023.107685",
      "title": "Inflating 2D Convolution Weights for Efficient Generation of 3D Medical\n  Images",
      "abstract": "  The generation of three-dimensional (3D) medical images has great application\npotential since it takes into account the 3D anatomical structure. Two problems\nprevent effective training of a 3D medical generative model: (1) 3D medical\nimages are expensive to acquire and annotate, resulting in an insufficient\nnumber of training images, and (2) a large number of parameters are involved in\n3D convolution.\n  Methods: We propose a novel GAN model called 3D Split&Shuffle-GAN. To address\nthe 3D data scarcity issue, we first pre-train a two-dimensional (2D) GAN model\nusing abundant image slices and inflate the 2D convolution weights to improve\nthe initialization of the 3D GAN. Novel 3D network architectures are proposed\nfor both the generator and discriminator of the GAN model to significantly\nreduce the number of parameters while maintaining the quality of image\ngeneration. Several weight inflation strategies and parameter-efficient 3D\narchitectures are investigated.\n  Results: Experiments on both heart (Stanford AIMI Coronary Calcium) and brain\n(Alzheimer's Disease Neuroimaging Initiative) datasets show that our method\nleads to improved 3D image generation quality (14.7 improvements on Fr\\'echet\ninception distance) with significantly fewer parameters (only 48.5% of the\nbaseline method).\n  Conclusions: We built a parameter-efficient 3D medical image generation\nmodel. Due to the efficiency and effectiveness, it has the potential to\ngenerate high-quality 3D brain and heart images for real use cases.\n",
      "subjects": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Connected Tur\\'an number of trees",
      "abstract": "  As a variant of the much studied Tur\\'an number, $ex(n,F)$, the largest\nnumber of edges that an $n$-vertex $F$-free graph may contain, we introduce the\nconnected Tur\\'an number $ex_c(n,F)$, the largest number of edges that an\n$n$-vertex connected $F$-free graph may contain. We focus on the case where the\nforbidden graph is a tree. The celebrated conjecture of Erd\\H{o}s and S\\'os\nstates that for any tree $T$, we have $ex(n,T)\\le(|T|-2)\\frac{n}{2}$. We\naddress the problem how much smaller $ex_c(n,T)$ can be, what is the smallest\npossible ratio of $ex_c(n,T)$ and $(|T|-2)\\frac{n}{2}$ as $|T|$ grows. We also\ndetermine the exact value of $ex_c(n,T)$ for small trees, in particular for all\ntrees with at most six vertices. We introduce general constructions of\nconnected $T$-free graphs based on graph parameters as longest path, matching\nnumber, branching number, etc.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "RIS-Aided Localization Algorithm and Analysis: Tackling Non-Gaussian\n  Angle Estimation Errors",
      "abstract": "  Reconfigurable intelligent surface (RIS)-aided localization systems are\nincreasingly recognized for enhancing accuracy in internet of things (IoT)\nnetworks. However, prevailing studies tend to either assume a Gaussian\ndistribution for angle estimation error (AEE) or directly neglect the impact of\nthe AEE, overlooking its non-Gaussian nature in real-world scenarios,\nparticularly with diverse estimation methods (e.g., 2D-DFT algorithm).\nAddressing this oversight, this paper explores the design and performance\nanalysis of RIS-aided localization systems, specifically tackling non-Gaussian\nAEE. We adopt the classical two-step three-dimensional (3D) localization scheme\nto determine the position of mobile user (MU). Initially, we estimate angles of\narrival (AoAs) and time differences of arrival (TDoAs) at the RIS using\ndifferent methods, resulting in non-Gaussian and Gaussian errors, respectively.\nSubsequently, to accommodate the non-Gaussian nature of AoAs errors and the\nGaussian character of TDoA errors, we design a multiple weighted least squares\n(mWLS) algorithm to accurately localize MU. Besides, our research also includes\na unique bias analysis for evaluating the performance of the proposed\nlocalization algorithm under both Gaussian and non-Gaussian errors. Simulation\nresults demonstrate the effectiveness of both the proposed mWLS algorithm and\nthe bias analysis methodology.\n",
      "subjects": [
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition\n  using a Novel Transformers-based Model and an Innovative 270 Million-Words\n  Multi-Font Corpus of Classical Arabic with Diacritics",
      "abstract": "  This research is the second phase in a series of investigations on developing\nan Optical Character Recognition (OCR) of Arabic historical documents and\nexamining how different modeling procedures interact with the problem. The\nfirst research studied the effect of Transformers on our custom-built Arabic\ndataset. One of the downsides of the first research was the size of the\ntraining data, a mere 15000 images from our 30 million images, due to lack of\nresources. Also, we add an image enhancement layer, time and space\noptimization, and Post-Correction layer to aid the model in predicting the\ncorrect word for the correct context. Notably, we propose an end-to-end text\nrecognition approach using Vision Transformers as an encoder, namely BEIT, and\nvanilla Transformer as a decoder, eliminating CNNs for feature extraction and\nreducing the model's complexity. The experiments show that our end-to-end model\noutperforms Convolutions Backbones. The model attained a CER of 4.46%.\n",
      "subjects": [
        "cs.CV",
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "GHN-Q: Parameter Prediction for Unseen Quantized Convolutional\n  Architectures via Graph Hypernetworks",
      "abstract": "  Deep convolutional neural network (CNN) training via iterative optimization\nhas had incredible success in finding optimal parameters. However, modern CNN\narchitectures often contain millions of parameters. Thus, any given model for a\nsingle architecture resides in a massive parameter space. Models with similar\nloss could have drastically different characteristics such as adversarial\nrobustness, generalizability, and quantization robustness. For deep learning on\nthe edge, quantization robustness is often crucial. Finding a model that is\nquantization-robust can sometimes require significant efforts. Recent works\nusing Graph Hypernetworks (GHN) have shown remarkable performance predicting\nhigh-performant parameters of varying CNN architectures. Inspired by these\nsuccesses, we wonder if the graph representations of GHN-2 can be leveraged to\npredict quantization-robust parameters as well, which we call GHN-Q. We conduct\nthe first-ever study exploring the use of graph hypernetworks for predicting\nparameters of unseen quantized CNN architectures. We focus on a reduced CNN\nsearch space and find that GHN-Q can in fact predict quantization-robust\nparameters for various 8-bit quantized CNNs. Decent quantized accuracies are\nobserved even with 4-bit quantization despite GHN-Q not being trained on it.\nQuantized finetuning of GHN-Q at lower bitwidths may bring further improvements\nand is currently being explored.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1021/acsomega.2c06030",
      "title": "Non-Markovianity between site-pairs in FMO complex using discrete-time\n  quantum jump model",
      "abstract": "  The Fenna-Mathews-Olson (FMO) complex present in green sulphur bacteria is\nknown to mediate the transfer of excitation energy between light-harvesting\nchlorosomes and membrane-embedded bacterial reaction centres. Due to the high\nefficiency of such transport process, it is an extensively studied\npigment-protein complex system with the eventual aim of modelling and\nengineering similar dynamics in other systems and use it for real-time\napplication. Some studies have attributed the enhancement of transport\nefficiency to wave-like behaviour and non-Markovian quantum jumps resulting in\nlong-lived and revival of quantum coherence, respectively. Since dynamics in\nthese systems reside in the quantum-classical regime, quantum simulation of\nsuch dynamics will help in exploring the subtle role of quantum features in\nenhancing the transport efficiency, which has remained unsettled. Discrete\nsimulation of the dynamics in the FMO complex can help in efficient engineering\nof the heat bath and controlling the environment with the system. In this work,\nusing the discrete quantum jump model we show and quantify the presence of\nhigher non-Markovian memory effects in specific site-pairs when internal\nstructures and environmental effects are in favour of faster transport. As a\nconsequence, our study leans towards the connection between non-Markovianity in\nquantum jumps with the enhancement of transport efficiency.\n",
      "subjects": [
        "physics.chem-ph",
        "q-bio.QM",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Multi-Dimensional Unlimited Sampling and Robust Reconstruction",
      "abstract": "  In this paper we introduce a new sampling and reconstruction approach for\nmulti-dimensional analog signals. Building on top of the Unlimited Sensing\nFramework (USF), we present a new folded sampling operator called the\nmulti-dimensional modulo-hysteresis that is also backwards compatible with the\nexisting one-dimensional modulo operator. Unlike previous approaches, the\nproposed model is specifically tailored to multi-dimensional signals. In\nparticular, the model uses certain redundancy in dimensions 2 and above, which\nis exploited for input recovery with robustness. We prove that the new operator\nis well-defined and its outputs have a bounded dynamic range. For the noiseless\ncase, we derive a theoretically guaranteed input reconstruction approach. When\nthe input is corrupted by Gaussian noise, we exploit redundancy in higher\ndimensions to provide a bound on the error probability and show this drops to 0\nfor high enough sampling rates leading to new theoretical guarantees for the\nnoisy case. Our numerical examples corroborate the theoretical results and show\nthat the proposed approach can handle a significantly larger amount of noise\ncompared to USF.\n",
      "subjects": [
        "cs.IT",
        "eess.SP",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Robust Scientific Machine Learning for Optimization: A Novel\n  Robustness Theorem",
      "abstract": "  Scientific machine learning (SciML) is a field of increasing interest in\nseveral different application fields. In an optimization context, SciML-based\ntools have enabled the development of more efficient optimization methods.\nHowever, implementing SciML tools for optimization must be rigorously evaluated\nand performed with caution. This work proposes the deductions of a robustness\ntest that guarantees the robustness of multiobjective SciML-based optimization\nby showing that its results respect the universal approximator theorem. The\ntest is applied in the framework of a novel methodology which is evaluated in a\nseries of benchmarks illustrating its consistency. Moreover, the proposed\nmethodology results are compared with feasible regions of rigorous\noptimization, which requires a significantly higher computational effort.\nHence, this work provides a robustness test for guaranteed robustness in\napplying SciML tools in multiobjective optimization with lower computational\neffort than the existent alternative.\n",
      "subjects": [
        "math.OC",
        "cs.LG",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Calibration Generalization Gap",
      "abstract": "  Calibration is a fundamental property of a good predictive model: it requires\nthat the model predicts correctly in proportion to its confidence. Modern\nneural networks, however, provide no strong guarantees on their calibration --\nand can be either poorly calibrated or well-calibrated depending on the\nsetting. It is currently unclear which factors contribute to good calibration\n(architecture, data augmentation, overparameterization, etc), though various\nclaims exist in the literature.\n  We propose a systematic way to study the calibration error: by decomposing it\ninto (1) calibration error on the train set, and (2) the calibration\ngeneralization gap. This mirrors the fundamental decomposition of\ngeneralization. We then investigate each of these terms, and give empirical\nevidence that (1) DNNs are typically always calibrated on their train set, and\n(2) the calibration generalization gap is upper-bounded by the standard\ngeneralization gap. Taken together, this implies that models with small\ngeneralization gap (|Test Error - Train Error|) are well-calibrated. This\nperspective unifies many results in the literature, and suggests that\ninterventions which reduce the generalization gap (such as adding data, using\nheavy augmentation, or smaller model size) also improve calibration. We thus\nhope our initial study lays the groundwork for a more systematic and\ncomprehensive understanding of the relation between calibration,\ngeneralization, and optimization.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Two Video Data Sets for Tracking and Retrieval of Out of Distribution\n  Objects",
      "abstract": "  In this work we present two video test data sets for the novel computer\nvision (CV) task of out of distribution tracking (OOD tracking). Here, OOD\nobjects are understood as objects with a semantic class outside the semantic\nspace of an underlying image segmentation algorithm, or an instance within the\nsemantic space which however looks decisively different from the instances\ncontained in the training data. OOD objects occurring on video sequences should\nbe detected on single frames as early as possible and tracked over their time\nof appearance as long as possible. During the time of appearance, they should\nbe segmented as precisely as possible. We present the SOS data set containing\n20 video sequences of street scenes and more than 1000 labeled frames with up\nto two OOD objects. We furthermore publish the synthetic CARLA-WildLife data\nset that consists of 26 video sequences containing up to four OOD objects on a\nsingle frame. We propose metrics to measure the success of OOD tracking and\ndevelop a baseline algorithm that efficiently tracks the OOD objects. As an\napplication that benefits from OOD tracking, we retrieve OOD sequences from\nunlabeled videos of street scenes containing OOD objects.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Deep Counterfactual Estimation with Categorical Background Variables",
      "abstract": "  Referred to as the third rung of the causal inference ladder, counterfactual\nqueries typically ask the \"What if ?\" question retrospectively. The standard\napproach to estimate counterfactuals resides in using a structural equation\nmodel that accurately reflects the underlying data generating process. However,\nsuch models are seldom available in practice and one usually wishes to infer\nthem from observational data alone. Unfortunately, the correct structural\nequation model is in general not identifiable from the observed factual\ndistribution. Nevertheless, in this work, we show that under the assumption\nthat the main latent contributors to the treatment responses are categorical,\nthe counterfactuals can be still reliably predicted. Building upon this\nassumption, we introduce CounterFactual Query Prediction (CFQP), a novel method\nto infer counterfactuals from continuous observations when the background\nvariables are categorical. We show that our method significantly outperforms\npreviously available deep-learning-based counterfactual methods, both\ntheoretically and empirically on time series and image data. Our code is\navailable at https://github.com/edebrouwer/cfqp.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Anomalous coupling studies with intact protons at the LHC",
      "abstract": "  We describe the reaches on quartic $\\gamma \\gamma \\gamma \\gamma$, $\\gamma\n\\gamma WW$, $\\gamma \\gamma ZZ$, $\\gamma \\gamma \\gamma Z$, $\\gamma \\gamma t\n\\bar{t}$ anomalous couplings at the LHC using intact protons in the final state\nmeasured in AFP in ATLAS or PPS in CMS-TOTEM.\n",
      "subjects": [
        "hep-ph",
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Structured Singular Value of a Repeated Complex Full-Block Uncertainty",
      "abstract": "  The structured singular value (SSV), or mu, is used to assess the robust\nstability and performance of an uncertain linear time-invariant system.\nExisting algorithms compute upper and lower bounds on the SSV for structured\nuncertainties that contain repeated (real or complex) scalars and/or\nnon-repeated complex full blocks. This paper presents algorithms to compute\nbounds on the SSV for the case of repeated complex full blocks. This specific\nclass of uncertainty is relevant for the input output analysis of many\nconvective systems, such as fluid flows. Specifically, we present a power\niteration to compute a lower bound on SSV for the case of repeated complex full\nblocks. This generalizes existing power iterations for repeated complex scalar\nand non-repeated complex full blocks. The upper bound can be formulated as a\nsemi-definite program (SDP), which we solve using a standard interior-point\nmethod to compute optimal scaling matrices associated with the repeated full\nblocks. Our implementation of the method only requires gradient information,\nwhich improves the computational efficiency of the method. Finally, we test our\nproposed algorithms on an example model of incompressible fluid flow. The\nproposed methods provide less conservative bounds as compared to prior results,\nwhich ignore the repeated full block structure.\n",
      "subjects": [
        "eess.SY",
        "cs.SY",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "UMFuse: Unified Multi View Fusion for Human Editing applications",
      "abstract": "  Numerous pose-guided human editing methods have been explored by the vision\ncommunity due to their extensive practical applications. However, most of these\nmethods still use an image-to-image formulation in which a single image is\ngiven as input to produce an edited image as output. This objective becomes\nill-defined in cases when the target pose differs significantly from the input\npose. Existing methods then resort to in-painting or style transfer to handle\nocclusions and preserve content. In this paper, we explore the utilization of\nmultiple views to minimize the issue of missing information and generate an\naccurate representation of the underlying human model. To fuse knowledge from\nmultiple viewpoints, we design a multi-view fusion network that takes the pose\nkey points and texture from multiple source images and generates an explainable\nper-pixel appearance retrieval map. Thereafter, the encodings from a separate\nnetwork (trained on a single-view human reposing task) are merged in the latent\nspace. This enables us to generate accurate, precise, and visually coherent\nimages for different editing tasks. We show the application of our network on\ntwo newly proposed tasks - Multi-view human reposing and Mix&Match Human Image\ngeneration. Additionally, we study the limitations of single-view editing and\nscenarios in which multi-view provides a better alternative.\n",
      "subjects": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Usability Study of Tactile and Voice Interaction Modes by People with\n  Disabilities for Home Automation Controls",
      "abstract": "  This paper presents a comparative usability study on tactile and vocal\ninteraction modes for home automation control of equipment at home for\ndifferent profiles of disabled people. The study is related to the HIP HOPE\nproject concerning the construction of 19 inclusive housing in the Toulouse\nmetropolitan area in France. The experimentation took place in a living lab\nwith 7 different disabled people who realize realistic use cases. The USE and\nUEQ questionnaires were selected as usability tools. The first results show\nthat both interfaces are easy to learn but that usefulness and ease of use\ndimensions need to be improved. This study shows that there is real need for\nmultimodality between touch and voice interaction to control the smart home.\nThis study also shows that there is need to adapt the interface and the\nenvironment to the person's disability.\n",
      "subjects": [
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.12693/APhysPolA.142.329",
      "title": "Exotic properties of N^*(1895) and its impact on photoproduction of\n  light hyperons",
      "abstract": "  In this work, we outline the findings of our recent study of the properties\nof $N^*(1895)$ and its consequential impacts on the cross sections of the\nphotoproduction of $\\Lambda(1405)$. Further, we discuss the possibility of the\nexistence of an isovector state, with the mass similar to $\\Lambda(1405)$,\nwhich we refer to as $\\Sigma(1400)$. With the idea of motivating experimental\ninvestigations of $\\Sigma(1400)$, we have studied its photoproduction process\nand determined the respective cross sections and polarization observables. We\nhave studied also the coupling of $N^*(1895)$ to $K\\Sigma(1400)$ and found that\nit gives an important contribution to the cross sections near the threshold. In\nthe process, we have determined the branching ratios of the decay of\n$N^*(1895)$, to the final states involving $\\Lambda(1405)$ and $\\Sigma(1400)$,\nto be in the range of 6-7 MeV. Our findings can motivate consideration of\nalternative processes in partial wave analyses of experimental data, when\nstudying the properties of $N^*(1895)$.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/202243690",
      "title": "Significance Mode Analysis (SigMA) for hierarchical structures. An\n  application to the Sco-Cen OB association",
      "abstract": "  We present a new clustering method, Significance Mode Analysis (SigMA), to\nextract co-spatial and co-moving stellar populations from large-scale surveys\nsuch as ESA Gaia. The method studies the topological properties of the density\nfield in the multidimensional phase space. We validate SigMA on simulated\nclusters and find that it outperforms competing methods, especially in cases\nwhere many clusters are closely spaced. We apply the new method to Gaia DR3\ndata of the closest OB association to Earth, Scorpio-Centaurus (Sco-Cen), and\nfind more than 13,000 co-moving young objects, with about 19% of these having a\nsub-stellar mass. SigMA finds 37 co-moving clusters in Sco-Cen. These clusters\nare independently validated by their narrow HRD sequences and, to a certain\nextent, by their association with massive stars too bright for Gaia, hence\nunknown to SigMA. We compare our results with similar recent work and find that\nthe SigMA algorithm recovers richer populations, is able to distinguish\nclusters with velocity differences down to about 0.5 km s$^{-1}$, and reaches\ncluster volume densities as low as 0.01 sources/pc$^3$. The 3D distribution of\nthese 37 coeval clusters implies a larger extent and volume for the Sco-Cen OB\nassociation than typically assumed in the literature. Additionally, we find the\nassociation to be more actively star-forming and dynamically more complex than\npreviously thought. We confirm that the star-forming molecular clouds in the\nSco-Cen region, namely, Ophiuchus, L134/L183, Pipe Nebula, Corona Australis,\nLupus, and Chamaeleon, are part of the Sco-Cen The application of SigMA to\nSco-Cen demonstrates that advanced machine learning tools applied to the superb\nGaia data allows to construct an accurate census of the young populations, to\nquantify their dynamics, and to reconstruct the recent star formation history\nof the local Milky Way.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1140/epjc/s10052-023-11796-1",
      "title": "Hawking effect can generate physically inaccessible genuine tripartite\n  nonlocality",
      "abstract": "  We explore the acceleration effect on the genuine tripartite nonlocality\n(GTN) for one or two accelerated detector(s) coupled to the vacuum field with\ninitial mixed tripartite states. We show that the Hawking radiation degrades\nthe physically accessible GTN, which suffers from \"sudden death\" at certain\ncritical Hawking temperature. An novel phenomenon has been observed first time\nthat the Hawking effect can generate the physically inaccessible GTN for\nfermion fields in curved spacetime, the \"sudden birth\" of the physically\ninaccessible GTN. This result shows that the GTN can pass through the event\nhorizon of black hole for certain mixed initial states. We also derived\nanalytically the tradeoff relations of genuine tripartite entanglement (GTE)\nand quantum coherence under the influence of Hawking effect.\n",
      "subjects": [
        "gr-qc",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.24144/2616-7700",
      "title": "On the convergence of Baum-Katz series for sums of linear 2-nd order\n  autoregressive sequences of random variables",
      "abstract": "  We consider complete convergence and closely related\nHsu-Robbins-Erdos-Spitzer-Baum-Katz series for sums whose terms are elements of\na linear 2-nd order autoregressive sequences of random variables and prove\nsufficient conditions for the convergence of this series.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.108.022001",
      "title": "Doppler effect in TianQin time-delay interferometry",
      "abstract": "  The current design of space-based gravitational wave detectors utilizes\nheterodyne laser interferometry in inter-satellite science measurements.\nFrequency variations of the heterodyne beatnotes are predominantly caused by\nthe Doppler effect from relative satellite motion along lines of sight.\nGenerally considered to be outside the measurement band, this Doppler frequency\nshift appears to have been overlooked in numerical simulations of time-delay\ninterferometry (TDI). However, the potential impact on the implementation of\nTDI should be assessed. The issue is particularly relevant to TianQin that\nfeatures geocentric orbits, because of strong gravity disturbances from the\nEarth-Moon system at frequencies $<1\\times 10^{-4}$ Hz. In this\nproof-of-principle study, based on high-precision orbital data obtained from\ndetailed gravity field modeling, we incorporate the Doppler shift in the\ngeneration of TianQin's beatnote phase signals. To remove the large-scale\nDoppler phase drift at frequencies $<1\\times 10^{-4}$ Hz, we develop a\nhigh-performance high-pass filter and consider two possible processing\nsequences, i.e., applying the filter before or after TDI combinations. Our\nsimulation results favor the former and demonstrate successful removal of the\nlow-frequency gravity disturbances for TianQin without degrading the TDI\nperformance, assuming 10 m pseudo-ranging uncertainty. The filtering scheme can\nbe used in developing the initial noise-reduction pipeline for TianQin.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Supplemental Transmission Aided Attenuation Correction for Quantitative\n  Cardiac PET/MR",
      "abstract": "  Quantitative PET attenuation correction (AC) for combined cardiac PET/MR is a\nchallenging problem. We propose and evaluate an AC approach that uses\ncoincidences from a relatively weak and physically fixed sparse external\nsource, in combination with that from the patient, to correct for PET\nattenuation based on physics principles alone. The low 30 ml volume of the\nsource makes it easy to fill and place, and the method does not use prior image\ndata or attenuation map assumptions. Our supplemental transmission aided\nmaximum likelihood reconstruction of attenuation and activity (sTX-MLAA)\nalgorithm contains an attenuation map update that maximizes the likelihood of\nterms representing coincidences originating from tracer in the patient and a\nweighted expression of counts segmented from the external source alone. Both\nexternal source and patient scatter and randoms are fully corrected. We\nevaluated performance of sTX-MLAA compared to reference standard CT-based AC\nwith FDG PET/CT phantom studies; including modeling a patient with myocardial\ninflammation. Through an ROI analysis we measured less than 5% bias in activity\nconcentrations for PET images generated with sTX-MLAA relative to CT-AC. PET\nbackground variability (from noise and sparse sampling) was substantially\nreduced with sTX-MLAA compared to using coincidences segmented from the\ntransmission source alone for AC. The study suggests that sTX-MLAA will produce\nPET images on PET/MR with quantification comparable to PET/CT results during\nhuman cardiac exams.\n",
      "subjects": [
        "physics.med-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Effect of emotions and personalisation on cancer website reuse\n  intentions",
      "abstract": "  The effect of emotions and personalisation on continuance use intentions in\nonline health services is underexplored. Accordingly, we propose a research\nmodel for examining the impact of emotion- and personalisation-based factors on\ncancer website reuse intentions. We conducted a study using a real-world NGO\ncancer-support website, which was evaluated by 98 participants via an online\nquestionnaire. Model relations were estimated using the PLS-SEM method. Our\nfindings indicated that pre-use emotions did not significantly influence\nperceived personalisation. However, satisfaction with personalisation, and\nperceived usefulness mediated by satisfaction, increased reuse intentions. In\naddition, post-use positive emotions potentially influenced reuse intentions.\nOur paper, therefore, illustrates the applicability of theory regarding\ncontinuance use intentions to cancer-support websites and highlights the\nimportance of personalisation for these purposes.\n",
      "subjects": [
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Numerical simulation of the radiation force from transient acoustic\n  fields: Application to laser-guided acoustic tweezers",
      "abstract": "  Using pulsed acoustic waves could provide a superior selectivity for\nmicroscale acoustic tweezers. However, the theory for the radiation force of\npulsed acoustic waves has only been recently derived and no numerical\nimplementations are available. In this paper, we present a finite-element\nimplementation of this model to simulate the transient acoustic radiation force\non small spheres. We use the model to simulate laser-guided acoustic tweezers\nand optimize their performance. By enabling numerical simulations of the\ntransient radiation force, this work may accelerate the rational design of\npulse-based high-selectivity acoustic tweezers devices.\n",
      "subjects": [
        "physics.flu-dyn",
        "physics.optics"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Improving the Inference of Topic Models via Infinite Latent State\n  Replications",
      "abstract": "  In text mining, topic models are a type of probabilistic generative models\nfor inferring latent semantic topics from text corpus. One of the most popular\ninference approaches to topic models is perhaps collapsed Gibbs sampling (CGS),\nwhich typically samples one single topic label for each observed document-word\npair. In this paper, we aim at improving the inference of CGS for topic models.\nWe propose to leverage state augmentation technique by maximizing the number of\ntopic samples to infinity, and then develop a new inference approach, called\ninfinite latent state replication (ILR), to generate robust soft topic\nassignment for each given document-word pair. Experimental results on the\npublicly available datasets show that ILR outperforms CGS for inference of\nexisting established topic models.\n",
      "subjects": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both\n  Worlds in Stochastic and Deterministic Environments",
      "abstract": "  We study variance-dependent regret bounds for Markov decision processes\n(MDPs). Algorithms with variance-dependent regret guarantees can automatically\nexploit environments with low variance (e.g., enjoying constant regret on\ndeterministic MDPs). The existing algorithms are either variance-independent or\nsuboptimal. We first propose two new environment norms to characterize the\nfine-grained variance properties of the environment. For model-based methods,\nwe design a variant of the MVP algorithm (Zhang et al., 2021a). We apply new\nanalysis techniques to demonstrate that this algorithm enjoys\nvariance-dependent bounds with respect to the norms we propose. In particular,\nthis bound is simultaneously minimax optimal for both stochastic and\ndeterministic MDPs, the first result of its kind. We further initiate the study\non model-free algorithms with variance-dependent regret bounds by designing a\nreference-function-based algorithm with a novel capped-doubling reference\nupdate schedule. Lastly, we also provide lower bounds to complement our upper\nbounds.\n",
      "subjects": [
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Out of Sample Predictability in Predictive Regressions with Many\n  Predictor Candidates",
      "abstract": "  This paper is concerned with detecting the presence of out of sample\npredictability in linear predictive regressions with a potentially large set of\ncandidate predictors. We propose a procedure based on out of sample MSE\ncomparisons that is implemented in a pairwise manner using one predictor at a\ntime and resulting in an aggregate test statistic that is standard normally\ndistributed under the global null hypothesis of no linear predictability.\nPredictors can be highly persistent, purely stationary or a combination of\nboth. Upon rejection of the null hypothesis we subsequently introduce a\npredictor screening procedure designed to identify the most active predictors.\nAn empirical application to key predictors of US economic activity illustrates\nthe usefulness of our methods and highlights the important forward looking role\nplayed by the series of manufacturing new orders.\n",
      "subjects": [
        "econ.EM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.130.260601",
      "title": "All-microwave manipulation of superconducting qubits with a\n  fixed-frequency transmon coupler",
      "abstract": "  All-microwave control of fixed-frequency superconducting quantum computing\ncircuits is advantageous for minimizing the noise channels and wiring costs.\nHere we introduce a swap interaction between two data transmons assisted by the\nthird-order nonlinearity of a coupler transmon under a microwave drive. We\nmodel the interaction analytically and numerically and use it to implement an\nall-microwave controlled-Z gate. The gate based on the coupler-assisted swap\ntransition maintains high drive efficiency and small residual interaction over\na wide range of detuning between the data transmons.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1017/S0013091524000518",
      "title": "Model structures, n-Gorenstein flat modules and PGF dimensions",
      "abstract": "  Given a non-negative integer $n$ and a ring $R$ with identity, we construct\nan abelian model structure on the category of left $R$-modules where the class\nof cofibrant objects coincides with $\\mathcal{GF}_n(R)$ the class of left\n$R$-modules with Gorenstein flat dimension less than $n$, the class of fibrant\nobjects coincides with $\\mathcal{F}_n(R)^\\perp$ the right ${\\rm\nExt}$-orthogonal class of left $R$-modules with flat dimension less than $n$,\nand the class of trivial objects coincides with $\\mathcal{PGF}(R)^\\perp$ the\nright ${\\rm Ext}$-orthogonal class of PGF left $R$-modules recently introduced\nby \\v{S}aroch and \\v{S}\\v{t}ov\\'{\\i}\\v{c}ek. The homotopy category of this\nmodel structure is triangulated equivalent to the stable category\n$\\underline{\\mathcal{GF}(R)\\cap\\mathcal{C}(R)}$ modulo flat-cotorsion modules\nand it is compactly generated when $R$ has finite global Gorenstein\nAC-projective dimension.\n  The second part of this paper deals with the PGF dimension of modules and\nrings. Our results suggest that this dimension could serve as an alternative\ndefinition of the Gorenstein projective dimension. We show, among other things,\nthat ($n$-)perfect rings can be characterized in terms of Gorenstein\nhomological dimensions, similar to the classical ones, and the global\nGorenstein projective dimension coincides with the global PGF dimension.\n",
      "subjects": [
        "math.RA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Ada-Grouper: Accelerating Pipeline Parallelism in Preempted Network by\n  Adaptive Group-Scheduling for Micro-Batches",
      "abstract": "  Pipeline parallelism has been demonstrated to be a remarkable approach to\nimprove throughput for training deep neural networks with billions of\nparameters over heterogeneous clusters. The 1F1B scheduling plan is a widely\nadopted strategy for memory and performance optimization, which interchanges\nthe forward and backward stage computations of different micro-batches. On the\nother hand, a common issue in using the 1F1B scheduling is that stage\ncomputation is delayed due to the data transfer when network resources are\npreempted by other tasks, even with the minimum communication between stages.\nThe exclusive access of these network resources cannot be guaranteed in cloud\nofferings. We present a general scheduling technique to accommodate pipeline\nparallelism to preempted network environments at the expense of a certain\namount of memory pressure. The core concept is to extend 1F1B schedule scheme\nto kFkB, which groups k micro-batches, and alternately executes k forward and\nbackward computations. We propose Ada-Grouper, an adaptive kFkB scheduler which\nregularly adjusts the number of group members k to maintain an optimal balance\nbetween communication and computation efficiency correspond to changes in a\nchanging network environment under the memory limit. Experimental results\ndemonstrate that our design maintain stable performance for pipeline\nparallelism, yielding a performance increase of up from 4% to 30%, compared\nwith 1F1B in preempted network scenarios.\n",
      "subjects": [
        "cs.DC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "FSVVD: A Dataset of Full Scene Volumetric Video",
      "abstract": "  Recent years have witnessed a rapid development of immersive multimedia which\nbridges the gap between the real world and virtual space. Volumetric videos, as\nan emerging representative 3D video paradigm that empowers extended reality,\nstand out to provide unprecedented immersive and interactive video watching\nexperience. Despite the tremendous potential, the research towards 3D\nvolumetric video is still in its infancy, relying on sufficient and complete\ndatasets for further exploration. However, existing related volumetric video\ndatasets mostly only include a single object, lacking details about the scene\nand the interaction between them. In this paper, we focus on the current most\nwidely used data format, point cloud, and for the first time release a\nfull-scene volumetric video dataset that includes multiple people and their\ndaily activities interacting with the external environments. Comprehensive\ndataset description and analysis are conducted, with potential usage of this\ndataset. The dataset and additional tools can be accessed via the following\nwebsite: https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/.\n",
      "subjects": [
        "cs.MM",
        "cs.CV",
        "eess.IV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.cose.2023.103176",
      "title": "Adv-Bot: Realistic Adversarial Botnet Attacks against Network Intrusion\n  Detection Systems",
      "abstract": "  Due to the numerous advantages of machine learning (ML) algorithms, many\napplications now incorporate them. However, many studies in the field of image\nclassification have shown that MLs can be fooled by a variety of adversarial\nattacks. These attacks take advantage of ML algorithms' inherent vulnerability.\nThis raises many questions in the cybersecurity field, where a growing number\nof researchers are recently investigating the feasibility of such attacks\nagainst machine learning-based security systems, such as intrusion detection\nsystems. The majority of this research demonstrates that it is possible to fool\na model using features extracted from a raw data source, but it does not take\ninto account the real implementation of such attacks, i.e., the reverse\ntransformation from theory to practice. The real implementation of these\nadversarial attacks would be influenced by various constraints that would make\ntheir execution more difficult. As a result, the purpose of this study was to\ninvestigate the actual feasibility of adversarial attacks, specifically evasion\nattacks, against network-based intrusion detection systems (NIDS),\ndemonstrating that it is entirely possible to fool these ML-based IDSs using\nour proposed adversarial algorithm while assuming as many constraints as\npossible in a black-box setting. In addition, since it is critical to design\ndefense mechanisms to protect ML-based IDSs against such attacks, a defensive\nscheme is presented. Realistic botnet traffic traces are used to assess this\nwork. Our goal is to create adversarial botnet traffic that can avoid detection\nwhile still performing all of its intended malicious functionality.\n",
      "subjects": [
        "cs.CR",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View-\n  and Category-Aware Transformers",
      "abstract": "  As we all know, multi-view data is more expressive than single-view data and\nmulti-label annotation enjoys richer supervision information than single-label,\nwhich makes multi-view multi-label learning widely applicable for various\npattern recognition tasks. In this complex representation learning problem,\nthree main challenges can be characterized as follows: i) How to learn\nconsistent representations of samples across all views? ii) How to exploit and\nutilize category correlations of multi-label to guide inference? iii) How to\navoid the negative impact resulting from the incompleteness of views or labels?\nTo cope with these problems, we propose a general multi-view multi-label\nlearning framework named label-guided masked view- and category-aware\ntransformers in this paper. First, we design two transformer-style based\nmodules for cross-view features aggregation and multi-label classification,\nrespectively. The former aggregates information from different views in the\nprocess of extracting view-specific features, and the latter learns subcategory\nembedding to improve classification performance. Second, considering the\nimbalance of expressive power among views, an adaptively weighted view fusion\nmodule is proposed to obtain view-consistent embedding features. Third, we\nimpose a label manifold constraint in sample-level representation learning to\nmaximize the utilization of supervised information. Last but not least, all the\nmodules are designed under the premise of incomplete views and labels, which\nmakes our method adaptable to arbitrary multi-view and multi-label data.\nExtensive experiments on five datasets confirm that our method has clear\nadvantages over other state-of-the-art methods.\n",
      "subjects": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "CoordFill: Efficient High-Resolution Image Inpainting via Parameterized\n  Coordinate Querying",
      "abstract": "  Image inpainting aims to fill the missing hole of the input. It is hard to\nsolve this task efficiently when facing high-resolution images due to two\nreasons: (1) Large reception field needs to be handled for high-resolution\nimage inpainting. (2) The general encoder and decoder network synthesizes many\nbackground pixels synchronously due to the form of the image matrix. In this\npaper, we try to break the above limitations for the first time thanks to the\nrecent development of continuous implicit representation. In detail, we\ndown-sample and encode the degraded image to produce the spatial-adaptive\nparameters for each spatial patch via an attentional Fast Fourier\nConvolution(FFC)-based parameter generation network. Then, we take these\nparameters as the weights and biases of a series of multi-layer\nperceptron(MLP), where the input is the encoded continuous coordinates and the\noutput is the synthesized color value. Thanks to the proposed structure, we\nonly encode the high-resolution image in a relatively low resolution for larger\nreception field capturing. Then, the continuous position encoding will be\nhelpful to synthesize the photo-realistic high-frequency textures by\nre-sampling the coordinate in a higher resolution. Also, our framework enables\nus to query the coordinates of missing pixels only in parallel, yielding a more\nefficient solution than the previous methods. Experiments show that the\nproposed method achieves real-time performance on the 2048$\\times$2048 images\nusing a single GTX 2080 Ti GPU and can handle 4096$\\times$4096 images, with\nmuch better performance than existing state-of-the-art methods visually and\nnumerically. The code is available at:\nhttps://github.com/NiFangBaAGe/CoordFill.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Improved Crouzeix-Raviart scheme for the Stokes and Navier-Stokes\n  problem",
      "abstract": "  The resolution of the incompressible Navier-Stokes equations is tricky, and\nit is well known that one of the major issue is to compute a divergence free\nvelocity. The non-conforming Crouzeix-Raviart finite element are convenient\nsince they induce local mass conservation. Moreover they are such that the\nstability constant of the Fortin operator is equal to 1. This implies that they\ncan easily handle anisotropic mesh [1, 2]. However spurious velocities may\nappear and damage the approximation. We propose a scheme here that allows to\nreduce the spurious velocities. It is based on a new discretisation for the\ngradient of pressure based on the symmetric MPFA scheme (finite volume\nMultiPoint Flux Approximation) [3, 4, 5].\n",
      "subjects": [
        "math.NA",
        "cs.NA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "DR.CPO: Diversified and Realistic 3D Augmentation via Iterative\n  Construction, Random Placement, and HPR Occlusion",
      "abstract": "  In autonomous driving, data augmentation is commonly used for improving 3D\nobject detection. The most basic methods include insertion of copied objects\nand rotation and scaling of the entire training frame. Numerous variants have\nbeen developed as well. The existing methods, however, are considerably limited\nwhen compared to the variety of the real world possibilities. In this work, we\ndevelop a diversified and realistic augmentation method that can flexibly\nconstruct a whole-body object, freely locate and rotate the object, and apply\nself-occlusion and external-occlusion accordingly. To improve the diversity of\nthe whole-body object construction, we develop an iterative method that\nstochastically combines multiple objects observed from the real world into a\nsingle object. Unlike the existing augmentation methods, the constructed\nobjects can be randomly located and rotated in the training frame because\nproper occlusions can be reflected to the whole-body objects in the final step.\nFinally, proper self-occlusion at each local object level and\nexternal-occlusion at the global frame level are applied using the Hidden Point\nRemoval (HPR) algorithm that is computationally efficient. HPR is also used for\nadaptively controlling the point density of each object according to the\nobject's distance from the LiDAR. Experiment results show that the proposed\nDR.CPO algorithm is data-efficient and model-agnostic without incurring any\ncomputational overhead. Also, DR.CPO can improve mAP performance by 2.08% when\ncompared to the best 3D detection result known for KITTI dataset. The code is\navailable at https://github.com/SNU-DRL/DRCPO.git\n",
      "subjects": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Structural Imbalance Aware Graph Augmentation Learning",
      "abstract": "  Graph machine learning (GML) has made great progress in node classification,\nlink prediction, graph classification and so on. However, graphs in reality are\noften structurally imbalanced, that is, only a few hub nodes have a denser\nlocal structure and higher influence. The imbalance may compromise the\nrobustness of existing GML models, especially in learning tail nodes. This\npaper proposes a selective graph augmentation method (SAug) to solve this\nproblem. Firstly, a Pagerank-based sampling strategy is designed to identify\nhub nodes and tail nodes in the graph. Secondly, a selective augmentation\nstrategy is proposed, which drops the noisy neighbors of hub nodes on one side,\nand discovers the latent neighbors and generates pseudo neighbors for tail\nnodes on the other side. It can also alleviate the structural imbalance between\ntwo types of nodes. Finally, a GNN model will be retrained on the augmented\ngraph. Extensive experiments demonstrate that SAug can significantly improve\nthe backbone GNNs and achieve superior performance to its competitors of graph\naugmentation methods and hub/tail aware methods.\n",
      "subjects": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Comparative analysis of five NH$_3$/air oxidation mechanisms",
      "abstract": "  Five recently developed chemical kinetics mechanisms for ammonia oxidation\nare analysed and compared, in the context of homogeneous adiabatic\nautoignition. The analysis focuses on the ignition delay and is based on the\nexplosive mode that is shown to drive the process. Using algorithmic tools\nbased on the Computational Singular Perturbation algorithm, the reactions\nresponsible for the generation of the explosive mode are identified, along with\nthe variables (species mass fractions and temperature) that associate the most\nto this mode. Comparison of these sets of reactions and variables, obtained for\neach mechanism, allows to correlate the differences in the predictive outcomes\nfrom the mechanisms with specific reactions. The major differences identified,\nwhich lead to different ignition delay times, relate to (i) the relative\nduration of chemical and thermal runaways (a sizeable chemical runaway develops\nonly in some mechanisms) and (ii) the dominant chemistry during the chemical\nrunaway (chemistry involving species with two nitrogen atoms is active only in\nsome mechanisms). The major similarities identified refer to the thermal\nrunaway and in particular to (i) the chemical activity, which is supported\nmainly by OH-producing reactions and by reactions producing their reactants and\n(ii) the thermal activity, which is dominated by strongly exothermic\nOH-consuming reactions.\n",
      "subjects": [
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Automatic Gradient Descent: Deep Learning without Hyperparameters",
      "abstract": "  The architecture of a deep neural network is defined explicitly in terms of\nthe number of layers, the width of each layer and the general network topology.\nExisting optimisation frameworks neglect this information in favour of implicit\narchitectural information (e.g. second-order methods) or architecture-agnostic\ndistance functions (e.g. mirror descent). Meanwhile, the most popular optimiser\nin practice, Adam, is based on heuristics. This paper builds a new framework\nfor deriving optimisation algorithms that explicitly leverage neural\narchitecture. The theory extends mirror descent to non-convex composite\nobjective functions: the idea is to transform a Bregman divergence to account\nfor the non-linear structure of neural architecture. Working through the\ndetails for deep fully-connected networks yields automatic gradient descent: a\nfirst-order optimiser without any hyperparameters. Automatic gradient descent\ntrains both fully-connected and convolutional networks out-of-the-box and at\nImageNet scale. A PyTorch implementation is available at\nhttps://github.com/jxbz/agd and also in Appendix B. Overall, the paper supplies\na rigorous theoretical foundation for a next-generation of\narchitecture-dependent optimisers that work automatically and without\nhyperparameters.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "cs.NE",
        "math.NA",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP07(2023)184",
      "title": "Operator growth and black hole formation",
      "abstract": "  When two particles collide in an asymptotically AdS spacetime with high\nenough energy and small enough impact parameter, they can form a black hole.\nMotivated by dual quantum circuit considerations, we propose a threshold\ncondition for black hole formation. Intuitively the condition can be understood\nas the onset of overlap of the butterfly cones describing the ballistic spread\nof the effect of the perturbations on the boundary systems. We verify the\ncorrectness of the condition in three bulk dimensions. We describe a six-point\ncorrelation function that can diagnose this condition and compute it in\ntwo-dimensional CFTs using eikonal resummation.\n",
      "subjects": [
        "hep-th",
        "gr-qc",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Cosmological Parameter Constraints from the SDSS Density and Momentum\n  Power Spectra",
      "abstract": "  We extract the galaxy density and momentum power spectra from a subset of\nearly-type galaxies in the SDSS DR7 main galaxy catalog. Using galaxy distance\ninformation inferred from the improved fundamental plane described in\n\\citet{Yoon_2020}, we reconstruct the peculiar velocities of the galaxies and\ngenerate number density and density-weighted velocity fields, from which we\nextract the galaxy density and momentum power spectra. We compare the measured\nvalues to the theoretical expectation of the same statistics, assuming an input\n$\\Lambda$CDM model and using a third-order perturbative expansion. After\nvalidating our analysis pipeline with a series of mock data sets, we apply our\nmethodology to the SDSS data and arrive at constraints $f\\sigma_{8} =\n0.471_{-0.080}^{+0.077}$ and $b_{1}\\sigma_{8} = 0.920_{-0.070}^{+0.070}$ at a\nmean redshift $\\bar{z} = 0.04$. Our result is consistent with the Planck\ncosmological best fit parameters for the $\\Lambda$CDM model. The momentum power\nspectrum is found to be strongly contaminated by small scale velocity\ndispersion, which suppresses power by $\\sim {\\cal O}(30\\%)$ on intermediate\nscales $k \\sim 0.05 \\, h \\, {\\rm Mpc}^{-1}$.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Information Design in Multi-Agent Reinforcement Learning",
      "abstract": "  Reinforcement learning (RL) is inspired by the way human infants and animals\nlearn from the environment. The setting is somewhat idealized because, in\nactual tasks, other agents in the environment have their own goals and behave\nadaptively to the ego agent. To thrive in those environments, the agent needs\nto influence other agents so their actions become more helpful and less\nharmful. Research in computational economics distills two ways to influence\nothers directly: by providing tangible goods (mechanism design) and by\nproviding information (information design). This work investigates information\ndesign problems for a group of RL agents. The main challenges are two-fold. One\nis the information provided will immediately affect the transition of the agent\ntrajectories, which introduces additional non-stationarity. The other is the\ninformation can be ignored, so the sender must provide information that the\nreceiver is willing to respect. We formulate the Markov signaling game, and\ndevelop the notions of signaling gradient and the extended obedience\nconstraints that address these challenges. Our algorithm is efficient on\nvarious mixed-motive tasks and provides further insights into computational\neconomics. Our code is publicly available at\nhttps://github.com/YueLin301/InformationDesignMARL.\n",
      "subjects": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Deletion Correcting Codes for Efficient DNA Synthesis",
      "abstract": "  The synthesis of DNA strands remains the most costly part of the DNA storage\nsystem. Thus, to make DNA storage system more practical, the time and materials\nused in the synthesis process have to be optimized. We consider the most common\ntype of synthesis process where multiple DNA strands are synthesized in\nparallel from a common alternating supersequence, one nucleotide at a time. The\nsynthesis time or the number of synthesis cycles is then determined by the\nlength of this common supersequence. In this model, we design quaternary codes\nthat minimizes synthesis time that can correct deletions or insertions, which\nare the most prevalent types of error in array-based synthesis. We also propose\npolynomial-time algorithms that encode binary strings into these codes and show\nthat the rate is close to capacity.\n",
      "subjects": [
        "cs.IT",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Task-Oriented Communication Design at Scale",
      "abstract": "  With countless promising applications in various domains such as IoT and\nindustry 4.0, task-oriented communication design (TOCD) is getting accelerated\nattention from the research community. This paper presents a novel approach for\ndesigning scalable task-oriented quantization and communications in cooperative\nmulti-agent systems (MAS). The proposed approach utilizes the TOCD framework\nand the value of information (VoI) concept to enable efficient communication of\nquantized observations among agents while maximizing the average return\nperformance of the MAS, a parameter that quantifies the MAS's task\neffectiveness. The computational complexity of learning the VoI, however, grows\nexponentially with the number of agents. Thus, we propose a three-step\nframework: i) learning the VoI (using reinforcement learning (RL)) for a\ntwo-agent system, ii) designing the quantization policy for an $N$-agent MAS\nusing the learned VoI for a range of bit-budgets and, (iii) learning the\nagents' control policies using RL while following the designed quantization\npolicies in the earlier step. We observe that one can reduce the computational\ncost of obtaining the value of information by exploiting insights gained from\nstudying a similar two-agent system - instead of the original $N$-agent system.\nWe then quantize agents' observations such that their more valuable\nobservations are communicated more precisely. Our analytical results show the\napplicability of the proposed framework under a wide range of problems.\nNumerical results show striking improvements in reducing the computational\ncomplexity of obtaining VoI needed for the TOCD in a MAS problem without\ncompromising the average return performance of the MAS.\n",
      "subjects": [
        "cs.IT",
        "cs.LG",
        "cs.MA",
        "math.IT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.109.L012101",
      "title": "Jensen bound for the entropy production rate in stochastic\n  thermodynamics",
      "abstract": "  Bounding and estimating entropy production has long been an important goal of\nnonequilibrium thermodynamics. We recently derived a lower bound on the total\nand subsystem entropy production rates of continuous stochastic systems. This\n`Jensen bound' has led to fundamental limits on the performance of collective\ntransport systems and permitted thermodynamic inference of free-energy\ntransduction between components of bipartite molecular machines. Our original\nderivation relied on a number of assumptions, which restricted the bound's\nregime of applicability. Here we derive the Jensen bound far more generally for\nmultipartite overdamped Langevin dynamics. We then consider several extensions,\nallowing for position-dependent diffusion coefficients, underdamped dynamics,\nand non-multipartite overdamped dynamics. Our results extend the Jensen bound\nto a far broader class of systems.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "CGELBank Annotation Manual v1.1",
      "abstract": "  CGELBank is a treebank and associated tools based on a syntactic formalism\nfor English derived from the Cambridge Grammar of the English Language. This\ndocument lays out the particularities of the CGELBank annotation scheme.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A $2$-complex with contracting non-positive immersions and positive\n  maximal irreducible curvature",
      "abstract": "  We prove that the $2$-complex associated to the presentation $\\langle a,b\n\\mid b,bab^{-1}a^{-2}\\rangle$ has contracting non-positive immersions and\npositive maximal irreducible curvature. This example shows that the contracting\nnon-positive immersions property is not equivalent to the notion of\nnon-positive irreducible curvature, answering a question raised by H. Wilton.\n",
      "subjects": [
        "math.GR",
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3583131.3590424",
      "title": "Algorithm Instance Footprint: Separating Easily Solvable and Challenging\n  Problem Instances",
      "abstract": "  In black-box optimization, it is essential to understand why an algorithm\ninstance works on a set of problem instances while failing on others and\nprovide explanations of its behavior. We propose a methodology for formulating\nan algorithm instance footprint that consists of a set of problem instances\nthat are easy to be solved and a set of problem instances that are difficult to\nbe solved, for an algorithm instance. This behavior of the algorithm instance\nis further linked to the landscape properties of the problem instances to\nprovide explanations of which properties make some problem instances easy or\nchallenging. The proposed methodology uses meta-representations that embed the\nlandscape properties of the problem instances and the performance of the\nalgorithm into the same vector space. These meta-representations are obtained\nby training a supervised machine learning regression model for algorithm\nperformance prediction and applying model explainability techniques to assess\nthe importance of the landscape features to the performance predictions. Next,\ndeterministic clustering of the meta-representations demonstrates that using\nthem captures algorithm performance across the space and detects regions of\npoor and good algorithm performance, together with an explanation of which\nlandscape properties are leading to it.\n",
      "subjects": [
        "cs.NE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Global approximation for the cubic NLS with strong magnetic confinement",
      "abstract": "  We consider nonlinear Schr\\\"{o}dinger equation with strong magnetic fields in\n3D. This model was derived by R L. Frank, F. M\\'{e}hats, C. Sparber in 2017. We\nprove modified scattering for small initial data and the existence of modified\nwave operator for small final data. To describe asymptotic behavior of the NLS\nwe use the time-averaged model which was derived by the same authors as \"the\nstrong magnetic confinement limit\" of the NLS. We construct asymptotic\nsolutions which satisfy both asymptotic in time evolution and convergence in\nthe strong magnetic confinement limit. We also analyze the error between the\nsolution to the NLS and the time-averaged model for the same initial data and\nobtain global estimates.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "NLU on Data Diets: Dynamic Data Subset Selection for NLP Classification\n  Tasks",
      "abstract": "  Finetuning large language models inflates the costs of NLU applications and\nremains the bottleneck of development cycles. Recent works in computer vision\nuse data pruning to reduce training time. Pruned data selection with static\nmethods is based on a score calculated for each training example prior to\nfinetuning, which involves important computational overhead. Moreover, the\nscore may not necessarily be representative of sample importance throughout the\nentire training duration. We propose to address these issues with a refined\nversion of dynamic data pruning, a curriculum which periodically scores and\ndiscards unimportant examples during finetuning. Our method leverages an EL2N\nmetric that we extend to the joint intent and slot classification task, and an\ninitial finetuning phase on the full train set. Our results on the GLUE\nbenchmark and four joint NLU datasets show a better time-accuracy trade-off\ncompared to static methods. Our method preserves full accuracy while training\non 50% of the data points and reduces computational times by up to 41%. If we\ntolerate instead a minor drop of accuracy of 1%, we can prune 80% of the\ntraining examples for a reduction in finetuning time reaching 66%.\n",
      "subjects": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Learning-Based Heuristic for Combinatorial Optimization of the Minimum\n  Dominating Set Problem using Graph Convolutional Networks",
      "abstract": "  A dominating set of a graph $\\mathcal{G=(V, E)}$ is a subset of vertices\n$S\\subseteq\\mathcal{V}$ such that every vertex $v\\in \\mathcal{V} \\setminus S$\noutside the dominating set is adjacent to a vertex $u\\in S$ within the set. The\nminimum dominating set problem seeks to find a dominating set of minimum\ncardinality and is a well-established NP-hard combinatorial optimization\nproblem. We propose a novel learning-based heuristic approach to compute\nsolutions for the minimum dominating set problem using graph convolutional\nnetworks. We conduct an extensive experimental evaluation of the proposed\nmethod on a combination of randomly generated graphs and real-world graph\ndatasets. Our results indicate that the proposed learning-based approach can\noutperform a classical greedy approximation algorithm. Furthermore, we\ndemonstrate the generalization capability of the graph convolutional network\nacross datasets and its ability to scale to graphs of higher order than those\non which it was trained. Finally, we utilize the proposed learning-based\nheuristic in an iterative greedy algorithm, achieving state-of-the-art\nperformance in the computation of dominating sets.\n",
      "subjects": [
        "cs.LG",
        "cs.DM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "ModuleFormer: Modularity Emerges from Mixture-of-Experts",
      "abstract": "  Large Language Models (LLMs) have achieved remarkable results. However,\nexisting models are expensive to train and deploy, and it is also difficult to\nexpand their knowledge beyond pre-training data without forgetting previous\nknowledge. This paper proposes a new neural network architecture, ModuleFormer,\nthat leverages modularity to improve the efficiency and flexibility of large\nlanguage models. ModuleFormer is based on the Sparse Mixture of Experts (SMoE).\nUnlike the previous SMoE-based modular language model, which requires\ndomain-labeled data to learn domain-specific experts, ModuleFormer can induce\nmodularity from uncurated data with its new load balancing and concentration\nlosses. ModuleFormer is a modular architecture that includes two different\ntypes of modules: new stick-breaking attention heads and feedforward experts.\nDifferent modules are sparsely activated conditions on the input token during\ntraining and inference. In our experiment, we found that the modular\narchitecture enables three important abilities for large pre-trained language\nmodels: 1) Efficiency, since ModuleFormer only activates a subset of its\nmodules for each input token, thus it could achieve the same performance as\ndense LLMs with more than two times throughput; 2) Extendability, ModuleFormer\nis more immune to catastrophic forgetting than dense LLMs and can be easily\nextended with new modules to learn new knowledge that is not included in the\ntraining data; 3) Specialisation, finetuning ModuleFormer could specialize a\nsubset of modules to the finetuning task and the task-unrelated modules could\nbe easily pruned for a lightweight deployment.\n",
      "subjects": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.23919/DATE56975.2023.10137129",
      "title": "Energy-efficient Wearable-to-Mobile Offload of ML Inference for\n  PPG-based Heart-Rate Estimation",
      "abstract": "  Modern smartwatches often include photoplethysmographic (PPG) sensors to\nmeasure heartbeats or blood pressure through complex algorithms that fuse PPG\ndata with other signals. In this work, we propose a collaborative inference\napproach that uses both a smartwatch and a connected smartphone to maximize the\nperformance of heart rate (HR) tracking while also maximizing the smartwatch's\nbattery life. In particular, we first analyze the trade-offs between running\non-device HR tracking or offloading the work to the mobile. Then, thanks to an\nadditional step to evaluate the difficulty of the upcoming HR prediction, we\ndemonstrate that we can smartly manage the workload between smartwatch and\nsmartphone, maintaining a low mean absolute error (MAE) while reducing energy\nconsumption. We benchmark our approach on a custom smartwatch prototype,\nincluding the STM32WB55 MCU and Bluetooth Low-Energy (BLE) communication, and a\nRaspberry Pi3 as a proxy for the smartphone. With our Collaborative Heart Rate\nInference System (CHRIS), we obtain a set of Pareto-optimal configurations\ndemonstrating the same MAE as State-of-Art (SoA) algorithms while consuming\nless energy. For instance, we can achieve approximately the same MAE of\nTimePPG-Small (5.54 BPM MAE vs. 5.60 BPM MAE) while reducing the energy by\n2.03x, with a configuration that offloads 80\\% of the predictions to the phone.\nFurthermore, accepting a performance degradation to 7.16 BPM of MAE, we can\nachieve an energy consumption of 179 uJ per prediction, 3.03x less than running\nTimePPG-Small on the smartwatch, and 1.82x less than streaming all the input\ndata to the phone.\n",
      "subjects": [
        "eess.SP",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Multi-Agent Reinforcement Learning Guided by Signal Temporal Logic\n  Specifications",
      "abstract": "  Reward design is a key component of deep reinforcement learning, yet some\ntasks and designer's objectives may be unnatural to define as a scalar cost\nfunction. Among the various techniques, formal methods integrated with DRL have\ngarnered considerable attention due to their expressiveness and flexibility to\ndefine the reward and requirements for different states and actions of the\nagent. However, how to leverage Signal Temporal Logic (STL) to guide\nmulti-agent reinforcement learning reward design remains unexplored. Complex\ninteractions, heterogeneous goals and critical safety requirements in\nmulti-agent systems make this problem even more challenging. In this paper, we\npropose a novel STL-guided multi-agent reinforcement learning framework. The\nSTL requirements are designed to include both task specifications according to\nthe objective of each agent and safety specifications, and the robustness\nvalues of the STL specifications are leveraged to generate rewards. We validate\nthe advantages of our method through empirical studies. The experimental\nresults demonstrate significant reward performance improvements compared to\nMARL without STL guidance, along with a remarkable increase in the overall\nsafety rate of the multi-agent systems.\n",
      "subjects": [
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Graph Structure and Feature Extrapolation for Out-of-Distribution\n  Generalization",
      "abstract": "  Out-of-distribution (OOD) generalization deals with the prevalent learning\nscenario where test distribution shifts from training distribution. With rising\napplication demands and inherent complexity, graph OOD problems call for\nspecialized solutions. While data-centric methods exhibit performance\nenhancements on many generic machine learning tasks, there is a notable absence\nof data augmentation methods tailored for graph OOD generalization. In this\nwork, we propose to achieve graph OOD generalization with the novel design of\nnon-Euclidean-space linear extrapolation. The proposed augmentation strategy\nextrapolates both structure and feature spaces to generate OOD graph data. Our\ndesign tailors OOD samples for specific shifts without corrupting underlying\ncausal mechanisms. Theoretical analysis and empirical results evidence the\neffectiveness of our method in solving target shifts, showing substantial and\nconstant improvements across various graph OOD tasks.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.109.044061",
      "title": "Geometry and covariance of symmetric teleparallel theories of gravity",
      "abstract": "  We present the geometric foundations and derivations of equations of motion\nfor symmetric teleparallel theories of gravity in the coincident gauge and\ncovariant frameworks. We discuss the theoretical challenges introduced by the\nauxiliary fields responsible for the covariantisation procedure. We elucidate a\ntetradic structure interpretation behind this covariant formulation. Regarding\nthe effect of covariantisation at the level of the equations of motion, we\nexplicitly show that the only physical change, in case of setting an arbitrary\nenergy-momentum tensor to the right hand side, resides in the requirement of\nthe fulfillment of the covariant conservation laws. Also, we have explicitly\nintroduced the fundamental covariantly-conserved teleparallel tetrad for the\nsymmetric teleparallel frameworks.\n",
      "subjects": [
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1073/pnas.2312822121",
      "title": "Chaotic turnover of rare and abundant species in a strongly interacting\n  model community",
      "abstract": "  The composition of ecological communities varies not only between different\nlocations but also in time. Understanding the fundamental processes that drive\nspecies towards rarity or abundance is crucial to assessing ecosystem\nresilience and adaptation to changing environmental conditions. In plankton\ncommunities in particular, large temporal fluctuations in species abundances\nhave been associated with chaotic dynamics. On the other hand, microbial\ndiversity is overwhelmingly sustained by a `rare biosphere' of species with\nvery low abundances. We consider here the possibility that interactions within\na species-rich community can relate both phenomena. We use a Lotka-Volterra\nmodel with weak immigration and strong, disordered, and mostly competitive\ninteractions between hundreds of species to bridge single-species temporal\nfluctuations and abundance distribution patterns. We highlight a generic\nchaotic regime where a few species at a time achieve dominance, but are\ncontinuously overturned by the invasion of formerly rare species. We derive a\nfocal-species model that captures the intermittent boom-and-bust dynamics that\nevery species undergoes. Although species cannot be treated as effectively\nuncorrelated in their abundances, the community's effect on a focal species can\nnonetheless be described by a time-correlated noise characterized by a few\neffective parameters that can be estimated from time series. The model predicts\na non-unitary exponent of the power-law abundance decay, which varies weakly\nwith ecological parameters, consistent with observation in marine protist\ncommunities. The chaotic turnover regime is thus poised to capture relevant\necological features of species-rich microbial communities.\n",
      "subjects": [
        "q-bio.PE",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/5.0164222",
      "title": "Compact Chirped Fiber Bragg Gratings for Single-Photon Generation from\n  Quantum Dots",
      "abstract": "  A scalable source of single photons is a key constituent of an efficient\nquantum photonic architecture. To realize this, it is beneficial to have an\nensemble of quantum emitters that can be collectively excited with high\nefficiency. Semiconductor quantum dots hold great potential in this context,\ndue to their excellent photophysical properties. Spectral variability of\nquantum dots is commonly regarded as a drawback introduced by the fabrication\nmethod. However, this is beneficial to realize a frequency-multiplexed\nsingle-photon platform. Chirped pulse excitation, relying on the so-called\nadiabatic rapid passage, is the most efficient scheme to excite a quantum dot\nensemble due to its immunity to individual quantum dot parameters. Yet, the\nexisting methods of generating chirped laser pulses to excite a quantum emitter\nare bulky, lossy, and mechanically unstable, which severely hampers the\nprospects of a quantum dot photon source. Here, we present a compact, robust,\nand high-efficiency alternative for chirped pulse excitation of solid-state\nquantum emitters. Our simple plug-and-play module consists of chirped fiber\nBragg gratings (CFBGs), fabricated via femtosecond inscription, to provide high\nvalues of dispersion in the near-infrared spectral range, where the quantum\ndots emit. We characterize and benchmark the performance of our method via\nchirped excitation of a GaAs quantum dot, establishing high-fidelity\nsingle-photon generation. Our highly versatile chirping module coupled to a\nphoton source is a significant milestone toward realizing practical quantum\nphotonic devices.\n",
      "subjects": [
        "physics.optics",
        "cond-mat.mes-hall",
        "physics.atom-ph",
        "physics.chem-ph",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Learning Latent Dynamics via Invariant Decomposition and\n  (Spatio-)Temporal Transformers",
      "abstract": "  We propose a method for learning dynamical systems from high-dimensional\nempirical data that combines variational autoencoders and (spatio-)temporal\nattention within a framework designed to enforce certain\nscientifically-motivated invariances. We focus on the setting in which data are\navailable from multiple different instances of a system whose underlying\ndynamical model is entirely unknown at the outset. The approach rests on a\nseparation into an instance-specific encoding (capturing initial conditions,\nconstants etc.) and a latent dynamics model that is itself universal across all\ninstances/realizations of the system. The separation is achieved in an\nautomated, data-driven manner and only empirical data are required as inputs to\nthe model. The approach allows effective inference of system behaviour at any\ncontinuous time but does not require an explicit neural ODE formulation, which\nmakes it efficient and highly scalable. We study behaviour through simple\ntheoretical analyses and extensive experiments on synthetic and real-world\ndatasets. The latter investigate learning the dynamics of complex systems based\non finite data and show that the proposed approach can outperform\nstate-of-the-art neural-dynamical models. We study also more general inductive\nbias in the context of transfer to data obtained under entirely novel system\ninterventions. Overall, our results provide a promising new framework for\nefficiently learning dynamical models from heterogeneous data with potential\napplications in a wide range of fields including physics, medicine, biology and\nengineering.\n",
      "subjects": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.108.114511",
      "title": "Bulk-preventing actions for SU(N) gauge theories",
      "abstract": "  Lattice gauge field theories may suffer from unphysical \"bulk\" phase\ntransitions at strong lattice gauge coupling. We introduce a one-parameter\nfamily of lattice SU(N) gauge actions which, when used in combination with an\nHMC update algorithm, prevents the appearance of the bulk phase transition. We\nbriefly discuss the (presumed) mechanism behind the prevention of the bulk\ntransition and present test results for different SU(N) gauge groups.\n",
      "subjects": [
        "hep-lat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On Positivity for the Peterson Variety",
      "abstract": "  We aim in this manuscript to describe a specific notion of geometric\npositivity that manifests in cohomology rings associated to the flag variety\n$G/B$ and, in some cases, to subvarieties of $G/B$. We offer an exposition on\nthe the well-known geometric basis of the homology of $G/B$ provided by\nSchubert varieties, whose dual basis in cohomology has nonnegative structure\nconstants. In recent work [22] we showed that the equivariant cohomology of\nPeterson varieties satisfies a positivity phenomenon similar to that for\nSchubert calculus for $G/B$. Here we explain how this positivity extends to\nthis particular nilpotent Hessenberg variety, and offer some open questions\nabout the ingredients for extending positivity results to other Hessenberg\nvarieties.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Can An Old Fashioned Feature Extraction and A Light-weight Model Improve\n  Vulnerability Type Identification Performance?",
      "abstract": "  Recent advances in automated vulnerability detection have achieved potential\nresults in helping developers determine vulnerable components. However, after\ndetecting vulnerabilities, investigating to fix vulnerable code is a\nnon-trivial task. In fact, the types of vulnerability, such as buffer overflow\nor memory corruption, could help developers quickly understand the nature of\nthe weaknesses and localize vulnerabilities for security analysis. In this\nwork, we investigate the problem of vulnerability type identification (VTI).\nThe problem is modeled as the multi-label classification task, which could be\neffectively addressed by \"pre-training, then fine-tuning\" framework with deep\npre-trained embedding models. We evaluate the performance of the well-known and\nadvanced pre-trained models for VTI on a large set of vulnerabilities.\nSurprisingly, their performance is not much better than that of the classical\nbaseline approach with an old-fashioned bag-of-word, TF-IDF. Meanwhile, these\ndeep neural network approaches cost much more resources and require GPU. We\nalso introduce a lightweight independent component to refine the predictions of\nthe baseline approach. Our idea is that the types of vulnerabilities could\nstrongly correlate to certain code tokens (distinguishing tokens) in several\ncrucial parts of programs. The distinguishing tokens for each vulnerability\ntype are statistically identified based on their prevalence in the type versus\nthe others. Our results show that the baseline approach enhanced by our\ncomponent can outperform the state-of-the-art deep pre-trained approaches while\nretaining very high efficiency. Furthermore, the proposed component could also\nimprove the neural network approaches by up to 92.8% in macro-average F1.\n",
      "subjects": [
        "cs.SE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1093/mnras/stad1939",
      "title": "Using the motion of S2 to constrain scalar clouds around SgrA*",
      "abstract": "  The motion of S2, one of the stars closest to the Galactic Centre, has been\nmeasured accurately and used to study the compact object at the centre of the\nMilky Way. It is commonly accepted that this object is a supermassive black\nhole but the nature of its environment is open to discussion. Here, we\ninvestigate the possibility that dark matter in the form of an ultralight\nscalar field ``cloud'' clusters around Sgr~A*. We use the available data for S2\nto perform a Markov Chain Monte Carlo analysis and find the best-fit estimates\nfor a scalar cloud structure. Our results show no substantial evidence for such\nstructures. When the cloud size is of the order of the size of the orbit of S2,\nwe are able to constrain its mass to be smaller than $0.1\\%$ of the central\nmass, setting a strong bound on the presence of new fields in the galactic\ncentre.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.IM",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3842/SIGMA.2024.090",
      "title": "Moving NS Punctures on Super Spheres",
      "abstract": "  One of the subtleties that has made superstring perturbation theory intricate\nat high string loop order is the fact that as shown by Donagi and Witten,\nsupermoduli space is not holomorphically projected, nor is it holomorphically\nsplit. In recent years, Sen (further refined by Sen and Witten) has introduced\nthe notion of vertical integration in moduli space. This enables one to build\nBRST-invariant and well-defined amplitudes by adding certain correction terms\nto the contributions associated to the traditional \"delta function\" gauge\nfixing for the worldsheet gravitino on local patches. The Sen and Witten\napproach is made possible due to there being no obstruction to a smooth\nsplitting of supermoduli space, but it may not necessarily be the most\nconvenient or natural solution to the problem. In particular, this approach\ndoes not determine what these corrections terms actually are from the outset.\nInstead, it shows that such correction terms in principle exist, and when\nincluded make all perturbative amplitudes well-defined. There may be situations\nhowever where one would like to instead have a well-defined and fully\ndetermined path integral at arbitrary string loop order from the outset. In\nthis paper, I initiate an alternative (differential-geometric) approach that\nimplements the fact that a smooth gauge slice for supermoduli space always\nexists. As a warmup, I focus specifically on super Riemann surfaces with the\ntopology of a sphere in heterotic string theory, incorporating the\ncorresponding super curvature locally, and introduce a new well-defined smooth\ngauge fixing that leads to a globally defined path integral measure that\ntranslates arbitrary fixed ($-1$) picture NS vertex operators (or handle\noperators) (that may or may not be offshell) to integrated (0) picture. I also\nprovide some comments on the extension to arbitrary super Riemann surfaces.\n",
      "subjects": [
        "hep-th",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.110.032416",
      "title": "Error mitigation, optimization, and extrapolation on a trapped ion\n  testbed",
      "abstract": "  Current noisy intermediate-scale quantum (NISQ) trapped-ion devices are\nsubject to errors which can significantly impact the accuracy of calculations\nif left unchecked. A form of error mitigation called zero noise extrapolation\n(ZNE) can decrease an algorithm's sensitivity to these errors without\nincreasing the number of required qubits. Here, we explore different methods\nfor integrating this error mitigation technique into the Variational Quantum\nEigensolver (VQE) algorithm for calculating the ground state of the HeH+\nmolecule at 0.8 Angstrom in the presence of realistic noise. Using the Quantum\nScientific Computing Open User Testbed (QSCOUT) trapped-ion device, we test\nthree methods of scaling noise for extrapolation: time-stretching the two-qubit\ngates, scaling the sideband amplitude parameter, and inserting two-qubit gate\nidentity operations into the ansatz circuit. We find time-stretching and\nsideband amplitude scaling fail to scale the noise on our particular hardware\nin a way that can be directly extrapolated to zero noise. Scaling our noise\nwith global gate identity insertions and extrapolating after variational\noptimization, we achieve an estimate of the ground state energy within -0.004\n+- 0.04 Hartree; outside chemical accuracy, but greatly improved over our\nnon-error-mitigated estimate with error 0.127 +- 0.008 Hartree. Our results\nshow that the efficacy of this error mitigation technique depends on choosing\nthe correct implementation for a given device architecture.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physletb.2023.138356",
      "title": "Catastrogenesis with unstable ALPs as the origin of the NANOGrav 15 yr\n  gravitational wave signal",
      "abstract": "  In post-inflation axion-like particle (ALP) models, a stable domain wall\nnetwork forms if the model's potential has multiple minima. This system must\nannihilate before dominating the Universe's energy density, producing ALPs and\ngravitational waves (a process we dub \"catastrogenesis,\" or \"creation via\nannihilation\"). We examine the possibility that the gravitational wave\nbackground recently reported by NANOGrav is due to catastrogenesis. For the\ncase of ALP decay into two photons, we identify the region of ALP mass and\ncoupling, just outside current limits, compatible with the NANOGrav signal.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "It's All Relative: Interpretable Models for Scoring Bias in Documents",
      "abstract": "  We propose an interpretable model to score the bias present in web documents,\nbased only on their textual content. Our model incorporates assumptions\nreminiscent of the Bradley-Terry axioms and is trained on pairs of revisions of\nthe same Wikipedia article, where one version is more biased than the other.\nWhile prior approaches based on absolute bias classification have struggled to\nobtain a high accuracy for the task, we are able to develop a useful model for\nscoring bias by learning to perform pairwise comparisons of bias accurately. We\nshow that we can interpret the parameters of the trained model to discover the\nwords most indicative of bias. We also apply our model in three different\nsettings - studying the temporal evolution of bias in Wikipedia articles,\ncomparing news sources based on bias, and scoring bias in law amendments. In\neach case, we demonstrate that the outputs of the model can be explained and\nvalidated, even for the two domains that are outside the training-data domain.\nWe also use the model to compare the general level of bias between domains,\nwhere we see that legal texts are the least biased and news media are the most\nbiased, with Wikipedia articles in between. Given its high performance,\nsimplicity, interpretability, and wide applicability, we hope the model will be\nuseful for a large community, including Wikipedia and news editors, political\nand social scientists, and the general public.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Critical exponents and fluctuations at BEC in a 2D harmonically trapped\n  ideal gas",
      "abstract": "  The critical properties displayed by an ideal 2D Bose gas trapped in a\nharmonic potential are determined and characterized in an exact numerical\nfashion. Beyond thermodynamics, addressed in terms of the global pressure and\nvolume which are the appropriate variables of a fluid confined in a non-uniform\nharmonic potential, the density-density correlation function is also calculated\nand the corresponding correlation length is found. Evaluation of all these\nquantities as Bose-Einstein condensation (BEC) is approached manifest its\ncritical continuous phase transition character. The divergence of the\ncorrelation length as the critical temperature is reached, unveils the expected\nspatial scale invariance proper of a critical transition. The logarithmic\nsingularities of this transition are traced back to the non-analytic behavior\nof the thermodynamic variables at vanishing chemical potential, which is the\nonset of BEC. The critical exponents associated with the ideal BEC transition\nin the 2D inhomogeneous fluid reveals its own universality class.\n",
      "subjects": [
        "cond-mat.quant-gas"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Landmark Detection using Transformer Toward Robot-assisted Nasal Airway\n  Intubation",
      "abstract": "  Robot-assisted airway intubation application needs high accuracy in locating\ntargets and organs. Two vital landmarks, nostrils and glottis, can be detected\nduring the intubation to accommodate the stages of nasal intubation. Automated\nlandmark detection can provide accurate localization and quantitative\nevaluation. The Detection Transformer (DeTR) leads object detectors to a new\nparadigm with long-range dependence. However, current DeTR requires long\niterations to converge, and does not perform well in detecting small objects.\nThis paper proposes a transformer-based landmark detection solution with\ndeformable DeTR and the semantic-aligned-matching module for detecting\nlandmarks in robot-assisted intubation. The semantics aligner can effectively\nalign the semantics of object queries and image features in the same embedding\nspace using the most discriminative features. To evaluate the performance of\nour solution, we utilize a publicly accessible glottis dataset and\nautomatically annotate a nostril detection dataset. The experimental results\ndemonstrate our competitive performance in detection accuracy. Our code is\npublicly accessible.\n",
      "subjects": [
        "eess.IV",
        "cs.CV",
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3390/e26030267",
      "title": "(Re)Construction of Quantum Space-Time: Transcribing Hilbert Into\n  Configuration Space",
      "abstract": "  Space-time in quantum mechanics is about bridging Hilbert and configuration\nspace. Thereby, an entirely new perspective is obtained by replacing the\nNewtonian space-time theater with the image of a presumably high-dimensional\nHilbert space, through which space-time becomes an epiphenomenon construed by\ninternal observers.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Cheap Lunch for Medical Image Segmentation by Fine-tuning SAM on Few\n  Exemplars",
      "abstract": "  The Segment Anything Model (SAM) has demonstrated remarkable capabilities of\nscaled-up segmentation models, enabling zero-shot generalization across a\nvariety of domains. By leveraging large-scale foundational models as\npre-trained models, it is a natural progression to fine-tune SAM for specific\ndomains to further enhance performances. However, the adoption of foundational\nmodels in the medical domain presents a challenge due to the difficulty and\nexpense of labeling sufficient data for adaptation within hospital systems. In\nthis paper, we introduce an efficient and practical approach for fine-tuning\nSAM using a limited number of exemplars, making it suitable for such scenarios.\nOur approach combines two established techniques from the literature: an\nexemplar-guided synthesis module and the widely recognized Low-Rank Adaptation\n(LoRA) fine-tuning strategy, serving as data-level and model-level attempts\nrespectively. Interestingly, our empirical findings suggest that SAM can be\neffectively aligned within the medical domain even with few labeled data. We\nvalidate our approach through experiments on brain tumor segmentation (BraTS)\nand multi-organ CT segmentation (Synapse). The comprehensive results underscore\nthe feasibility and effectiveness of such an approach, paving the way for the\npractical application of SAM in the medical domain.\n",
      "subjects": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Helicity of the magnetic axes of quasi-isodynamic stellarators",
      "abstract": "  In this study, we explore the influence of the helicity of the magnetic\naxis-defined as the self-linking number of the curve-on the quality of\nquasi-isodynamic stellarator-symmetric configurations constructed using the\nnear-axis expansion method (Camacho Mata et al. 2022; Plunk et al. 2019). A\nclass of magnetic axes previously unexplored within this formalism is\nidentified when analyzing the axis shape of the QIPC configuration (Subbotin et\nal. 2006): the case of half-helicity (per field period). We show these shapes\nare compatible with the near-axis formalism and how they can be used to\nconstruct near-axis stellarators with up-to 5 field-periods, $\\epsilon_{eff}\n\\approx$ 1.3%, and similar rotational transform as existing conventionally\noptimized designs, without the need of a plasma boundary optimization.\n",
      "subjects": [
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1162/tacl_a_00654",
      "title": "Text-to-OverpassQL: A Natural Language Interface for Complex Geodata\n  Querying of OpenStreetMap",
      "abstract": "  We present Text-to-OverpassQL, a task designed to facilitate a natural\nlanguage interface for querying geodata from OpenStreetMap (OSM). The Overpass\nQuery Language (OverpassQL) allows users to formulate complex database queries\nand is widely adopted in the OSM ecosystem. Generating Overpass queries from\nnatural language input serves multiple use-cases. It enables novice users to\nutilize OverpassQL without prior knowledge, assists experienced users with\ncrafting advanced queries, and enables tool-augmented large language models to\naccess information stored in the OSM database. In order to assess the\nperformance of current sequence generation models on this task, we propose\nOverpassNL, a dataset of 8,352 queries with corresponding natural language\ninputs. We further introduce task specific evaluation metrics and ground the\nevaluation of the Text-to-OverpassQL task by executing the queries against the\nOSM database. We establish strong baselines by finetuning sequence-to-sequence\nmodels and adapting large language models with in-context examples. The\ndetailed evaluation reveals strengths and weaknesses of the considered learning\nstrategies, laying the foundations for further research into the\nText-to-OverpassQL task.\n",
      "subjects": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DB",
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "RigNet++: Semantic Assisted Repetitive Image Guided Network for Depth\n  Completion",
      "abstract": "  Depth completion aims to recover dense depth maps from sparse ones, where\ncolor images are often used to facilitate this task. Recent depth methods\nprimarily focus on image guided learning frameworks. However, blurry guidance\nin the image and unclear structure in the depth still impede their performance.\nTo tackle these challenges, we explore a repetitive design in our image guided\nnetwork to gradually and sufficiently recover depth values. Specifically, the\nrepetition is embodied in both the image guidance branch and depth generation\nbranch. In the former branch, we design a dense repetitive hourglass network\n(DRHN) to extract discriminative image features of complex environments, which\ncan provide powerful contextual instruction for depth prediction. In the latter\nbranch, we present a repetitive guidance (RG) module based on dynamic\nconvolution, in which an efficient convolution factorization is proposed to\nreduce the complexity while modeling high-frequency structures progressively.\nFurthermore, in the semantic guidance branch, we utilize the well-known large\nvision model, i.e., segment anything (SAM), to supply RG with semantic prior.\nIn addition, we propose a region-aware spatial propagation network (RASPN) for\nfurther depth refinement based on the semantic prior constraint. Finally, we\ncollect a new dataset termed TOFDC for the depth completion task, which is\nacquired by the time-of-flight (TOF) sensor and the color camera on\nsmartphones. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance on KITTI, NYUv2, Matterport3D, 3D60, VKITTI, and\nour TOFDC.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/ITSC57777.2023.10422079",
      "title": "Collective PV-RCNN: A Novel Fusion Technique using Collective Detections\n  for Enhanced Local LiDAR-Based Perception",
      "abstract": "  Comprehensive perception of the environment is crucial for the safe operation\nof autonomous vehicles. However, the perception capabilities of autonomous\nvehicles are limited due to occlusions, limited sensor ranges, or environmental\ninfluences. Collective Perception (CP) aims to mitigate these problems by\nenabling the exchange of information between vehicles. A major challenge in CP\nis the fusion of the exchanged information. Due to the enormous bandwidth\nrequirement of early fusion approaches and the interchangeability issues of\nintermediate fusion approaches, only the late fusion of shared detections is\npractical. Current late fusion approaches neglect valuable information for\nlocal detection, this is why we propose a novel fusion method to fuse the\ndetections of cooperative vehicles within the local LiDAR-based detection\npipeline. Therefore, we present Collective PV-RCNN (CPV-RCNN), which extends\nthe PV-RCNN++ framework to fuse collective detections. Code is available at\nhttps://github.com/ekut-es\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Unconventional superconducting pairing in a B20 Kramers Weyl semimetal",
      "abstract": "  Topological superconductors present an ideal platform for exploring\nnontrivial superconductivity and realizing Majorana boundary modes in\nmaterials. However, finding a single-phase topological material with nontrivial\nsuperconducting states is a challenge. Here, we predict nontrivial\nsuperconductivity in the pristine chiral metal RhGe with a transition\ntemperature of 5.8 K. Chiral symmetries in RhGe enforce multifold Weyl fermions\nat high-symmetry momentum points and spin-polarized Fermi arc states that span\nthe whole surface Brillouin zone. These bulk and surface chiral states support\nmultiple type-II van Hove singularities that enhance superconductivity in RhGe.\nOur detailed analysis of superconducting pairing symmetries involving Chiral\nFermi pockets in RhGe, indicates the presence of nontrivial superconducting\npairing. Our study establishes RhGe as a promising candidate material for\nhosting mixed-parity pairing and topological superconductivity.\n",
      "subjects": [
        "cond-mat.supr-con",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1109/ICDL55364.2023.10364473",
      "title": "Goal Space Abstraction in Hierarchical Reinforcement Learning via\n  Set-Based Reachability Analysis",
      "abstract": "  Open-ended learning benefits immensely from the use of symbolic methods for\ngoal representation as they offer ways to structure knowledge for efficient and\ntransferable learning. However, the existing Hierarchical Reinforcement\nLearning (HRL) approaches relying on symbolic reasoning are often limited as\nthey require a manual goal representation. The challenge in autonomously\ndiscovering a symbolic goal representation is that it must preserve critical\ninformation, such as the environment dynamics. In this paper, we propose a\ndevelopmental mechanism for goal discovery via an emergent representation that\nabstracts (i.e., groups together) sets of environment states that have similar\nroles in the task. We introduce a Feudal HRL algorithm that concurrently learns\nboth the goal representation and a hierarchical policy. The algorithm uses\nsymbolic reachability analysis for neural networks to approximate the\ntransition relation among sets of states and to refine the goal representation.\nWe evaluate our approach on complex navigation tasks, showing the learned\nrepresentation is interpretable, transferrable and results in data efficient\nlearning.\n",
      "subjects": [
        "cs.LG",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.dark.2024.101570",
      "title": "Detecting Relativistic Doppler in Galaxy Clustering with Tailored Galaxy\n  Samples",
      "abstract": "  We present a method to obtain a high-significance detection of relativistic\neffects on cosmological scales. Measurements of such effects would be\ninstrumental for our understanding of the Universe, as they would provide a\nfurther confirmation of the validity of general relativity as the correct\ndescription of the gravitational interaction, in a regime very far from that of\nstrong gravity, where it has been tested to exquisite accuracy. Despite its\nrelevance, the detection of relativistic effects has hitherto eluded us, mainly\nbecause they are stronger on the largest cosmic scales, plagued by cosmic\nvariance. Our work focuses on the cosmological probe of galaxy clustering,\ndescribing the excess probability of finding pairs of galaxies at a given\nseparation due to them being part of the same underlying cosmic large-scale\nstructure. We focus on the two-point correlation function of the distribution\nof galaxies in Fourier space -- the power spectrum -- where relativistic\neffects appear as an imaginary contribution to the real power spectrum. By\ncarefully tailoring cuts in magnitude/luminosity, we are able to obtain two\nsamples (bright and faint) of the same galaxy population, whose\ncross-correlation power spectrum allows for a detection of the relativistic\ncontribution. In particular, we optimise the definition of the samples to\nmaximise the detection significance of the relativistic Doppler term for both a\nlow-$z$ Bright Galaxy Sample and a high-$z$ H$\\alpha$ emission line galaxy\npopulation.\n",
      "subjects": [
        "astro-ph.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Portrait Stylization: Artistic Style Transfer with Auxiliary Networks\n  for Human Face Stylization",
      "abstract": "  Today's image style transfer methods have difficulty retaining humans face\nindividual features after the whole stylizing process. This occurs because the\nfeatures like face geometry and people's expressions are not captured by the\ngeneral-purpose image classifiers like the VGG-19 pre-trained models. This\npaper proposes the use of embeddings from an auxiliary pre-trained face\nrecognition model to encourage the algorithm to propagate human face features\nfrom the content image to the final stylized result.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Unified Bayesian Framework for Modeling Measurement Error in\n  Multinomial Data",
      "abstract": "  Measurement error in multinomial data is a well-known and well-studied\ninferential problem that is encountered in many fields, including engineering,\nbiomedical and omics research, ecology, finance, official statistics, and\nsocial sciences. Methods developed to accommodate measurement error in\nmultinomial data are typically equipped to handle false negatives or false\npositives, but not both. We provide a unified framework for accommodating both\nforms of measurement error using a Bayesian hierarchical approach. We\ndemonstrate the proposed method's performance on simulated data and apply it to\nacoustic bat monitoring and official crime data.\n",
      "subjects": [
        "stat.ME",
        "stat.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Distributed Gradient Tracking Methods with Guarantees for Computing a\n  Solution to Stochastic MPECs",
      "abstract": "  We consider a class of hierarchical multi-agent optimization problems over\nnetworks where agents seek to compute an approximate solution to a single-stage\nstochastic mathematical program with equilibrium constraints (MPEC). MPECs\nsubsume several important problem classes including Stackelberg games, bilevel\nprograms, and traffic equilibrium problems, to name a few. Our goal in this\nwork is to provably resolve stochastic MPECs in distributed regimes where the\nagents only have access to their local objectives and an inexact best-response\nto the lower-level equilibrium problem. To this end, we devise a new method\ncalled randomized smoothed distributed zeroth-order gradient tracking\n(rs-DZGT). This is a novel gradient tracking scheme where agents employ a\nzeroth-order implicit scheme to approximate their (unavailable) local\ngradients. Leveraging the properties of a randomized smoothing technique, we\nestablish the convergence of the method and derive complexity guarantees for\ncomputing a stationary point of an optimization problem with a smoothed\nimplicit global objective. We also provide preliminary numerical experiments\nwhere we compare the performance of rs-DZGT on networks under different\nsettings with that of its centralized counterpart.\n",
      "subjects": [
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A New Discriminant for the Hardy Z-Function and the Corrected Gram's law",
      "abstract": "  In this paper, we introduce a novel variational framework rooted in algebraic\ngeometry for the analysis of the Hardy $Z$-function. Our primary contribution\nlies in the definition and exploration of $\\Delta_n(\\overline{a})$, a newly\ndevised discriminant that measures the realness of consecutive zeros of $Z(t)$.\nOur investigation into $\\Delta_n(\\overline{a})$ and its properties yields a\nwealth of compelling insights into the zeros of $Z(t)$, including the corrected\nGram's law, the second-order approximation of $\\Delta_n(\\overline{a})$, and the\ndiscovery of the G-B-G repulsion relation. Collectively, these results provide\ncompelling evidence supporting a new plausibility argument for the Riemann\nhypothesis.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Measuring the bending rigidity of microbial glucolipid (biosurfactant)\n  bioamphiphile self-assembled structures by neutron spin-echo (NSE):\n  interdigitated vesicles, lamellae and fibers",
      "abstract": "  Bending rigidity, k, is classically measured for lipid membranes to\ncharacterize their nanoscale mechanical properties as a function of\ncomposition. Widely employed as a comparative tool, it helps understanding the\nrelationship between the lipid's molecular structure and the elastic properties\nof its corresponding bilayer. Widely measured for phospholipid membranes in the\nshape of giant unilamellar vesicles (GUVs), bending rigidity is determined here\nfor three self-assembled structures formed by a new biobased glucolipid\nbioamphiphile, rather associated to the family of glycolipid biosurfactants\nthan phospholipids. In its oleyl form, glucolipid G-C18:1 can assemble into\nvesicles or crystalline fibers, while in its stearyl form, glucolipid G-C18:0\ncan assemble into lamellar gels. Neutron spin-echo (NSE) is employed in the\nq-range between 0.3 nm-1 (21 nm) and 1.5 nm-1 (4.1 nm) with a spin-echo time in\nthe range of up to 500 ns to characterize the bending rigidity of three\ndifferent structures (Vesicle suspension, Lamellar gel, Fiber gel) solely\ncomposed of a single glucolipid. The low (k= 0.30 $\\pm$ 0.04 kbT) values found\nfor the Vesicle suspension and high values found for the Lamellar (k= 130 $\\pm$\n40 kbT) and Fiber gels (k= 900 $\\pm$ 500 kbT) are unusual when compared to most\nphospholipid membranes. By attempting to quantify for the first time the\nbending rigidity of self-assembled bioamphiphiles, this work not only\ncontributes to the fundamental understanding of these new molecular systems,\nbut it also opens new perspectives in their integration in the field of soft\nmaterials.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevResearch.6.033149",
      "title": "Honeybee-like collective decision making in a kilobot swarm",
      "abstract": "  Drawing inspiration from honeybee swarms' nest-site selection process, we\nassess the ability of a kilobot robot swarm to replicate this captivating\nexample of collective decision-making. Honeybees locate the optimal site for\ntheir new nest by aggregating information about potential locations and\nexchanging it through their waggle-dance. The complexity and elegance of\nsolving this problem relies on two key abilities of scout honeybees:\nself-discovery and imitation, symbolizing independence and interdependence,\nrespectively. We employ a mathematical model to represent this nest-site\nselection problem and program our kilobots to follow its rules. Our experiments\ndemonstrate that the kilobot swarm can collectively reach consensus decisions\nin a decentralized manner, akin to honeybees. However, the strength of this\nconsensus depends not only on the interplay between independence and\ninterdependence but also on critical factors such as swarm density and the\nmotion of kilobots. These factors enable the formation of a percolated\ncommunication network, through which each robot can receive information beyond\nits immediate vicinity. By shedding light on this crucial layer of complexity\n--the crowding and mobility conditions during the decision-making--, we\nemphasize the significance of factors typically overlooked but essential to\nliving systems and life itself.\n",
      "subjects": [
        "cond-mat.dis-nn",
        "cond-mat.soft",
        "cond-mat.stat-mech",
        "nlin.AO",
        "physics.bio-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361/202346312",
      "title": "Coronal bright point statistics I. Lifetime, shape, and coronal\n  co-rotation",
      "abstract": "  Context. The corona of the Sun is the part of the solar atmosphere with\ntemperatures of over one million Kelvin, which needs to be heated internally in\norder to exist. This heating mechanism remains a mystery; we see large\nmagnetically active regions in the photosphere lead to strong extreme UV (EUV)\nemission in the corona. On much smaller scales (on the order of tens of Mm),\nthere are bipolar and multipolar regions that can be associated with evenly\nsized coronal bright points (CBPs). Aims. Our aim was to study the properties\nof CBPs in a statistical sense and to use continuous data from the SDO\nspacecraft, which makes it possible to track CBPs over their whole lifetime.\nFurthermore, we tested various rotation-speed profiles for CBPs in order to\nfind out if the lower corona is co-rotating with the photosphere. Then we\ncompiled a database with about 346 CBPs together with information of their\nsizes, shapes, appearance and disappearance, and their visibility in the EUV\nchannels of the AIA instrument. We want to verify our methods with similar\nprevious studies. Methods. We used the high-cadence data of the largest\ncontinuous SDO observation interval in 2015 to employ an automated tracking\nalgorithm for CBPs. Some of the information (e.g., the total lifetime, the\ncharacteristic shape, and the magnetic polarities below the CBPs) still\nrequires human interaction. Results. In this work we present statistics on\nfundamental properties of CBPs along with some comparison tables that relate,\nfor example, the CBP lifetime with their shape. CBPs that are visible in all\nAIA channels simultaneously seem to be brighter in total and also have a\nstronger heating, and hence a higher total radiation flux. We compared the EUV\nemission visibility in different AIA channels with the CBP's shape and\nlifetime. ... (full version see pdf)\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1073/pnas.2401644121",
      "title": "Theory of topological exciton insulators and condensates in flat Chern\n  bands",
      "abstract": "  Excitons are the neutral quasiparticles that form when Coulomb interactions\ncreate bound states between electrons and holes. Due to their bosonic nature,\nexcitons are expected to condense and exhibit superfluidity at sufficiently low\ntemperatures. In interacting Chern insulators, excitons may inherit the\nnontrivial topology and quantum geometry from the underlying electron\nwavefunctions. We theoretically investigate the excitonic bound states and\nsuperfluidity in flat-band insulators pumped with light. We find that the\nexciton wavefunctions exhibit vortex structures in momentum space, with the\ntotal vorticity being equal to the difference of Chern numbers between the\nconduction and valence bands. Moreover, both the exciton binding energy and the\nexciton superfluid density are proportional to the Brillouin-zone average of\nthe quantum metric and the Coulomb potential energy per unit cell. Spontaneous\nemission of circularly polarized light from radiative decay is a detectable\nsignature of the vorticity of excitons. We propose that the exciton vorticity\ncan also be experimentally measured by the nonlinear anomalous Hall effect,\nwhereas the exciton superfluidity can be detected by voltage-drop quantization\nthrough a combination of the quantum geometry and the Aharonov-Casher effect.\nTopological excitons and their superfluid phase could be realized in flat bands\nof twisted Van der Waals heterostructures.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Hallucination-minimized Data-to-answer Framework for Financial\n  Decision-makers",
      "abstract": "  Large Language Models (LLMs) have been applied to build several automation\nand personalized question-answering prototypes so far. However, scaling such\nprototypes to robust products with minimized hallucinations or fake responses\nstill remains an open challenge, especially in niche data-table heavy domains\nsuch as financial decision making. In this work, we present a novel\nLangchain-based framework that transforms data tables into hierarchical textual\ndata chunks to enable a wide variety of actionable question answering. First,\nthe user-queries are classified by intention followed by automated retrieval of\nthe most relevant data chunks to generate customized LLM prompts per query.\nNext, the custom prompts and their responses undergo multi-metric scoring to\nassess for hallucinations and response confidence. The proposed system is\noptimized with user-query intention classification, advanced prompting, data\nscaling capabilities and it achieves over 90% confidence scores for a variety\nof user-queries responses ranging from {What, Where, Why, How, predict, trend,\nanomalies, exceptions} that are crucial for financial decision making\napplications. The proposed data to answers framework can be extended to other\nanalytical domains such as sales and payroll to ensure optimal hallucination\ncontrol guardrails.\n",
      "subjects": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Foundation Model for Cell Segmentation",
      "abstract": "  Cells are the fundamental unit of biological organization, and identifying\nthem in imaging data - cell segmentation - is a critical task for various\ncellular imaging experiments. While deep learning methods have led to\nsubstantial progress on this problem, models that have seen wide use are\nspecialist models that work well for specific domains. Methods that have\nlearned the general notion of \"what is a cell\" and can identify them across\ndifferent domains of cellular imaging data have proven elusive. In this work,\nwe present CellSAM, a foundation model for cell segmentation that generalizes\nacross diverse cellular imaging data. CellSAM builds on top of the Segment\nAnything Model (SAM) by developing a prompt engineering approach to mask\ngeneration. We train an object detector, CellFinder, to automatically detect\ncells and prompt SAM to generate segmentations. We show that this approach\nallows a single model to achieve state-of-the-art performance for segmenting\nimages of mammalian cells (in tissues and cell culture), yeast, and bacteria\ncollected with various imaging modalities. To enable accessibility, we\nintegrate CellSAM into DeepCell Label to further accelerate human-in-the-loop\nlabeling strategies for cellular imaging data. A deployed version of CellSAM is\navailable at https://label-dev.deepcell.org/.\n",
      "subjects": [
        "q-bio.QM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Photometric monitoring of PMS stars with the telescopes at Rozhen\n  Observatory",
      "abstract": "  For several decades we have been performing photometric monitoring of some of\nthe star formation regions. Significant place in our program take observations\nof objects of the type FU Orionis, EX Lupi, UX Orionis and other similar but\nunclassified objects. These three types of young variable objects show changes\nin brightness with large amplitudes and attract the attention of star formation\nresearchers. But it is not always possible to distinguish them from each other\nwithout the presence of long-term multicolor photometric data. For this reason,\nwe collect data from current CCD observations and supplement them with data\nfrom the photographic plates archives. In this paper, we show the latest data\nfrom optical photometric studies of four PMS objects (V2493 Cyg, V582 Aur, V733\nCep and V1180 Tau) made at the Rozhen Observatory. Our monitoring is carried\nout in $BVRI$ filters, which allows studying the variability in color indexes\nalso. By analysis the historical light curves of these objects we are trying to\nobtain information about the processes associated with the early stages of\nstellar evolution.\n",
      "subjects": [
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1475-7516/2024/03/030",
      "title": "WIMP constraints from black hole low-mass X-ray binaries",
      "abstract": "  The abnormally fast orbital decay observed in the black hole (BH) Low-Mass\nX-ray binaries (BH-LMXB) A0620-00 and XTE J1118+480 can be explained by the\ndynamical friction between Dark Matter (DM) and the companion star orbiting\naround the low-mass BH (of a few $M_\\odot$) of the system. In this case the\nvalue of the index $\\gamma_{\\rm sp}$ of the DM spike surrounding the BH can be\npinned down with an accuracy of a few percent, way better than that for much\nbigger systems such as the super massive BHs (SMBHs) in the Galactic Center or\nin M87. We have used data from XTE J1118+480 to put bounds on the WIMP\nannihilation cross section times velocity $\\langle \\sigma v\\rangle$, assuming\nthat DM annihilation is driven by the $b\\bar{b}$ annihilation channel and that\nit proceeds in $s$-wave. The bounds are driven by the radio synchrotron signal\nproduced by $e^\\pm$ final states propagating in the magnetic field near the BH.\nFor DM masses $m_\\chi$ up to the TeV scale XTE J1118+480 allows to constrain\n$\\langle \\sigma v\\rangle$ well below $\\langle\\sigma v\\rangle_{\\rm thermal}$,\ncorresponding to the observed DM relic density in the Universe for a thermal\nWIMP. On the other hand, for $m_\\chi \\gtrsim$ 15 GeV, the bounds from the SMBHs\nin the GC or in M87 do not reach $\\langle\\sigma v\\rangle_{\\rm thermal}$ when\nthe very large uncertainties on the corresponding spike indices are taken into\naccount, in spite of potentially producing much larger DM densities compared to\nXTE J1118+480. Our bounds for XTE J1118+480 have a mild sensitivity on spatial\ndiffusion, but diffusion enhances the sensitivity of the results upon the\nintensity of the magnetic field. Taken at face value the bound from XTE\nJ1118+480 on $\\langle \\sigma v\\rangle$ is the most constraining compared to all\nothers for $m_\\chi\\lesssim$ 1 TeV, unless the intensity of the magnetic field\nis significantly smaller than its equipartition estimation.\n",
      "subjects": [
        "hep-ph",
        "astro-ph.CO",
        "astro-ph.HE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Rethinking Detection Based Table Structure Recognition for Visually Rich\n  Document Images",
      "abstract": "  Table Structure Recognition (TSR) is a widely discussed task aiming at\ntransforming unstructured table images into structured formats, such as HTML\nsequences, to make text-only models, such as ChatGPT, that can further process\nthese tables. One type of solution is using detection models to detect table\ncomponents, such as columns and rows, then applying a rule-based\npost-processing method to convert detection results into HTML sequences.\nHowever, existing detection-based models usually cannot perform as well as\nother types of solutions regarding cell-level TSR metrics, such as TEDS, and\nthe underlying reasons limiting the performance of these models on the TSR task\nare also not well-explored. Therefore, we revisit existing detection-based\nmodels comprehensively and explore the underlying reasons hindering these\nmodels' performance, including the improper problem definition, the mismatch\nissue of detection and TSR metrics, the characteristics of detection models,\nand the impact of local and long-range features extraction. Based on our\nanalysis and findings, we apply simple methods to tailor a typical two-stage\ndetection model, Cascade R-CNN, for the TSR task. The experimental results show\nthat the tailored Cascade R-CNN based model can improve the base Cascade R-CNN\nmodel by 16.35\\% on the FinTabNet dataset regarding the structure-only TEDS,\noutperforming other types of state-of-the-art methods, demonstrating that our\nfindings can be a guideline for improving detection-based TSR models and that a\npurely detection-based solution is competitive with other types of solutions,\nsuch as graph-based and image-to-sequence solutions.\n",
      "subjects": [
        "cs.CV",
        "cs.IR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "SPEEDNet: Salient Pyramidal Enhancement Encoder-Decoder Network for\n  Colonoscopy Images",
      "abstract": "  Accurate identification and precise delineation of regions of significance,\nsuch as tumors or lesions, is a pivotal goal in medical imaging analysis. This\npaper proposes SPEEDNet, a novel architecture for precisely segmenting lesions\nwithin colonoscopy images. SPEEDNet uses a novel block named\nDilated-Involutional Pyramidal Convolution Fusion (DIPC). A DIPC block combines\nthe dilated involution layers pairwise into a pyramidal structure to convert\nthe feature maps into a compact space. This lowers the total number of\nparameters while improving the learning of representations across an optimal\nreceptive field, thereby reducing the blurring effect. On the EBHISeg dataset,\nSPEEDNet outperforms three previous networks: UNet, FeedNet, and AttesResDUNet.\nSpecifically, SPEEDNet attains an average dice score of 0.952 and a recall of\n0.971. Qualitative results and ablation studies provide additional insights\ninto the effectiveness of SPEEDNet. The model size of SPEEDNet is 9.81 MB,\nsignificantly smaller than that of UNet (22.84 MB), FeedNet(185.58 MB), and\nAttesResDUNet (140.09 MB).\n",
      "subjects": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Airdrops: Giving Money Away Is Harder Than It Seems",
      "abstract": "  Airdrops are a common strategy used by blockchain protocols to attract and\ngrow an initial user base. Tokens are typically distributed to select users as\na \"reward\" for engaging with the protocol, aiming to foster long-term community\nloyalty and sustained economic activity. Despite their prevalence, there is\nlimited understanding of what makes an airdrop successful. This paper outlines\nthe design space for airdrops and proposes key outcomes for an effective\nstrategy. We analyze on-chain data from six large-scale airdrops to assess\ntheir success and find that a substantial portion of tokens is often sold off\nby \"airdrop farmers.\" Based on this analysis, we highlight common pitfalls and\noffer guidelines for improving airdrop design.\n",
      "subjects": [
        "cs.CR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Four-dimensional $\\mathcal N=2$ superconformal long circular quivers",
      "abstract": "  We study four-dimensional $\\mathcal N=2$ superconformal circular, cyclic\nsymmetric quiver theories which are planar equivalent to $\\mathcal N=4$ super\nYang-Mills. We use localization to compute nonplanar corrections to the free\nenergy and the circular half-BPS Wilson loop in these theories for an arbitrary\nnumber of nodes, and examine their behaviour in the limit of long quivers.\nExploiting the relationship between the localization quiver matrix integrals\nand an integrable Bessel operator, we find a closed-form expression for the\nleading nonplanar correction to both observables in the limit when the number\nof nodes and 't Hooft coupling become large. We demonstrate that it has\ndifferent asymptotic behaviour depending on how the two parameters are\ncompared, and interpret this behaviour in terms of properties of a lattice\nmodel defined on the quiver diagram.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Sharp bounds on the height of K-semistable Fano varieties II, the log\n  case",
      "abstract": "  In our previous work we conjectured - inspired by an algebro-geometric result\nof Fujita - that the height of an arithmetic Fano variety X of relative\ndimension $n$ is maximal when X is the projective space\n$\\mathbb{P}^n_{\\mathbb{Z}}$ over the integers, endowed with the Fubini-Study\nmetric, if the corresponding complex Fano variety is K-semistable. In this work\nthe conjecture is settled for diagonal hypersurfaces in\n$\\mathbb{P}^{n+1}_{\\mathbb{Z}}$. The proof is based on a logarithmic extension\nof our previous conjecture, of independent interest, which is established for\ntoric log Fano varieties of relative dimension at most three, hyperplane\narrangements on $\\mathbb{P}^n_{\\mathbb{Z}}$, as well as for general arithmetic\norbifold Fano surfaces.\n",
      "subjects": [
        "math.AG",
        "math.DG",
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Line configurations and K3 surfaces",
      "abstract": "  We study the realization spaces of $10_3$ line configurations. Answering a\nquestion posed by Sturmfels in 1991, we use elliptic surface techniques to show\nthat realizations over $\\mathbb{Q}$ are dense in those over $\\mathbb{R}$ for\nall $10_3$ configurations. We find that for exactly four of the ten\nconfigurations, the realization space admits a compactification by a K3\nsurface. We show that these have Picard number 20 and compute their\ndiscriminants. Finally, we use geometric invariant theory to give an elegant\ninterpretation of these K3 surfaces as moduli spaces.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "I'M HOI: Inertia-aware Monocular Capture of 3D Human-Object Interactions",
      "abstract": "  We are living in a world surrounded by diverse and \"smart\" devices with rich\nmodalities of sensing ability. Conveniently capturing the interactions between\nus humans and these objects remains far-reaching. In this paper, we present\nI'm-HOI, a monocular scheme to faithfully capture the 3D motions of both the\nhuman and object in a novel setting: using a minimal amount of RGB camera and\nobject-mounted Inertial Measurement Unit (IMU). It combines general motion\ninference and category-aware refinement. For the former, we introduce a\nholistic human-object tracking method to fuse the IMU signals and the RGB\nstream and progressively recover the human motions and subsequently the\ncompanion object motions. For the latter, we tailor a category-aware motion\ndiffusion model, which is conditioned on both the raw IMU observations and the\nresults from the previous stage under over-parameterization representation. It\nsignificantly refines the initial results and generates vivid body, hand, and\nobject motions. Moreover, we contribute a large dataset with ground truth human\nand object motions, dense RGB inputs, and rich object-mounted IMU measurements.\nExtensive experiments demonstrate the effectiveness of I'm-HOI under a hybrid\ncapture setting. Our dataset and code will be released to the community.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dual Branch Network Towards Accurate Printed Mathematical Expression\n  Recognition",
      "abstract": "  Over the past years, Printed Mathematical Expression Recognition (PMER) has\nprogressed rapidly. However, due to the insufficient context information\ncaptured by Convolutional Neural Networks, some mathematical symbols might be\nincorrectly recognized or missed. To tackle this problem, in this paper, a Dual\nBranch transformer-based Network (DBN) is proposed to learn both local and\nglobal context information for accurate PMER. In our DBN, local and global\nfeatures are extracted simultaneously, and a Context Coupling Module (CCM) is\ndeveloped to complement the features between the global and local contexts. CCM\nadopts an interactive manner so that the coupled context clues are highly\ncorrelated to each expression symbol. Additionally, we design a Dynamic Soft\nTarget (DST) strategy to utilize the similarities among symbol categories for\nreasonable label generation. Our experimental results have demonstrated that\nDBN can accurately recognize mathematical expressions and has achieved\nstate-of-the-art performance.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.109.115154",
      "title": "On the Adequacy of the Dynamical Mean Field Theory for Low Density and\n  Dirac Materials",
      "abstract": "  The qualitative reliability of the dynamical mean field theory (DMFT) is\ninvestigated for systems in which either the actual carrier density or the\neffective carrier density is low, by comparing the exact perturbative and\ndynamical mean field expressions of electron scattering rates and optical\nconductivities. We study two interacting systems: tight binding models in which\nthe chemical potential is near a band edge and Dirac systems in which the\nchemical potential is near the Dirac point. In both systems it is found that\nDMFT underestimates the low frequency, near-Fermi surface single particle\nscattering rate by a factor proportional to the particle density. The\nquasiparticle effective mass is qualitatively incorrect for the low density\ntight binding model but not necessarily for Dirac systems. The dissipative part\nof the optical conductivity is more subtle: in the exact calculation vertex\ncorrections, typically neglected in DMFT calculations, suppress the low\nfrequency optical absorption, compensating for some of the DMFT underestimate\nof the scattering rate. The role of vertex corrections in calculating the\nconductivity for Dirac systems is clarified and a systematic discussion is\ngiven of the approach to the Galilean/Lorentz invariant low density limit.\nRelevance to recent calculations related to Weyl metals is discussed.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/JHEP03(2024)158",
      "title": "Cone Holography with Neumann Boundary Conditions and Brane-localized\n  Gauge Fields",
      "abstract": "  Cone holography is a codimension-$n$ doubly holographic model, which can be\ninterpreted as the holographic dual of edge modes on defects. The initial model\nof cone holography is based on mixed boundary conditions. This paper formulates\ncone holography with Neumann boundary conditions, where the brane-localized\ngauge fields play an essential role. Firstly, we illustrate the main ideas in\nan AdS$_4$/CFT$_1$ toy model. We show that the $U(1)$ gauge field on the\nend-of-the-world brane can make the typical solution consistent with Neumann\nboundary conditions. Then, we generalize the discussions to general\ncodimension-$n$ cone holography by employing brane-localized $p$-form gauge\nfields. We also investigate perturbative solutions and prove the mass spectrum\nof Kaluza-Klein gravitons is non-negative. Furthermore, we prove that cone\nholography obeys holographic $c$-theorem. Finally, inspired by the recently\nproposed chiral model in AdS/BCFT, we construct another type of cone holography\nwith Neumann boundary conditions by applying massive vector (Proca) fields on\nthe end-of-the-world brane.\n",
      "subjects": [
        "hep-th",
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Natural Language Processing and Multimodal Stock Price Prediction",
      "abstract": "  In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.\n",
      "subjects": [
        "cs.LG",
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Asymptotically Optimal Proper Conflict-Free Colouring",
      "abstract": "  A proper conflict-free colouring of a graph is a colouring of the vertices\nsuch that any two adjacent vertices receive different colours, and for every\nnon-isolated vertex $v$, some colour appears exactly once on the neighbourhood\nof $v$. Caro, Petru\\v{s}evski and \\v{S}krekovski conjectured that every\nconnected graph with maximum degree $\\Delta \\geq 3$ has a proper conflict-free\ncolouring with at most $\\Delta+1$ colours. This conjecture holds for $\\Delta=3$\nand remains open for $\\Delta \\geq 4$. In this paper we prove that this\nconjecture holds asymptotically; namely, every graph with maximum degree\n$\\Delta$ has a proper conflict-free colouring with $(1+o(1))\\Delta$ colours.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fourier analysis of spatial point processes",
      "abstract": "  In this article, we develop comprehensive frequency domain methods for\nestimating and inferring the second-order structure of spatial point processes.\nThe main element here is on utilizing the discrete Fourier transform (DFT) of\nthe point pattern and its tapered counterpart. Under second-order stationarity,\nwe show that both the DFTs and the tapered DFTs are asymptotically jointly\nindependent Gaussian even when the DFTs share the same limiting frequencies.\nBased on these results, we establish an $\\alpha$-mixing central limit theorem\nfor a statistic formulated as a quadratic form of the tapered DFT. As\napplications, we derive the asymptotic distribution of the kernel spectral\ndensity estimator and establish a frequency domain inferential method for\nparametric stationary point processes. For the latter, the resulting model\nparameter estimator is computationally tractable and yields meaningful\ninterpretations even in the case of model misspecification. We investigate the\nfinite sample performance of our estimator through simulations, considering\nscenarios of both correctly specified and misspecified models. Furthermore, we\nextend our proposed DFT-based frequency domain methods to a class of\nnon-stationary spatial point processes.\n",
      "subjects": [
        "stat.ME",
        "math.ST",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Querying Easily Flip-flopped Samples for Deep Active Learning",
      "abstract": "  Active learning is a machine learning paradigm that aims to improve the\nperformance of a model by strategically selecting and querying unlabeled data.\nOne effective selection strategy is to base it on the model's predictive\nuncertainty, which can be interpreted as a measure of how informative a sample\nis. The sample's distance to the decision boundary is a natural measure of\npredictive uncertainty, but it is often intractable to compute, especially for\ncomplex decision boundaries formed in multiclass classification tasks. To\naddress this issue, this paper proposes the {\\it least disagree metric} (LDM),\ndefined as the smallest probability of disagreement of the predicted label, and\nan estimator for LDM proven to be asymptotically consistent under mild\nassumptions. The estimator is computationally efficient and can be easily\nimplemented for deep learning models using parameter perturbation. The\nLDM-based active learning is performed by querying unlabeled data with the\nsmallest LDM. Experimental results show that our LDM-based active learning\nalgorithm obtains state-of-the-art overall performance on all considered\ndatasets and deep architectures.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Sharing Energy in Wide Area: A Two-Layer Energy Sharing Scheme for\n  Massive Prosumers",
      "abstract": "  The popularization of distributed energy resources transforms end-users from\nconsumers into prosumers. Inspired by the sharing economy principle, energy\nsharing markets for prosumers are proposed to facilitate the utilization of\nrenewable energy. This paper proposes a novel two-layer energy sharing market\nfor massive prosumers, which can promote social efficiency by wider-area\nsharing. In this market, there is an upper-level wide-area market (WAM) in the\ndistribution system and numerous lower-level local-area markets (LAMs) in\ncommunities. Prosumers in the same community share energy with each other in\nthe LAM, which can be uncleared. The energy surplus and shortage of LAMs are\ncleared in the WAM. Thanks to the wide-area two-layer structure, the market\noutcome is near-social-optimal in large-scale systems. However, the proposed\nmarket forms a complex mathematical program with equilibrium constraints\n(MPEC). To solve the problem, we propose an efficient and hierarchically\ndistributed bidding algorithm. The proposed two-layer market and bidding\nalgorithm are verified on the IEEE 123-bus system with 11250 prosumers, which\ndemonstrates the practicality and efficiency for large-scale markets.\n",
      "subjects": [
        "cs.GT",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Visualization Generation with Large Language Models: An Evaluation",
      "abstract": "  Analysts frequently need to create visualizations in the data analysis\nprocess to obtain and communicate insights. To reduce the burden of creating\nvisualizations, previous research has developed various approaches for analysts\nto create visualizations from natural language queries. Recent studies have\ndemonstrated the capabilities of large language models in natural language\nunderstanding and code generation tasks. The capabilities imply the potential\nof using large language models to generate visualization specifications from\nnatural language queries. In this paper, we evaluate the capability of a large\nlanguage model to generate visualization specifications on the task of natural\nlanguage to visualization (NL2VIS). More specifically, we have opted for\nGPT-3.5 and Vega-Lite to represent large language models and visualization\nspecifications, respectively. The evaluation is conducted on the nvBench\ndataset. In the evaluation, we utilize both zero-shot and few-shot prompt\nstrategies. The results demonstrate that GPT-3.5 surpasses previous NL2VIS\napproaches. Additionally, the performance of few-shot prompts is higher than\nthat of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS,\nsuch as misunderstanding the data attributes and grammar errors in generated\nspecifications. We also summarized several directions, such as correcting the\nground truth and reducing the ambiguities in natural language queries, to\nimprove the NL2VIS benchmark.\n",
      "subjects": [
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Incorporating Test-Time Optimization into Training with Dual Networks\n  for Human Mesh Recovery",
      "abstract": "  Human Mesh Recovery (HMR) is the task of estimating a parameterized 3D human\nmesh from an image. There is a kind of methods first training a regression\nmodel for this problem, then further optimizing the pretrained regression model\nfor any specific sample individually at test time. However, the pretrained\nmodel may not provide an ideal optimization starting point for the test-time\noptimization. Inspired by meta-learning, we incorporate the test-time\noptimization into training, performing a step of test-time optimization for\neach sample in the training batch before really conducting the training\noptimization over all the training samples. In this way, we obtain a\nmeta-model, the meta-parameter of which is friendly to the test-time\noptimization. At test time, after several test-time optimization steps starting\nfrom the meta-parameter, we obtain much higher HMR accuracy than the test-time\noptimization starting from the simply pretrained regression model. Furthermore,\nwe find test-time HMR objectives are different from training-time objectives,\nwhich reduces the effectiveness of the learning of the meta-model. To solve\nthis problem, we propose a dual-network architecture that unifies the\ntraining-time and test-time objectives. Our method, armed with meta-learning\nand the dual networks, outperforms state-of-the-art regression-based and\noptimization-based HMR approaches, as validated by the extensive experiments.\nThe codes are available at https://github.com/fmx789/Meta-HMR.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Strongly minimal group relics of algebraically closed valued fields",
      "abstract": "  We prove Zilber's trichotomy for reducts of ACVF expanding $(K,+)$ or $(K^*,\n\\cdot)$.\n",
      "subjects": [
        "math.LO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Densely Decoded Networks with Adaptive Deep Supervision for Medical\n  Image Segmentation",
      "abstract": "  Medical image segmentation using deep neural networks has been highly\nsuccessful. However, the effectiveness of these networks is often limited by\ninadequate dense prediction and inability to extract robust features. To\nachieve refined dense prediction, we propose densely decoded networks (ddn), by\nselectively introducing 'crutch' network connections. Such 'crutch' connections\nin each upsampling stage of the network decoder (1) enhance target localization\nby incorporating high resolution features from the encoder, and (2) improve\nsegmentation by facilitating multi-stage contextual information flow. Further,\nwe present a training strategy based on adaptive deep supervision (ads), which\nexploits and adapts specific attributes of input dataset, for robust feature\nextraction. In particular, ads strategically locates and deploys auxiliary\nsupervision, by matching the average input object size with the layer-wise\neffective receptive fields (lerf) of a network, resulting in a class of ddns.\nSuch inclusion of 'companion objective' from a specific hidden layer, helps the\nmodel pay close attention to some distinct input-dependent features, which the\nnetwork might otherwise 'ignore' during training. Our new networks and training\nstrategy are validated on 4 diverse datasets of different modalities,\ndemonstrating their effectiveness.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/ad64d2",
      "title": "Braving the Storm: Quantifying Disk-wide Ionized Outflows in the Large\n  Magellanic Cloud with ULLYSES",
      "abstract": "  The Large Magellanic Cloud (LMC) is home to many HII regions, which may lead\nto significant outflows. We examine the LMC's multiphase gas ($T\\sim10^{4-5}$\nK) in HI, SII, SiIV, and CIV using 110 stellar sight lines from the HST's\nUltraviolet Legacy Library of Young Stars as Essential Standards (ULLYSES)\nprogram. We develop a continuum fitting algorithm based on the concept of\nGaussian Process regression and identify reliable LMC interstellar absorption\nover $v_{\\rm helio}=175-375$ km s$^{-1}$. Our analyses show disk-wide ionized\noutflows in SiIV and CIV across the LMC with bulk velocities of $|v_{\\rm out,\nbulk}|\\sim20-60$ km s$^{-1}$, which indicates that most of the outflowing mass\nis gravitationally bound. The outflows' column densities correlate with the\nLMC's star formation rate surface densities ($\\Sigma_{\\rm SFR}$), and the\noutflows with higher $\\Sigma_{\\rm SFR}$ tend to be more ionized. Considering\noutflows from both sides of the LMC as traced by CIV, we conservatively\nestimate a total outflow rate of $\\dot{M}_{\\rm out}\\gtrsim 0.03~M_\\odot {\\rm\nyr}^{-1}$ and a mass loading factor of $\\eta\\gtrsim 0.15$. We compare the LMC's\noutflows with those detected in starburst galaxies and simulation predictions,\nand find a universal scaling relation of $|v_{\\rm out, bulk}|\\propto\n\\Sigma_{\\rm SFR}^{0.23}$ over a wide range of star-forming conditions\n($\\Sigma_{\\rm SFR}\\sim10^{-4.5}-10^{2}~M_\\odot {\\rm yr}^{-1} {\\rm kpc}^{-2}$).\nLastly, we find that the outflows are co-rotating with the LMC's young stellar\ndisk and the velocity field does not seem to be significantly impacted by\nexternal forces; we thus speculate on the existence of a bow shock leading the\nLMC, which may have shielded the outflows from ram pressure as the LMC orbits\nthe Milky Way.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s00440-024-01329-6",
      "title": "Deformed Fr\\'echet law for Wigner and sample covariance matrices with\n  tail in crossover regime",
      "abstract": "  Given $A_n:=\\frac{1}{\\sqrt{n}}(a_{ij})$ an $n\\times n$ symmetric random\nmatrix, with elements above the diagonal given by i.i.d. random variables\nhaving mean zero and unit variance. It is known that when\n$\\lim_{x\\to\\infty}x^4\\mathbb{P}(|a_{ij}|>x)=0$, then fluctuation of the largest\neigenvalue of $A_n$ follows a Tracy-Widom distribution. When the law of\n$a_{ij}$ is regularly varying with index $\\alpha\\in(0,4)$, then the largest\neigenvalue has a Fr\\'echet distribution. An intermediate regime is recently\nuncovered in \\cite{diaconu2023more}: when\n$\\lim_{x\\to\\infty}x^4\\mathbb{P}(|a_{ij}|>x)=c\\in(0,\\infty)$, then the law of\nthe largest eigenvalue follows a deformed Fr\\'echet distribution. In this work\nwe vastly extend the scope where the latter distribution may arise. We show\nthat the same deformed Fr\\'echet distribution arises (1) for sparse Wigner\nmatrices with an average of $n^{O(1)}$ nonzero entries on each row; (2) for\nperiodically banded Wigner matrices with bandwidth $d_n=n^{O(1)}$; and more\ngenerally for weighted adjacency matrices of any $k_n$-regular graphs with\n$k_n=n^{O(1)}$. In all these cases, we further prove that the joint\ndistribution of the finitely many largest eigenvalues of $A_n$ form a deformed\nPoisson process, and that eigenvectors of the outlying eigenvalues of $A_n$ are\nlocalized, implying a mobility edge phenomenon at the spectral edge $2$. The\nsparser case with average degree $n^{o(1)}$ is also explored. Our technique\nextends to sample covariance matrices, proving for the first time that its\nlargest eigenvalue still follows a deformed Fr\\'echet distribution, assuming\nthe matrix entries satisfy\n$\\lim_{x\\to\\infty}x^4\\mathbb{P}(|a_{ij}|>x)=c\\in(0,\\infty)$.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.3847/1538-4357/ad3ba8",
      "title": "The Redshift Evolution of the Binary Black Hole Mass Distribution from\n  Dense Star Clusters",
      "abstract": "  Gravitational-wave detectors are unveiling a population of binary black hole\n(BBH) mergers out to redshifts $z \\approx 1$, and are starting to constrain how\nthe BBH population evolves with redshift. We present predictions for the\nredshift evolution of the BBH mass and spin distributions for systems\noriginating from dense star clusters. Utilizing a grid of 144 state-of-the-art\ndynamical models for globular clusters, we demonstrate that BBH merger rates\npeak at higher redshifts for larger black hole primary masses $M_1$.\nSpecifically, for $M_1\\gtrsim40\\,M_{\\odot}$, the BBH merger rate reaches its\npeak at redshift $z\\approx2.1$, while for $M_1\\lesssim20\\,M_{\\odot}$, the peak\noccurs at $z\\approx1.1$, assuming that the cluster formation rate peaks at\n$z=2.2$. The average BBH primary mass also increases from $\\sim 10\\,M_{\\odot}$\nat $z=0$ to $\\sim 30\\,M_{\\odot}$ at $z=10$. We show that $\\sim 20\\%$ BBHs\ncontain massive remnants from next-generation mergers, with this fraction\nincreasing (decreasing) for larger (smaller) primary masses. This difference is\nnot large enough to significantly alter the effective spins of the BBH\npopulation originating from globular clusters, and we find that their effective\nspin distribution does not evolve across cosmic time. These findings can be\nused to distinguish BBHs from dense star clusters by future gravitational wave\nobservations.\n",
      "subjects": [
        "astro-ph.HE",
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On particle systems and critical strengths of general singular\n  interactions",
      "abstract": "  For finite interacting particle systems with strong repulsing-attracting or\ngeneral interactions, we prove global weak well-posedness almost up to the\ncritical threshold of the strengths of attracting interactions (independent of\nthe number of particles), and establish other regularity results, such as a\nheat kernel bound in the regions where strongly attracting particles are close\nto each other. Our main analytic instruments are a variant of De Giorgi's\nmethod in $L^p$ with appropriately chosen large $p$, and an abstract\ndesingularization theorem.\n",
      "subjects": [
        "math.PR",
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "New Rigidity Results for Critical Metrics of Some Quadratic Curvature\n  Functionals",
      "abstract": "  We prove a new rigidity result for metrics defined on closed smooth $ n\n$-manifolds that are critical for the quadratic functional $ \\mathfrak{F}_{t}\n$, which depends on the Ricci curvature $ Ric $ and the scalar curvature $ R $,\nand that satisfy a pinching condition of the form $ Sec > \\epsilon R $, where $\n\\epsilon $ is a function of $ t $ and $ n $, while $ Sec $ denotes the\nsectional curvature. In particular, we show that Bach-flat metrics with\nconstant scalar curvature satisfying $ Sec > \\frac{1}{48} R $ are Einstein and,\nby a known result, are isometric to $ \\mathbb{S}^{4} $, $ \\mathbb{RP}^{4} $ or\n$ \\mathbb{CP}^{2} $.\n",
      "subjects": [
        "math.DG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Electrochemical Evaluation of Mg and a Mg-Al 5%Zn Metal Rich Primers for\n  Protection of Al-Zn-Mg-Cu Alloy in NaCl",
      "abstract": "  High purity magnesium and a Mg-Al 5wt% Zn metal rich primer (MRP) were\ncompared for their ability to suppress intergranular corrosion (IGC) and\nintergranular stress corrosion cracking (IG-SCC) in peak aged AA 7075-T651 by\nsacrificial anode-based cathodic prevention. Tests were conducted in 0.6 M NaCl\nsolution under full immersion. These evaluations considered the ability of the\nprimer to attain an intermediate negative open circuit potential (OCP) such\nthat the galvanic couple potential with bare aluminum alloy (AA) 7075-T651\nresided below a range of potentials where IGC is prevalent. The ability of the\nprimer to achieve an OCP negative enough that the AA 7075-T651 could be\nprotected by sacrificial anode-based cathodic prevention and the ability to\nsustain this function over time were evaluated as a first step by utilizing a\nNaCl solution. The primers consisted of epoxy resins embedded with either (1)\nMg flake pigments (MgRP) or (2) Mg flake pigments and spherical Al-5 wt.% Zn\ntogether as a composite (MgAlRP). MgRP was an effective coating for cathodic\nprotection but dispensed less anodic charge than the composite MgAlRP.\nCross-sectional analysis demonstrated that some Mg flakes dissolved while\nuniform surface oxidation occurred on the remaining Mg flakes which led to\nimpaired activation. The composite MgAlRP maintained a suitably negative OCP\nover time, remained activated, dispensed high anodic charge, and remained an\nanode in zero resistance ammeter testing. Chemical stability modeling and zero\nresistance ammeter testing suggest that Mg corrosion elevates the pH which\ndissolved aluminum oxides and hydroxide thereby activates the Al-5wt.% Zn\npigments, thereby providing a primary (i.e. Mg corrosion) and secondary process\nto enable superior (activation of Al-5wt%Zn) sacrificial anode-based cathodic\nprotection.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Measurement of Dependence of Microlensing Planet Frequency on The Host\n  Star Mass and Galactocentric Distance by using a Galactic Model",
      "abstract": "  We measure the dependence of planet frequency on host star mass, $M_{\\rm L}$,\nand distance from the Galactic center, $R_{\\rm L}$, using a sample of planets\ndiscovered by gravitational microlensing. We compare the two-dimensional\ndistribution of the lens-source proper motion, $\\mu_{\\rm rel}$, and the\nEinstein radius crossing time, $t_{\\rm E}$, measured for 22 planetary events\nfrom Suzuki et al. (2016) with the distribution expected from Galactic model.\nAssuming that the planet-hosting probability of a star is proportional to\n$M_{\\rm L}^m R_{\\rm L}^r$, we calculate the likelihood distribution of $(m,r)$.\nWe estimate that $r = 0.10^{+0.51}_{-0.37}$ and $m = 0.50^{+0.90}_{-0.70}$\nunder the assumption that the planet-hosting probability is independent of the\nmass ratio. We also divide the planet sample into subsamples based on their\nmass ratio, $q$, and estimate that $m=-0.08^{+0.95}_{-0.65}$ for $q < 10^{-3}$\nand $1.25^{+1.07}_{-1.14}$ for $q > 10^{-3}$. Although uncertainties are still\nlarge, this result implies a possibility that in orbits beyond the snowline,\nmassive planets are more likely to exist around more massive stars whereas\nlow-mass planets exist regardless of their host star mass.\n",
      "subjects": [
        "astro-ph.EP",
        "astro-ph.GA",
        "astro-ph.SR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On Latency Predictors for Neural Architecture Search",
      "abstract": "  Efficient deployment of neural networks (NN) requires the co-optimization of\naccuracy and latency. For example, hardware-aware neural architecture search\nhas been used to automatically find NN architectures that satisfy a latency\nconstraint on a specific hardware device. Central to these search algorithms is\na prediction model that is designed to provide a hardware latency estimate for\na candidate NN architecture. Recent research has shown that the sample\nefficiency of these predictive models can be greatly improved through\npre-training on some \\textit{training} devices with many samples, and then\ntransferring the predictor on the \\textit{test} (target) device. Transfer\nlearning and meta-learning methods have been used for this, but often exhibit\nsignificant performance variability. Additionally, the evaluation of existing\nlatency predictors has been largely done on hand-crafted training/test device\nsets, making it difficult to ascertain design features that compose a robust\nand general latency predictor. To address these issues, we introduce a\ncomprehensive suite of latency prediction tasks obtained in a principled way\nthrough automated partitioning of hardware device sets. We then design a\ngeneral latency predictor to comprehensively study (1) the predictor\narchitecture, (2) NN sample selection methods, (3) hardware device\nrepresentations, and (4) NN operation encoding schemes. Building on conclusions\nfrom our study, we present an end-to-end latency predictor training strategy\nthat outperforms existing methods on 11 out of 12 difficult latency prediction\ntasks, improving latency prediction by 22.5\\% on average, and up to to 87.6\\%\non the hardest tasks. Focusing on latency prediction, our HW-Aware NAS reports\na $5.8\\times$ speedup in wall-clock time. Our code is available on\n\\href{https://github.com/abdelfattah-lab/nasflat_latency}{https://github.com/abdelfattah-lab/nasflat\\_latency}.\n",
      "subjects": [
        "cs.LG",
        "cs.AR",
        "cs.CV",
        "cs.PF"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "AGN feedback in the Local Universe: multiphase outflow of the Seyfert\n  galaxy NGC 5506",
      "abstract": "  We present new optical GTC/MEGARA seeing-limited (0.9\") integral-field\nobservations of NGC 5506, together with ALMA observations of the CO(3-2)\ntransition at a 0.2\" (25 pc) resolution. NGC 5506 is a luminous (bolometric\nluminosity of $\\sim 10^{44}$ erg/s) nearby (26 Mpc) Seyfert galaxy, part of the\nGalaxy Activity, Torus, and Outflow Survey (GATOS). We modelled the CO(3-2)\nkinematics with 3D-Barolo, revealing a rotating and outflowing cold gas ring\nwithin the central 1.2 kpc. We derived an integrated cold molecular gas mass\noutflow rate for the ring of 8 M$_{\\odot}$/yr. We fitted the optical emission\nlines with a maximum of two Gaussian components to separate rotation from\nnon-circular motions. We detected high [OIII]$\\lambda$5007 projected velocities\n(up to 1000 km/s) at the active galactic nucleus (AGN) position, decreasing\nwith radius to an average 330 km/s around 350 pc. We also modelled the [OIII]\ngas kinematics with a non-parametric method, estimating the ionisation\nparameter and electron density in every spaxel, from which we derived an\nionised mass outflow rate of 0.076 M$_{\\odot}$/yr within the central 1.2 kpc.\nRegions of high CO(3-2) velocity dispersion, extending to projected distances\nof 350 pc from the AGN, appear to be the result from the interaction of the AGN\nwind with molecular gas in the galaxy's disc. Additionally, we find the ionised\noutflow to spatially correlate with radio and soft X-ray emission in the\ncentral kiloparsec. We conclude that the effects of AGN feedback in NGC 5506\nmanifest as a large-scale ionised wind interacting with the molecular disc,\nresulting in outflows extending to radial distances of 610 pc\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Signature Isolation Forest",
      "abstract": "  Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly\nDetection (AD) algorithm designed for functional data. It relies on a tree\npartition procedure where an abnormality score is computed by projecting each\ncurve observation on a drawn dictionary through a linear inner product. Such\nlinear inner product and the dictionary are a priori choices that highly\ninfluence the algorithm's performances and might lead to unreliable results,\nparticularly with complex datasets. This work addresses these challenges by\nintroducing \\textit{Signature Isolation Forest}, a novel AD algorithm class\nleveraging the rough path theory's signature transform. Our objective is to\nremove the constraints imposed by FIF through the proposition of two algorithms\nwhich specifically target the linearity of the FIF inner product and the choice\nof the dictionary. We provide several numerical experiments, including a\nreal-world applications benchmark showing the relevance of our methods.\n",
      "subjects": [
        "stat.ML",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "GreenBytes: Intelligent Energy Estimation for Edge-Cloud",
      "abstract": "  This study investigates the application of advanced machine learning models,\nspecifically Long Short-Term Memory (LSTM) networks and Gradient Booster\nmodels, for accurate energy consumption estimation within a Kubernetes cluster\nenvironment. It aims to enhance sustainable computing practices by providing\nprecise predictions of energy usage across various computing nodes. Through\nmeticulous analysis of model performance on both master and worker nodes, the\nresearch reveals the strengths and potential applications of these models in\npromoting energy efficiency. The LSTM model demonstrates remarkable predictive\naccuracy, particularly in capturing dynamic computing workloads over time,\nevidenced by low mean squared error (MSE) rates and the ability to closely\ntrack actual energy consumption trends. Conversely, the Gradient Booster model\nshowcases robustness and adaptability across different computational\nenvironments, despite slightly higher MSE values. The study underscores the\ncomplementary nature of these models in advancing sustainable computing\npractices, suggesting their integration into energy management systems could\nsignificantly enhance environmental sustainability in technology operations.\n",
      "subjects": [
        "cs.DC",
        "cs.ET",
        "cs.NI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Diffusion Posterior Sampling for Synergistic Reconstruction in Spectral\n  Computed Tomography",
      "abstract": "  Using recent advances in generative artificial intelligence (AI) brought by\ndiffusion models, this paper introduces a new synergistic method for spectral\ncomputed tomography (CT) reconstruction. Diffusion models define a neural\nnetwork to approximate the gradient of the log-density of the training data,\nwhich is then used to generate new images similar to the training ones.\nFollowing the inverse problem paradigm, we propose to adapt this generative\nprocess to synergistically reconstruct multiple images at different energy bins\nfrom multiple measurements. The experiments suggest that using multiple energy\nbins simultaneously improves the reconstruction by inverse diffusion and\noutperforms state-of-the-art synergistic reconstruction techniques.\n",
      "subjects": [
        "physics.med-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Flow of Electrically Charged Fluids Through Elastic Porous Media",
      "abstract": "  We study the flow of an electrically charged fluid through an elastic and\nporous medium. A three continuum model consisting of an elastic solid, a\nviscous fluid, and a mobile charge continuum is used. The relevant laws of\nphysics are applied systematically to the constituents or the combined\ncontinuum, leading to their continuity equations for conservation of mass or\ncharge, linear and angular momentum equations as well as constitutive\nrelations. The analysis assumes quasistatic electric fields and is for\nnonmagnetizable materials. The resulting theory is nonlinear, valid for large\ndeformations and strong fields and can be specialized or generalized in various\nways.\n",
      "subjects": [
        "cond-mat.soft",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Learning-Based Pricing and Matching for Two-Sided Queues",
      "abstract": "  We consider a dynamic system with multiple types of customers and servers.\nEach type of waiting customer or server joins a separate queue, forming a\nbipartite graph with customer-side queues and server-side queues. The platform\ncan match the servers and customers if their types are compatible. The matched\npairs then leave the system. The platform will charge a customer a price\naccording to their type when they arrive and will pay a server a price\naccording to their type. The arrival rate of each queue is determined by the\nprice according to some unknown demand or supply functions. Our goal is to\ndesign pricing and matching algorithms to maximize the profit of the platform\nwith unknown demand and supply functions, while keeping queue lengths of both\ncustomers and servers below a predetermined threshold. This system can be used\nto model two-sided markets such as ride-sharing markets with passengers and\ndrivers. The difficulties of the problem include simultaneous learning and\ndecision making, and the tradeoff between maximizing profit and minimizing\nqueue length. We use a longest-queue-first matching algorithm and propose a\nlearning-based pricing algorithm, which combines gradient-free stochastic\nprojected gradient ascent with bisection search. We prove that our proposed\nalgorithm yields a sublinear regret $\\tilde{O}(T^{5/6})$ and anytime\nqueue-length bound $\\tilde{O}(T^{1/6})$, where $T$ is the time horizon. We\nfurther establish a tradeoff between the regret bound and the queue-length\nbound: $\\tilde{O}(T^{1-\\gamma})$ versus $\\tilde{O}(T^{\\gamma})$ for $\\gamma \\in\n(0, 1/6].$\n",
      "subjects": [
        "math.OC",
        "cs.LG",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "ResNet101 and DAE for Enhance Quality and Classification Accuracy in\n  Skin Cancer Imaging",
      "abstract": "  Skin cancer is a crucial health issue that requires timely detection for\nhigher survival rates. Traditional computer vision techniques face challenges\nin addressing the advanced variability of skin lesion features, a gap partially\nbridged by convolutional neural networks (CNNs). To overcome the existing\nissues, we introduce an innovative convolutional ensemble network approach\nnamed deep autoencoder (DAE) with ResNet101. This method utilizes\nconvolution-based deep neural networks for the detection of skin cancer. The\nISIC-2018 public data taken from the source is used for experimental results,\nwhich demonstrate remarkable performance with the different in terms of\nperformance metrics. The methods result in 96.03% of accuracy, 95.40 % of\nprecision, 96.05% of recall, 0.9576 of F-measure, 0.98 of AUC.\n",
      "subjects": [
        "eess.IV",
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Analysis of Constraint-Relaxation in PDE-Based Inverse Problems",
      "abstract": "  Inverse problems are ubiquitous in science and engineering. Many of these are\nnaturally formulated as a PDE-constrained optimization problem. These\nnon-linear, large-scale, constrained optimization problems know many\nchallenges, of which the inherent non-linearity of the problem is an important\none. In this paper, we focus on a relaxed formulation of the PDE-constrained\noptimization problem and provide an in-depth analysis of it. Starting from an\ninfinite-dimensional formulation of the inverse problem with discrete data, we\npropose a general framework for the analysis and discretisation of such\nproblems. The relaxed formulation of the PDE-constrained optimization problem\nis shown to reduce to a weighted non-linear least-squares problem. The weight\nmatrix turns out to be the Gram matrix of solutions of the PDE and, in some\ncases, can be estimated directly from the measurements. The latter observation\npoints to a potential way to unify recently proposed data-driven reduced-order\nmodels for inverse problems with PDE-constrained optimization. We provide a\nnumber of representative case studies and numerical examples to illustrate our\nfindings.\n",
      "subjects": [
        "math.OC",
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.110.044006",
      "title": "Hairy black holes in extended Einstein-Maxwell-scalar theories with\n  magnetic charge and kinetic couplings",
      "abstract": "  We study black hole (BH) solutions in extended Einstein-Maxwell-scalar\ntheories, which are classified in a subclass of the $U(1)$ gauge-invariant\nscalar-vector-tensor theories. The scalar field is coupled to the vector field,\nwhich has electric and magnetic charges. For the static and spherically\nsymmetric spacetime, we investigate modifications to the Reissner-Nordstr\\\"{o}m\nsolutions focusing on the three types of scalar-vector interactions, including\nderivative couplings. We solve the field equations analytically in two\nasymptotic regions which are the vicinity of the BH horizon and the spatial\ninfinity, and clarify the condition for the existence of scalar hair. To\nunderstand the behaviors of solutions in intermediate scales, the field\nequations are integrated numerically for concrete models with different types\nof couplings. We find new hairy BH solutions with scalar hair in the presence\nof magnetic charge and kinetic coupling. The magnetic charge plays an important\nrole in distinguishing hairy BH solutions originated from three types of\ndifferent interactions at a large coupling limit.\n",
      "subjects": [
        "gr-qc",
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.110.103008",
      "title": "Velocity Distribution of Dark Matter Spike around Schwarzschild Black\n  Holes and Effects on Gravitational Waves from EMRIs",
      "abstract": "  Dark matter (DM) constitutes the predominant portion of matter in our\nuniverse. Despite compelling evidence, the precise characteristics of DM remain\nelusive. Among the leading DM candidates are weakly-interacting massive\nparticles, which may clump into steep concentrations around the central black\nholes of galaxies. However, DM profiles of the resulting dense spikes remain\nuncertain. Here we employ the relativistic dynamics in Schwarzschild geometry\nand first evaluate the velocity distributions of DM within such spikes. Through\nvariations in black hole masses and dark halo parameters, we identify universal\nfeatures in DM profiles and fit them with Gaussian distributions. Additionally,\nwe illustrate with the impact of dynamical friction on gravitational waves\ngenerated by extreme-mass-ratio inspirals (EMRIs) within DM spikes, taking into\naccount the velocity distribution of DM in the relativistic regime. Our\nfindings demonstrate the phase shifts in the time-domain waveform, potentially\nproviding useful insights for probing DM in galactic centers by\ngravitational-wave experiments.\n",
      "subjects": [
        "astro-ph.GA",
        "astro-ph.CO",
        "gr-qc",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Note on Klein-Nishina effect in strong-field QED: the case of nonlinear\n  Compton scattering",
      "abstract": "  Suitably normalized differential probabilities of one-photon emission in\nexternal electromagnetic fields are compared to quantify the transit of\nnonlinear Compton scattering to linear Compton scattering, described by the\nKlein-Nishina formula, and to constant crossed field treatment. The known\nKlein-Nishina suppression at large energies is further enforced by increasing\nfield intensity. In view of the Ritus-Narozhny conjecture, we demonstrate that\ndifferent paths in the field intensity vs. energy plane towards large values of\nthe quantum non-linearity parameter $\\chi$ facilitate significantly different\nasymptotic dependencies, both in the Klein-Nishina regime and the constant\ncrossed field regime and in between.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Exploiting Individual Graph Structures to Enhance Ecological Momentary\n  Assessment (EMA) Forecasting",
      "abstract": "  In the evolving field of psychopathology, the accurate assessment and\nforecasting of data derived from Ecological Momentary Assessment (EMA) is\ncrucial. EMA offers contextually-rich psychopathological measurements over\ntime, that practically lead to Multivariate Time Series (MTS) data. Thus, many\nchallenges arise in analysis from the temporal complexities inherent in\nemotional, behavioral, and contextual EMA data as well as their\ninter-dependencies. To address both of these aspects, this research\ninvestigates the performance of Recurrent and Temporal Graph Neural Networks\n(GNNs). Overall, GNNs, by incorporating additional information from graphs\nreflecting the inner relationships between the variables, notably enhance the\nresults by decreasing the Mean Squared Error (MSE) to 0.84 compared to the\nbaseline LSTM model at 1.02. Therefore, the effect of constructing graphs with\ndifferent characteristics on GNN performance is also explored. Additionally,\nGNN-learned graphs, which are dynamically refined during the training process,\nwere evaluated. Using such graphs showed a similarly good performance. Thus,\ngraph learning proved also promising for other GNN methods, potentially\nrefining the pre-defined graphs.\n",
      "subjects": [
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Disentangling degree and tie strength heterogeneity in egocentric social\n  networks",
      "abstract": "  The structure of personal networks reflects how we organise and maintain\nsocial relationships. The distribution of tie strengths in personal networks is\nheterogeneous, with a few close, emotionally intense relationships and a larger\nnumber of weaker ties. Recent results indicate this feature is universal across\ncommunication channels. Within this general pattern, there is a substantial and\npersistent inter-individual variation that is also similarly distributed among\nchannels. The reason for the observed universality is yet unclear -- one\npossibility is that people's traits determine their personal network features\non any channel. To address this hypothesis, we need to compare an individual's\npersonal networks across channels, which is a non-trivial task: while we are\ninterested in measuring the differences in tie strength heterogeneity, personal\nnetwork size is also expected to vary a lot across channels. Therefore, for any\nmeasure that compares personal networks, one needs to understand the\nsensitivity with respect to network size. Here, we study different measures of\npersonal network similarity and show that a recently introduced\nalter-preferentiality parameter and the Gini coefficient are equally suitable\nmeasures for tie strength heterogeneity, as they are fairly insensitive to\ndifferences in network size. With these measures, we show that the earlier\nobserved individual-level persistence of personal network structure cannot be\nattributed to network size stability alone, but that the tie strength\nheterogeneity is persistent too. We also demonstrate the effectiveness of the\ntwo measures on multichannel data, where tie strength heterogeneity in personal\nnetworks is seen to moderately correlate for the same users across two\ncommunication channels (calls and text messages).\n",
      "subjects": [
        "physics.soc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Data-Adaptive Tradeoffs among Multiple Risks in Distribution-Free\n  Prediction",
      "abstract": "  Decision-making pipelines are generally characterized by tradeoffs among\nvarious risk functions. It is often desirable to manage such tradeoffs in a\ndata-adaptive manner. As we demonstrate, if this is done naively, state-of-the\nart uncertainty quantification methods can lead to significant violations of\nputative risk guarantees.\n  To address this issue, we develop methods that permit valid control of risk\nwhen threshold and tradeoff parameters are chosen adaptively. Our methodology\nsupports monotone and nearly-monotone risks, but otherwise makes no\ndistributional assumptions.\n  To illustrate the benefits of our approach, we carry out numerical\nexperiments on synthetic data and the large-scale vision dataset MS-COCO.\n",
      "subjects": [
        "stat.ME",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Text2HOI: Text-guided 3D Motion Generation for Hand-Object Interaction",
      "abstract": "  This paper introduces the first text-guided work for generating the sequence\nof hand-object interaction in 3D. The main challenge arises from the lack of\nlabeled data where existing ground-truth datasets are nowhere near\ngeneralizable in interaction type and object category, which inhibits the\nmodeling of diverse 3D hand-object interaction with the correct physical\nimplication (e.g., contacts and semantics) from text prompts. To address this\nchallenge, we propose to decompose the interaction generation task into two\nsubtasks: hand-object contact generation; and hand-object motion generation.\nFor contact generation, a VAE-based network takes as input a text and an object\nmesh, and generates the probability of contacts between the surfaces of hands\nand the object during the interaction. The network learns a variety of local\ngeometry structure of diverse objects that is independent of the objects'\ncategory, and thus, it is applicable to general objects. For motion generation,\na Transformer-based diffusion model utilizes this 3D contact map as a strong\nprior for generating physically plausible hand-object motion as a function of\ntext prompts by learning from the augmented labeled dataset; where we annotate\ntext labels from many existing 3D hand and object motion data. Finally, we\nfurther introduce a hand refiner module that minimizes the distance between the\nobject surface and hand joints to improve the temporal stability of the\nobject-hand contacts and to suppress the penetration artifacts. In the\nexperiments, we demonstrate that our method can generate more realistic and\ndiverse interactions compared to other baseline methods. We also show that our\nmethod is applicable to unseen objects. We will release our model and newly\nlabeled data as a strong foundation for future research. Codes and data are\navailable in: https://github.com/JunukCha/Text2HOI.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Machine Learning Robustness: A Primer",
      "abstract": "  This chapter explores the foundational concept of robustness in Machine\nLearning (ML) and its integral role in establishing trustworthiness in\nArtificial Intelligence (AI) systems. The discussion begins with a detailed\ndefinition of robustness, portraying it as the ability of ML models to maintain\nstable performance across varied and unexpected environmental conditions. ML\nrobustness is dissected through several lenses: its complementarity with\ngeneralizability; its status as a requirement for trustworthy AI; its\nadversarial vs non-adversarial aspects; its quantitative metrics; and its\nindicators such as reproducibility and explainability. The chapter delves into\nthe factors that impede robustness, such as data bias, model complexity, and\nthe pitfalls of underspecified ML pipelines. It surveys key techniques for\nrobustness assessment from a broad perspective, including adversarial attacks,\nencompassing both digital and physical realms. It covers non-adversarial data\nshifts and nuances of Deep Learning (DL) software testing methodologies. The\ndiscussion progresses to explore amelioration strategies for bolstering\nrobustness, starting with data-centric approaches like debiasing and\naugmentation. Further examination includes a variety of model-centric methods\nsuch as transfer learning, adversarial training, and randomized smoothing.\nLastly, post-training methods are discussed, including ensemble techniques,\npruning, and model repairs, emerging as cost-effective strategies to make\nmodels more resilient against the unpredictable. This chapter underscores the\nongoing challenges and limitations in estimating and achieving ML robustness by\nexisting approaches. It offers insights and directions for future research on\nthis crucial concept, as a prerequisite for trustworthy AI systems.\n",
      "subjects": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tensor factorization in ab initio many-body calculations:\n  Triaxially-deformed (B) MBPT calculations in large bases",
      "abstract": "  Whether for fundamental studies or nuclear data evaluations, first-principle\ncalculations of atomic nuclei constitute the path forward. Today, performing\n\\textit{ab initio} calculations (a) of heavy nuclei, (b) of doubly open-shell\nnuclei or (c) with a sub-percent accuracy is at the forefront of nuclear\nstructure theory. While combining any two of these features constitutes a major\nchallenge, addressing the three at the same time is currently impossible. From\na numerical standpoint, these challenges relate to the necessity to handle (i)\nvery large single bases and (ii) mode-6, \\textit{i.e.} three-body, tensors\n(iii) that must be stored repeatedly. Performing second-order many-body\nperturbation theory(ies) calculations based on triaxially deformed and\nsuperfluid reference states of doubly open-shell nuclei up to mass $A=72$, the\npresent work achieves a significant step forward by addressing challenge (i).\nTo do so, the memory and computational cost associated with the handling of\nlarge tensors is scaled down via the use of tensor factorization techniques.\nThe presently used factorization format is based on a randomized singular value\ndecomposition that does not require the computation and storage of the very\nlarge initial tensor. The procedure delivers an inexpensive and controllable\napproximation to the original problem, as presently illustrated for\ncalculations that could not be performed without tensor factorization. With the\npresently developed technology at hand, one can envision to perform\ncalculations of yet heavier doubly open-shell nuclei at sub-percent accuracy in\na foreseeable future.\n",
      "subjects": [
        "nucl-th",
        "physics.comp-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "LongEmbed: Extending Embedding Models for Long Context Retrieval",
      "abstract": "  Embedding models play a pivot role in modern NLP applications such as IR and\nRAG. While the context limit of LLMs has been pushed beyond 1 million tokens,\nembedding models are still confined to a narrow context window not exceeding 8k\ntokens, refrained from application scenarios requiring long inputs such as\nlegal contracts. This paper explores context window extension of existing\nembedding models, pushing the limit to 32k without requiring additional\ntraining. First, we examine the performance of current embedding models for\nlong context retrieval on our newly constructed LongEmbed benchmark. LongEmbed\ncomprises two synthetic tasks and four carefully chosen real-world tasks,\nfeaturing documents of varying length and dispersed target information.\nBenchmarking results underscore huge room for improvement in these models.\nBased on this, comprehensive experiments show that training-free context window\nextension strategies like position interpolation can effectively extend the\ncontext window of existing embedding models by several folds, regardless of\ntheir original context being 512 or beyond 4k. Furthermore, for models\nemploying absolute position encoding (APE), we show the possibility of further\nfine-tuning to harvest notable performance gains while strictly preserving\noriginal behavior for short inputs. For models using rotary position embedding\n(RoPE), significant enhancements are observed when employing RoPE-specific\nmethods, such as NTK and SelfExtend, indicating RoPE's superiority over APE for\ncontext window extension. To facilitate future research, we release E5-Base-4k\nand E5-RoPE-Base, along with the LongEmbed benchmark.\n",
      "subjects": [
        "cs.CL",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/2515-7639/ad71f5",
      "title": "Optimization of reactively sputtered Mn3GaN films based on resistivity\n  measurements",
      "abstract": "  Mn-based nitrides with antiperovskite structures have several properties that\ncan be utilised for antiferromagnetic spintronics. Their magnetic properties\ndepend on the structural quality, composition and doping of the cubic\nantiperovskite structure. Such nitride thin films are usually produced by\nreactive physical vapour deposition, where the deposition rate of N can only be\ncontrolled by the N2 gas flow. We show that the tuning of the N content can be\noptimised using low temperature resistivity measurements, which serve as an\nindicator of the degree of structural disorder. Several Mn3GaNx films were\nprepared by reactive magnetron sputtering under different N2 gas flows. Under\noptimised conditions, we obtain films that exhibit a metal-like temperature\ndependence, a vanishing logarithmic increase in resistivity towards zero, the\nhighest resistivity ratio and a lattice contraction of 0.4 % along the growth\ndirection when heated above that of the N\\'eel temperature in agreement with\nthe bulk samples.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1475-7516/2024/11/027",
      "title": "Relic gravitons and non-stationary processes",
      "abstract": "  Stationary processes do not accurately describe the diffuse backgrounds of\nrelic gravitons whose correlations are homogeneous in space (i.e. only\ndependent upon the distance between the two spatial locations) but not in time.\nThe symmetries of the autocorrelations ultimately reflect the quantum\nmechanical origin of the diffuse backgrounds and lead to non-stationary\nobservables at late time. In particular, large oscillations are believed to\narise in the spectral energy density that is customarily (but approximately)\nrelated to the tensor power spectrum. When the full expression of the spectral\nenergy density is employed the amplitudes of oscillation are instead suppressed\nin the large-scale limit and the non-stationary features of the late-time\nsignal practically disappear. For similar reasons the relations between the\nspectral energy density and the spectral amplitude are ambiguous in the\npresence of non-stationary features. While it is debatable if the\nnon-stationary features are (or will be) directly detectable, we argue that the\nspectral amplitude following from the Wiener-Khintchine theorem is generally\ninappropriate for a consistent description of the relic signal. Nevertheless\nthe strong oscillatory behaviour of the late-time observables is naturally\nsmeared out provided the spectral energy density is selected as pivotal\nvariable.\n",
      "subjects": [
        "gr-qc",
        "astro-ph.CO",
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Mutual information and the encoding of contingency tables",
      "abstract": "  Mutual information is commonly used as a measure of similarity between\ncompeting labelings of a given set of objects, for example to quantify\nperformance in classification and community detection tasks. As argued\nrecently, however, the mutual information as conventionally defined can return\nbiased results because it neglects the information cost of the so-called\ncontingency table, a crucial component of the similarity calculation. In\nprinciple the bias can be rectified by subtracting the appropriate information\ncost, leading to the modified measure known as the reduced mutual information,\nbut in practice one can only ever compute an upper bound on this information\ncost, and the value of the reduced mutual information depends crucially on how\ngood a bound is established. In this paper we describe an improved method for\nencoding contingency tables that gives a substantially better bound in typical\nuse cases, and approaches the ideal value in the common case where the\nlabelings are closely similar, as we demonstrate with extensive numerical\nresults.\n",
      "subjects": [
        "cs.SI",
        "cond-mat.stat-mech",
        "stat.ML"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/5.0216377",
      "title": "Characterization of a graphene-hBN superlattice field effect transistor",
      "abstract": "  Graphene provides a unique platform for hosting high quality 2D electron\nsystems. Encapsulating graphene with hexagonal boron nitride (hBN) to shield it\nfrom noisy environments offers the potential to achieve ultrahigh performance\nnanodevices, such as photodiodes and transistors. However, the absence of a\nbandgap at the Dirac point presents challenges for using this system as a\nuseful transistor. In this study, we investigated the functionality of\nhBN-aligned monolayer graphene as a field effect transistor (FET). By precisely\naligning the hBN and graphene, bandgaps open at the first Dirac point and at\nthe hole-doped induced Dirac point via an interfacial moir\\'e potential. To\ncharacterize this as a submicrometer scale FET, we fabricated a global bottom\ngate to tune the density of a conducting channel and a local top gate to switch\noff this channel. This demonstrated that the system could be tuned to an\noptimal on/off ratio regime by separately controlling the gates. These findings\nprovide a valuable reference point for the further development of FETs based on\ngraphene heterostructures.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "physics.app-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "PyZoBot: A Platform for Conversational Information Extraction and\n  Synthesis from Curated Zotero Reference Libraries through Advanced\n  Retrieval-Augmented Generation",
      "abstract": "  The exponential growth of scientific literature has resulted in information\noverload, challenging researchers to effectively synthesize relevant\npublications. This paper explores the integration of traditional reference\nmanagement software with advanced computational techniques, including Large\nLanguage Models and Retrieval-Augmented Generation. We introduce PyZoBot, an\nAI-driven platform developed in Python, incorporating Zoteros reference\nmanagement with OpenAIs sophisticated LLMs. PyZoBot streamlines knowledge\nextraction and synthesis from extensive human-curated scientific literature\ndatabases. It demonstrates proficiency in handling complex natural language\nqueries, integrating data from multiple sources, and meticulously presenting\nreferences to uphold research integrity and facilitate further exploration. By\nleveraging LLMs, RAG, and human expertise through a curated library, PyZoBot\noffers an effective solution to manage information overload and keep pace with\nrapid scientific advancements. The development of such AI-enhanced tools\npromises significant improvements in research efficiency and effectiveness\nacross various disciplines.\n",
      "subjects": [
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Challenges and opportunities for digital twins in precision medicine: a\n  complex systems perspective",
      "abstract": "  The adoption of digital twins (DTs) in precision medicine is increasingly\nviable, propelled by extensive data collection and advancements in artificial\nintelligence (AI), alongside traditional biomedical methodologies. However, the\nreliance on black-box predictive models, which utilize large datasets, presents\nlimitations that could impede the broader application of DTs in clinical\nsettings. We argue that hypothesis-driven generative models, particularly\nmultiscale modeling, are essential for boosting the clinical accuracy and\nrelevance of DTs, thereby making a significant impact on healthcare innovation.\nThis paper explores the transformative potential of DTs in healthcare,\nemphasizing their capability to simulate complex, interdependent biological\nprocesses across multiple scales. By integrating generative models with\nextensive datasets, we propose a scenario-based modeling approach that enables\nthe exploration of diverse therapeutic strategies, thus supporting dynamic\nclinical decision-making. This method not only leverages advancements in data\nscience and big data for improving disease treatment and prevention but also\nincorporates insights from complex systems and network science, quantitative\nbiology, and digital medicine, promising substantial advancements in patient\ncare.\n",
      "subjects": [
        "physics.bio-ph",
        "nlin.AO",
        "q-bio.QM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the limit distribution of extremes of generalized Oppenheim random\n  variables",
      "abstract": "  This paper investigates the asymptotic behavior of the extremes of a sequence\nof generalized Oppenheim random variables. Particularly, we establish\nconditions under which some normalized extremes of sequences arising from\nOppenheim expansions belong to the maximum domain of attraction of the Frechet\ndistribution. Additionally, we identify conditions under which the maxima and\nminima of Oppenheim random variables demonstrate some kind of asymptotic\nindependence. Finally, we prove an Extreme Types theorem for Oppenheim\nexpansions with unknown dependent structure.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "P-adic Rankin-Selberg L-functions in universal deformation families and\n  functional equations",
      "abstract": "  We construct a $p$-adic Rankin-Selberg $L$-function associated to the product\nof two families of modular forms, where the first is an ordinary (Hida) family,\nand the second an arbitrary universal-deformation family (without any\nordinarity condition at $p$). This gives a function on a 4-dimensional base\nspace - strictly larger than the ordinary eigenvariety, which is 3-dimensional\nin this case. We prove our $p$-adic $L$-function interpolates all critical\nvalues of the Rankin-Selberg $L$-functions for the classical specialisations of\nour family, and derive a functional equation for our $p$-adic $L$-function.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Experimental observations of bifurcated power decay lengths in the near\n  Scrape-Off Layer of tokamak plasmas",
      "abstract": "  The scrape-off layer parallel heat flux decay lengths measured at ST40, a\nhigh field, low aspect ratio spherical tokamak, have been observed to bifurcate\ninto two groups. The wide group matches closely with the scale of ion poloidal\nLarmour radius and follows existing H-mode scalings, while the narrow group\nfalls up to 10 times below scalings, on the scale of ion total Larmour radius.\nThe onset of the narrow scrape-off layer width is observed to be associated\nwith suppressed magnetic fluctuations, suggesting reduced electromagnetic\nturbulence levels in the SOL.\n",
      "subjects": [
        "physics.plasm-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On the classification of multiprojective spaces",
      "abstract": "  Given a positive integer $n$ and a partition $(n_1,\\ldots,n_r)$ of $n$, one\ncan consider the $n$-dimensional multiprojective space $\\mathbb{P}^{n_1}\\times\n\\cdots \\times \\mathbb{P}^{n_r}$ corresponding to that partition. In this paper,\nwe classify these multiprojective spaces. To be precise, we prove that given\nany two distinct partitions of any positive integer $n$, corresponding\nmultiprojective spaces are not isomorphic using a decomposition of tensor\nproducts of irreducible representations of simple Lie algebras.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Geometry of non-classical period domains",
      "abstract": "  In this paper we prove a conjecture of Griffiths about vanishing of the\nzeroth cohomology groups of locally homogeneous vector bundles on compact\nquotients of non-classical period domains, and construct a new $G_\\R$-invariant\ncomplex structure on any non-classical period domain $D=G_\\R/V$ with $G_\\R$ of\nHermitian type. Various geometric and algebraic characterizations of\nnon-classical period domains and several geometric applications on their\ncompact quotients are deduced as consequences of our results.\n",
      "subjects": [
        "math.AG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal\n  High-Frequency Components for Endoscopic Scene Reconstruction",
      "abstract": "  Robot-assisted minimally invasive surgery benefits from enhancing dynamic\nscene reconstruction, as it improves surgical outcomes. While Neural Radiance\nFields (NeRF) have been effective in scene reconstruction, their slow inference\nspeeds and lengthy training durations limit their applicability. To overcome\nthese limitations, 3D Gaussian Splatting (3D-GS) based methods have emerged as\na recent trend, offering rapid inference capabilities and superior 3D quality.\nHowever, these methods still struggle with under-reconstruction in both static\nand dynamic scenes. In this paper, we propose HFGS, a novel approach for\ndeformable endoscopic reconstruction that addresses these challenges from\nspatial and temporal frequency perspectives. Our approach incorporates\ndeformation fields to better handle dynamic scenes and introduces Spatial\nHigh-Frequency Emphasis Reconstruction (SHF) to minimize discrepancies in\nspatial frequency spectra between the rendered image and its ground truth.\nAdditionally, we introduce Temporal High-Frequency Emphasis Reconstruction\n(THF) to enhance dynamic awareness in neural rendering by leveraging flow\npriors, focusing optimization on motion-intensive parts. Extensive experiments\non two widely used benchmarks demonstrate that HFGS achieves superior rendering\nquality.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Aligning to Thousands of Preferences via System Message Generalization",
      "abstract": "  Although humans inherently have diverse values, current large language model\n(LLM) alignment methods often assume that aligning LLMs with the general\npublic's preferences is optimal. A major challenge in adopting a more\nindividualized approach to LLM alignment is its lack of scalability, as it\ninvolves repeatedly acquiring preference data and training new reward models\nand LLMs for each individual's preferences. To address these challenges, we\npropose a new paradigm where users specify what they value most within the\nsystem message, steering the LLM's generation behavior to better align with the\nuser's intentions. However, a naive application of such an approach is\nnon-trivial since LLMs are typically trained on a uniform system message (e.g.,\n\"You are a helpful assistant\") which limits their ability to generalize to\ndiverse, unseen system messages. To improve this generalization, we create the\nMultifaceted Collection, a preference dataset with 192k combinations of values\nbeyond generic helpfulness and harmlessness, spanning 65k user instructions.\nUsing this dataset, we train a 7B LLM called Janus and test it on 921 prompts\nfrom 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct)\nby adding various unseen system messages that reflect user preferences. Janus\nachieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct\nv0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks\nfocused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto\nv0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0%\nmargin, underscoring that training with a vast array of system messages could\nalso enhance alignment to the general public's preference as well. Our code,\ndataset, benchmark, and models are available at\nhttps://github.com/kaistAI/Janus.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Llarull's theorem on punctured sphere with $L^\\infty$ metric",
      "abstract": "  The classical Llarull theorem states that a smooth metric on $n$-sphere\ncannot have scalar curvature no less than $n(n-1)$ and dominate the standard\nspherical metric at the same time unless it is the standard spherical metric.\nIn this work, we prove that Llarull's rigidity theorem holds for $L^{\\infty}$\nmetrics on spheres with finitely many points punctured. This is related to a\nquestion of Gromov.\n",
      "subjects": [
        "math.DG",
        "math.MG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nonparametric regression on random geometric graphs sampled from\n  submanifolds",
      "abstract": "  We consider the nonparametric regression problem when the covariates are\nlocated on an unknown smooth compact submanifold of a Euclidean space. Under\ndefining a random geometric graph structure over the covariates we analyze the\nasymptotic frequentist behaviour of the posterior distribution arising from\nBayesian priors designed through random basis expansion in the graph Laplacian\neigenbasis. Under Holder smoothness assumption on the regression function and\nthe density of the covariates over the submanifold, we prove that the posterior\ncontraction rates of such methods are minimax optimal (up to logarithmic\nfactors) for any positive smoothness index.\n",
      "subjects": [
        "math.ST",
        "stat.ML",
        "stat.TH"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Iwasawa's main conjecture for Rankin-Selberg motives in the\n  anticyclotomic case",
      "abstract": "  In this article, we study the Iwasawa theory for cuspidal automorphic\nrepresentations of $\\mathrm{GL}(n)\\times\\mathrm{GL}(n+1)$ over CM fields along\nanticyclotomic directions, in the framework of the Gan-Gross-Prasad conjecture\nfor unitary groups. We prove one-side divisibility of the corresponding Iwasawa\nmain conjecture: when the global root number is $1$, the $p$-adic $L$-function\nbelongs to the characteristic ideal of the Iwasawa Bloch-Kato Selmer group;\nwhen the global root number is $-1$, the square of the characteristic ideal of\na certain Iwasawa module is contained in the characteristic ideal of the\ntorsion part of the Iwasawa Bloch-Kato Selmer group (analogous to Perrin-Riou's\nHeegner point main conjecture).\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1145/3643834.3661557",
      "title": "Mind Mansion: Exploring Metaphorical Interactions to Engage with\n  Negative Thoughts in Virtual Reality",
      "abstract": "  Recurrent negative thoughts can significantly disrupt daily life and\ncontribute to negative emotional states. Facing, confronting, and noticing such\nthoughts without support can be challenging. To provide a playful setting and\nleverage the technical maturation of Virtual Reality (VR), our VR experience,\nMind Mansion, places the user in an initially cluttered virtual apartment. Here\nwe utilize established concepts from traditional therapy and metaphors\nidentified in prior works to let users engage metaphorically with\nrepresentations of thoughts, gradually sorting the space, fostering awareness\nof thoughts, and supporting mental self-care. The results of our user study (n\n= 30) reveal that Mind Mansion encourages the exploration of alternative\nperspectives, fosters acceptance, and potentially offers new coping mechanisms.\nOur findings suggest that this VR intervention can reduce negative affect and\nimprove overall emotional awareness.\n",
      "subjects": [
        "cs.HC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "NeRSP: Neural 3D Reconstruction for Reflective Objects with Sparse\n  Polarized Images",
      "abstract": "  We present NeRSP, a Neural 3D reconstruction technique for Reflective\nsurfaces with Sparse Polarized images. Reflective surface reconstruction is\nextremely challenging as specular reflections are view-dependent and thus\nviolate the multiview consistency for multiview stereo. On the other hand,\nsparse image inputs, as a practical capture setting, commonly cause incomplete\nor distorted results due to the lack of correspondence matching. This paper\njointly handles the challenges from sparse inputs and reflective surfaces by\nleveraging polarized images. We derive photometric and geometric cues from the\npolarimetric image formation model and multiview azimuth consistency, which\njointly optimize the surface geometry modeled via implicit neural\nrepresentation. Based on the experiments on our synthetic and real datasets, we\nachieve the state-of-the-art surface reconstruction results with only 6 views\nas input.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Accurate estimate of the ESPRESSO fiber-injection losses inferred from\n  integrated field-stabilization images",
      "abstract": "  Ground-based astronomy is unavoidably subject to the adverse effect of\natmospheric turbulence, a.k.a. the seeing, which blurs the images and limits\nthe achievable spatial resolution. For spectroscopic observations, it leads to\nslit or fiber-injection losses, since not all photons distributed over the\nextended seeing disk can be captured. These losses might have a very\nsubstantial impact on the overall efficiency of a spectrograph and are\nnaturally highly variable. Assessing the fiber-injection losses requires\naccurate information about the image quality (IQ) delivered by the telescope to\nthe instrument over the course of the observations, which, however, is often\nnot directly available. ESPRESSO provides acquisition and field-stabilization\nimages attached to the science data and thus offers the opportunity for a\npost-processing analysis. Here, we present a novel method to infer the IQ\nprofile and fiber-injection losses from the integrated field-stabilization\nimages, utilizing the spill-over light that does not get injected into the\nfiber. We validate these measurements against the IQ observed in the\nacquisition images and determine that our method delivers unbiased estimates\nwith a scatter of 0.11\" for the FWHM of the profile and 15% in terms of\nfiber-injection losses. This compares favorably to the estimates derived from\neither the differential image motion monitor (DIMM) or the telescope guide\nprobe sensors and therefore represents a valuable tool to characterize the\ninstrument efficiency and to correct raw spectra for fiber-injection losses.\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Banal Deception Human-AI Ecosystems: A Study of People's Perceptions of\n  LLM-generated Deceptive Behaviour",
      "abstract": "  Large language models (LLMs) can provide users with false, inaccurate, or\nmisleading information, and we consider the output of this type of information\nas what Natale (2021) calls `banal' deceptive behaviour. Here, we investigate\npeoples' perceptions of ChatGPT-generated deceptive behaviour and how this\naffects peoples' own behaviour and trust. To do this, we use a mixed-methods\napproach comprising of (i) an online survey with 220 participants and (ii)\nsemi-structured interviews with 12 participants. Our results show that (i) the\nmost common types of deceptive information encountered were\nover-simplifications and outdated information; (ii) humans' perceptions of\ntrust and `worthiness' of talking to ChatGPT are impacted by `banal' deceptive\nbehaviour; (iii) the perceived responsibility for deception is influenced by\neducation level and the frequency of deceptive information; and (iv) users\nbecome more cautious after encountering deceptive information, but they come to\ntrust the technology more when they identify advantages of using it. Our\nfindings contribute to the understanding of human-AI interaction dynamics in\nthe context of \\textit{Deceptive AI Ecosystems}, and highlight the importance\nof user-centric approaches to mitigating the potential harms of deceptive AI\ntechnologies.\n",
      "subjects": [
        "cs.CY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Language Modeling with Editable External Knowledge",
      "abstract": "  When the world changes, so does the text that humans write about it. How do\nwe build language models that can be easily updated to reflect these changes?\nOne popular approach is retrieval-augmented generation, in which new documents\nare inserted into a knowledge base and retrieved during prediction for\ndownstream tasks. Most prior work on these systems have focused on improving\nbehavior during prediction through better retrieval or reasoning. This paper\nintroduces ERASE, which instead improves model behavior when new documents are\nacquired, by incrementally deleting or rewriting other entries in the knowledge\nbase each time a document is added. In two new benchmark datasets evaluating\nmodels' ability to answer questions about a stream of news articles or\nconversations, ERASE improves accuracy relative to conventional\nretrieval-augmented generation by 7-13% (Mixtral-8x7B) and 6-10% (Llama-3-8B)\nabsolute. Code and data are available at https://github.com/belindal/ERASE\n",
      "subjects": [
        "cs.CL",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Computationally Efficient System Level Tube-MPC for Uncertain Systems",
      "abstract": "  Tube-based model predictive control (MPC) is the principal robust control\ntechnique for constrained linear systems affected by additive disturbances.\nWhile tube-based methods that compute the tubes online have been successfully\napplied to systems with additive disturbances, their application to systems\naffected by additional model uncertainties is challenging. This paper\nintroduces a new tube-based MPC method - named filter-based system level\ntube-MPC (SLTMPC) - which overapproximates both uncertainties with an online\noptimized disturbance set, while simultaneously computing the tube controller\nonline. Extending prior work, we generalize the method to polytopic disturbance\nsets and for the first time provide rigorous closed-loop guarantees for the\nreceding horizon controller. These guarantees are obtained by virtue of a new\nterminal controller design and an online optimized terminal set. To reduce the\ncomputational complexity of the proposed method, we additionally introduce an\nasynchronous computation scheme that separates the optimization of the tube\ncontroller and the nominal trajectory. Finally, we provide a comprehensive\nnumerical evaluation of the proposed methods to demonstrate their\neffectiveness.\n",
      "subjects": [
        "eess.SY",
        "cs.SY"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Amplitude Amplification and Estimation using a Floquet system",
      "abstract": "  The quantum kicked rotor (QKR) is a fundamental model of time-dependent\nquantum chaos and the physics of Anderson localization. It is one of the most\nwell-studied Floquet systems. In this work, it is shown that QKR can be used to\nimplement a quantum algorithm to perform unstructured search; namely Amplitude\nAmplification, a generalization of Grover's search algorithm. Further, the QKR\nis employed for amplitude estimation when the amplitude of the marked states is\nunknown. It is also shown that the characteristic property of dynamical\nlocalization of the QKR can be exploited to enhance the performance of the\namplitude amplification algorithm by reducing its average runtime. The\nsensitivity of the success probability of unstructured search to detuning from\nresonance and the effects of noisy kick strengths are analyzed and the\nrobustness of the QKR based algorithm is demonstrated. The experimental\nfeasibility of every component of the algorithm is discussed.\n",
      "subjects": [
        "quant-ph",
        "cond-mat.quant-gas"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "CholecInstanceSeg: A Tool Instance Segmentation Dataset for Laparoscopic\n  Surgery",
      "abstract": "  In laparoscopic and robotic surgery, precise tool instance segmentation is an\nessential technology for advanced computer-assisted interventions. Although\npublicly available procedures of routine surgeries exist, they often lack\ncomprehensive annotations for tool instance segmentation. Additionally, the\nmajority of standard datasets for tool segmentation are derived from\nporcine(pig) surgeries. To address this gap, we introduce CholecInstanceSeg,\nthe largest open-access tool instance segmentation dataset to date. Derived\nfrom the existing CholecT50 and Cholec80 datasets, CholecInstanceSeg provides\nnovel annotations for laparoscopic cholecystectomy procedures in patients. Our\ndataset comprises 41.9k annotated frames extracted from 85 clinical procedures\nand 64.4k tool instances, each labelled with semantic masks and instance IDs.\nTo ensure the reliability of our annotations, we perform extensive quality\ncontrol, conduct label agreement statistics, and benchmark the segmentation\nresults with various instance segmentation baselines. CholecInstanceSeg aims to\nadvance the field by offering a comprehensive and high-quality open-access\ndataset for the development and evaluation of tool instance segmentation\nalgorithms.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Environmental Variation or Instrumental Drift? A Probabilistic Approach\n  to Gas Sensor Drift Modeling and Evaluation",
      "abstract": "  Drift is a significant issue that undermines the reliability of gas sensors.\nThis paper introduces a probabilistic model to distinguish between\nenvironmental variation and instrumental drift, using low-cost non-dispersive\ninfrared (NDIR) CO2 sensors as a case study. Data from a long-term field\nexperiment is analyzed to evaluate both sensor performance and environmental\nchanges over time. Our approach employs importance sampling to isolate\ninstrumental drift from environmental variation, providing a more accurate\nassessment of sensor performance. The results show that failing to account for\nenvironmental variation can significantly affect the evaluation of sensor\ndrift, leading to improper calibration processes.\n",
      "subjects": [
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Entropy-Stable Model Reduction of One-Dimensional Hyperbolic Systems\n  using Rational Quadratic Manifolds",
      "abstract": "  In this work we propose a novel method to ensure important entropy\ninequalities are satisfied semi-discretely when constructing reduced order\nmodels (ROMs) on nonlinear reduced manifolds. We are in particular interested\nin ROMs of systems of nonlinear hyperbolic conservation laws. The so-called\nentropy stability property endows the semi-discrete ROMs with physically\nadmissible behaviour. The method generalizes earlier results on entropy-stable\nROMs constructed on linear spaces. The ROM works by evaluating the projected\nsystem on a well-chosen approximation of the state that ensures entropy\nstability. To ensure accuracy of the ROM after this approximation we locally\nenrich the tangent space of the reduced manifold with important quantities.\nUsing numerical experiments on some well-known equations (the inviscid Burgers\nequation, shallow water equations and compressible Euler equations) we show the\nimproved structure-preserving properties of our ROM compared to standard\napproaches and that our approximations have minimal impact on the accuracy of\nthe ROM. We additionally generalize the recently proposed polynomial reduced\nmanifolds to rational polynomial manifolds and show that this leads to an\nincrease in accuracy for our experiments.\n",
      "subjects": [
        "math.NA",
        "cs.NA",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Hausdorff dimension of planar elliptic measures via quasiconformal\n  mappings",
      "abstract": "  In this paper we study the dimension of planar elliptic measures via the\napplication of quasiconformal mappings. In fact, in our case studies, we find a\nquasiconformal mapping that relates the elliptic measure in a domain to the\nharmonic measure in its image domain, and we deduce bounds for the Hausdorff\ndimension of the elliptic measure by the known results on the harmonic side.\n",
      "subjects": [
        "math.CA",
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Segment-Anything Models Achieve Zero-shot Robustness in Autonomous\n  Driving",
      "abstract": "  Semantic segmentation is a significant perception task in autonomous driving.\nIt suffers from the risks of adversarial examples. In the past few years, deep\nlearning has gradually transitioned from convolutional neural network (CNN)\nmodels with a relatively small number of parameters to foundation models with a\nhuge number of parameters. The segment-anything model (SAM) is a generalized\nimage segmentation framework that is capable of handling various types of\nimages and is able to recognize and segment arbitrary objects in an image\nwithout the need to train on a specific object. It is a unified model that can\nhandle diverse downstream tasks, including semantic segmentation, object\ndetection, and tracking. In the task of semantic segmentation for autonomous\ndriving, it is significant to study the zero-shot adversarial robustness of\nSAM. Therefore, we deliver a systematic empirical study on the robustness of\nSAM without additional training. Based on the experimental results, the\nzero-shot adversarial robustness of the SAM under the black-box corruptions and\nwhite-box adversarial attacks is acceptable, even without the need for\nadditional training. The finding of this study is insightful in that the\ngigantic model parameters and huge amounts of training data lead to the\nphenomenon of emergence, which builds a guarantee of adversarial robustness.\nSAM is a vision foundation model that can be regarded as an early prototype of\nan artificial general intelligence (AGI) pipeline. In such a pipeline, a\nunified model can handle diverse tasks. Therefore, this research not only\ninspects the impact of vision foundation models on safe autonomous driving but\nalso provides a perspective on developing trustworthy AGI. The code is\navailable at: https://github.com/momo1986/robust_sam_iv.\n",
      "subjects": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Meta-Learning Empowered Graph Neural Networks for Radio Resource\n  Management",
      "abstract": "  In this paper, we consider a radio resource management (RRM) problem in the\ndynamic wireless networks, comprising multiple communication links that share\nthe same spectrum resource. To achieve high network throughput while ensuring\nfairness across all links, we formulate a resilient power optimization problem\nwith per-user minimum-rate constraints. We obtain the corresponding Lagrangian\ndual problem and parameterize all variables with neural networks, which can be\ntrained in an unsupervised manner due to the provably acceptable duality gap.\nWe develop a meta-learning approach with graph neural networks (GNNs) as\nparameterization that exhibits fast adaptation and scalability to varying\nnetwork configurations. We formulate the objective of meta-learning by\namalgamating the Lagrangian functions of different network configurations and\nutilize a first-order meta-learning algorithm, called Reptile, to obtain the\nmeta-parameters. Numerical results verify that our method can efficiently\nimprove the overall throughput and ensure the minimum rate performance. We\nfurther demonstrate that using the meta-parameters as initialization, our\nmethod can achieve fast adaptation to new wireless network configurations and\nreduce the number of required training data samples.\n",
      "subjects": [
        "eess.SP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A result on the Chermak-Delgado measure of a finite group",
      "abstract": "  In this short note, we describe finite groups all of whose non-trivial cyclic\nsubgroups have the same Chermak-Delgado measure.\n",
      "subjects": [
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Composition, Structure and Origin of the Moon",
      "abstract": "  Here we critically examine the geophysical and geochemical properties of the\nMoon in order to identify the extent to which dynamical scenarios satisfy these\nobservations. New joint inversions of existing lunar geophysical data (mean\nmass, moment of inertia, and tidal response) assuming a laterally- and\nvertically homogeneous lunar mantle show that, in all cases, a core with a\nradius of 300$\\pm$20 km ($\\sim$0.8 to 1.5 % the mass of the Moon) is required.\nHowever, an Earth-like Mg# (0.89) in the lunar mantle results in core densities\n(7800$\\pm$100 kg/m$^3$) consistent with that of Fe-Ni alloy, whereas FeO-rich\ncompositions (Mg# = 0.80--0.84) require lower densities (6100$\\pm$800\nkg/m$^3$). Geochemically, we use new data on mare basalts to reassess the bulk\ncomposition of the Moon for 70 elements, and show that the lunar core likely\nformed near 5 GPa, 2100 K and $\\sim$1 log unit below the iron-w\\\"ustite buffer.\nMoreover, the Moon is depleted relative to the Earth's mantle in elements with\nvolatilities higher than that of Li, with this volatile loss likely having\noccurred at low temperatures (1400$\\pm$100 K), consistent with mass-dependent\nstable isotope fractionation of moderately volatile elements (e.g., Zn, K, Rb).\nThe identical nucleosynthetic (O, Cr, Ti) and radiogenic (W) isotope\ncompositions of the lunar and terrestrial mantles, strongly suggest the two\nbodies were made from the same material, rather than from an Earth-like\nimpactor. Rb-Sr in FANs and Lu-Hf and Pb-Pb zircon ages point Moon formation\nclose to $\\sim$4500 Ma. Taken together, there is no unambiguous geochemical or\nisotopic evidence for the role of an impactor in the formation of the Moon,\nimplying perfect equilibration between the proto-Earth and Moon-forming\nmaterial or alternative scenarios for its genesis.\n",
      "subjects": [
        "astro-ph.EP",
        "physics.geo-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Lifting Brauer indecomposability of a Scott module",
      "abstract": "  It is proven that if a finite group $G$ has a normal subgroup $H$ with\n$p'$-index (where $p$ is a prime) and $G/H$ is solvable, then for a\n$p$-subgroup $P$ of $H$, if the Scott $kH$-module with vertex $P$ is Brauer\nindecomposable, then so is the Scott $kG$-module with vertex $P$, where $k$ is\na field of characteristic $p>0$. This has several applications.\n",
      "subjects": [
        "math.RT",
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Semi-Deterministic and Stochastic Sampling of Feynman Diagrams with\n  1/N$_f$ Expansions",
      "abstract": "  We introduced a family of bold-line series, assisted with 1/$\\mathrm{N}_{f}$\nexpansions, with $\\mathrm{N}_{f}$ being the number of fermion flavours. The\nmethod was benchmarked with exact diagonalization for $3\\times3$ Hubbard\nsquare, which was then applied to $60\\times60$ lattice. We showed its\nexponential convergence for half-filled non-fermi liquids phase at\n$\\beta\\mathrm{t}=4$ and presented several exemplary parameters away from\nhalf-filling, including $\\mathrm{U}/\\mathrm{t}=9$.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Molecular clouds as hubs in spiral galaxies : gas inflow and\n  evolutionary sequence",
      "abstract": "  We decomposed the molecular gas in the spiral galaxy NGC 628 (M74) into\nmulti-scale hub-filament structures using the CO (2-1) line by the dendrogram\nalgorithm. All leaf structures as potential hubs were classified into three\ncategories, i.e. leaf-HFs-A, leaf-HFs-B and leaf-HFs-C. leaf-HFs-A exhibit the\nbest hub-filament morphology, which also have the highest density contrast, the\nlargest mass and the lowest virial ratio. We employed the FILFINDER algorithm\nto identify and characterize filaments within 185 leaf-HFs-A structures, and\nfitted the velocity gradients around the intensity peaks. Measurements of\nvelocity gradients provide evidence for gas inflow within these structures. The\nnumbers of the associated 21 $\\mu$m and H$_{\\alpha}$ structures and the peak\nintensities of 7.7 $\\mu$m, 21 $\\mu$m and H$_{\\alpha}$ emissions decrease from\nleaf-HFs-A to leaf-HFs-C. The spatial separations between the intensity peaks\nof CO and 21 $\\mu$m structures of leaf-HFs-A are larger than those of\nleaf-HFs-C. These evidence indicate that leaf-HFs-A are more evolved than\nleaf-HFs-C. There may be an evolutionary sequence from leaf-HFs-C to\nleaf-HFs-A. Currently, leaf-HFs-C lack a distinct gravitational collapse\nprocess that would result in a significant density contrast. The density\ncontrast can effectively measure the extent of the gravitational collapse and\nthe depth of the gravitational potential of the structure which, in turn,\nshapes the hub-filament morphology. Combined with the kinematic analysis\npresented in previous studies, a picture emerges that molecular gas in spiral\ngalaxies is organized into network structures through the gravitational\ncoupling of multi-scale hub-filament structures. Molecular clouds, acting as\nknots within these networks, serve as hubs, which are local gravitational\ncenters and the main sites of star formation.\n",
      "subjects": [
        "astro-ph.GA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "FEM-based Neural Networks for Solving Incompressible Fluid Flows and\n  Related Inverse Problems",
      "abstract": "  The numerical simulation and optimization of technical systems described by\npartial differential equations is expensive, especially in multi-query\nscenarios in which the underlying equations have to be solved for different\nparameters. A comparatively new approach in this context is to combine the good\napproximation properties of neural networks (for parameter dependence) with the\nclassical finite element method (for discretization). However, instead of\nconsidering the solution mapping of the PDE from the parameter space into the\nFEM-discretized solution space as a purely data-driven regression problem,\nso-called physically informed regression problems have proven to be useful. In\nthese, the equation residual is minimized during the training of the neural\nnetwork, i.e. the neural network \"learns\" the physics underlying the problem.\nIn this paper, we extend this approach to saddle-point and non-linear fluid\ndynamics problems, respectively, namely stationary Stokes and stationary\nNavier-Stokes equations. In particular, we propose a modification of the\nexisting approach: Instead of minimizing the plain vanilla equation residual\nduring training, we minimize the equation residual modified by a\npreconditioner. By analogy with the linear case, this also improves the\ncondition in the present non-linear case. Our numerical examples demonstrate\nthat this approach significantly reduces the training effort and greatly\nincreases accuracy and generalizability. Finally, we show the application of\nthe resulting parameterized model to a related inverse problem.\n",
      "subjects": [
        "math.NA",
        "cs.LG",
        "cs.NA",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Small scales in inviscid limits of steady fluids",
      "abstract": "  In this article, we study the 2D incompressible steady Navier-Stokes equation\nin a channel $(-L,0)\\times(-1,1)$ with the no-slip boundary condition on $\\{Y =\n\\pm 1\\}$, and consider the inviscid limit $\\varepsilon \\to 0$. In the special\ncase of Euler shear flow $(u_e(Y),0)$, we construct a steady Navier-Stokes\nsolution for $\\varepsilon \\ll1$, $$\\left\\{ \\begin{aligned} &u^\\varepsilon \\sim\nu_e + u_p + O(\\sqrt{\\varepsilon}),\\\\ &v^\\varepsilon \\sim h(Y)\n\\exp\\{Xu_e(Y)/\\varepsilon\\} + O(\\sqrt{\\varepsilon}), \\end{aligned}\\right. $$\nwhere $u_p$ represents the classical Prandtl layer profile, and $h(Y)$ is an\narbitrary smooth, compactly-supported function with small magnitude. While the\nclassical Prandtl boundary layer $u_p$ exhibits a small scale of order\n$\\sqrt{\\varepsilon}$ in $Y$ near $Y = \\pm 1$, the profile we construct reveals\nan $\\varepsilon$ small scale of $Xu_e(Y)$ in the vertical velocity component.\n",
      "subjects": [
        "math.AP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Leadership and Engagement Dynamics in Legislative Twitter Networks:\n  Statistical Analysis and Modeling",
      "abstract": "  In this manuscript, we analyze the interaction network on Twitter among\nmembers of the 117th U.S. Congress to assess the visibility of political\nleaders and explore how systemic properties and node attributes influence the\nformation of legislative connections. We employ descriptive social network\nstatistical methods, the exponential random graph model (ERGM), and the\nstochastic block model (SBM) to evaluate the relative impact of network\nsystemic properties, as well as institutional and personal traits, on the\ngeneration of online relationships among legislators. Our findings reveal that\nlegislative networks on social media platforms like Twitter tend to reinforce\nthe leadership of dominant political actors rather than diminishing their\ninfluence. However, we identify that these leadership roles can manifest in\nvarious forms. Additionally, we highlight that online connections within\nlegislative networks are influenced by both the systemic properties of the\nnetwork and institutional characteristics.\n",
      "subjects": [
        "stat.AP",
        "cs.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1117/12.3020559",
      "title": "CuRIOS-ED: The Technology Demonstrator for the CubeSats for Rapid\n  Infrared and Optical Surveys Mission",
      "abstract": "  The rise of time-domain astronomy including electromagnetic counterparts to\ngravitational waves, gravitational microlensing, explosive phenomena, and even\nastrometry with Gaia, are showing the power and need for surveys with\nhigh-cadence, large area, and long time baselines to study the transient\nuniverse. A constellation of SmallSats or CubeSats providing wide,\ninstantaneous sky coverage down to 21 Vega mag at optical wavelengths would be\nideal for addressing this need. We are assembling CuRIOS-ED (CubeSats for Rapid\nInfrared and Optical Survey--Exploration Demo), an optical telescope payload\nwhich will act as a technology demonstrator for a larger constellation of\nseveral hundred 16U CubeSats known as CuRIOS. In preparation for CuRIOS,\nCuRIOS-ED will launch in late 2025 as part of the 12U Starspec InspireSat MVP\npayload. CuRIOS-ED will be used to demonstrate the StarSpec ADCS pointing\ncapabilities to <1\" and to space-qualify a commercial camera package for use on\nthe full CuRIOS payload. The CuRIOS-ED camera system will utilize a Sony IMX455\nCMOS detector delivered in an off-the-shelf Atik apx60 package which we\nmodified to be compatible with operations in vacuum as well as the CubeSat form\nfactor, power, and thermal constraints. By qualifying this commercial camera\nsolution, the cost of each CuRIOS satellite will be greatly decreased (~100x)\nwhen compared with current space-qualified cameras with IMX455 detectors. We\ndiscuss the CuRIOS-ED mission design with an emphasis on the disassembly,\nrepackaging, and testing of the Atik apx60 for space-based missions.\nCharacterization of the apx60's read noise, dark current, patterned noise, and\nthermal behavior are reported for a range of temperatures (-35 C to 40 C) and\nexposure times (0.001s to 30 s). Additionally, we comment on preliminary\nenvironmental testing results from a successful thermal vacuum test.\n",
      "subjects": [
        "astro-ph.IM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Measuring Sound Symbolism in Audio-visual Models",
      "abstract": "  Audio-visual pre-trained models have gained substantial attention recently\nand demonstrated superior performance on various audio-visual tasks. This study\ninvestigates whether pre-trained audio-visual models demonstrate non-arbitrary\nassociations between sounds and visual representations$\\unicode{x2013}$known as\nsound symbolism$\\unicode{x2013}$which is also observed in humans. We developed\na specialized dataset with synthesized images and audio samples and assessed\nthese models using a non-parametric approach in a zero-shot setting. Our\nfindings reveal a significant correlation between the models' outputs and\nestablished patterns of sound symbolism, particularly in models trained on\nspeech data. These results suggest that such models can capture sound-meaning\nconnections akin to human language processing, providing insights into both\ncognitive architectures and machine learning strategies.\n",
      "subjects": [
        "cs.CL",
        "cs.CV",
        "cs.SD",
        "eess.AS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Bounds on heavy neutral leptons from tree level unitarity",
      "abstract": "  Heavy neutral leptons (HNLs) can explain the origin of neutrino masses and\noscillations over a wide range of masses. Direct experimental probes of HNLs\nbecome unfeasible for masses significantly above the electroweak scale.\nConsequently, the strongest limits arise from the non-observation of charged\nlepton flavor-violating processes induced by HNLs at loop level. Counter\nintuitively, these bounds tighten as the HNL mass increases, an effect that\npersists within the perturbative regime.\n  This work explores the precise form of these bounds for HNLs with masses well\nbeyond the electroweak scale by analyzing the full matrix of partial waves\n(tree-level unitarity). At high energies, the HNL model simplifies to a Yukawa\ntheory, allowing unitarity constraints to be expressed in terms of the total\nYukawa coupling $|Y_{\\mathrm{tot}}|^2$ involving HNLs, lepton doublets, and the\nHiggs boson. Processes with $J=0$ and $J=1/2$ yield the well-known bound\n$|Y_{\\mathrm{tot}}|^2 \\leq 8\\pi$. However, the most stringent constraint arises\nfrom the eigenvalues of the $(\\mathcal{N}^2 + 20) \\times (\\mathcal{N}^2 + 20)$\nmatrix, which describes the $J=1$ partial wave amplitude for $\\mathcal{N}$\ngenerations of HNLs. This bound is given by $|Y_{\\mathrm{tot}}|^2 \\leq\n8\\pi/\\varphi \\approx 15.533$, where $\\varphi$ is the Golden ratio. Finally, we\ndetermine the maximum mass that an HNL can have in the type-I seesaw model\nwhile remaining the sole source of neutrino masses.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tactile Functasets: Neural Implicit Representations of Tactile Datasets",
      "abstract": "  Modern incarnations of tactile sensors produce high-dimensional raw sensory\nfeedback such as images, making it challenging to efficiently store, process,\nand generalize across sensors. To address these concerns, we introduce a novel\nimplicit function representation for tactile sensor feedback. Rather than\ndirectly using raw tactile images, we propose neural implicit functions trained\nto reconstruct the tactile dataset, producing compact representations that\ncapture the underlying structure of the sensory inputs. These representations\noffer several advantages over their raw counterparts: they are compact, enable\nprobabilistically interpretable inference, and facilitate generalization across\ndifferent sensors. We demonstrate the efficacy of this representation on the\ndownstream task of in-hand object pose estimation, achieving improved\nperformance over image-based methods while simplifying downstream models. We\nrelease code, demos and datasets at\nhttps://www.mmintlab.com/tactile-functasets.\n",
      "subjects": [
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Stripes, pair density wave, and holon Wigner crystal in single-band\n  Hubbard model on diagonal square lattice",
      "abstract": "  We investigate the ground-state properties of the Hubbard model on wide\ndiagonal square cylinders, rotated by $\\pi/4$ relative to the regular lattice\norientation. Using state-of-the-art density matrix renormalization group\ncalculations with a large number of states, we convincingly demonstrate the\ndevelopment of a unidirectional charge density wave (CDW) characterized by\ninfinite-length stripes along the primitive vector of square lattice in models\nwith next-nearest-neighbor hopping $t'=-0.1\\sim -0.3$ and doping $\\delta \\sim\n14\\%$. Intriguingly, analysis of pair-pair correlation functions along these\nstripes reveals incommensurate pair density wave (PDW) superconductivity with\ndiverged susceptibility. To the best of our knowledge, this is probably the\nfirst controlled numerical evidence of dominant PDW in the single-band Hubbard\nmodel on square lattices. At lower doping $\\delta \\sim 10\\%$, we observed the\nformation of an additional CDW order within each stripe, which aligns across\ndifferent stripes, forming a holon Wigner crystal phase. The spin pattern\nretains antiferromagnetic stripes with anti-phase domain walls. The ordering\nmomentum of this emerged CDW order is remarkably close to the center-of-mass\nmomentum of Cooper pairs in the PDW phase, suggesting a multifaceted\nrelationship between CDW and PDW ordering.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "TwinArray Sort: An Ultrarapid Conditional Non-Comparison Based Sorting\n  Algorithm",
      "abstract": "  In computer science, sorting algorithms are crucial for data processing and\nmachine learning. Large datasets and high efficiency requirements provide\nchallenges for comparison-based algorithms like Quicksort and Merge sort, which\nachieve O(n log n) time complexity. Non-comparison-based algorithms like\nSpreadsort and Counting Sort have memory consumption issues and a relatively\nhigh computational demand, even if they can attain linear time complexity under\ncertain circumstances. We present TwinArray Sort, a novel conditional\nnon-comparison-based sorting algorithm that effectively uses array indices.\nWhen it comes to worst-case time and space complexities, TwinArray Sort\nachieves O(n+k). The approach remains efficient under all settings and works\nwell with datasets with randomly sorted, reverse-sorted, or nearly sorted\ndistributions. TwinArray Sort can handle duplicates and optimize memory\nefficiently since thanks to its two auxiliary arrays for value storage and\nfrequency counting, as well as a conditional distinct array verifier. TwinArray\nSort constantly performs better than conventional algorithms, according to\nexperimental assessments and particularly when sorting unique arrays under all\ndata distribution scenarios. The approach is suitable for massive data\nprocessing and machine learning dataset management due to its creative use of\ndual auxiliary arrays and a conditional distinct array verification, which\nimproves memory use and duplication handling. TwinArray Sort overcomes\nconventional sorting algorithmic constraints by combining cutting-edge methods\nwith non-comparison-based sorting advantages. Its reliable performance in a\nrange of data distributions makes it an adaptable and effective answer for\ncontemporary computing requirements.\n",
      "subjects": [
        "cs.DS",
        "cs.CC"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.35199/dsm2024.08",
      "title": "Optimizing Token Usage on Large Language Model Conversations Using the\n  Design Structure Matrix",
      "abstract": "  As Large Language Models become ubiquitous in many sectors and tasks, there\nis a need to reduce token usage, overcoming challenges such as short context\nwindows, limited output sizes, and costs associated with token intake and\ngeneration, especially in API-served LLMs. This work brings the Design\nStructure Matrix from the engineering design discipline into LLM conversation\noptimization. Applied to a use case in which the LLM conversation is about the\ndesign of a spacecraft and its subsystems, the DSM, with its analysis tools\nsuch as clustering and sequencing, demonstrates being an effective tool to\norganize the conversation, minimizing the number of tokens sent to or retrieved\nfrom the LLM at once, as well as grouping chunks that can be allocated to\ndifferent context windows. Hence, this work broadens the current set of\nmethodologies for token usage optimization and opens new avenues for the\nintegration of engineering design practices into LLMs.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "It's Not Easy Being Green: On the Energy Efficiency of Programming\n  Languages",
      "abstract": "  Does the choice of programming language affect energy consumption? Previous\nhighly visible studies have established associations between certain\nprogramming languages and energy consumption. A causal misinterpretation of\nthis work has led academics and industry leaders to use or support certain\nlanguages based on their claimed impact on energy consumption. This paper\ntackles this causal question directly. It first corrects and improves the\nmeasurement methodology used by prior work. It then develops a detailed causal\nmodel capturing the complex relationship between programming language choice\nand energy consumption. This model identifies and incorporates several critical\nbut previously overlooked factors that affect energy usage. These factors, such\nas distinguishing programming languages from their implementations, the impact\nof the application implementations themselves, the number of active cores, and\nmemory activity, can significantly skew energy consumption measurements if not\naccounted for. We show -- via empirical experiments, improved methodology, and\ncareful examination of anomalies -- that when these factors are controlled for,\nnotable discrepancies in prior work vanish. Our analysis suggests that the\nchoice of programming language implementation has no significant impact on\nenergy consumption beyond execution time.\n",
      "subjects": [
        "cs.PL",
        "cs.PF"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Generative Portrait Shadow Removal",
      "abstract": "  We introduce a high-fidelity portrait shadow removal model that can\neffectively enhance the image of a portrait by predicting its appearance under\ndisturbing shadows and highlights. Portrait shadow removal is a highly\nill-posed problem where multiple plausible solutions can be found based on a\nsingle image. While existing works have solved this problem by predicting the\nappearance residuals that can propagate local shadow distribution, such methods\nare often incomplete and lead to unnatural predictions, especially for\nportraits with hard shadows. We overcome the limitations of existing local\npropagation methods by formulating the removal problem as a generation task\nwhere a diffusion model learns to globally rebuild the human appearance from\nscratch as a condition of an input portrait image. For robust and natural\nshadow removal, we propose to train the diffusion model with a compositional\nrepurposing framework: a pre-trained text-guided image generation model is\nfirst fine-tuned to harmonize the lighting and color of the foreground with a\nbackground scene by using a background harmonization dataset; and then the\nmodel is further fine-tuned to generate a shadow-free portrait image via a\nshadow-paired dataset. To overcome the limitation of losing fine details in the\nlatent diffusion model, we propose a guided-upsampling network to restore the\noriginal high-frequency details (wrinkles and dots) from the input image. To\nenable our compositional training framework, we construct a high-fidelity and\nlarge-scale dataset using a lightstage capturing system and synthetic graphics\nsimulation. Our generative framework effectively removes shadows caused by both\nself and external occlusions while maintaining original lighting distribution\nand high-frequency details. Our method also demonstrates robustness to diverse\nsubjects captured in real environments.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Strictly convex norms and the local diameter two property",
      "abstract": "  We introduce and study a strict monotonicity property of the norm in solid\nBanach lattices of real functions that prevents such spaces from having the\nlocal diameter two property. Then we show that any strictly convex 1-symmetric\nnorm on $\\ell_\\infty(\\mathbb N)$ possesses this strict monotonicity property.\n  In the opposite direction, we show that any Banach space which is strictly\nconvex renormable and contains a complemented copy of $c_0,$ admits an\nequivalent strictly convex norm for which the space has the local diameter two\nproperty. In particular, this enables us to construct a strictly convex norm on\n$c_0(\\Gamma),$ where $\\Gamma$ is uncountable, for which the space has a\n1-unconditional basis and the local diameter two property.\n",
      "subjects": [
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Distributed Blind Source Separation based on FastICA",
      "abstract": "  With the emergence of wireless sensor networks (WSNs), many traditional\nsignal processing tasks are required to be computed in a distributed fashion,\nwithout transmissions of the raw data to a centralized processing unit, due to\nthe limited energy and bandwidth resources available to the sensors. In this\npaper, we propose a distributed independent component analysis (ICA) algorithm,\nwhich aims at identifying the original signal sources based on observations of\ntheir mixtures measured at various sensor nodes. One of the most commonly used\nICA algorithms is known as FastICA, which requires a spatial pre-whitening\noperation in the first step of the algorithm. Such a pre-whitening across all\nnodes of a WSN is impossible in a bandwidth-constrained distributed setting as\nit requires to correlate each channel with each other channel in the WSN. We\nshow that an explicit network-wide pre-whitening step can be circumvented by\nleveraging the properties of the so-called Distributed Adaptive Signal Fusion\n(DASF) framework. Despite the lack of such a network-wide pre-whitening, we can\nstill obtain the $Q$ least Gaussian independent components of the centralized\nICA solution, where $Q$ scales linearly with the required communication load.\n",
      "subjects": [
        "eess.SP",
        "cs.LG",
        "cs.MA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Inverse Modeling Constrained Multi-Objective Evolutionary Algorithm\n  Based on Decomposition",
      "abstract": "  This paper introduces the inverse modeling constrained multi-objective\nevolutionary algorithm based on decomposition (IM-C-MOEA/D) for addressing\nconstrained real-world optimization problems. Our research builds upon the\nadvancements made in evolutionary computing-based inverse modeling, and it\nstrategically bridges the gaps in applying inverse models based on\ndecomposition to problem domains with constraints. The proposed approach is\nexperimentally evaluated on diverse real-world problems (RWMOP1-35), showing\nsuperior performance to state-of-the-art constrained multi-objective\nevolutionary algorithms (CMOEAs). The experimental results highlight the\nrobustness of the algorithm and its applicability in real-world constrained\noptimization scenarios.\n",
      "subjects": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Classical theory of nucleation applied to condensation of a\n  Lennard-Jones fluid",
      "abstract": "  The classical nucleation theory (CNT) and its modified versions provide a\nconvenient framework for describing the nucleation process under the capillary\napproximation. However, these models often predict nucleation rates that depart\nsignificantly from simulation results, even for a simple Lennard-Jones fluid.\nThis large discrepancy is likely due to the inaccurate estimation of the\ndriving force for nucleation, which most traditional models estimate within the\nideal solution approximation. In this study, we address this issue by directly\ncalculating the driving force for nucleation using equations of state (EOS) and\nintegrating this approach into the calculation of nucleation rates within the\nframework of CNT and its modified model. We apply this method to examine the\ncondensation of a Lennard-Jones fluid and compare the resulting nucleation\nrates with molecular dynamics (MD) simulation data. Our results demonstrate\nthat at relatively low supersaturation, where the capillary approximation is\nreasonable, our thermodynamic models exhibit excellent agreement with MD\nresults, significantly outperforming traditional models. At moderate and high\nsupersaturation, our approach continues to show a reasonable agreement with MD\nresults. Furthermore, when comparing the results obtained by using different\nEOS, we find that more precise EOS generally yield better agreement with MD\ndata.\n",
      "subjects": [
        "cond-mat.soft",
        "physics.chem-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Multi-layer network analysis of deliberation in an online discussion\n  platform: the case of Reddit",
      "abstract": "  This paper uses a multi-layer network model to study deliberation in online\ndiscussion platforms, focusing on the Reddit platform. The model comprises two\nlayers: a discussion layer, which represents the comment-to-comment replies as\na hierarchical tree, and an actor layer, which represent the actor-to-actor\nreply interactions. The interlayer links represent user-comment ownership. We\nfurther propose several different network metrics to characterise the level of\ndeliberation in discussion threads, and apply the model and metrics to a large\nReddit dataset containing posts from 72 subreddits focused on different topics.\nWe compare the level of deliberation that occurs on different subreddits,\nfinding that subreddits that are based on geographical regions or focus on\nsports have the highest levels of deliberation. Analysis of the actor layer\nreveals several features consistent across all subreddits, such as small-world\ncharacteristics and similar numbers of highly active users.\n",
      "subjects": [
        "cs.SI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Periodic orbits on 2-regular circulant digraphs",
      "abstract": "  Periodic orbits (equivalence classes of closed cycles up to cyclic shifts)\nplay an important role in applications of graph theory. For example, they\nappear in the definition of the Ihara zeta function and exact trace formulae\nfor the spectra of quantum graphs. Circulant graphs are Cayley graphs of\n$\\mathbb{Z}_n$. Here we consider directed Cayley graphs with two generators\n(2-regular Cayley digraphs). We determine the number of primitive periodic\norbits of a given length (total number of directed edges) in terms of the\nnumber of times edges corresponding to each generator appear in the periodic\norbit (the step count). Primitive periodic orbits are those periodic orbits\nthat cannot be written as a repetition of a shorter orbit. We describe the\nlattice structure of lengths and step counts for which periodic orbits exist\nand characterize the repetition number of a periodic orbit by its winding\nnumber (the sum of the step sequence divided by the number of vertices) and the\nrepetition number of its step sequence. To obtain these results, we also\nevaluate the number of Lyndon words on an alphabet of two letters with a given\nlength and letter count.\n",
      "subjects": [
        "math.CO",
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Task-Oriented Real-time Visual Inference for IoVT Systems: A Co-design\n  Framework of Neural Networks and Edge Deployment",
      "abstract": "  As the volume of image data grows, data-oriented cloud computing in Internet\nof Video Things (IoVT) systems encounters latency issues. Task-oriented edge\ncomputing addresses this by shifting data analysis to the edge. However,\nlimited computational power of edge devices poses challenges for executing\nvisual tasks. Existing methods struggle to balance high model performance with\nlow resource consumption; lightweight neural networks often underperform, while\ndevice-specific models designed by Neural Architecture Search (NAS) fail to\nadapt to heterogeneous devices. For these issues, we propose a novel co-design\nframework to optimize neural network architecture and deployment strategies\nduring inference for high-throughput. Specifically, it implements a dynamic\nmodel structure based on re-parameterization, coupled with a Roofline-based\nmodel partitioning strategy to enhance the computational performance of edge\ndevices. We also employ a multi-objective co-optimization approach to balance\nthroughput and accuracy. Additionally, we derive mathematical consistency and\nconvergence of partitioned models. Experimental results demonstrate significant\nimprovements in throughput (12.05\\% on MNIST, 18.83\\% on ImageNet) and superior\nclassification accuracy compared to baseline algorithms. Our method\nconsistently achieves stable performance across different devices, underscoring\nits adaptability. Simulated experiments further confirm its efficacy in\nhigh-accuracy, real-time detection for small objects in IoVT systems.\n",
      "subjects": [
        "cs.CV",
        "cs.AI"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Biomass phenotyping of oilseed rape through UAV multi-view oblique\n  imaging with 3DGS and SAM model",
      "abstract": "  Biomass estimation of oilseed rape is crucial for optimizing crop\nproductivity and breeding strategies. While UAV-based imaging has advanced\nhigh-throughput phenotyping, current methods often rely on orthophoto images,\nwhich struggle with overlapping leaves and incomplete structural information in\ncomplex field environments. This study integrates 3D Gaussian Splatting (3DGS)\nwith the Segment Anything Model (SAM) for precise 3D reconstruction and biomass\nestimation of oilseed rape. UAV multi-view oblique images from 36 angles were\nused to perform 3D reconstruction, with the SAM module enhancing point cloud\nsegmentation. The segmented point clouds were then converted into point cloud\nvolumes, which were fitted to ground-measured biomass using linear regression.\nThe results showed that 3DGS (7k and 30k iterations) provided high accuracy,\nwith peak signal-to-noise ratios (PSNR) of 27.43 and 29.53 and training times\nof 7 and 49 minutes, respectively. This performance exceeded that of structure\nfrom motion (SfM) and mipmap Neural Radiance Fields (Mip-NeRF), demonstrating\nsuperior efficiency. The SAM module achieved high segmentation accuracy, with a\nmean intersection over union (mIoU) of 0.961 and an F1-score of 0.980.\nAdditionally, a comparison of biomass extraction models found the point cloud\nvolume model to be the most accurate, with an determination coefficient (R2) of\n0.976, root mean square error (RMSE) of 2.92 g/plant, and mean absolute\npercentage error (MAPE) of 6.81%, outperforming both the plot crop volume and\nindividual crop volume models. This study highlights the potential of combining\n3DGS with multi-view UAV imaging for improved biomass phenotyping.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A typical medium cluster approach for multi-branch phonon localization",
      "abstract": "  The phenomenon of Anderson localization in various disordered media has\nsustained significant interest over many decades. Specifically, the Anderson\nlocalization of phonons has been viewed as a potential mechanism for creating\nfascinating thermal transport properties in materials. However, despite\nextensive work, the influence of the vector nature of phonons on the Anderson\nlocalization transition has not been well explored. In order to achieve such an\nunderstanding, we extend a recently developed phonon dynamical cluster\napproximation (DCA) and its typical medium variant (TMDCA) to investigate\nspectra and localization of multi-branch phonons in the presence of pure mass\ndisorder. We validate the new formalism against several limiting cases and\nexact diagonalization results. A comparison of results for the single-branch\nversus multi-branch case shows that the vector nature of the phonons does not\naffect the Anderson transition of phonons significantly. The developed\nmulti-branch TMDCA formalism can be employed for studying phonon localization\nin real materials.\n",
      "subjects": [
        "cond-mat.dis-nn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "BitMoD: Bit-serial Mixture-of-Datatype LLM Acceleration",
      "abstract": "  Large language models (LLMs) have demonstrated remarkable performance across\nvarious machine learning tasks. Yet the substantial memory footprint of LLMs\nsignificantly hinders their deployment. In this paper, we improve the\naccessibility of LLMs through BitMoD, an algorithm-hardware co-design solution\nthat enables efficient LLM acceleration at low weight precision. On the\nalgorithm side, BitMoD introduces fine-grained data type adaptation that uses a\ndifferent numerical data type to quantize a group of (e.g., 128) weights.\nThrough the careful design of these new data types, BitMoD is able to quantize\nLLM weights to very low precision (e.g., 4 bits and 3 bits) while maintaining\nhigh accuracy. On the hardware side, BitMoD employs a bit-serial processing\nelement to easily support multiple numerical precisions and data types; our\nhardware design includes two key innovations: First, it employs a unified\nrepresentation to process different weight data types, thus reducing the\nhardware cost. Second, it adopts a bit-serial dequantization unit to rescale\nthe per-group partial sum with minimal hardware overhead. Our evaluation on six\nrepresentative LLMs demonstrates that BitMoD significantly outperforms\nstate-of-the-art LLM quantization and acceleration methods. For discriminative\ntasks, BitMoD can quantize LLM weights to 4-bit with $<\\!0.5\\%$ accuracy loss\non average. For generative tasks, BitMoD is able to quantize LLM weights to\n3-bit while achieving better perplexity than prior LLM quantization scheme.\nCombining the superior model performance with an efficient accelerator design,\nBitMoD achieves an average of $1.69\\times$ and $1.48\\times$ speedups compared\nto prior LLM accelerators ANT and OliVe, respectively.\n",
      "subjects": [
        "cs.LG",
        "cs.AR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Continuous-Variable Multiplexed Quantum Repeater Networks",
      "abstract": "  Continuous-variable (CV) codes and their application in quantum communication\nhave attracted increasing attention. In particular, one typical CV codes,\ncat-codes, has already been experimentally created using trapped atoms in\ncavities with relatively high fidelities. However, when these codes are used in\na repeater protocol, the secret key rate (SKR) that can be extracted between\ntwo remote users is extremely low. Here we propose a quantum repeater protocol\nbased on cat codes with a few quantum memories or graph states as additional\nresources. This allows us to considerably increase the secret key rate by\nseveral orders of magnitude. Our findings provide valuable insights for\ndesigning efficient quantum repeater systems, advancing the feasibility and\nperformance of quantum communication over long distances.\n",
      "subjects": [
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Gassidy: Gaussian Splatting SLAM in Dynamic Environments",
      "abstract": "  3D Gaussian Splatting (3DGS) allows flexible adjustments to scene\nrepresentation, enabling continuous optimization of scene quality during dense\nvisual simultaneous localization and mapping (SLAM) in static environments.\nHowever, 3DGS faces challenges in handling environmental disturbances from\ndynamic objects with irregular movement, leading to degradation in both camera\ntracking accuracy and map reconstruction quality. To address this challenge, we\ndevelop an RGB-D dense SLAM which is called Gaussian Splatting SLAM in Dynamic\nEnvironments (Gassidy). This approach calculates Gaussians to generate\nrendering loss flows for each environmental component based on a designed\nphotometric-geometric loss function. To distinguish and filter environmental\ndisturbances, we iteratively analyze rendering loss flows to detect features\ncharacterized by changes in loss values between dynamic objects and static\ncomponents. This process ensures a clean environment for accurate scene\nreconstruction. Compared to state-of-the-art SLAM methods, experimental results\non open datasets show that Gassidy improves camera tracking precision by up to\n97.9% and enhances map quality by up to 6%.\n",
      "subjects": [
        "cs.RO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dynamic Self-Distillation via Previous Mini-batches for Fine-tuning\n  Small Language Models",
      "abstract": "  Knowledge distillation (KD) has become a widely adopted approach for\ncompressing large language models (LLMs) to reduce computational costs and\nmemory footprints. However, the availability of complex teacher models is a\nprerequisite for running most KD pipelines. Thus, the traditional KD procedure\ncan be unachievable or budget-unfriendly, particularly when relying on\ncommercial LLMs like GPT4. In this regard, Self-distillation (SelfD) emerges as\nan advisable alternative, enabling student models to learn without teachers'\nguidance. Nonetheless, existing SelfD approaches for LMs often involve\narchitectural modifications, assuming the models are open-source, which may not\nalways be practical. In this work, we introduce a model-agnostic and\ntask-agnostic method named dynamic SelfD from the previous minibatch (DynSDPB),\nwhich realizes current iterations' distillation from the last ones' generated\nlogits. Additionally, to address prediction inaccuracies during the early\niterations, we dynamically adjust the distillation influence and temperature\nvalues to enhance the adaptability of fine-tuning. Furthermore, DynSDPB is a\nnovel fine-tuning policy that facilitates the seamless integration of existing\nself-correction and self-training techniques for small language models (SLMs)\nbecause they all require updating SLMs' parameters. We demonstrate the superior\nperformance of DynSDPB on both encoder-only LMs (e.g., BERT model families) and\ndecoder-only LMs (e.g., LLaMA model families), validating its effectiveness\nacross natural language understanding (NLU) and natural language generation\n(NLG) benchmarks.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "KV Shifting Attention Enhances Language Modeling",
      "abstract": "  The current large language models are mainly based on decode-only structure\ntransformers, which have great in-context learning (ICL) capabilities. It is\ngenerally believed that the important foundation of its ICL capability is the\ninduction heads mechanism, which requires at least two layers attention. In\norder to more efficiently implement the ability of the model's induction, we\nrevisit the induction heads mechanism and proposed a KV shifting attention. We\ntheoretically prove that the KV shifting attention reducing the model's\nrequirements for the depth and width of the induction heads mechanism. Our\nexperimental results demonstrate that KV shifting attention is beneficial to\nlearning induction heads and language modeling, which lead to better\nperformance or faster convergence from toy models to the pre-training models\nwith more than 10 B parameters.\n",
      "subjects": [
        "cs.CL"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An explicit version of Carlson's theorem",
      "abstract": "  Let $N(\\sigma,T)$ denote the number of nontrivial zeros of the Riemann zeta\nfunction with real part greater than $\\sigma$ and imaginary part lying between\n$0$ and $T$. In this article, we provide an explicit version of Carlson's zero\ndensity estimate, that is, $N(\\sigma, T) \\leq 0.78 T^{4 \\sigma (1- \\sigma)}\n(\\log T)^{5-2 \\sigma} $, with a slight improvement in the exponent of the\nlogarithm factor.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Archimedean Vector Lattice Functional Calculus For Semicontinuous\n  Positively Homogeneous Functions",
      "abstract": "  We develop a functional calculus on Archimedean vector lattices for\nsemicontinuous positively homogeneous real-valued functions defined on $\\R^n$\nwhich are bounded on the unit sphere. It is further shown that this\nsemicontinuous Archimedean vector lattice functional calculus extends the\nexisting continuous Archimedean vector lattice functional calculus by Buskes,\nde Pagter, and van Rooij. We further utilize saddle representations of\ncontinuous positively homogeneous functions to provide concrete formulas, for\nfunctions abstractly defined via the continuous functional calculus, which are\ncompletely in terms of vector lattice operations. Finally, we provide some\nexamples to illustrate the utility of the theory presented.\n",
      "subjects": [
        "math.FA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Analyzing and Improving Model Collapse in Rectified Flow Models",
      "abstract": "  Generative models aim to produce synthetic data indistinguishable from real\ndistributions, but iterative training on self-generated data can lead to\n\\emph{model collapse (MC)}, where performance degrades over time. In this work,\nwe provide the first theoretical analysis of MC in Rectified Flow by framing it\nwithin the context of Denoising Autoencoders (DAEs). We show that when DAE\nmodels are trained on recursively generated synthetic data with small noise\nvariance, they suffer from MC with progressive diminishing generation quality.\nTo address this MC issue, we propose methods that strategically incorporate\nreal data into the training process, even when direct noise-image pairs are\nunavailable. Our proposed techniques, including Reverse Collapse-Avoiding (RCA)\nReflow and Online Collapse-Avoiding Reflow (OCAR), effectively prevent MC while\nmaintaining the efficiency benefits of Rectified Flow. Extensive experiments on\nstandard image datasets demonstrate that our methods not only mitigate MC but\nalso improve sampling efficiency, leading to higher-quality image generation\nwith fewer sampling steps.\n",
      "subjects": [
        "cs.CV",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Three-in-One: Robust Enhanced Universal Transferable Anti-Facial\n  Retrieval in Online Social Networks",
      "abstract": "  Deep hash-based retrieval techniques are widely used in facial retrieval\nsystems to improve the efficiency of facial matching. However, it also carries\nthe danger of exposing private information. Deep hash models are easily\ninfluenced by adversarial examples, which can be leveraged to protect private\nimages from malicious retrieval. The existing adversarial example methods\nagainst deep hash models focus on universality and transferability, lacking the\nresearch on its robustness in online social networks (OSNs), which leads to\ntheir failure in anti-retrieval after post-processing. Therefore, we provide\nthe first in-depth discussion on robustness adversarial perturbation in\nuniversal transferable anti-facial retrieval and propose Three-in-One\nAdversarial Perturbation (TOAP). Specifically, we construct a local and global\nCompression Generator (CG) to simulate complex post-processing scenarios, which\ncan be used to mitigate perturbation. Then, we propose robust optimization\nobjectives based on the discovery of the variation patterns of model's\ndistribution after post-processing, and generate adversarial examples using\nthese objectives and meta-learning. Finally, we iteratively optimize\nperturbation by alternately generating adversarial examples and fine-tuning the\nCG, balancing the performance of perturbation while enhancing CG's ability to\nmitigate them. Numerous experiments demonstrate that, in addition to its\nadvantages in universality and transferability, TOAP significantly outperforms\ncurrent state-of-the-art methods in multiple robustness metrics. It further\nimproves universality and transferability by 5% to 28%, and achieves up to\nabout 33% significant improvement in several simulated post-processing\nscenarios as well as mainstream OSNs, demonstrating that TOAP can effectively\nprotect private images from malicious retrieval in real-world scenarios.\n",
      "subjects": [
        "cs.CV"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/5.0243186",
      "title": "Cavitation Onset in an Impulsively Accelerated Liquid Column",
      "abstract": "  This paper introduces a novel piston-driven apparatus to study the onset of\ncavitation in an impulsively accelerated liquid column as it compresses a\nclosed gas volume. The experiment is monitored using high-speed videography and\npiezoelectric pressure transducers. Cavitation onset is observed in the liquid\ncolumn as it undergoes an abrupt deceleration and is associated with a sudden\ndrop in pressure in the liquid that leads to negative pressure (tension). A\nnovel numerical modeling approach is introduced where the liquid column is\ntreated as a spring-mass system. This approach can reproduce compressibility\neffects in the liquid column and is used to investigate the wave dynamics\nresponsible for the onset of tension and cavitation in the liquid column. The\nmodel is formulated as a coupled set of non-linear differential equations that\nreproduce the dynamics of an experiment while capturing the pressure wave\nactivity in the liquid column. A parametric study is conducted experimentally\nand numerically to investigate the behavior behind the onset of cavitation. The\nmechanism for the onset of cavitation is identified as a series of wave\nreflections at the boundaries of the liquid column, and this mechanism is found\nto be well reproduced by the model. While a traditional cavitation number\ncriterion is shown to be unable to predict cavitation onset in our experiment,\nour numerical model is found to correctly predict the onset of cavitation for a\nwide range of experimental parameters.\n",
      "subjects": [
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "N\\'eel-vector Control of Magnetization Dynamics in\n  $\\alpha$-Fe$_2$O$_3$/NiFe Heterostructures",
      "abstract": "  We investigate spin dynamics in $\\alpha$-Fe$_{2}$O$_{3}$/Ni$_{80}$Fe$_{20}$\n(Py) heterostructures, uncovering a robust mechanism for in-situ modulation of\nferromagnetic resonance (FMR) through precise control of temperature, applied\nmagnetic field and crystal orientation. Employing cryogenic ferromagnetic\nresonance spectroscopy, we demonstrate that the interfacial coupling between\nthe N\\'eel vector of $\\alpha$-Fe$_{2}$O$_{3}$ and the magnetization of the Py\nlayer is highly tunable across the Morin transition temperature $(T_M)$. Our\nexperiments reveal distinct resonance behavior for different crystal\norientations, highlighting the pivotal role of exchange coupling strength in\ndictating FMR frequencies. Theoretical modeling corroborates the experimental\nfindings, elucidating the dependence of coupling on the relative alignment of\nthe N\\'eel vector and ferromagnetic magnetization. Notably, we achieve\nsignificant modulation of FMR frequencies by manipulating the N\\'eel vector\nconfiguration, facilitated by temperature variations, applied magnetic fields\nand crystal orientation adjustments. These advancements demonstrate the\npotential for dynamic control of spin interactions in AFM/FM heterostructures,\npaving the way for the development of advanced spintronic devices with tunable\nmagnetic properties. Our work provides critical insights into the fundamental\ninteractions governing hybrid spin systems and opens new avenues for the design\nof versatile, temperature-responsive magnetoelectronic applications.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Neutrino decay and the thermochemical equilibrium of the interstellar\n  medium",
      "abstract": "  We calculate the thermochemical equilibrium of the diffuse interstellar\nmedium, including ionization by a photon flux F_{nu} from neutrino decay. The\nmain heating mechanism considered is photoelectrons from grains and PAHs. For\nthe studied range of F_{nu} values, there always exists two regions of\nstability (a warm and a cold phase) that can coexist in equilibrium if the\nthermal interstellar pressure is between a maximum value P_{max} and a minimum\nvalue P_{min}. High F_{nu} values (~10^4-10^5 cm^{-2} s^{-1}) can be consistent\nwith observed interstellar pressures only if more efficient sources are heating\nthe gas. It is shown that a neutrino flux increase (due, for example, to an\nincrease in the supernova explosion rate) may stimulate the condensation of\ncold gas by decreasing P_{max} below the interstellar pressure value.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1046/j.1365-8711.2000.03664.x",
      "title": "beta-model and cooling flows in X-ray clusters of galaxies",
      "abstract": "  The spatial emission from the core of cooling flow clusters of galaxies is\ninadequately described by a beta-model(Cavaliere and Fusco-Femiano 1976).\nSpectrally, the central region of these clusters are well approximated with a\ntwo-temperature model, where the inner temperature represents the multiphase\nstatus of the core and the outer temperature is a measure of the ambient gas\ntemperature.Following this observational evidence, I extend the use of the\nbeta-model to a two-phase gas emission, where the two components coexist within\na boundary radius r_cool and the ambient gas alone fills the volume shell at\nradius above r_cool. This simple model still provides an analytic expression\nfor the total surface brightness profile. Based upon a physically meaningful\nmodel for the X-ray emission, this formula can be used (i) to improve\nsignificantly the modeling of the surface brightness profile of cooling flow\nclusters of galaxies when compared to the standard beta-model results, (ii) to\nconstrain properly the physical characteristics of the intracluster plasma in\nthe outskirts, like, e.g., the ambient gas temperature.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/320857",
      "title": "The Radio Galaxy Populations of Nearby Northern Abell Clusters",
      "abstract": "  We report on the use of the NRAO VLA Sky Survey (NVSS) to identify radio\ngalaxie s in eighteen nearby Abell clusters. The listings extend from the cores\nof the clusters out to radii of 3 Mpc, which corresponds to 1.5 Abell radii and\napproximately four orders of magnitude in galaxy density. To create a truly\nuseful catalog, we have collected optical spectra for nearly all of the\ngalaxies lacking public velocity measurements. Consequently, we are able to\ndiscriminate between those radio galaxies seen in projection on the cluster and\nthose which are in actuality cluster members. The resulting catalog consists of\n329 cluster radio galaxies plus 138 galaxies deemed foreground/background\nobjects, and new velocity measurements are reported for 273 of these radio\ngalaxies.\n  The motivation for the catalog is the study of galaxy evolution in the\ncluster environment. The radio luminosity function (RLF) is a powerful tool in\nthe identification of active galaxies, as it is dominated by star-forming\ngalaxies at intermediate luminosities and active galactic nuclei (AGN) at\nhigher luminosities. The flux limit of the NVSS allows us to identify AGN and\nstar- forming galaxies down to star formation rates (SFR) less than 1 solar\nmass per year. This sensitivity, coupled with the all-sky nature of the NVSS,\nallows us to produce a catalog of considerable depth and breadth. In addition\nto these data, we report detected infrared fluxes and upper limits obtained\nfrom IRAS data. It is hoped that this database will prove useful in a number of\npotential studies of the effect of environment on galaxy evolution.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1046/j.1365-8711.2002.05673.x",
      "title": "The redshift and scale dependence of the cosmic shear signal from\n  numerical simulations",
      "abstract": "  The weak lensing shear signal has been measured numerically in $N$-body\nsimulations at 14 different redshifts ($z_s = 0.1$ to 3.6) and on angular\nscales of $\\theta = 2'$ to 32'. In addition, the data have been validated by\nanalytical computations for an identical cosmology, with density parameter\n$\\Omega_m = 0.3$ and vacuum energy density parameter $\\lambda_0 = 0.7$. This\npaper reports on the scale and redshift dependence of the shear variance,\n$<\\gamma^2>$, which may be described by a simple formula of the form\n$<\\gamma^2>(\\theta,z_s) = a(\\theta)z_s^{b(\\theta)}$. The redshift dependence\nfor source redshifts up to 1.6, is found to be close to $z_s^2$, which is a\nstronger dependence than earlier analytical predictions ($<\\gamma^2 > \\propto\nz_s^{1.52}$), although, at higher redshifts, the $z_s$ dependence of the shear\nvariance is clearly less steep. The strong redshift dependence further\nemphasises the need to know the precise redshift distribution for the galaxy\nsources in any given survey, so that they can be allocated to redshift bins\naccordingly, and the cosmic shear signal correctly interpreted. Equations are\nalso given for the variance in the reduced shear, which is a more directly\nmeasurable quantity observationally.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Negative skewness of radial pairwise velocity in the quasi-nonlinear\n  regime: Zel'dovich approximation",
      "abstract": "  According to N-body numerical simulations, the radial pairwise velocities of\ngalaxies have negative skewness in the quasi-nonlinear regime. To understand\nits origin, we calculate the probability distribution function of the radial\npairwise velocity using the Zel'dovich approximation, i.e., an analytical\napproximation for gravitational clustering. The calculated probability\ndistribution function is in good agreement with the result of N-body\nsimulations. Thus the negative skewness originates in relative motions of\ngalaxies in the clustering process that the infall dominates over the\nexpansion.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/341139",
      "title": "Bow Shocks from Neutron Stars: Scaling Laws and HST Observations of the\n  Guitar Nebula",
      "abstract": "  The interaction of high-velocity neutron stars with the interstellar medium\nproduces bow shock nebulae, where the relativistic neutron star wind is\nconfined by ram pressure. We present multi-wavelength observations of the\nGuitar Nebula, including narrow-band H-alpha imaging with HST/WFPC2, which\nresolves the head of the bow shock. The HST observations are used to fit for\nthe inclination of the pulsar velocity vector to the line of sight, and to\ndetermine the combination of spindown energy loss, velocity, and ambient\ndensity that sets the scale of the bow shock. We find that the velocity vector\nis most likely in the plane of the sky. We use the Guitar Nebula and other\nobserved neutron star bow shocks to test scaling laws for their size and\nH-alpha emission, discuss their prevalence, and present criteria for their\ndetectability in targeted searches. The set of H-alpha bow shocks shows\nremarkable consistency, in spite of the expected variation in ambient densities\nand orientations. Together, they support the assumption that a pulsar's\nspindown energy losses are carried away by a relativistic wind that is\nindistinguishable from being isotropic. Comparison of H-alpha bow shocks with\nX-ray and nonthermal, radio-synchrotron bow shocks produced by neutron stars\nindicates that the overall shape and scaling is consistent with the same\nphysics. It also appears that nonthermal radio emission and H-alpha emission\nare mutually exclusive in the known objects and perhaps in all objects.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Redshift of Galaxy Clusters from the Sunyaev-Zel'dovich effect",
      "abstract": "  We develop a new method for estimating the redshift of galaxy clusters\nthrough resolved images of the Sunyaev-Zel'dovich effect (SZE). Our method is\nbased on morphological observables which can be measured by actual and future\nSZE experiments. The method is tested using a set of high resolution\nhydrodynamical simulations of galaxy clusters at different redshifts. The\nmethod combines the observables in a principal component analysis. We show how\nthis can give an estimate of the redshift of the galaxy clusters. Although the\nuncertainty in the redshift estimation is large, the method should be useful\nfor future SZE surveys where hundreds of clusters are expected to be detected.\nA first preselection of the high redshift candidates could be done using our\nproposed morphological redshift estimator.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1046/j.1365-8711.2003.06160.x",
      "title": "R Aquarii spectra revisited by SUMA",
      "abstract": "  We analyse the optical spectra and the UV spectral evolution of the jets and\nof the HII region inside the R Aquarii binary system by the code SUMA which\nconsistently accounts for shock and photoionization. The temperature of the hot\nstar results 80,000 K as for a white dwarf. We find that the shock velocity in\nthe NE jet increased between 1983 and 1989. The spectral evolution between 1989\nand 1991 of the SW jet indicates that a larger contribution from low\ndensity-velocity matter affects the 1991 spectra. The evolution of the UV\nspectra from 8/11/1980 to 26/5/1991 in the HII region indicates that the\nreverse shock is actually a standing shock. The results obtained by modelling\nthe line spectra are cross-checked by the fit of the continuum SED. It is found\nthat a black-body temperature of 2800 K reproduces the radiation from the red\ngiant. A black-body emission component corresponding to 1000 K is emitted by\ndust in the surrounding of the red giant. Model calculations confirm that the\nradio emission is of thermal origin. We found that the NE jet bulk emission is\nat a distance of about 2 (15) cm from the internal system, while the distance\nof the SW jet bulk is about 6 (14) cm. The distance of the reverse shock from\nthe hot source in the internal region is < 9 (13) cm.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/367791",
      "title": "The Behaviour of the Optical and X-ray Emission from Scorpius X-1",
      "abstract": "  In 1970, Hiltner & Mook reported the results of the first multiyear study of\nthe optical emission from Sco X-1. They found that the Sco X-1 B-magnitude\nhistograms changed from year to year. Subsequent multi-wavelength campaigns\nconfirmed the variable nature of these optical histograms and also found that\nthe X-ray and optical emissions were only correlated when Sco X-1 was brighter\nthan about B = 12.6. Models had suggested that the optical emission from this\nsource arose from X-rays reprocessed in an accretion disk surrounding the\ncentral neutron star. It was therefore difficult to explain why the optical and\nX-ray fluxes were not more closely correlated. In 1994 and 1995, two new\nsimultaneous optical and X-ray campaigns on Sco X-1 were conducted with the\nBurst and Transient Source Experiment on the Compton Gamma Ray Observatory and\nthe 1 m Yale telescope at Cerro Tololo Inter-American Observatory. Using these\ndata and models by Psaltis, Lamb & Miller, it is now possible to provide a\nqualitative picture of how the X-ray and optical emissions from Sco X-1 are\nrelated. Differences in the B-magnitude histograms are caused by variations in\nthe mass accretion rate and the relatively short time period usually covered by\noptical investigations. The tilted Gamma pattern seen in plots of the\nsimultaneous X-ray and optical emission from Sco X-1 arises from (1) the nearly\nlinear relation between the optical B magnitude and the mass accretion rate in\nthe range 13.3 > B > 12.3 and an asymptotic behaviour in the B magnitude\noutside this range, and (2) a double-valued relation between the X-ray emission\nand mass accretion rate along the normal branch and the lower flaring branch of\nthis source.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.1629427",
      "title": "High Redshift Supermassive Black Holes: X-ray observations",
      "abstract": "  The spectrum of the hard X-ray background records the history of accretion\nprocesses integrated over the cosmic time. Several observational and\ntheoretical evidences indicate that a significant fraction of the energy\ndensity is obscured by large columns of gas and dust. X-ray surveys are the\nmost efficient way to trace accretion onto supermassive black holes, since\nobscured, accreting sources are more difficult to select at all other\nwavelengths. The current status of hard X-ray surveys after the recent\nobservations carried out with Chandra and XMM-Newton satellites is reviewed\nalong with the results of extensive follow-up multiwavelength observations. In\nparticular recent results concerning the physical and evolutive properties of\nthe supermassive black holes hosted by X-ray selected Active Galactic Nuclei at\nhigh redshifts will be discussed.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Cosmic Rays in the 'Knee'-Region - Recent Results from KASCADE -",
      "abstract": "  Recent results from the KASCADE experiment on measurements of cosmic rays in\nthe energy range of the knee are presented. Emphasis is placed on energy\nspectra of individual mass groups as obtained from sophisticated unfolding\nprocedures applied to the reconstructed electron and truncated muon numbers of\nEAS. The data show a knee-like structure in the energy spectra of light\nprimaries (p, He, C) and an increasing dominance of heavy ones (A>20) towards\nhigher energies. This basic result is robust against uncertainties of the\napplied interaction models QGSJET and SIBYLL. Slight differences observed\nbetween experimental data and EAS simulations provide important clues for\nimprovements of the interaction models. The data are complemented by new limits\non global anisotropies in the arrival directions of CRs and by upper limits on\npoint sources. Astrophysical implications for discriminating models of maximum\nacceleration energy vs galactic diffusion/drift models of the knee are\ndiscussed based on this data. To improve the reconstruction quality and\nstatistics around 10^17 eV, KASCADE has recently been extended by a factor 10\nin area. The status and expected performance of the new experiment\nKASCADE-Grande is presented.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361:200400035",
      "title": "The G9.62+0.19-F Hot Molecular Core - The infrared view on very young\n  massive stars",
      "abstract": "  (abridged) We present the results of an extensive infrared study of the\nmassive star-forming region G9.62+0.19. The data cover information from broad-\nand narrow-band filters in the wavelength range from 1 to 19 micrometer and are\nobtained with ESO's infrared cameras ISAAC and TIMMI2 and with SpectroCam-10\n(Mt. Palomar). The high sensitivity and resolution provided by these facilities\nrevealed intriguing new details of this star-forming region and especially\nabout the embedded hot molecular core (HMC) - component F. We analyse the newly\nfound infrared sub-structure of four objects in this HMC region. While one of\nthese objects (F2) is probably a foreground field star, the nature of the\nbrightest object in the near-infrared there (F1) remains somewhat enigmatic.\nOur new astrometry proves that this object is not coincident with the peak of\nthe molecular line emission of the HMC, but displaced by 1.7 arcsecs (nearly\n10000 AU on a linear scale). We estimate this object to be an additional\nembedded object with a dense dust shell. Very near the HMC location we find L'\nband emission which strongly rises in flux towards longer wavelengths. We\npresume that this emission (F4) arises from the envelope of the HMC which is\nknown to be associated with a molecular outflow roughly aligned along the line\nof sight. Thus, the clearing effect of this outflow causes strong deviations\nfrom spherical symmetry which might allow infrared emission from the HMC to\nescape through the outflow cavities. This presents the first direct detection\nof an HMC at a wavelength as short as 3.8 micron. At 11.7 and 18.75 micron, the\nHMC counterpart F4 ultimately proves to be the most luminous IR source within\nthe G9.62+0.19-F region.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The All Sky Automated Survey. The Catalog of Variable Stars. IV.18^h -\n  24^h Quarter of the Southern Hemisphere",
      "abstract": "  In this paper we present the fourth part of the photometric data from the 9x9\ndeg ASAS camera monitoring the whole southern hemisphere in V-band. Preliminary\nlist (based on observations obtained since January 2001) of variable stars\nlocated between RA 18^h - 24^h is released. 10311 stars brighter than V=14 were\nfound to be variable (1641 eclipsing, 1116 regularly pulsating, 938 Mira and\n6616 other stars). Light curves have been classified using the automated\nalgorithm taking into account periods, amplitudes, fourier coefficients of the\nlight curves, 2MASS colors and IRAS infrared fluxes. Basic photometric\nproperties are presented in the tables and some examples of thumbnail light\ncurves are printed for reference. All photometric data are available over the\nINTERNET at http://www.astrouw.edu.pl/~gp/asas/asas.html or\nhttp://archive.princeton.edu/~asas\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Nonradial mode excitation as the cause of the Blazhko effect in RR Lyrae\n  stars",
      "abstract": "  A significant fraction of RR Lyrae stars exhibits amplitude and/or phase\nmodulation known as the the Blazhko effect. The oscillation spectra suggest\nthat, at least in most of the cases, excitation of nonradial modes in addition\nto the dominant radial modes is responsible for the effect. Though model\ncalculations predict that nonradial modes may be excited, there are problems\nwith explaining their observed properties in terms of finite amplitude\ndevelopment of the linear instability. We propose a scenario, which like some\nprevious, postulates energy transfer from radial to nonradial modes, but avoids\nthose problems. The scenario predicts lower amplitudes in Blazhko stars. We\ncheck this prediction with a new analysis of the Galactic bulge RR Lyrae stars\nfrom OGLE-II database. The effect is seen, but the amplitude reduction is\nsmaller than predicted.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/430054",
      "title": "The uBVI Photometric System. II. Standard Stars",
      "abstract": "  Paper I of this series described the design of a CCD-based photometric system\nthat is optimized for ground-based measurements of the size of the Balmer\ndiscontinuity in stellar spectra. This \"uBVI\" system combines the Thuan-Gunn u\nfilter with the standard Johnson-Kron-Cousins BVI filters, and it can be used\nto discover luminous yellow supergiants in extragalactic systems and\npost-asymptotic-giant-branch stars in globular clusters and galactic halos. In\nthe present paper we use uBVI observations obtained on 54 nights with 0.9-m\ntelescopes at Kitt Peak and Cerro Tololo to construct a catalog of standardized\nu magnitudes for standard stars taken from the 1992 catalog of Landolt. We\ndescribe the selection of our 14 Landolt fields, and give details of the\nphotometric reductions, including red-leak and extinction corrections,\ntransformation of all of the observations onto a common magnitude system, and\nestablishment of the photometric zero point. We present a catalog of u\nmagnitudes of 103 stars suitable for use as standards. We show that data\nobtained with other telescopes can be transformed to our standard system with\nbetter than 1% accuracy.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2005.09104.x",
      "title": "A dearth of planetary transits in the direction of NGC 6940",
      "abstract": "  We present results of our survey for planetary transits in the field of NGC\n6940. We think nearly all of our observed stars are field stars. We have\nobtained high precision (3-10 millimags at the bright end) photometric\nobservations of 50,000 stars spanning 18 nights in an attempt to identify low\namplitude and short period transit events. We have used a matched filter\nanalysis to identify 14 stars that show multiple events, and four stars that\nshow single transits. Of these 18 candidates, we have identified two that\nshould be further researched. However, none of the candidates are convincing\nhot Jupiters.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0264-9381/23/15/020",
      "title": "Cosmological models with Gurzadyan-Xue dark energy",
      "abstract": "  The formula for dark energy density derived by Gurzadyan and Xue provides a\nvalue of density parameter of dark energy in remarkable agreement with current\ncosmological datasets, unlike numerous phenomenological dark energy scenarios\nwhere the corresponding value is postulated. This formula suggests the\npossibility of variation of physical constants such as the speed of light and\nthe gravitational constant. Considering several cosmological models based on\nthat formula and deriving the cosmological equations for each case, we show\nthat, in all models source terms appear in the continuity equation. So, one one\nhand, GX models make up a rich set covering a lot of currently proposed models\nof dark energy, on the other hand, they reveal hidden symmetries, with a\nparticular role of the separatrix $\\Omega_m=2/3$, and link with the issue of\nthe content of physical constants.\n",
      "subjects": [
        "astro-ph",
        "hep-th",
        "physics.class-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1111/j.1365-2966.2005.10018.x",
      "title": "Average Extinction Curves and Relative Abundances for QSO Absorption\n  Line Systems at 1 <= z_abs < 2",
      "abstract": "  We have studied a sample of 809 Mg II absorption systems with 1.0 < z_abs <\n1.86 in the spectra of SDSS QSOs, with the aim of understanding the nature and\nabundance of the dust and the chemical abundances in the intervening absorbers.\nNormalized, composite spectra were derived, for abundance measurements, for the\nfull sample and several sub-samples, chosen on the basis of the line strengths\nand other absorber and QSO properties. Average extinction curves were obtained\nfor the sub-samples by comparing their geometric mean spectra with those of\nmatching samples of QSOs without absorbers in their spectra. There is clear\nevidence for the presence of dust in the intervening absorbers. The 2175 A\nfeature is not present in the extinction curves, for any of the sub-samples.\nThe extinction curves are similar to the SMC extinction curve with a rising UV\nextinction below 2200 A. The absorber rest frame colour excess, E(B-V), derived\nfrom the extinction curves, depends on the absorber properties and ranges from\n< 0.001 to 0.085 for various sub-samples. The column densities of several ions\ndo not show such a correspondingly large variation. The depletion pattern is\nsimilar to halo clouds in the Galaxy. Assuming an SMC gas-to-dust ratio we find\na trend of increasing abundance with decreasing extinction; systems with N_H I\n\\~ 10^{20} cm^{-2} show solar abundance of Zn. The large velocity spread of\nstrong Mg II systems seems to be mimicked by weak lines of other elements. The\nionization of the absorbers, in general appears to be low. QSOs with absorbers\nare, in general, at least three times as likely to have highly reddened spectra\nas compared to QSOs without any absorption systems in their spectra.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.newar.2006.06.073",
      "title": "Evolution of the Black Hole - Bulge Relationship in QSOs",
      "abstract": "  QSOs allow study of the evolution of the relationship between black holes in\ngalactic nuclei and their host galaxies. The black hole mass can be derived\nfrom the widths of the broad emission lines, and the stellar velocity\ndispersion (sigma_*) of the host galaxy can be inferred from the narrow\nemission lines. Results based on [OIII] and [OII] line widths indicate that the\nblack hole mass - sigma_* relationship, at redshifts up to z ~ 2, is consistent\nwith no evolution or an increase of up to ~ 0.5 dex in black hole mass at fixed\nsigma_*. CO line widths offer an estimate of sigma_* for luminous QSOs at high\nredshifts. The available objects from z ~ 4 to 6 have very massive black holes,\n\\~ 10^9.5 M_sun, but their CO line widths suggest much smaller host galaxies\nthan would be expected by the local black hole mass - sigma_* relationship. The\nmost massive black holes must continue to reside in comparatively modest\ngalaxies today, because their number density inferred from QSO statistics\nexceeds the present-day abundance of proportionally massive galaxies.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The XMM-Newton view of GRS1915+105 during a \"plateau\"",
      "abstract": "  Two XMM-Newton observations of the black-hole binary GRS1915+105 were\ntriggered in 2004 (April 17 and 21), during a long \"plateau\" state of the\nsource. We analyzed the data collected with EPIC-pn in Timing and Burst modes,\nrespectively. No thermal disc emission is required by the data; the spectrum is\nwell fitted by four components: a primary component (either a simple power law\nor thermal Comptonization) absorbed by cold matter with abundances different\nthan those of standard ISM; reprocessing from an ionized disc; emission and\nabsorption lines; and a soft X-ray excess around 1 keV. The latter is not\nconfirmed by RGS (which were used in the second observation only); if real, the\nexcess could be due to reflection from the optically thin, photoionized plasma\nof a disc wind, in which case it may provide a way to disentangle intrinsic\nfrom interstellar absorption. Indeed, the former is best traced by the higher\nabundances of heavier elements, while an independent estimate of the latter may\nbe given by the value we get for the disc wind component only, which roughly\ncoincides with what is found for lower-Z species.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1051/0004-6361:20064856",
      "title": "The X-ray afterglow of the short gamma ray burst 050724",
      "abstract": "  Short duration (<2 s) Gamma-ray bursts (GRBs) have been a mystery since their\ndiscovery. Until May 2005 very little was known about short GRBs, but this\nsituation has changed rapidly in the last few months since the Swift and HETE-2\nsatellites have made it possible to discover X-ray and optical counterparts to\nthese sources. Positional associations indicate that short GRBs arise in\nclose-by galaxies (z<0.7). Here we report on a detailed study of the short GRB\n050724 X-ray afterglow. This burst shows strong flaring variability in the\nX-ray band. It clearly confirms early suggestions of X-ray activity in the\n50-100 s time interval following the GRB onset seen with BATSE. Late flare\nactivity is also observed. These observations support the idea that flares are\nrelated to the inner engine for short GRBs, as well as long GRBs.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/511187",
      "title": "Simplified solution to determination of a binary orbit",
      "abstract": "  We present a simplified solution to orbit determination of a binary system\nfrom astrometric observations. An exact solution was found by Asada, Akasaka\nand Kasai by assuming no observational errors. We extend the solution\nconsidering observational data. The generalized solution is expressed in terms\nof elementary functions, and therefore requires neither iterative nor numerical\nmethods.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/978-3-540-73484-0_53",
      "title": "Tracing the evolution in the iron content of the ICM",
      "abstract": "  We present a Chandra analysis of the X-ray spectra of 56 clusters of galaxies\nat z>0.3, which cover a temperature range of 3>kT>15 keV. Our analysis is aimed\nat measuring the iron abundance in the ICM out to the highest redshift probed\nto date. We find that the emission-weighted iron abundance measured within\n(0.15-0.3)R_vir in clusters below 5 keV is, on average, a factor of ~2 higher\nthan in hotter clusters, following Z(T)~0.88T^-(0.47)Z_o, which confirms the\ntrend seen in local samples. We made use of combined spectral analysis\nperformed over five redshift bins at 0.3>z>1.3 to estimate the average emission\nweighted iron abundance. We find a constant average iron abundance Z_Fe~0.25Z_o\nas a function of redshift, but only for clusters at z>0.5. The\nemission-weighted iron abundance is significantly higher (Z_Fe~0.4Z_o) in the\nredshift range z~0.3-0.5, approaching the value measured locally in the inner\n0.15R_vir radii for a mix of cool-core and non cool-core clusters in the\nredshift range 0.1<z<0.3. The decrease in Z_Fe with redshift can be\nparametrized by a power law of the form ~(1+z)^(-1.25). The observed evolution\nimplies that the average iron content of the ICM at the present epoch is a\nfactor of ~2 larger than at z=1.2. We confirm that the ICM is already\nsignificantly enriched (Z_Fe~0.25Z_o) at a look-back time of 9 Gyr. Our data\nprovide significant constraints on the time scales and physical processes that\ndrive the chemical enrichment of the ICM.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/511330",
      "title": "Infrared Photometric Analysis of White Dwarfs from The Two Micron All\n  Sky Survey and the Spitzer Space Telescope",
      "abstract": "  We review the available near- and mid-infrared photometry for white dwarfs\nobtained from the Two Micron All-Sky Survey (2MASS) and by the Spitzer Space\nTelescope. Both data sets have recently been used to seek white dwarfs with\ninfrared excesses due to the presence of unresolved companions or circumstellar\ndisks, and also to derive the atmospheric parameters of cool white dwarfs. We\nfirst attempt to evaluate the reliability of the 2MASS photometry by comparing\nit with an independent set of published JHK CIT magnitudes for 160 cool white\ndwarf stars, and also by comparing the data with the predictions of detailed\nmodel atmosphere calculations. The possibility of using 2MASS to identify\nunresolved M dwarf companions or circumstellar disks is then discussed. We also\nrevisit the analysis of 46 binary candidates from Wachter et al. using the\nsynthetic flux method and confirm the large near-infrared excesses in most\nobjects. We perform a similar analysis by fitting Spitzer 4.5 and 8 micron\nphotometric observations of white dwarfs with our grid of model atmospheres,\nand demonstrate the reliability of both the Spitzer data and the theoretical\ncalculations up to 8 micron. Finally, we search for massive disks resulting\nfrom the merger of two white dwarfs in a 2MASS sample composed of 57 massive\ndegenerates, and show that massive disks are uncommon in such stars.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.76.023508",
      "title": "Probing the Coupling between Dark Components of the Universe",
      "abstract": "  We place observational constraints on a coupling between dark energy and dark\nmatter by using 71 Type Ia supernovae (SNe Ia) from the first year of the\nfive-year Supernova Legacy Survey (SNLS), the cosmic microwave background (CMB)\nshift parameter from the three-year Wilkinson Microwave Anisotropy Probe\n(WMAP), and the baryon acoustic oscillation (BAO) peak found in the Sloan\nDigital Sky Survey (SDSS). The interactions we study are (i) constant coupling\ndelta and (ii) varying coupling delta(z) that depends on a redshift z, both of\nwhich have simple parametrizations of the Hubble parameter to confront with\nobservational data. We find that the combination of the three databases\nmarginalized over a present dark energy density gives stringent constraints on\nthe coupling, -0.08 < delta < 0.03 (95% CL) in the constant coupling model and\n-0.4 < delta_0 < 0.1 (95% CL) in the varying coupling model, where delta_0 is a\npresent value. The uncoupled LambdaCDM model (w_X = -1 and delta = 0) still\nremains a good fit to the data, but the negative coupling (delta < 0) with the\nequation of state of dark energy w_X < -1 is slightly favoured over the\nLambdaCDM model.\n",
      "subjects": [
        "astro-ph",
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/187003",
      "title": "Focusing of Alfvenic Power in the Context of Gamma-Ray Burst Emissivity",
      "abstract": "  Highly dynamic magnetospheric perturbations in neutron star environments can\nnaturally account for the features observed in Gamma-ray Burst spectra. The\nsource distribution, however, appears to be extragalactic. Although\nnoncatastrophic isotropic emission mechanisms may be ruled out on energetic and\ntiming arguments, MHD processes can produce strongly anisotropic gamma-rays\nwith an observable flux out to distances of around 1-2 Gpc. Here we show that\nsheared Alfven waves propagating along open magnetospheric field lines at the\npoles of magnetized neutron stars transfer their energy dissipationally to the\ncurrent sustaining the field misalignment and thereby focus their power into a\nspatial region around 1000 times smaller than that of the crustal disturbance.\nThis produces a strong (observable) flux enhancement along certain directions.\nWe apply this model to a source population of ``turned-off'' pulsars that have\nnonetheless retained their strong magnetic fields and have achieved alignment\nat a period of greater than 5 seconds.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0370-2693(96)00815-5",
      "title": "Galactic diffusion and the antiprotron signal of supersymmetric dark\n  matter",
      "abstract": "  The leaky box model is now ruled out by measurements of a cosmic ray gradient\nthroughout the galactic disk. It needs to be replaced by a more refined\ntreatment which takes into account the diffusion of cosmic rays in the magnetic\nfields of the Galaxy. We have estimated the flux of antiprotons on the Earth in\nthe framework of a two-zone diffusion model. Those species are created by the\nspallation reactions of high-energy nuclei with the interstellar gas. Another\npotential source of antiprotons is the annihilation of supersymmetric particles\nin the dark halo that surrounds our Galaxy. In this letter, we investigate both\nprocesses. Special emphasis is given to the antiproton signature of\nsupersymmetric dark matter. The corresponding signal exceeds the conventional\nspallation flux below 300 MeV, a domain that will be thoroughly explored by the\nAntimatter Spectrometer experiment. The propagation of the antiprotons produced\nin the remote regions of the halo back to the Earth plays a crucial role.\nDepending on the energy, the leaky box estimates are wrong by a factor varying\nfrom 0.5 up to 3.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/310723",
      "title": "The Nuclear Ionized Gas in the Radio Galaxy M84 (NGC 4374)",
      "abstract": "  We present optical images of the nucleus of the nearby radio galaxy M84 (NGC\n4374 = 3C272.1) obtained with the Wide Field/Planetary Camera 2 (WFPC2) aboard\nthe Hubble Space Telescope (HST). Our three images cover the H$\\alpha$ + [N II]\nemission lines as well as the V and I continuum bands. Analysis of these images\nconfirms that the H$\\alpha$ + [N II] emission in the central 5'' (410 pc) is\nelongated along position angle (P.A.) $\\approx 72\\arcdeg$, which is roughly\nparallel to two nuclear dust lanes.Our high-resolution images reveal that the\nH$\\alpha$ + [N II] emission has three components, namely a nuclear gas disk,an\n`ionization cone', and outer filaments. The nuclear disk of ionized gas has\ndiameter $\\approx 1'' = 82$ pc and major axis P.A. $\\approx 58\\arcdeg \\pm\n6\\arcdeg$. On an angular scale of $0\\farcs5$, the major axis of this nuclear\ngas disk is consistent with that of the dust. However, the minor axis of the\ngas disk (P.A. $\\approx 148\\arcdeg$) is tilted with respect to that of the\nfilamentary H$\\alpha$ + [N II] emission at distances > 2'' from the nucleus;\nthe minor axis of this larger scale gas is roughly aligned with the axis of the\nkpc-scale radio jets (P.A. $\\approx 170\\arcdeg$). The ionization cone (whose\napex is offset by $\\approx 0\\farcs3$ south of the nucleus) extends 2'' from the\nnucleus along the axis of the southern radio jet. This feature is similar to\nthe ionization cones seen in some Seyfert nuclei, which are also aligned with\nthe radio axes.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/305325",
      "title": "Two-Component Fokker-Planck Models for the Evolution of Isolated\n  Globular Clusters",
      "abstract": "  Two-component (normal and degenerate stars) models are the simplest\nrealization of clusters with a mass spectrum because high mass stars evolve\nquickly into degenerates, while low mass stars remain on the main-sequence for\nthe age of the universe. Here we examine the evolution of isolated globular\nclusters using two-component Fokker-Planck (FP) models that include heating by\nbinaries formed in tidal capture and in three-body encounters. Three-body\nbinary heating dominates and the postcollapse expansion is self-similar, at\nleast in models with total mass M <= 3 x 10^5 M_\\odot, initial half-mass radius\nr_{h,i} >= 5 pc, component mass ratio m_2/m_1 <= 2, and number ratio N_1/N_2 <=\n300 when m_2=1.4 M_\\odot. We derive scaling laws for \\rho_c, v_c, r_c, and r_h\nas functions of m_1/m_2, N, M, and time t from simple energy-balance arguments,\nand these agree well with the FP simulations. We have studied the conditions\nunder which gravothermal oscillations (GTOs) occur. If E_{tot} and E_c are the\nenergies of the cluster and of the core, respectively, and t_{rh} and t_c are\ntheir relaxation times, then \\epsilon \\equiv (E_{tot}/t_{rh})/(E_c/t_{rc}) is a\ngood predictor of GTOs: all models with \\epsilon>0.01 are stable, and all but\none with \\epsilon < 0.01 oscillate. We derive a scaling law for \\epsilon\nagainst N and m_1/m_2 and compared with our numerical results. Clusters with\nlarger m_2/m_1 or smaller N are stabler.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S1384-1076(98)00013-X",
      "title": "Star Formation Histories versus Redshift : Consequences for Overall\n  Metallicity and Deuterium Destruction",
      "abstract": "  The flood of new data on deep surveys, and above all the CFRS\n(Canada-France-Redshift-Survey), has had a great impact on studies of galactic\nevolution. On the basis of cosmological models consistent with the improved\nvalues of the Hubble parameter, different star formation histories are tested\nagainst the observed UV, B and IR broad band comoving luminosity densities.\nUsing these spectrophotometric results, we analyze the global metal enrichment\nwith the help of chemical evolutionary models and we discuss the pertinence of\ndifferent metallicity tracers (quasar absorption systems and clusters of\ngalaxies) as representative of the bulk chemical evolution of the Universe.\nMoreover, as deuterium is very fragile, this isotope is destroyed in all stars\nand its evolution is particularly sensitive to the history of star formation.\nRelying on models constrained to fit the solar vicinity, it is shown that\nmodels with high D destruction corresponding to a large decrease of the star\nformation rate (SFR) from $z=1.5$ to 0 are in good agreement with\nspectrophotometric data. In contrast, low D destruction models which require\nonly a moderate variation of the SFR in the same redshift range seem to\nencounter difficulties in matching the evolution of the luminosity densities\n(UV, B and IR) versus redshift. The sensitivity of the results with the\ncosmological models of the universe is discussed.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1046/j.1365-8711.1998.01799.x",
      "title": "What is the nature of RX J0720.4-3125?",
      "abstract": "  RX J0720.4-3125 has recently been identified as a pulsating soft X-ray source\nin the ROSAT all-sky survey with a period of 8.391 s. Its spectrum is well\ncharacterized by a black-body with a temperature of $8 \\times 10^5$ K. We\npropose that the radiation from this object is thermal emission from a cooling\nneutron star. For this black-body temperature we can obtain a robust estimate\nof the object's age of $\\sim 3 \\times 10^5$ yr, yielding a polar field $\\sim\n10^{14}$ G for magnetic-dipole spin down and a value of ${\\dot P}$ compatible\nwith current observations.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/BFb0104721",
      "title": "Study of the Local Interstellar Medium using Pulsar Scintillation",
      "abstract": "  We present here the results from an extensive scintillation study of twenty\npulsars in the dispersion measure (DM) range 3 - 35 pc cm^-3 carried out using\nthe Ooty Radio Telescope, to investigate the distribution of ionized material\nin the local interstellar medium (LISM). Our analysis reveals several anomalies\nin the scattering strength, which suggest that the distribution of scattering\nmaterial in the Solar neighborhood is not uniform. Our model suggests the\npresence of a low density bubble surrounded by a shell of much higher density\nfluctuations. We are able to put some constraints on geometrical and scattering\nproperties of such a structure, and find it to be morphologically similar to\nthe Local Bubble known from other studies.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Large-scale perturbations in the circumstellar envelopes of Be/X-ray\n  binaries",
      "abstract": "  We investigate the spectroscopic characteristics of the optical components of\nBe/X-ray binary systems, using data collected during our seven-year monitoring\ncampaign. We find examples of major changes in the emission line profiles\nassociated with Type II X-ray outbursts, later developing into V/R variability\ncycles. We show that the time-scales for V/R variability in Be/X-ray transients\nextend from a few weeks to years and interpret all these changes as due to the\npresence of global disruptions of the axisymmetric density distribution in the\nextended envelopes of the Be stars in these systems. The association between\nX-ray outbursts and V/R variability, the occurrence of very fast changes and\nthe very short quasi-periods of variability displayed by Be/X-ray binaries lead\nus to conclude that the presence of the neutron star is an important factor\naffecting the dynamics of the disc-like envelopes. The interaction between the\ncompact companion and the disc would explain the correlation between H-alpha\nstrength and orbital period recently found. The characteristics of the V/R\ncycles are, however, mainly independent of the binary parameters.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Primordial Magnetic Fields that Last?",
      "abstract": "  The magnetic fields we observe in galaxies today may have their origins in\nthe very early universe. While a number of mechanisms have been proposed which\nlead to an appreciable field amplitude at early times, the subsequent evolution\nof the field is of crucial importance, especially whether the correlation\nlength of the field can grow as large as the size of a protogalaxy. This talk\nis a report on work in progress, in which we consider the fate of one specific\nprimordial field scenario, driven by pseudoscalar effects near the electroweak\nphase transition. We argue that such a scenario has a number of attractive\nfeatures, although it is still uncertain whether a field of appropriate size\ncan survive until late times.\n",
      "subjects": [
        "astro-ph",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1086/312321",
      "title": "Phase Transitions in Neutron Stars and Maximum Masses",
      "abstract": "  Using the most recent realistic effective interactions for nuclear matter\nwith a smooth extrapolation to high densities including causality, we constrain\nthe equation of state and calculate maximum masses of rotating neutron stars.\nFirst and second order phase transitions to, e.g., quark matter at high\ndensities are included. If neutron star masses of $\\sim 2.3M_\\odot$ from\nquasi-periodic oscillations in low mass X-ray binaries are confirmed, a soft\nequation of state as well as strong phase transitions can be excluded in\nneutron star cores.\n",
      "subjects": [
        "astro-ph",
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Photomeson production in astrophysical sources",
      "abstract": "  Photomeson production is the main energy loss for relativistic nucleons in\ndense radiation fields like the cosmic microwave background and the radiation\nfields in Gamma Ray Bursts (GRB) and jets of Active Galactic Nuclei (AGN). In\nthis paper we study photomeson production in typical GRB and AGN jet radiation\nfields by using the recently developed Monte Carlo event generator SOPHIA (see\nthese proceedings). We discuss processes that are relevant for the physics of\ncosmic ray acceleration and the production of neutrinos and gamma rays. We\ncompare our results with widely used approximations, and find significant\ndeviations, particularly for GRBs. The photoproduction of antibaryons as a so\nfar not considered effect in astrophysics is briefly discussed.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Polarization and Variations of BL Lacertae Objects",
      "abstract": "  BL Lacertae objects are an extreme subclass of AGNs showing rapid and\nlarge-amplitude variability, high and variable polarization, and core-dominated\nradio emissions. If a strong beaming effect is the cause of the extreme\nobservation properties, one would expect that these properties would be\ncorrelated with each other. Based on the relativistic beaming model,\nrelationships between the polarization and the magnitude variation in\nbrightness, as well as the core- dominance parameter are derived and used\nstatistically to compare with the observational data of a BL Lacertae object\nsample. The statistical results are consistent with these correlations, which\nsuggests that the polarization, the variation, and the core-dominance parameter\nare possible indications of the beaming effect.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A Serendipitous Search for Hy-Redshift Ly$Alpha$ Emission: A Case Study\n  of Two Sources at $z\\simeq 3$",
      "abstract": "  In the course of our on-going search for serendipitous high-redshift LyA\nemission in deep archival Keck spectra, we discovered two LyA emission line\ncandidates in a moderate dispersion ($\\lambda/{\\Delta \\lambda} +~ 1200$)\nspectrogram. Both lines have high equivalent width (EW_{obs}>= 450A), low\nvelocity dispersions ($\\sigma_v ~ 60 km/s), and deconvolved effective radii\n$r_e ~ 1.0 h_{50}^{-1}$ kpc. Their sizes and luminosities are suggestive of the\nprimeval galaxy model of Lin & Murray (1992), based on the self-similar\ncollapse of an isothermal sphere. We argue that the line emission is LyA, and\nit is stellar in origin. The sources are consistent with being primeval.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "RX J0537.7-7034: The shortest-period supersoft X-ray source",
      "abstract": "  We present new photometric and spectroscopic observations of the transient\nsupersoft X-ray source RX J0537.7-7034 and find a periodicity of approximately\n3.5 hrs. This establishes RX J0537.7-7034 as the supersoft X-ray source with\nthe shortest orbital period. We furthermore derive an inclination of the binary\nsystem of 45<i<70 deg, and the masses of the two binary components: M_accretor\n= 0.6+-0.2 Msun, M_donor = 0.35+-0.02 Msun. This implies that the standard\nscenario of supersoft X-ray sources, in which the donor is thought to be more\nmassive than the accreting white dwarf to ensure high mass transfer rates on a\nthermal timescale (van den Heuvel et al 1992), is not applicable for this\nsystem. We discuss alternative interpretations of this source as a former nova\nin which the thermonuclear flashes have become mild and most accreted mass is\nretained by the white dwarf (SMC 13 type systems), or as a self-sustained\nwind-driven system.\n",
      "subjects": [
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.63.033602",
      "title": "Moment of Inertia and Quadrupole Response Function of a Trapped\n  Superfluid",
      "abstract": "  We derive an explicit relationship between the moment of inertia and the\nquadrupole response function of an interacting gas confined in a harmonic trap.\nThe relationship holds for both Bose and Fermi systems and is well suited to\nreveal the effects of irrotationality of the superfluid motion. Recent\nexperimental results on the scissors mode are used to extract the value of the\nmoment of inertia of a trapped Bose gas and to point out the deviations from\nthe rigid value due to superfluidity.\n",
      "subjects": [
        "cond-mat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1038/35068515",
      "title": "Stable ultrahigh-density magneto-optical recordings using introduced\n  linear defects",
      "abstract": "  The stability of data bits in magnetic recording media at ultrahigh densities\nis compromised by thermal `flips' -- magnetic spin reversals -- of nano-sized\nspin domains, which erase the stored information. Media that are magnetized\nperpendicular to the plane of the film, such as ultrathin cobalt films or\nmultilayered structures, are more stable against thermal self-erasure than\nconventional memory devices. In this context, magneto-optical memories seem\nparticularly promising for ultrahigh-density recording on portable disks, and\nbit densities of $\\sim$100 Gbit inch$^{-2}$ have been demonstrated using recent\nadvances in the bit writing and reading techniques. But the roughness and\nmobility of the magnetic domain walls prevents closer packing of the magnetic\nbits, and therefore presents a challenge to reaching even higher bit densities.\nHere we report that the strain imposed by a linear defect in a magnetic thin\nfilm can smooth rough domain walls over regions hundreds of micrometers in\nsize, and halt their motion. A scaling analysis of this process, based on the\ngeneric physics of disorder-controlled elastic lines, points to a simple way by\nwhich magnetic media might be prepared that can store data at densities in\nexcess of 1 Tbit inch$^{-2}$.\n",
      "subjects": [
        "cond-mat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Vortex dynamics, pinning, and critical currents in a Ginzburg-Landau\n  type-II superconductor",
      "abstract": "  The dynamics of vortices in a type-II superconductor with defects are studied\nby solving the time-dependent Ginzburg-Landau equations in two and three\ndimensions. We show that vortex flux tubes are trapped by volume defects up to\na critical current density where they begin to jump between pinning sites along\nstatic flow channels. We study the dependence of the critical current on the\npinning distribution and find for random distributions a maximum critical\ncurrent equal to a few percent of the depairing current at a pinning density\nthree times larger than the vortex line density. Whereas for a regular\ntriangular pinning array, the critical current is significantly larger when the\npinning density matches the vortex line density.\n",
      "subjects": [
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1143/JPSJ.71.1238",
      "title": "High Temperature Expansion for the SU(n) Heisenberg Model in One\n  Dimension",
      "abstract": "  Thermodynamic properties of the SU($n$) Heisenberg model in one dimension is\nstudied by means of high-temperature expansion for arbitrary $n$. The specific\nheat up to $O[(\\beta J)^{23}]$ and the correlation function up to $O[(\\beta\nJ)^{18}]$ are derived with $\\beta J$ being the antiferromagnetic exchange in\nunits of temperature. It is found for $n>2$ that the specific heat shows a\nshoulder in the high-temperature side of a peak. The origin of this structure\nis clarified by deriving the temperature dependence of the correlation\nfunction. With decreasing temperature, the short-range correlation with\ntwo-site periodicity develops first, and then another correlation with $n$-site\nperiodicity at lower temperature. This behavior is in contrast to that of the\ninverse square interaction model, where the specific heat shows a single peak\naccording to the exact solution. Our algorithm has an advantage that neither\ncomputational time nor memory depends on the multiplicity $n$ per site; the\nseries coefficients are obtained as explicit functions of $n$.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.68.174502",
      "title": "Antiferromagnetic fluctuations and d-wave superconductivity in\n  electron-doped high-temperature superconductors",
      "abstract": "  We show that, at weak to intermediate coupling, antiferromagnetic\nfluctuations enhance d-wave pairing correlations until, as one moves closer to\nhalf-filling, the antiferromagnetically-induced pseudogap begins to suppress\nthe tendency to superconductivity. The accuracy of our approach is gauged by\ndetailed comparisons with Quantum Monte Carlo simulations. The negative\npressure dependence of Tc and the existence of photoemission hot spots in\nelectron-doped cuprate superconductors find their natural explanation within\nthis approach.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The macroscopic dynamics in separable neural networks",
      "abstract": "  The parallel dynamics is given in the case of neural networks with separable\ncoupling through starting from Coolen-Sherrington (CS) theory. It is shown that\nthis retrieve dynamics as is the case of sequential evolution in the postulate\nof away from saturation and finite temperature. The finite-size effects is\ngoverned by a homogeneous Markov process, which differs from the time-dependent\nOrnstein-Uhlenbeck process in sequential dynamics. PACS number(s): 87.10.+e,\n75.10.Nr, 02.50.+s\n",
      "subjects": [
        "cond-mat.dis-nn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0921-4534(02)02624-2",
      "title": "Nuclear Magnetic Relaxation Rate in the Vortex State of a Chiral p-Wave\n  Superconductor",
      "abstract": "  The site-selective nuclear spin-lattice relaxation rate T1^{-1} is\ntheoretically studied inside a vortex core in a chiral p-wave superconductor\nwithin the framework of the quasiclassical theory of superconductivity. It is\nfound that T1^{-1} at the vortex center depends on the sense of the chirality\nrelative to the sense of the magnetic field. Our numerical result shows a\ncharacteristic difference in T1^{-1} between the two chiral states, k_x + i k_y\nand k_x - i k_y under the magnetic field.\n",
      "subjects": [
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A note on the upward and downward intruder segregation in granular media",
      "abstract": "  The intruder segregation dependence on size and density is investigated in\nthe framework of a hydrodynamic theoretical model for vibrated granular media.\nWe propose a segregation mechanism based on the difference of densities between\ndifferent regions of the granular system, which give origin to a buoyant force\nthat acts on the intruder. From the analytic solution of the segregation\nvelocity we can analyze the transition from the upward to downward intruder's\nmovement.\n",
      "subjects": [
        "cond-mat.stat-mech",
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.67.235408",
      "title": "Nonideal quantum detectors in Bayesian formalism",
      "abstract": "  The Bayesian formalism for a continuous measurement of solid-state qubits is\nderived for a model which takes into account several factors of the detector\nnonideality. In particular, we consider additional classical output and\nbackaction noises (with finite correlation), together with quantum-limited\noutput and backaction noises, and take into account possible asymmetry of the\ndetector coupling. The formalism is first derived for a single qubit and then\ngeneralized to the measurement of entangled qubits.\n",
      "subjects": [
        "cond-mat.mes-hall",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.91.117001",
      "title": "Mott Gap Excitations and Resonant Inelastic X-Ray Scattering in Doped\n  Cuprates",
      "abstract": "  Predictions are made for the momentum- and carrier-dependent degradation of\nthe Mott gap upon doping in high-Tc cuprates as would be observed in Cu K-edge\nresonant inelastic x-ray scattering (RIXS). The two-dimensional Hubbard model\nwith second- and third-nearest-neighbor hopping terms has been studied by\nnumerical exact diagonalization. Special emphasis is placed on the\nparticle-hole asymmetry of the Mott gap excitations. We argue that the Mott gap\nexcitations observed by RIXS are significantly influenced by the interaction\nbetween charge carriers and antiferromagnetic correlations.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.93.017204",
      "title": "Bound spinons in an antiferromagnetic S=1/2 chain with a staggered field",
      "abstract": "  Inelastic neutron scattering was used to measure the magnetic field\ndependence of spin excitations in the antiferromagnetic S=1/2 chain CuCl_2\n2(dimethylsulfoxide) (CDC) in the presence of uniform and staggered fields.\nDispersive bound states emerge from a zero-field two-spinon continuum with\ndifferent finite energy minima at wave numbers q=pi and q_i approx pi\n(1-2<S_z>). The ratios of the field dependent excitation energies are in\nexcellent agreement with predictions for breather and soliton solutions to the\nquantum sine-Gordon model, the proposed low-energy theory for S=1/2 chains in a\nstaggered field. The data are also consistent with the predicted soliton and\nn=1,2 breather polarizations and scattering cross sections.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.68.056118",
      "title": "Bose-Einstein condensation in random directed networks",
      "abstract": "  We consider the phenomenon of Bose-Einstein condensation in a random growing\ndirected network. The network grows by the addition of vertices and edges. At\neach time step the network gains a vertex with probabilty $p$ and an edge with\nprobability $1-p$. The new vertex has a fitness $(a,b)$ with probability\n$f(a,b)$. A vertex with fitness $(a,b)$, in-degree $i$ and out-degree $j$ gains\na new incoming edge with rate $a(i+1)$ and an outgoing edge with rate $b(j+1)$.\nThe Bose-Einstein condensation occurs as a function of fitness distribution\n$f(a,b)$.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.92.126601",
      "title": "Dynamic ferromagnetic proximity effect in photoexcited semiconductors",
      "abstract": "  The spin dynamics of photoexcited carriers in semiconductors in contact with\na ferromagnet is treated theoretically and compared with time-dependent Faraday\nrotation experiments. The long time response of the system is found to be\ngoverned by the first tens of picoseconds in which the excited plasma interacts\nstrongly with the intrinsic interface between semiconductor and ferromagnet in\nspite of the existence of a Schottky barrier in equilibrium.\n",
      "subjects": [
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.70.043627",
      "title": "Confinement control by optical lattices",
      "abstract": "  It is shown that the interplay of a confining potential with a periodic\npotential leads for free particles to states spatially confined on a fraction\nof the total extension of the system. A more complex `slicing' of the system\ncan be achieved by increasing the period of the lattice potential. These\nresults are especially relevant for fermionic systems, where interaction\neffects are in general strongly reduced for a single species at low\ntemperatures.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Towards Microscopic Theory of Phase Transitions: Correlation Radii and\n  Critical Indices",
      "abstract": "  From the microscopic point of view almost all bonds between particles of\ncondensed substances must be performed by exchanges of virtual photons.\nConsequently the duration of their virtuality must be longer than the extent of\ntheir free path in the substance, the magnitudes of all expressions in such\ninequality are known from low frequencies scattering. This approach allows to\nsuggest that the break of some set of bonds of particles, i.e. the phase\ntransitions, will be originated just at the reversing of established\ninequality. Such assumption leads to definition of the radius of correlations\nor bonds: $R_{c}\\symbol{126} E^{-2/3}$ that proves the universality of this\ncritical index. The energies E, which can be liberated at phase transitions,\nare definite for different types of critical phenomena. Reformulation of the\nGinzburg-Landau model of phase transitions via expansion of thermodynamic\npotentials over $R_{c}$, instead temperatures distance, leads to the correct\nsystem of all critical indices.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0951-7715/18/6/011",
      "title": "A simple model of the charge transfer in DNA-like substances",
      "abstract": "  We present a very simple model for the study of charge transport in a\nmolecule patterned on B-DNA. In this model we use a discrete non-linear\nSchr\\\"{o}dinger equation to describe electrons propagating along the\nsugar-phosphate backbone of the DNA molecule. We find that in this model, for a\ngiven nonlinearity, the transport is controlled by $J$, a parameter which\nrelates to the electronic coupling between different molecules on the backbone.\nFor smaller values of $J$ we have localised states while at higher values of\n$J$ the soliton field is spread out and through its interaction with the\nlattice it has stronger effects on the distortion of the lattice.\n",
      "subjects": [
        "cond-mat.soft",
        "nlin.PS",
        "q-bio.BM"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.70.195402",
      "title": "Real space finite difference method for conductance calculations",
      "abstract": "  We present a general method for calculating coherent electronic transport in\nquantum wires and tunnel junctions. It is based upon a real space high order\nfinite difference representation of the single particle Hamiltonian and wave\nfunctions. Landauer's formula is used to express the conductance as a\nscattering problem. Dividing space into a scattering region and left and right\nideal electrode regions, this problem is solved by wave function matching (WFM)\nin the boundary zones connecting these regions. The method is tested on a model\ntunnel junction and applied to sodium atomic wires. In particular, we show that\nusing a high order finite difference approximation of the kinetic energy\noperator leads to a high accuracy at moderate computational costs.\n",
      "subjects": [
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.70.195412",
      "title": "Dispersive force between dissimilar materials: geometrical effects",
      "abstract": "  We calculate the Casimir force or dispersive van der Waals force between a\nspherical nanoparticle and a planar substrate, both with arbitrary dielectric\nproperties. We show that the force between a sphere and a plane can be\ncalculated through the interacting surface plasmons of the bodies. Using a\nSpectral Representation formalism, we show that the force of a sphere made of a\nmaterial A and a plane made of a material B, differ from the case when the\nsphere is made of B, and the plane is made of A. We found that the difference\ndepends on the plasma frequency of the materials, the geometry, and the\ndistance of separation between sphere and plane. The differences show the\nimportance of the geometry, and make evident the necessity of realistic\ndescriptions of the sphere-plane system beyond the Derjaguin Approximation or\nProximity Theorem Approximation.\n",
      "subjects": [
        "cond-mat.other",
        "cond-mat.mtrl-sci"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.94.157003",
      "title": "Superconductivity in charge Kondo systems",
      "abstract": "  We present a theory of superconductivity in charge Kondo systems, materials\nwith resonant quantum valence fluctuations, in the regime where the transition\ntemperature is comparable to the charge Kondo resonance. We find\nsuperconductivity induced by charge Kondo impurities, study how pairing of a\nsuperconducting host is enhanced due to charge Kondo centers and investigate\nthe interplay between Kondo-scattering and inter-impurity Josephson coupling.\nWe discuss the implications of our theory for Tl-doped PbTe, which has recently\nbeen identified as a candidate charge Kondo system.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.72.064523",
      "title": "Theory of fluctuations in a two-band superconductor",
      "abstract": "  A theory of fluctuations in two-band superconductor MgB$_{2}$ is developed.\nSince the standard Ginzburg-Landau (GL) approach fails in description of its\nproperties, we generalize it basing on the microscopic theory of a two-band\nsuperconductor. Calculating the microscopic fluctuation propagator, we build up\nthe nonlocal two-band GL functional and the corresponding time-dependent GL\nequations. This allows us to calculate the main fluctuation observables such as\nfluctuation specific heat and conductivity.\n",
      "subjects": [
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.1863173",
      "title": "Effect of Chemical Structure on the Isobaric and Isochoric Fragility in\n  Polychlorinated Biphenyls",
      "abstract": "  Pressure-volume-temperature data, along with dielectric relaxation\nmeasurements, are reported for a series of polychlorinated biphenyls (PCB),\ndiffering in the number of chlorine atoms on their phenyl rings. Analysis of\nthe results reveals that with increasing chlorine content, the relaxation times\nof the PCB become governed to a greater degree by density, rho, relative to the\neffect of temperature, T. This result is consistent with the respective\nmagnitudes of the scaling exponent, gamma, yielding superpositioning of the\nrelaxation times measured at various temperatures and pressures, when plotted\nversus rho^gamma/T. While at constant (atmospheric) pressure, fragilities for\nthe various PCB are equivalent, the fragility at constant volume varies\ninversely with chlorine content. Evidently, the presence of bulkier chlorine\natoms on the phenyl rings magnifies the effect density has on the relaxation\ndynamics.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Note on cond-mat/0510119: Jarzynski equation for adiabatically stretched\n  rotor",
      "abstract": "  In a recent article (cond-mat/0510119) it has been argued that the Jarzynski\nequation is violated for adiabatic stretching processes of a three dimensional\nrotor system. Here we want to show that the reasoning is not correct. Rather,\nthe Jarzynski equation is fulfilled for this adiabatically stretched rotor.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Tetris Model for Granular Drag",
      "abstract": "  Motivated by recent experiments on objects moved vertically through a bed a\nglass beads, a simple model to study granular drag is proposed. The model\nconsists of dimers on a slanted two-dimensional lattice through which objects\nare dragged very slowly to obtain full relaxation between moves. Such an\napproach avoids complications due to static friction in more realistic\noff-lattice models, and provides for fast simulations at large system sizes.\nThe upward motion of objects of various diameters embedded in the lattice is\nsimulated and close resemblance with the experiments is found.\n",
      "subjects": [
        "cond-mat.soft"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physb.2006.01.327",
      "title": "Pressure dependence of the superconducting transition temperature in\n  C$_6$Yb and C$_6$Ca",
      "abstract": "  We have studied the evolution, with hydrostatic pressure, of the recently\ndiscovered superconductivity in the graphite intercalation compounds C$_6$Yb\nand C$_6$Ca. We present pressure-temperature phase diagrams, for both\nsuperconductors, established by electrical transport and magnetization\nmeasurements. In the range 0-1.2 GPa the superconducting transition temperature\nincreases linearly with pressure in both materials with $dT_c/dP = +0.39 K/GPa$\nand $dT_c/dP = +0.50 K/GPa$ for C$_6$Yb and C$_6$Ca respectively. The\ntransition temperature in C$_6$Yb, which has beenmeasured up to 2.3 GPa,\nreaches a peak at around 1.8 GPa and then starts to drop. We also discuss how\nthis pressure dependence may be explained within a plasmon pairing mechanism.\n",
      "subjects": [
        "cond-mat.supr-con"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Modeling of Self-Healing Polymer Composites Reinforced with Nanoporous\n  Glass Fibers",
      "abstract": "  We report on our progress towards continuum rate equation modeling, as well\nas numerical simulations, of self-healing of fatigue in composites reinforced\nwith glue carrying nanoporous fibers. We conclude that with the proper choice\nof the material parameters, effects of fatigue can be partially overcome and\ndegradation of mechanical properties can be delayed.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "cond-mat.other",
        "cond-mat.soft",
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1143/JPSJ.75.123602",
      "title": "Low-lying optical phonon modes in the filled skutterudite CeRu4Sb12",
      "abstract": "  The phonon dynamics of filled skutterudite CeRu4Sb12 have been studied at\nroom temperature by inelastic neutron scattering. Optical phonons associated\nwith a large vibration of Ce atoms are observed at a relatively low energy of E\n= 6 meV, and show anticrossing behavior with acoustic phonons. We propose that\nthe origin of the low lattice thermal conductivity in filled skutterudites can\nbe attributed to intensive Umklapp scattering originating from low-lying\noptical phonons. By an analysis based on a Born-von Karman force model, the\nlongitudinal force constants of the nearest Ce-Sb and Ce-Ru pairs are estimated\nto be 0.025 mdyn/A, while that of the nearest Ru-Sb pair is estimated to be 1.4\nmdyn/A, indicating that the Ce atoms are bound very weakly to the surrounding\nrigid RuSb6-octahedron cages.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.74.224411",
      "title": "Spin-charge separation and simultaneous spin and charge Kondo effect",
      "abstract": "  We study the spin-charge separation in a Kondo-like model for an impurity\nwith a spin and a charge (isospin) degree of freedom coupled to a single\nconduction channel (the ``spin-charge'' Kondo model). We show that the spin and\ncharge Kondo effects can occur simultaneously at any coupling strength. In the\ncontinuum (wide-band or weak coupling) limit, the Kondo screening in each\nsector is independent, while at finite bandwidth and strong coupling the\nlattice effects lead to a renormalization of the effective Kondo exchange\nconstants; nevertheless, universal spin and charge Kondo effects still occur.\nWe find similar behavior in the two-impurity Anderson model with positive and\nnegative electron-electron interaction and in the two-impurity\nAnderson-Holstein model with a single phonon mode. We comment on the\napplicability of such models to describe the conductance of deformable\nmolecules with a local magnetic moment.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1742-5468/2007/05/P05010",
      "title": "Quasi-Adiabatic Continuation in Gapped Spin and Fermion Systems:\n  Goldstone's Theorem and Flux Periodicity",
      "abstract": "  We apply the technique of quasi-adiabatic continuation to study systems with\ncontinuous symmetries. We first derive a general form of Goldstone's theorem\napplicable to gapped nonrelativistic systems with continuous symmetries. We\nthen show that for a fermionic system with a spin gap, it is possible to insert\n$\\pi$-flux into a cylinder with only exponentially small change in the energy\nof the system, a scenario which covers several physically interesting cases\nsuch as an s-wave superconductor or a resonating valence bond state.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Sharp switching of the magnetization in Fe1/4TaS2",
      "abstract": "  Anisotropic magneto-transport measurements are reported on Fe1/4TaS2 single\ncrystals grown by vapor transport. Both the magnetization and resistivity are\nextremely anisotropic, with the magnetic moments aligned parallel to the c\ncrystallographic direction. Fe1/4TaS2 orders ferromagnetically below TC = 160 K\nand displays very sharp hysteresis loops in the ordered state for H||c. The\ncorresponding magnetoresistance is negative, and it qualitatively reproduces\nthe features observed in the M(H) data, by showing a sharp drop around the\ncritical field Hs for the moment reversal. The magnetization switching time\nshows an unusual increase with increasing temperature. For field applied within\nthe ab plane, the magnetization remains small and linear in field up to 5 T,\nand the magnetoresistance is positive and quadratic in field, with no visible\nhysteresis. The squareness of the H||c M(H) loops and the high critical field\nfor the magnetization switch (Hs = 3.7 T at T = 2 K) allow us to classify\nFe1/4TaS2 as a strong ferromagnet.\n",
      "subjects": [
        "cond-mat.str-el"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevB.76.033305",
      "title": "Mean Free Path in Disordered Multichannel Tight-Binding Wires",
      "abstract": "  Transport in a disordered tight-binding wire involves a collection of\ndifferent mean free paths resulting from the distinct fermi points, which\ncorrespond to the various scattering channels of the wire. The generalization\nof Thouless' relation between the mean free path and the localization length\n$\\xi$ permits to define an average channel mean free path,$\\bar\\ell$, such that\n$\\xi\\sim N\\bar\\ell$ in an $N$-channel system. The averaged mean free path\n$\\bar\\ell$ is expressed exactly in terms of the total reflection coefficient of\nthe wire and compared with the mean free path defined in the maximum entropy\napproach.\n",
      "subjects": [
        "cond-mat.dis-nn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0038-1098(97)00069-0",
      "title": "The Nature of the Hall Insulator",
      "abstract": "  We have conducted an experimental study of the linear transport properties of\nthe magnetic-field induced insulating phase which terminates the quantum Hall\n(QH) series in two dimensional electron systems. We found that a direct and\nsimple relation exists between measurements of the longitudinal resistivity,\n$\\rho_{xx}$, in this insulating phase and in the neighboring QH phase. In\naddition, we find that the Hall resistivity, $\\rho_{xy}$, can be quantized in\nthe insulating phase. Our results indicate that a close relation exists between\nthe conduction mechanism in the insulator and in the QH liquid.\n",
      "subjects": [
        "cond-mat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.79.5270",
      "title": "Backflow in a Fermi Liquid",
      "abstract": "  We calculate the backflow current around a fixed impurity in a Fermi liquid.\nThe leading contribution at long distances is radial and proportional to 1/r^2.\nIt is caused by the current induced density modulation first discussed by\nLandauer. The familiar 1/r^3 dipolar backflow obtained in linear response by\nPines and Nozieres is only the next to leading term, whose strength is\ncalculated here to all orders in the scattering. In the charged case the\ncondition of perfect screening gives rise to a novel sum rule for the phase\nshifts. Similar to the behavior in a classical viscous liquid, the friction\nforce is due only to the leading contribution in the backflow while the dipolar\nterm does not contribute.\n",
      "subjects": [
        "cond-mat.str-el",
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Magnetotransport in PbTe nipi structures",
      "abstract": "  In this paper the 3D- and 2D- behavior of wide quantum wells which consist of\none period of a PbTe nipi-structure is studied theoretically and\nexperimentally. A simple model combines the 2D- subband levels and the\n3D-Landau levels in order to calculate the density of states in a magnetic\nfield perpendicular to the 2D plane. It is shown that at a channel width of\nabout 500 nm on can expect to observe 3D- and 2D-behavior at the same time.\nFinally the general design aspects for PbTe wide quantum wells are discussed.\n",
      "subjects": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0375-9601(98)00264-3",
      "title": "Bose-Einstein condensation under external conditions",
      "abstract": "  We discuss the phenomenon of Bose-Einstein condensation under general\nexternal conditions using connections between partition sums and the\nheat-equation. Thermodynamical quantities like the critical temperature are\ngiven in terms of the heat-kernel coefficients of the associated Schr\\\"odinger\nequation. The general approach is applied to situations where the gas is\nconfined by arbitrary potentials or by boxes of arbitrary shape.\n",
      "subjects": [
        "cond-mat.stat-mech"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Bipartite graph partitioning and data clustering",
      "abstract": "  Many data types arising from data mining applications can be modeled as\nbipartite graphs, examples include terms and documents in a text corpus,\ncustomers and purchasing items in market basket analysis and reviewers and\nmovies in a movie recommender system. In this paper, we propose a new data\nclustering method based on partitioning the underlying bipartite graph. The\npartition is constructed by minimizing a normalized sum of edge weights between\nunmatched pairs of vertices of the bipartite graph. We show that an approximate\nsolution to the minimization problem can be obtained by computing a partial\nsingular value decomposition (SVD) of the associated edge weight matrix of the\nbipartite graph. We point out the connection of our clustering algorithm to\ncorrespondence analysis used in multivariate analysis. We also briefly discuss\nthe issue of assigning data objects to multiple clusters. In the experimental\nresults, we apply our clustering algorithm to the problem of document\nclustering to illustrate its effectiveness and efficiency.\n",
      "subjects": [
        "cs.IR",
        "cs.LG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Boundary knot method for Laplace and biharmonic problems",
      "abstract": "  The boundary knot method (BKM) [1] is a meshless boundary-type radial basis\nfunction (RBF) collocation scheme, where the nonsingular general solution is\nused instead of fundamental solution to evaluate the homogeneous solution,\nwhile the dual reciprocity method (DRM) is employed to approximation of\nparticular solution. Despite the fact that there are not nonsingular RBF\ngeneral solutions available for Laplace and biharmonic problems, this study\nshows that the method can be successfully applied to these problems. The\nhigh-order general and fundamental solutions of Burger and Winkler equations\nare also first presented here.\n",
      "subjects": [
        "cs.CE",
        "cs.MS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0370-2693(02)01808-7",
      "title": "New hairy black holes with negative cosmological constant",
      "abstract": "  Black hole solutions with nonspherical event horizon topology are shown to\nexist in an Einstein-Yang-Mills theory with negative cosmological constant. The\nmain characteristics of the solutions are presented and differences with\nrespect to the spherically symmetric case are studied. The stability of these\nconfigurations is also addressed.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.65.044022",
      "title": "Bounding the mass of the graviton using binary pulsar observations",
      "abstract": "  The close agreement between the predictions of dynamical general relativity\nfor the radiated power of a compact binary system and the observed orbital\ndecay of the binary pulsars PSR B1913+16 and PSR B1534+12 allows us to bound\nthe graviton mass to be less than 7.6 x 10^{-20} eV with 90% confidence. This\nbound is the first to be obtained from dynamic, as opposed to static-field,\nrelativity. The resulting limit on the graviton mass is within two orders of\nmagnitude of that from solar system measurements, and can be expected to\nimprove with further observations.\n",
      "subjects": [
        "gr-qc",
        "astro-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0218271802002967",
      "title": "Vacuum selection by inflation as the origin of the dark energy",
      "abstract": "  I propose a new mechanism to account for the observed tiny but finite dark\nenergy in terms of a non-Abelian Higgs theory, which has infinitely many\nperturbative vacua characterized by a winding number, in the framework of\ninflationary cosmology. Inflation homogenizes field configuration and\npractically realizes a perturbative vacuum with vanishing winding number, which\nis expressed by a superposition of eigenstates of the Hamiltonian with\ndifferent vacuum energy density. As a result, we naturally find a nonvanishing\nvacuum energy density with fairly large probability, under the assumption that\nthe cosmological constant vanishes in some vacuum state. Since the predicted\nmagnitude of dark energy is exponentially suppressed by the instanton action,\nwe can fit observation without introducing any tiny parameters.\n",
      "subjects": [
        "gr-qc",
        "astro-ph",
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0264-9381/19/20/314",
      "title": "What role pressures play to determine the final end-state of\n  gravitational collapse?",
      "abstract": "  We examine here in what way the pressures affect the final fate of a\ncontinual gravitational collapse. It is shown that the presence of a\nnon-vanishing pressure gradient in the collapsing cloud determines directly the\nepoch of formation of trapped surfaces and the apparent horizon, thus changing\nthe causal structure in the vicinity of singularity.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Classical solutions from quantum regime for barotropic FRW model",
      "abstract": "  The quantization of gravity coupled to barotropic perfect fluid as matter\nfield and cosmological constant is made and the wave function can be determined\nfor any $\\kappa$ in the FRW minisuperspace model. The meaning of the existence\nof the classical solution is discussed in the WKB semiclassical approximation\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.71.024032",
      "title": "Asymmetric brane-worlds with induced gravity",
      "abstract": "  The Randall-Sundrum scenario, with a 1+3-dimensional brane in a 5-dimensional\nbulk spacetime, can be generalized in various ways. We consider the case where\nthe Z2-symmetry at the brane is relaxed, and in addition the gravitational\naction is generalized to include an induced gravity term on the brane. We\nderive the complete set of equations governing the gravitational dynamics for a\ngeneral brane and bulk, and identify how the asymmetry and the induced gravity\nact as effective source terms in the projected field equations on the brane.\nFor a Friedmann brane in an anti de Sitter bulk, the solution of the Friedmann\nequation is given by the solution of a quartic equation. We find the\nperturbative solutions for small asymmetry, which has an effect at late times.\n",
      "subjects": [
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s10714-005-0189-6",
      "title": "The nearly flat universe",
      "abstract": "  We study here what it means for the Universe to be nearly flat, as opposed to\nexactly flat. We give three definitions of nearly flat, based on density,\ngeometry and dynamics; all three definitions are equivalent and depend on a\nsingle constant flatness parameter epsilon that quantifies the notion of nearly\nflat. Observations can only place an upper limit on epsilon, and always allow\nthe possibility that the Universe is infinite with k=-1 or finite with k=1. We\nuse current observational data to obtain a numerical upper limit on the\nflatness parameter and discuss its implications, in particular the\n\"naturalness\" of the nearly flat Universe.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217751X06031004",
      "title": "Scalar Field Entropy in Brane World Black Holes",
      "abstract": "  A semiclassical calculation of entropy of a scalar field in the background of\na class of brane world black holes (BWBH) is carried out in the presence of a\nbrick wall cutoff when the 5D-bulk induced \\textquotedblleft tidal charge\" has\ngeneric or extreme values.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Slowly rotating fluid balls with linear equation of state",
      "abstract": "  Slowly rotating perfect fluid balls with regular center and asymptotically\nflat exterior are considered to second order in the rotation parameter. The\nnecessary condition for being Petrov type D is given for general perfect fluid\nmatter. As a special case, fluids with a linear equation of state are\nconsidered. Using a power series expansion at the regular center, it is shown\nthat the Petrov D condition is inconsistent with the linear equation of state\nassumption.\n",
      "subjects": [
        "gr-qc"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0218271893000313",
      "title": "Cosmological Constant and Gravitational Repulsion Effect: 1. Homogeneous\n  models with radiation",
      "abstract": "  Within the framework of the minimum quadratic Poincare gauge theory of\ngravity in the Riemann-Cartan spacetime we study the influence of gravitational\nvacuum energy density (a cosmological constant) on the dynamics of various\ngravitating systems. It is shown that the inclusion of the cosmological term\ncan lead to gravitational repulsion. For some simple cases of spatially\nhomogeneous cosmological models with radiation we obtain non-singular solutions\nin form of elementary functions and elliptic integrals.\n",
      "subjects": [
        "gr-qc",
        "astro-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.56.3371",
      "title": "Physical Interpretation of Cylindrically Symmetric Static Gravitational\n  Fields",
      "abstract": "  The explicit relationship is determined between the interior properties of a\nstatic cylindrical matter distribution and the metric of the exterior\nspace-time according to Einstein gravity for space-time dimensionality larger\nor equal to four. This is achieved through use of a coordinate system isotropic\nin the transverse coordinates. As a corollary, similar results are obtained for\na spherical matter distribution in Brans-Dicke gravity for dimensions larger\nthan or equal to three. The approach used here leads to consistency conditions\nfor those parameters characterizing the exterior metric. It is shown that these\nconditions are equivalent to the requirement of hydrostatic equilibrium of the\nmatter distribution (generalized Oppenheimer-Volkoff equations). These\nconditions lead to a consistent Newtonian limit where pressures and the\ngravitational constant go to zero at the same rate.\n",
      "subjects": [
        "gr-qc",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Determination of Electroweak Parameters at the SLC",
      "abstract": "  We present an improved measurement of the left-right cross section asymmetry\nAlr for Z boson production by e+e- collisions. The measurement was performed at\na center-of-mass energy of 91.28 GeV with the SLD detector at the SLAC Linear\nCollider (SLC) during the 1994-95 running period. The luminosity-weighted\naverage polarization of the SLC electron beam during this run was measured to\nbe (77.23 +/- 0.52)%. Using a sample of 93,644 hadronic Z decays, we measure\nthe pole asymmetry Alr0 to be 0.1512 +/- 0.0042(stat.) +/- 0.0011(syst.) which\nis equivalent to an effective weak mixing angle of 0.23100 +/- 0.00054(stat.)\n+/- 0.00014(syst.). We also present a preliminary direct measurement of the\nZ-lepton coupling asymmetries A_e,A_mu, and A_tau extracted from the\ndifferential cross section observed in leptonic Z decays. We combine these\nresults with our previous Alr measurement to obtain a combined determination of\nthe weak mixing angle of 0.23061 +/- 0.00047.\n",
      "subjects": [
        "hep-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0550-3213(95)00458-5",
      "title": "The classically perfect fixed point action for SU(3) gauge theory",
      "abstract": "  In this paper (the first of a series) we describe the construction of fixed\npoint actions for lattice $SU(3)$ pure gauge theory. Fixed point actions have\nscale invariant instanton solutions and the spectrum of their quadratic part is\nexact (they are classical perfect actions). We argue that the fixed point\naction is even 1--loop quantum perfect, i.e. in its physical predictions there\nare no $g^2 a^n$ cut--off effects for any $n$. We discuss the construction of\nfixed point operators and present examples. The lowest order $q {\\bar q}$\npotential $V(\\vec{r})$ obtained from the fixed point Polyakov loop correlator\nis free of any cut--off effects which go to zero as an inverse power of the\ndistance $r$.\n",
      "subjects": [
        "hep-lat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The Spin Structure of the Proton",
      "abstract": "  It is shown that the proton \"spin crisis'' or \"spin puzzle\" can be understood\nby the relativistic effect of quark transversal motions due to the\nMelosh-Wigner rotation. The quark helicity $\\Delta q$ measured in polarized\ndeep inelastic scattering is actually the quark spin in the infinite momentum\nframe or in the light-cone formalism, and it is different from the quark spin\nin the nucleon rest frame or in the quark model. The flavor asymmetry of the\nMelosh-Wigner effect for the valence $u$ and $d$ quarks and the intrinsic sea\n$q \\bar{q}$ pairs are also the important ingredients in a SU(6)\nquark-spectator-diquark model framework to understand the \"spin puzzle\". Such a\npicture of the spin structure can be tested by use of several simple relations\nto measure the quark spin distributions in the quark model.\n",
      "subjects": [
        "hep-ph",
        "hep-ex",
        "nucl-ex",
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0370-2693(01)01433-2",
      "title": "Lower Limits on Soft Supersymmetry-Breaking Scalar Masses",
      "abstract": "  Working in the context of the CMSSM, we argue that phenomenological\nconstraints now require the universal soft supersymmetry-breaking scalar mass\nm_0 be non-zero at the input GUT scale. This conclusion is primarily imposed by\nthe LEP lower limit on the Higgs mass and the requirement that the lightest\nsupersymmetric particle not be charged. We find that m_0 > 0 for all tan beta\nif mu < 0, and m_0 = 0 may be allowed for mu > 0 only when tan beta sim 8 and\none allows an uncertainty of 3+ GeV in the theoretical calculation of the Higgs\nmass. Upper limits on flavour-changing neutral interactions in the MSSM squark\nsector allow substantial violations of non-universality in the m_0 values, even\nif their magnitudes are comparable to the lower limit we find in the CMSSM.\nAlso, we show that our lower limit on m_0 at the GUT scale in the CMSSM is\ncompatible with the no-scale boundary condition m_0 = 0 at the Planck scale.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "QCD Studies at HERA",
      "abstract": "  Several topics from the wide field of QCD studies in Deep-inelastic $ep$\nScattering at HERA are addressed. They include QCD analyses of the inclusive\ncross section with the determination of $\\alpha_s$ and the proton gluon density\nfrom the $F_2$ scaling violations, and the determination of the longitudinal\nstructure function $F_L$. QCD analyses of inclusive jet and dijet data are also\npresented. Finally jet substructure and three-jet production are discussed.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Longitudinal virtual photons and the interference terms in ep collisions",
      "abstract": "  The importance of the contributions of the longitudinally polarized virtual\nphoton in ep collisions is investigated. We derive the factorization formulae\nfor the unpolarized inclusive and semi-inclusive ep collisions in an arbitrary\nreference frame. The numerical calculations for the prompt photons production\nin the unpolarized Compton process (e p --> e gamma X) at the ep HERA collider\nare performed in the Born approximation. We studied various distributions in\nthe ep centre-of-mass frame and found that the differential cross section for\nthe longitudinally polarized intermediate photon and the term due to the\ninterference between the longitudinal- and transverse- polarization states of\nthe photon are small, i.e. below 10% of the cross section. Moreover, these two\ncontributions almost cancel one another, leading to a stronger domination of\nthe transversely polarized virtual photon, even for its large virtuality.\nRelevance of the resolved longitudinal photon in a jet production in DIS events\nat HERA is commented. A relatively large (about 30%) effect due to the\nlongitudinal-transverse interference term was found in the azimuthal-angle\ndistribution in the Breit frame.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.71.054001",
      "title": "Leading twist nuclear shadowing: uncertainties, comparison to\n  experiments and higher twist effects",
      "abstract": "  Using the leading twist approach to nuclear shadowing, which is based on the\nrelationship between nuclear shadowing and diffraction on a nucleon, we\ncalculate next-to-leading order nuclear parton distribution functions (nPDFs)\nand structure functions in the region $0.2 > x > 10^{-5}$ and $Q^2 \\geq 4$\nGeV$^2$.\n  The uncertainties of our predictions due the uncertainties of the\nexperimental input and the theory are quantified. We determine the relative\nrole of the small ($\\sim Q^2$) and large ($\\gg Q^2$) diffractive masses in\nnuclear shadowing as a function of $x$ and find that the large mass\ncontribution, which is an analog of the triple Pomeron exchange, becomes\nsignificant only for $x \\le 10^{-4}$. Comparing our predictions to the\navailable fixed-target nuclear DIS data, we argue, based on the current\nexperimental studies of the leading twist diffraction, that the data at\nmoderately small $x\\sim 0.01$ and $Q^2 \\sim 2$ GeV$^2$ could contain\nsignificant higher twist effects hindering the extraction of nPDFs from that\ndata. Also, we find that the next-to-leading order effects in nuclear shadowing\nin the ratio of the nucleus to nucleon structure functions $F_2$ are quite\nsizable. Within the same formalism, we also present results for the impact\nparameter dependence of nPDFs. We also address the problem of extracting of the\nneutron\n  $F_{2n}(x,Q^2)$ from the deuteron and proton data. We suggest a simple and\nnearly model-independent procedure of correcting for nuclear shadowing effects\nusing $F_2^A/F_2^D$ ratios.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/9789812702326_0013",
      "title": "Summing Logs of the Velocity in NRQCD and Top Threshold Physics",
      "abstract": "  To achieve reliable predictions of the top-antitop threshold cross section at\na future e+e- Linear Collider logarithms of the top velocity need to be\nresummed. I review the issues that make this problem complicated and show how\nthe task can be achieved by renormalization in an effective theory using the so\ncalled velocity renormalization group. The most recent NNLL order results are\ndiscussed.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.physletb.2005.11.050",
      "title": "Possible new interactions of neutrino and the KATRIN experiment",
      "abstract": "  We analyse the possible role of new interactions of neutrino in the\nforthcoming tritium beta decay experiment KATRIN aimed at detecting the\nneutrino mass with the sensitivity of 0.3 - 0.2 eV. It is shown that under\ncertain circumstances the standard procedure of data analysis would have to be\nmodified by the introduction of an extra parameter describing the strength of\nthe new interactions. Our model simulations show that the modified procedure\nmay improve the quality of the fit compared with the standard case. Ignoring\nthe possibility of new interactions may lead to a systematic error in the\nneutrino mass determination.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0034-4885/68/10/R03",
      "title": "Top quark physics in hadron collisions",
      "abstract": "  The top quark is the heaviest elementary particle observed to date. Its large\nmass makes the top quark an ideal laboratory to test predictions of\nperturbation theory concerning heavy quark production at hadron colliders. The\ntop quark is also a powerful probe for new phenomena beyond the Standard Model\nof particle physics. In addition, the top quark mass is a crucial parameter for\nscrutinizing the Standard Model in electroweak precision tests and for\npredicting the mass of the yet unobserved Higgs boson. Ten years after the\ndiscovery of the top quark at the Fermilab Tevatron top quark physics has\nentered an era where detailed measurements of top quark properties are\nundertaken. In this review article an introduction to the phenomenology of top\nquark production in hadron collisions is given, the lessons learned in Tevatron\nRun I are summarized, and first Run II results are discussed. A brief outlook\nto the possibilities of top quark research a the Large Hadron Collider,\ncurrently under construction at CERN, is included.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.73.067401",
      "title": "Self-consistent quasi-particle model for relativistic plasma",
      "abstract": "  Relativistic plasma with radiation at thermodynamic equilibrium is ageneral\nsystem of interest in astrophysics and high energy physics. We develop a new\nself-consistent quasi-particle model for such a system to take account of\ncollective behaviour of plasma andthermodynamic properties are derived. It is\napplied to electrodynamic plasma and quark gluon plasma and compared with\nexisting results.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dileptons, spectral weights, and conductivity in the Quark-Gluon Plasma",
      "abstract": "  We re-examine soft dilepton emission from a weakly coupled Quark-Gluon\nPlasma. We show that Braaten, Pisarski, and Yuan's result that the dilepton\nrate rises as E^-4 (and the spectral weight scales as 1/E) at small energy\nE<<gT is correct, but that the coefficient they found for this behavior is not\ncorrect, because their analysis was incomplete. At still smaller scales, the\nbehavior moderates to ~1/E^2 for E <= g^4 T, consistent with a finite\nelectrical conductivity. We evaluate the spectral weight in the E~g^4 T region\nby kinetic theory techniques and show that it satisfies a sum rule, which makes\nthe determination of electrical conductivity from the Euclidean correlation\nfunction very challenging.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "CPT and Quantum Mechanics Tests with Kaons",
      "abstract": "  In this review we first discuss the theoretical motivations for possible CPT\nviolation and deviations from ordinary quantum-mechanical behavior of\nfield-theoretic systems in the context of an extended class of quantum-gravity\nmodels. Then we proceed to a description of precision tests of CPT symmetry\nusing mainly neutral kaons. We emphasize the possibly unique role of neutral\nmeson factories in providing specific tests of models where the\nquantum-mechanical CPT operator is not well-defined, leading to modifications\nof Einstein-Podolsky-Rosen particle correlators. Finally, we present tests of\nCPT, T, and CP using charged kaons, and in particular K_l4 decays, which are\ninteresting due to the high statistics attainable in experiments.\n",
      "subjects": [
        "hep-ph",
        "gr-qc",
        "hep-ex",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/9789812790873_0234",
      "title": "Masses and decay constants of B_q mesons in the QCD string approach",
      "abstract": "  The relativistic string Hamiltonian is used to calculate the masses and decay\nconstants of $B_q$ mesons: they appear to be expressed through onlythree\nfundamental values: the string tension $\\sigma $, $\\alpha_s$, and the quark\npole masses. The values $f_B =186 $ MeV, $f_{B_s}= 222$ MeV are calculated\nwhile $f_{B_c}$ depends on the $c$-quark pole mass used, namely $f_{B_c}=440\n(424)$ MeV for $m_c =1.40 (1.35)$ GeV. For the $1P$ states we predict the\nspin-averaged masses: $\\bar M(B_J)=5730$ MeV and $\\bar M(B_{sJ})=5830$ MeV\nwhich are in good agreement with the recent data of the D0 and CDF\nCollaborations, at the same time owning to the string correction being by $\\sim\n50$ MeV smaller than in other calculations.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.75.116005",
      "title": "J/Psi Photoproduction in a Dual Model",
      "abstract": "  J/Psi photoproduction is studied in the framework of the analytic S-matrix\ntheory. The differential and integrated elastic cross sections for J/Psi\nphotoproduction are calculated from a Dual Amplitude with Mandelstam\nAnalyticity. It is argued that at low energies, the background, which is the\nlow-energy equivalent of the high-energy diffraction replaces the Pomeron\nexchange. The onset of the high energy Pomeron dominance is estimated from the\nfits to the data.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0370-2693(92)90805-E",
      "title": "Analysis of Running Coupling Constant Unification in String Theory",
      "abstract": "  We use recently obtained 2-loop string coupling constants to analyze a class\nof string models based on orbifold compactification. Assuming weak coupling at\nthe string scale and single-scale unification leads to restrictions on the\nspectrum of massive (between the string scale and the weak scale) matter\nsupermultiplets and/or on the Kac-Moody algebra level.\n",
      "subjects": [
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.50.1060",
      "title": "Phase Transitions and Mass Generation in 2+1 Dimensions",
      "abstract": "  The possibility that the epsilon expansion can predict the order of phase\ntransitions in three dimensional field theories is examined. For a Hermitean\nmatrix-valued order parameter, the epsilon expansion predicts fluctuation\ninduced first order phase transitions. We analyze two 2+1-dimensional quantum\nfield theories which exhibit spontaneous symmetry breaking and have martix\norder parameters. Using the large $N$ expansion, we show that these models\nexhibit second order transitions and discuss the implications for the chiral\nsymmetry breaking transition in 2+1-dimensional QCD for a critical number of\nquark flavors.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0550-3213(95)00129-8",
      "title": "Gauge Theory High-Energy Behavior from J-Plane Unitarity",
      "abstract": "  In a non-abelian gauge theory the $t$-channel multiparticle unitarity\nequations continued in the complex j-plane can be systematically expanded\naround $j=1$. The combination of Ward identity constraints with unitarity is\nsufficient to produce directly many results obtained by Regge limit leading-log\nand next-to-leading log momentum space calculations. The $O(g^2)$ BFKL kernel\nis completely determined. $O(g^4)$ contributions to the kernel are also\ndetermined, including the leading contribution of a new partial-wave amplitude\n- previously identified as a separate forward component with a holomorphically\nfactorizable spectrum. For this amplitude the only scale ambiguity is the\noverall normalization and it is anticipated to be a new conformally invariant\nkernel. The results suggest that all conformally invariant reggeon interactions\nare determined by $t$-channel unitarity.\n",
      "subjects": [
        "hep-ph",
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "SU(7) SUSY GUTs with a natural intermediate scale",
      "abstract": "  We investigate the SU(N) supersymmetric Grand Unified Theories with\n``custodial symmetry'' mechanism to explane the doublet-triplet hierarchy. We\nshow that in such type of SU(7) SUSY theory intermediate scale appears\nnaturally and the correct value for sin^2(\\theta)_W is predicted via\nvector-like matter superfields splitting. The unification appears to be closed\nto M_Pl for all the reasonable values of \\alpha_s and M_SUSY. Due to the large\nunification scale the baryon number violating d=5 operator is suppressed in\ncomparison with that in minimal SU(5) theory.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Unusual Signal for Supersymmetry at the Tevatron",
      "abstract": "  We propose a new scenario in which the dominant signal for supersymmetry at\nthe Tevatron are the events having two or three $\\tau$ leptons with high $p_T$\naccompanied by large missing transverse energy. This signal is very different\nfrom the multijet or multileptons (involving $e$ and/or $\\mu$ only) or the\nphotonic signals that have been extensively investigated both theoretically and\nexperimentally. A large region of the GMSB parameter space with the lighter\nstau as the NLSP allow this possibility. Such a signal may be present in the\npast Tevatron data to be analyzed.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.58.116008",
      "title": "Effects of R-parity Violating Couplings on CP Asymmetries in Neutral B\n  Decays",
      "abstract": "  A detailed analysis of the effects of supersymmetric models without R-parity\non various CP asymmetries in neutral $B$ decays is given. We concentrate on\nmodels with Abelian horizontal symmetries that allow us to estimate the order\nof magnitude of the new effects. We focus on channels where the Standard Model\ngives clean predictions: $ B_{d}\\to\\psi K_{S} $ and $B_{d}\\to\\phi K_{S}$. The\ntwo asymmetries can have a value different from $\\sin2\\beta.$ Moreover, they\ncan be different from each other.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s100529800986",
      "title": "Diffractive photo- and leptoproduction of vector mesons $\\rho$, $\\rho'$\n  and $\\rho''$",
      "abstract": "  We calculate diffractive photo- and leptoproduction of $\\rho$-, $\\rho'$- and\n$\\rho''$-mesons. The incoming photon dissociates into a $q\\bar{q}$-dipole which\nscatters on the nucleon and transforms into a vector meson state. The\nscattering amplitude is calculated in non-perturbative QCD with the model of\nthe stochastic vacuum. Assuming that the physical $\\rho'$- and $\\rho''$-mesons\nare mixed states of an active 2S-excitation and some residual hybrid state\nwhich cannot be produced diffractively in lowest order QCD, we obtain good\nagreement with the data, especially the markedly different spectrum in the\n$\\pi^+\\pi^-$-invariant mass for photoproduction and $e^+e^-$-annihilation.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0370-2693(99)00109-4",
      "title": "Neutrino mixing and masses from long baseline and atmospheric\n  oscillation experiments",
      "abstract": "  We argue that regardless of the outcome of future Long Baseline experiments,\nadditional information will be needed to unambiguously decide among the\ndifferent scenarios of neutrino mixing. We use, for this purpose, a simple test\nof underground data: an asymmetry between downward and upward going events.\nSuch an asymmetry, in which matter effects can be crucial, tests electron and\nmuon neutrino data separately and can be compared with the theoretical\nprediction without relying on any simulation program.\n",
      "subjects": [
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.62.065008",
      "title": "Phases of dual superconductivity and confinement in softly broken N=2\n  supersymmetric Yang-Mills theories",
      "abstract": "  We study the electric flux tubes that undertake color confinement in N=2\nsupersymmetric Yang-Mills theories softly broken down to N=1 by perturbing with\nthe first two Casimir operators. The relevant Abelian Higgs model is not the\nstandard one due to the presence of an off-diagonal coupling among different\nmagnetic U(1) factors. We perform a preliminary study of this model at a\nqualitative level. BPS vortices are explicitely obtained for particular values\nof the soft breaking parameters. Generically however, even in the ultrastrong\nscaling limit, vortices are not critical but live in a \"hybrid\" type II phase.\nAlso, ratios among string tensions are seen to follow no simple pattern. We\nexamine the situation at the half Higgsed vacua and find evidence for solutions\nwith the behaviour of superconducting strings. In some cases they are solutions\nto BPS equations.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1126-6708/2000/12/020",
      "title": "Brane Configurations of BPS Domain Walls for the N=1^* SU(N) Gauge\n  Theory",
      "abstract": "  We study supersymmetric domain walls in N=1 SU(N) gauge theory with 3 massive\nadjoint representation chiral multiplets. This theory, known as N=1^*, can be\nobtained as a massive deformation of N=4 Yang-Mills theory. Following\nPolchinski and Strassler, we consider the string dual of this theory in terms\nof spherical 5-branes and construct BPS domain walls interpolating between the\nmany vacua. We compare our results to field theoretic domain walls and also\nfind that this work is related to the physics of expanded ``dielectric'' branes\nnear zero radius.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217732301003401",
      "title": "Chiral Gauge Anomalies on Noncommutative Minkowski Space-time",
      "abstract": "  Chiral gauge anomalies on noncommutative Minkowski Space-time are computed\nand have their origin elucidated. The consistent form and the covariant form of\nthe anomaly are obtained. Both Fujikawa's method and Feynman diagram techniques\nare used to carry out the calculations\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0393-0440(01)00095-X",
      "title": "Twisted K-theory in $g>1$ from D-branes",
      "abstract": "  We study the wrapping of N type IIB Dp-branes on a compact Riemann surface\n$\\Sigma$ in genus $g>1$ by means of the Sen-Witten construction, as a\nsuperposition of N' type IIB Dp'-brane/antibrane pairs, with $p'>p$. A\nbackground Neveu-Schwarz field B deforms the commutative $C^{\\star}$-algebra of\nfunctions on $\\Sigma$ to a noncommutative $C^{\\star}$-algebra. Our construction\nprovides an explicit example of the $N'\\to\\infty$ limit advocated by\nBouwknegt-Mathai and Witten in order to deal with twisted K-theory. We provide\nthe necessary elements to formulate M(atrix) theory on this new\n$C^{\\star}$-algebra, by explicitly constructing a family of projective\n$C^{\\star}$-modules admitting constant-curvature connections. This allows us to\ndefine the $g>1$ analogue of the BPS spectrum of states in $g=1$, by means of\nDonaldson's formulation of the Narasimhan-Seshadri theorem.\n",
      "subjects": [
        "hep-th",
        "math-ph",
        "math.AG",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1126-6708/2002/10/010",
      "title": "Fractional D3-branes in diverse backgrounds",
      "abstract": "  In the first part of this article, we find fractional D3-branes supergravity\nsolutions on orientifolded C^2/Z_2 orbifolds of type IIB string theory. The\none-loop corrected gauge couplings for the symplectic or orthogonal groups\nliving on the D-branes are reproduced on the world-volume of probes. In the\nsecond part of the paper, we construct a D3-brane solution on the two-centers\nTaub-NUT manifold which interpolates between fractional D3-branes in the ALE\nspace limit and a T-dual smeared type IIA configuration. Then, we lift this\nconfiguration to M-theory and comment on the connections with wrapped M5-branes\nsolutions.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/1126-6708/2002/12/025",
      "title": "On the consistency of de Sitter vacua",
      "abstract": "  In this paper the consistency of the de Sitter invariant $\\alpha $-vacua,\nwhich have been introduced as simple tools to study the effects of\ntransplanckian physics, is investigated. In particular possible non\nrenormalization problems are discussed, as well as non standard properties of\nGreens functions. We also discuss the non thermal properties of the $\\alpha\n$-vacua and the necessity of $\\alpha$ to change. The conclusion is that non of\nthese problems necessarily exclude an application of the $\\alpha $-vacua to\ninflation.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1023/B:TAMP.0000036542.47378.ba",
      "title": "N=4 Multiplets in N=3 Harmonic Superspace",
      "abstract": "  It is shown that the N=3 harmonic-superfield equations of motion are\ninvariant with respect to the 4-th supersymmetry. The SU(3) harmonics are also\nused to analyze a more flexible form of superfield constraints for the Abelian\nN=4 vector multiplet and its N=3 decomposition. An alternative unusual\nrepresentation of the N=4 supersymmetry is realized on infinite multiplets of\nanalytic superfields in the N=3 harmonic superspace. U(1) charges of\nsuperfields in these multiplets are parametrized by an integer- valued\nparameter which plays the role of the discrete coordinate. Each superfield term\nof the N=3 Yang-Mills action has the infinite-dimensional N=4 generalization.\nThe gauge group of this model contains an infinite number of superfield\nparameters.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevD.72.066004",
      "title": "An explicit example of a moduli driven phase transition in heterotic\n  models",
      "abstract": "  We present an explicit example of a gauge symmetry breaking phase transition\nin heterotic models, the dynamics of which are not thermal and can be described\nin a well controlled manner throughout. The phase transition is driven by the\nevolution of bundle moduli - moduli associated with gauge field vacuum\nexpectation values in the hidden dimensions. We present the necessary parts of\nthe four dimensional effective theory including moduli which describe the\nembedding of the gauge bundle within the gauge group. We then present exact\ncosmological solutions to the system before going on to use them to describe\nthe phase transition. The explicit nature of our description enables us to plot\nhow the gauge bosons associated with the symmetries which are broken in the\ntransition gain masses with time. This is in contrast to the use, for example,\nof a brane collision as a modulus driven phase transition. In the course of\nthis work we find a number of other interesting results. We observe that the\nKahler potential of the system is given by the logarithm of the volume of the\ncompact space even when bundle moduli are included. We also note that the\ndynamics of the gauge bundle mean that small instanton transitions are\nclassically forbidden for all but a set of measure zero of the initial\nconditions of the system. The paper is written in such a manner that the\ncosmological description of the phase transition can be read independently of\nthe derivation of the four dimensional theory.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/978-3-540-71117-9_4",
      "title": "Quantum Field Theory: Where We Are",
      "abstract": "  We comment on the present status, the concepts and their limitations, and the\nsuccesses and open problems of the various approaches to a relativistic quantum\ntheory of elementary particles, with a hindsight to questions concerning\nquantum gravity and string theory.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Noncommutative QED corrections to process $e^+e^-\\to\\mu^+\\mu^-\\gamma$ at\n  linear collider energies",
      "abstract": "  The cross section for process $e^+e^-\\to\\mu^+\\mu^-\\gamma$ in the framework of\nnoncommutative quantum electrodynamics(NC QED) is studied. It is shown that the\nNC correction of scattering sections is not monotonous enhancement with total\nenergy of colliding electrons, but there is an optimal collision energy to get\nthe greatest NC correction. Moreover, there is a linear relation between NC QED\nscale energy and the optimal collision energy. The experimental methods to\nimprove the precision of determining NC effects are discussed, because this\nprocess is an ${\\cal O}(\\alpha^3) $ NC QED process, high precision tests are\nnecessary.\n",
      "subjects": [
        "hep-th",
        "hep-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217732391002049",
      "title": "$W_\\infty$ and Anomalies of Self-Dual Einstein Theories",
      "abstract": "  This manuscripts corrects some minor error in the paper, Mod. Phys. Lett. A 6\n1893 (1991)\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.69.2623",
      "title": "Attractive Forces Between Electrons in QED$_{3}$",
      "abstract": "  Vacuum polarization effects are non-perturbatively incorporated into the\nphoton propagator to eliminate the severe infrared problems characteristic of\nQED$_3$. The theory is thus rephrased in terms of a massive vector boson whose\nmass is $e^2/(8\\pi)$. Subsequently, it is shown that electron-electron bound\nstates are possible in QED$_3$.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1143/ptp/90.3.743",
      "title": "Exact Solutions to the Wheeler-DeWitt Equation of Two Dimensional\n  Dilaton Gravity",
      "abstract": "  The two dimensional dilaton gravity with the cosmological term and with an\neven number of matter fields minimally coupled to the gravity is considered.\nThe exact solutions to the Wheeler-DeWitt equation are obtained in an explicit\nfunctional form, which contain an arbitrary holomorphic function of the matter\nfields.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On a non-CP-violating electric dipole moment of elementary particles",
      "abstract": "  A description of elementary particles should be based on irreducible\nrepresentations of the Poincar\\'e group. In the theory of massive\nrepresentations of the full Poincar\\'e group there are essentially four\ndifferent cases. One of them corresponds to the ordinary Dirac theory. The\nextension of Dirac theory to the remaining three cases makes it possible to\ndescribe an anomalous electric dipole moment of elementary particles without\nbreaking the reflections.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0370-2693(95)00108-W",
      "title": "c>1 Non-Critical Strings and Large-N Matrix Field Theory",
      "abstract": "  Motivated by a possible relativistic string description of hadrons we use a\ndiscretised light-cone quantisation and Lanczos algorithm to investigate the\nphase structure of phi^3 matrix field theory in the large N limit. In 1+1\ndimensions we confirm the existence of Polyakov's non-critical string theory at\nthe boundary between parton-like and string-like phases, finding critical\nexponents for longitudinal oscillations equal to or consistent with those given\nby a mean field argument. The excitation spectrum is finite, possibly discrete.\nWe calculate light-cone structure functions and find evidence that the\nprobability Q(x) of a parton in the string carrying longitudinal momentum\nfraction between x and x+dx has support on all 0<x<1, despite the average\nnumber of partons being infinite.\n",
      "subjects": [
        "hep-th",
        "hep-lat"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Effective quark interactions from QCD",
      "abstract": "  We propose a new method for an analytical, non-perturbative computation of\neffective quark interactions from QCD. It is based on an exact flow equation\nwhich describes the scale dependence of the effective average action for quarks\nin presence of gluons.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0550-3213(96)00584-6",
      "title": "Path integral of the hydrogen atom, the Jacobi's principle of least\n  action and one-dimensional quantum gravity",
      "abstract": "  A path integral evaluation of the Green's function for the hydrogen atom\ninitiated by Duru and Kleinert is studied by recognizing it as a special case\nof the general treatment of the separable Hamiltonian of Liouville-type. The\nbasic dynamical principle involved is identified as the Jacobi's principle of\nleast action for given energy which is reparametrization invariant, and thus\nthe appearance of a gauge freedom is naturally understood. The separation of\nvariables in operator formalism corresponds to a choice of gauge in path\nintegral, and the Green's function is shown to be gauge independent if the\noperator ordering is properly taken into account. Unlike the conventional\nFeynman path integral,which deals with a space-time picture of particle motion,\nthe path integral on the basis of the Jacobi's principle sums over orbits in\nspace. We illustrate these properties by evaluating an exact path integral of\nthe Green's function for the hydrogen atom in parabolic coordinates, and thus\navoiding the use of the Kustaanheimo-Stiefel transformation. In the present\nformulation , the Hamiltonian for Stark effect is converted to the one for\nanharmonic oscillators with an unstable quartic coupling. We also study the\nhydrogen atom path integral from a view point of one-dimensional quantum\ngravity coupled to matter fields representing the electron coordinates. A\nsimple BRST analysis of the problem with an evaluation of Weyl anomaly is\npresented .\n",
      "subjects": [
        "hep-th",
        "quant-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1142/S0217751X97000736",
      "title": "Relativistic Self-Dual Chern-Simons Systems: A Perspective",
      "abstract": "  The self-dual systems are constrained and so are simpler to understand. In\nrecent years there have been several studies on the self-dual Chern-Simons\nsystems. Here I present a brief survey of works done by my collaborators and\nmyself. I also discuss several questions related to these self-dual models.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Local State Probabilities of Solvable Lattice Models: Relatives of\n  $A_{n}^{(1)}$ Family",
      "abstract": "  We present the results for the local state probabilities (LSP) of the\nsolvable lattice models, constructed around rational conformal field theory\ngiven by WZW model on $SO(3)_{4 R}=SU(2)_{4 R} / Z_{2}$ together with primary\nfield $\\phi_{1}$(symmetric tensor of degree 2). Some conjectures for the LSP\nfor some higher rank relatives of $A_{n}^{(1)}$ face models are also presented.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0550-3213(98)00444-1",
      "title": "On N=8 Supergravity on $AdS_5$ and N=4 Superconformal Yang-Mills theory",
      "abstract": "  We discuss the spectrum of states of IIB supergravity on $AdS_5\\times S^5$ in\na manifest $SU(2,2/4)$ invariant setting. The boundary fields are described in\nterms of N=4 superconformal Yang-Mills theory and the proposed correspondence\nbetween supergravity in $AdS_5$ and superconformal invariant singleton theory\nat the boundary is formulated in an N=4 superfield covariant language.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0920-5632(00)00791-X",
      "title": "An insider's guide to quantum causal histories",
      "abstract": "  A review is given of recent work aimed at constructing a quantum theory of\ncosmology in which all observables refer to information measurable by observers\ninside the universe. At the classical level the algebra of observables should\nbe modified to take into account the fact that observers can only give truth\nvalues to observables that have to do with their backwards light cone. The\nresulting algebra is a Heyting rather than a Boolean algebra. The complement is\nnon-trivial and contains information about horizons and topology change.\nRepresentation of such observables quantum mechanically requires a many-Hilbert\nspace formalism, in which different observers make measurements in different\nHilbert spaces. I describe such a formalism, called \"quantum causal histories\";\nexamples include causally evolving spin networks and quantum computers.\n",
      "subjects": [
        "hep-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1007/s002200100512",
      "title": "Correlations between zeros and supersymmetry",
      "abstract": "  In our previous work [math-ph/9904020], we proved that the correlation\nfunctions for simultaneous zeros of random generalized polynomials have\nuniversal scaling limits and we gave explicit formulas for pair correlations in\ncodimensions 1 and 2. The purpose of this paper is to compute these universal\nlimits in all dimensions and codimensions. First, we use a supersymmetry method\nto express the n-point correlations as Berezin integrals. Then we use the Wick\nmethod to give a closed formula for the limit pair correlation function for the\npoint case in all dimensions.\n",
      "subjects": [
        "math-ph",
        "math.AG",
        "math.CV",
        "math.MP",
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1006/jfan.2001.3855",
      "title": "Generalised Brownian Motion and Second Quantisation",
      "abstract": "  A new approach to the generalised Brownian motion introduced by M. Bozejko\nand R. Speicher is described, based on symmetry rather than deformation. The\nsymmetrisation principle is provided by Joyal's notions of tensorial and\ncombinatorial species. Any such species V gives rise to an endofunctor F_V of\nthe category of Hilbert spaces with contractions. A generalised Brownian motion\nis an algebra of creation and annihilation operators acting on F_V(H) for\narbitrary Hilbert spaces H and having a prescription for the calculation of\nvacuum expectations in terms of a function t on pair partitions. The positivity\nis encoded by a *-semigroup of \"broken pair partitions\" whose representation\nspace with respect to t is V. The existence of the second quantisation as\nfunctor Gamma_t from Hilbert spaces to noncommutative probability spaces is\nproved to be equivalent to the multiplicative property of the function t. For a\ncertain one parameter interpolation between the fermionic and the free Brownian\nmotion it is shown that the ``field algebras'' Gamma(K) are type II_1 factors\nwhen K is infinite dimensional.\n",
      "subjects": [
        "math-ph",
        "math.MP",
        "math.OA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "On Zeeman Topology in Kaluza-Klein and Gauge Theories",
      "abstract": "  E. C. Zeeman [1] has criticized the fact that in all articles and books until\nthat moment (1967) the topology employed to work with the Minkowski space was\nthe Euclidean one. He has proposed a new topology, which was generalized for\nmore general space-times by Goebel [2]. In the Zeeman and Goebel topologies for\nthe space-time, the unique continuous curves are polygonals composed by\ntime-like straight lines and geodesics respectively. In his paper, Goebel\nproposes a topology for which the continuous curves are polygonals composed by\nmotions of charged particles. Here we obtain in a very simple way a\ngeneralization of this topology, valid for any gauge fields, by employing the\nprojection theorem of Kaluza-Klein theories (page 144 of Bleecker [3]). This\napproach relates Zeeman topologies and Kaluza-Klein, therefore Gauge Theories,\nwhat brings insights and points in the direction of a completely geometric\ntheory.\n",
      "subjects": [
        "math-ph",
        "math.MP"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "A non-ribbon plumbing of fibered ribbon knots",
      "abstract": "  A closer look at an example introduced by Livingston & Melvin and later\nstudied by Miyazaki shows that a plumbing of two fibered ribbon knots (along\ntheir fiber surfaces) may be algebraically slice yet not ribbon.\n",
      "subjects": [
        "math.GT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The computation of the non-commutative generalization of the\n  A-polynomial for the figure-eight knot",
      "abstract": "  The paper contains the computation of the noncommutative A-ideal of the\nfigure-eight knot, a noncommutative generalization of the A-polynomial. We show\nthat if a knot has the same noncommutative A-ideal as the figure-eight knot,\nthen all colored Kauffman brackets are the same as those of the figure-eight\nknot.\n",
      "subjects": [
        "math.GT",
        "math.QA"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Palindromes and orderings in Artin groups",
      "abstract": "  The braid group $B_{n}$, endowed with Artin's presentation, admits two\ndistinguished involutions. One is the anti-automorphism ${\\rm{rev}}: B_{n} \\to\nB_{n}$, $v \\mapsto \\bar{v}$, defined by reading braids in the reverse order\n(from right to left instead of left to right). Another one is the conjugation\n$\\tau:x \\mapsto \\Delta^{-1}x \\Delta$ by the generalized half-twist (Garside\nelement).\n  More generally, the involution ${\\rm{rev}}$ is defined for all Artin groups\n(equipped with Artin's presentation) and the involution $\\tau$ is defined for\nall Artin groups of finite type. A palindrome is an element invariant under\nrev. We classify palindromes and palindromes invariant under $\\tau$ in Artin\ngroups of finite type. The tools are elementary rewriting and the construction\nof explicit left-orderings compatible with rev.\n  Finally, we discuss generalizations to Artin groups of infinite type and\nGarside groups.\n",
      "subjects": [
        "math.GT",
        "math.GR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Hook-lengths and Pairs of Compositions",
      "abstract": "  The monomial basis for polynomials in N variables is labeled by compositions.\nTo each composition there is associated a hook-length product, which is a\nproduct of linear functions of a parameter. The zeroes of this product are\nrelated to \"critical pairs\" of compositions; a concept defined in this paper.\nThis property can be described in an elementary geometric way; for example:\nconsider the two compositions (2,7,8,2,0,0) and (5,1,2,5,3,3), then the\nrespective ranks, permutations of the index set {1,2,...,6} sorting the\ncompositions, are (3,2,1,4,5,6) and (1,6,5,2,3,4), and the two vectors of\ndifferences (between the compositions and the ranks, respectively) are\n(-3,6,6,-3,-3,-3) and (2,-4,-4,2,2,2), which are parallel, with ratio -3/2. For\na given composition and zero of its hook-length product there is an algorithm\nfor constructing another composition with the parallelism property and which is\ncomparable to it in a certain partial order on compositions, derived from the\ndominance order. This paper presents the motivation from the theory of\nnonsymmetric Jack polynomials and the description of the algorithm, as well as\nthe proof of its validity.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Perfect matchings and perfect powers",
      "abstract": "  In the last decade there have been many results about special families of\ngraphs whose number of perfect matchings is given by perfect or near perfect\npowers. In this paper we present an approach that allows proving them in a\nunified way. We use this approach to prove a conjecture of James Propp stating\nthat the number of tilings of the so-called Aztec dungeon regions is a power\n(or twice a power) of 13. We also prove a conjecture of Matt Blum stating that\nthe number of perfect matchings of a certain family of subgraphs of the square\nlattice is a power of 3 or twice a power of 3. In addition we obtain\nmulti-parameter generalizations of previously known results, and new\nmulti-parameter exact enumeration results. We obtain in particular a simple\ncombinatorial proof of Bo-Yin Yang's multivariate generalization of fortresses,\na result whose previously known proof was quite complicated, amounting to\nevaluation of the Kasteleyn matrix by explicit row reduction. We also include a\nnew multivariate exact enumeration of Aztec diamonds, in the spirit of\nStanley's multivariate version.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "The degree of the discriminant of irreducible representations",
      "abstract": "  We present a formula for the degree of the discriminant of irreducible\nrepresentations of a Lie group, in terms of the roots of the group and the\nhighest weight of the representation. The proof uses equivariant cohomology\ntechniques, namely, the theory of Thom polynomials, and a new method for their\ncomputation. We study the combinatorics of our formulas in various special\ncases.\n",
      "subjects": [
        "math.AG",
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Gradient Bounds for Solutions of Elliptic and Parabolic Equations",
      "abstract": "  Let $L$ be a second order elliptic operator on $R^d$ with a constant\ndiffusion matrix and a dissipative (in a weak sense) drift $b \\in L^p_{loc}$\nwith some $p>d$.\n  We assume that $L$ possesses a Lyapunov function, but no local boundedness of\n$b$ is assumed. It is known that then there exists a unique probability measure\n$\\mu$ satisfying the equation $L^*\\mu=0$ and that the closure of $L$ in\n$L^1(\\mu)$ generates a Markov semigroup $\\{T_t\\}_{t\\ge 0}$ with the resolvent\n$\\{G_\\lambda\\}_{\\lambda > 0}$.\n  We prove that, for any Lipschitzian function $f\\in L^1(\\mu)$ and all\n$t,\\lambda>0$, the functions $T_tf$ and $G_\\lambda f$ are Lipschitzian and\n|\\nabla T_tf(x)| \\leq T_t|\\nabla f|(x) and |\\nabla G_\\lambda f(x)| \\leq\n\\frac{1}{\\lambda} G_\\lambda |\\nabla f|(x).\n  An analogous result is proved in the parabolic case.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Stable Hilbert series of $\\mathcal S(\\mathfrak g)^K$ for classical\n  groups",
      "abstract": "  Given a classical symmetric pair, $(G,K)$, with $\\mathfrak g = Lie(G)$, we\nprovide descriptions of the Hilbert series of the algebra of $K$-invariant\nvectors in the associated graded algebra of $\\mathcal U(\\mathfrak g)$ viewed as\na $K$-representation under restriction of the adjoint representation. The\ndescription illuminates a certain stable behavior of the Hilbert series, which\nis investigated in a case-by-case basis. We note that the stable Hilbert series\nof one symmetric pair often coincides with others. Also, for the case of the\nreal form $U(p,q)$ we derive a closed expression for the Hilbert series when\n$\\min(p,q) \\to \\infty$.\n",
      "subjects": [
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non-equilibrium stochastic dynamics in continuum: The free case",
      "abstract": "  We study the problem of identification of a proper state-space for the\nstochastic dynamics of free particles in continuum, with their possible birth\nand death. In this dynamics, the motion of each separate particle is described\nby a fixed Markov process $M$ on a Riemannian manifold $X$. The main problem\narising here is a possible collapse of the system, in the sense that, though\nthe initial configuration of particles is locally finite, there could exist a\ncompact set in $X$ such that, with probability one, infinitely many particles\nwill arrive at this set at some time $t>0$. We assume that $X$ has infinite\nvolume and, for each $\\alpha\\ge1$, we consider the set $\\Theta_\\alpha$ of all\ninfinite configurations in $X$ for which the number of particles in a compact\nset is bounded by a constant times the $\\alpha$-th power of the volume of the\nset. We find quite general conditions on the process $M$ which guarantee that\nthe corresponding infinite particle process can start at each configuration\nfrom $\\Theta_\\alpha$, will never leave $\\Theta_\\alpha$, and has cadlag (or,\neven, continuous) sample paths in the vague topology. We consider the following\nexamples of applications of our results: Brownian motion on the configuration\nspace, free Glauber dynamics on the configuration space (or a birth-and-death\nprocess in $X$), and free Kawasaki dynamics on the configuration space. We also\nshow that if $X=\\mathbb R^d$, then for a wide class of starting distributions,\nthe (non-equilibrium) free Glauber dynamics is a scaling limit of\n(non-equilibrium) free Kawasaki dynamics.\n",
      "subjects": [
        "math.PR"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Theorems for a Price: Tomorrow's Semi-Rigorous Mathematical Culture",
      "abstract": "  The future of mathematics is described, by using the WZ algorithmic proof\ntheory as a parable.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "$R$--groups and elliptic representations for similitude groups",
      "abstract": "  The tempered spectrum of the similitude groups of non-degenerate symplectic,\nhermitian, or split orthogonal forms defined over $p$\\snug-adic groups of\ncharacteristic zero is studied. The components of representations induced from\ndiscrete series of proper parabolic subgroups are classified in terms of\n$R$\\snug-groups. Multiplicity one is proved. The tempered elliptic spectrum is\nidentified, and the relation between elliptic characters appearing in a given\ninduced representation is determined. Those irreducible tempered\nrepresentations which are not elliptic and not fully induced from elliptic\ntempered representations are described.\n",
      "subjects": [
        "math.RT",
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "An Infinite Antichain of Permutations",
      "abstract": "  We constructively prove that the partially ordered set of finite permutations\nordered by deletion of entries contains an infinite antichain.\n",
      "subjects": [
        "math.CO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Non-symmetric convex domains have no basis of exponentials",
      "abstract": "  A conjecture of Fuglede states that a bounded measurable set $\\Omega$ in\nspace, of measure 1, can tile space by translations if and only if the Hilbert\nspace $L^2(\\Omega)$ has an orthonormal basis consisting of exponentials. If\n$\\Omega$ has the latter property it is called spectral. We generalize a result\nof Fuglede, that a triangle in the plane is not spectral, proving that every\nnon-symmetric convex domain is not spectral.\n",
      "subjects": [
        "math.CA",
        "math.MG"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Density of cubic field discriminants",
      "abstract": "  In this paper we give a conjectural refinement of the Davenport-Heilbronn\ntheorem on the density of cubic field discriminants. We explain how this\nrefinement is plausible theoretically and agrees very well with computational\ndata.\n",
      "subjects": [
        "math.NT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Symmetry groups and Lagrangians associated to Tzitzeica surfaces",
      "abstract": "  One applies the symmetry group theory for study the partial differential\nequations of Tzitzeica surfaces theory. One finds infinitesimal symmetries,\nLagrangians and a new solution of Titzeica equation.\n",
      "subjects": [
        "math.DG",
        "math.RT"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevE.68.046306",
      "title": "Turbulence with Pressure: Anomalous Scaling of a Passive Vector Field",
      "abstract": "  The field-theoretic renormalization group (RG) and the operator product\nexpansion are applied to the model of a divergence-free vector quantity,\npassively advected by the ``synthetic'' turbulent flow with a finite\ncorrelation time. The vector field is described by the stochastic\nadvection-diffusion equation with the most general form of the inertial\nnonlinearity. The statistics of the advecting velocity field is Gaussian with\npowerlike energy spectrum and dispersion law. The inertial-range behavior of\nthe model is described by seven regimes that correspond to nontrivial fixed\npoints of the RG equations and exhibit anomalous scaling. The corresponding\nanomalous exponents are associated with the critical dimensions of tensor\ncomposite operators built solely of the passive vector field, which allows to\nconstruct a regular perturbation expansion. The actual calculation is performed\nin one-loop approximation, including the anisotropic sectors. Universality of\nthe exponents, their (in)dependence on the forcing, effects of the large-scale\nanisotropy, compressibility and pressure are discussed. In particular, for all\nthe scaling regimes the exponents obey a hierarchy related to the degree of\nanisotropy: the more anisotropic is the contribution of a composite operator to\na correlation function, the faster it decays in the inertial-range. Relevance\nof the results for the real developed turbulence described by the stochastic\nNavier-Stokes equation is discussed.\n",
      "subjects": [
        "nlin.CD"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Dynamics and Development of the International System: A Complexity\n  Science Perspective",
      "abstract": "  In this article I discuss the outcome of an exploratory research project\nbased on complexity science concepts and theories; this research is focused on\nthe Great Power war dynamics in the time period 1495 - 1945. According to this\nresearch, the international system has self-organized critical (SOC)\ncharacteristics. A critical point is the attractor of the international system.\nThe war dynamics of Great Powers can be illustrated by a power law. As a result\nof a driving force, the international system is constantly being pushed toward\nthis critical point. The security dilemma is a booster of this driving force.\nTension and frustration build up in the international system as a result of\nvarious system thresholds, and are periodically discharged through wars. The\nSOC characteristics of the international system result in a punctuated\nequilibrium dynamic. The punctuations produce new international systems, each\nwith its specific characteristics. A quantifiable development of the\ninternational system toward a condition of increased stability and reduced\nresilience can be observed. In addition to SOC characteristics, the\ninternational system exhibits characteristics of a chaotic system. Chaos, order\nand development are closely linked. The SOC dynamics generate a process of\nsocial expansion. It is possible to explain the social integration of Europe\nfrom this perspective.\n",
      "subjects": [
        "nlin.AO"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0954-3899/31/4/018",
      "title": "System size dependence of strange particle yields and spectra at\n  sqrt(s)=17.3 GeV",
      "abstract": "  Yields and spectra of strange hadrons (K+, K-, phi, Lambda and Antilambda) as\nwell as of charged pions were measured in near central C+C and Si+Si collisions\nat 158 AGeV beam energy with the NA49 detector. Together with earlier data for\np+p, S+S and Pb+Pb reactions the system size dependence can be studied.\nRelative strangeness production rises fast and saturates at about 60\nparticipating nucleons; the net hyperon spectra show an increasing shift\ntowards midrapidity for larger colliding nuclei. An interpretation based on the\nformation of coherent systems of increasing volume is proposed. The transverse\nmass spectra can be described by a blast wave ansatz. Increasing flow velocity\nis accompanied by decreasing temperatures for both kinetic and chemical freeze\nout. The increasing gap between inelastic and elastic decoupling leaves space\nfor rescattering.\n",
      "subjects": [
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.82.5000",
      "title": "Phase Transitions in Finite Nuclei and the Integer Nucleon Number\n  Problem",
      "abstract": "  The study of spherical-deformed ground--state phase transitions in finite\nnuclei as a function of N and Z is hindered by the discrete values of the\nnucleon number. A resolution of the integer nucleon number problem, and\nevidence relating to phase transitions in finite nuclei, are discussed from the\nexperimental point of view and interpreted within the framework of the\ninteracting boson model.\n",
      "subjects": [
        "nucl-ex",
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.71.024003",
      "title": "Charge-Symmetry-Breaking Three-Nucleon Forces",
      "abstract": "  Leading-order three-nucleon forces that violate isospin symmetry are\ncalculated in Chiral Perturbation Theory. The effect of the\ncharge-symmetry-breaking three-nucleon force is investigated in the trinucleon\nsystems using Faddeev calculations. We find that the contribution of this force\nto the 3He - 3H binding-energy difference is approximately 5 keV.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Scattering as a tool to study nuclear structure toward the drip lines",
      "abstract": "  Results are presented for the elastic scattering of electrons and protons\nfrom the exotic He and Li isotopes. Comparison with scattering results from the\nstable He and Li nuclei allows for an investigation into the effects that the\nextensive neutron distributions have on the charge density. For comparison we\nalso consider the proton halo nucleus 8B. The consequences and possible\nsuggestions for proposed electron scattering facilities for exotic nuclei are\ndiscussed.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevC.74.054611",
      "title": "Dynamical aspects of isotopic scaling",
      "abstract": "  Investigation of the effect of the dynamical stage of heavy-ion collisions\nindicates that the increasing width of the initial isospin distributions is\nreflected by a significant modification of the isoscaling slope for the final\nisotopic distributions after de-excitation. For narrow initial distributions,\nthe isoscaling slope assumes the limiting value of the two individual initial\nnuclei while for wide initial isotopic distributions the slope for hot\nfragments approaches the initial value. The isoscaling slopes for final cold\nfragments increase due to secondary emissions. The experimentally observed\nevolution of the isoscaling parameter in multifragmentation of hot\nquasiprojectiles at E$_{inc}$=50 AMeV, fragmentation of $^{86}$Kr projectiles\nat E$_{inc}$=25 AMeV and multifragmentation of target spectators at\nrelativistic energies was reproduced by a simulation with the dynamical stage\ndescribed using the appropriate model (deep inelastic transfer and incomplete\nfusion at the Fermi energy domain and spectator-participant model at\nrelativistic energies) and the de-excitation stage described with the\nstatistical multifragmentation model. In all cases the isoscaling behavior was\nreproduced by a proper description of the dynamical stage and no unambiguous\nsignals of the decrease of the symmetry energy coefficient were observed.\n",
      "subjects": [
        "nucl-th",
        "nucl-ex"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Inclusive electron scattering off 4He",
      "abstract": "  Inclusive electron scattering off 4He is investigated for low and medium\nenergy and momentum transfers. The final state interaction, given by the simple\nsemirealistic Malfliet-Tjon potential, is treated rigorously applying the\nLorentz Integral Transform (LIT) method. Besides the nonrelativistic one-body\ncurrent a consistent meson exchange current is constructed and implemented.\nResults are presented for both longitudinal and transverse response functions\nat various momentum transfers. Good agreement with experimental data is found\nfor the longitudinal response function, while some strength is missing in the\ntransverse response function on the low-energy side of the quasi-elastic peak.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0370-2693(93)90772-A",
      "title": "Nuclear Polarization Corrections for the S--Levels of Electronic and\n  Muonic Deuterium",
      "abstract": "  We calculate the second-order corrections to the atomic energy level shifts\nin ordinary and muonic deuterium due to virtual excitations of the deuteron\nwhich are important for ongoing and planned precise experiments in these\nsystems. For light atoms a method can be used in which the shift is expressed\nas integrals over the longitudinal and transverse inelastic structure functions\nof the nucleus. We employ the structure functions arising from separable NN\npotentials of the Yamaguchi and Tabakin form which can be evaluated\nanalytically. Special emphasis is put on gauge invariance which requires a\nconsistent inclusion of interaction currents and seagull terms. The effect of\nthe D-wave component of the deuteron is investigated for the leading\nlongitudinal contribution. We also estimate the shift for pionic deuterium.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/0375-9474(96)00217-5",
      "title": "Triplet pairing in beta-stable neutron star matter",
      "abstract": "  $^{3}P_{2}$ pairing in neutron matter is investigated using the Bonn\npotential models. We find pairing energy gaps in pure neutron matter comparable\nto the results of previous investigators when the attractive tensor coupling is\nincluded. However, taking into account that in a neutron star we have matter at\n$\\beta$ equilibrium, we find that the $^{3}P_{2}$-$^{3}F_{2}$ energy gap is\nreduced considerably.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/S0375-9474(97)00028-6",
      "title": "On the Coulomb and higher-order sum rules in the relativistic Fermi gas",
      "abstract": "  Two different methods for establishing a space-like Coulomb sum rule for the\nrelativistic Fermi gas are compared. Both of them divide the charge response by\na normalizing factor such that the reduced response thus obtained fulfills the\nsum rule at large momentum transfer. To determine the factor, in the first\napproach one exploits the scaling property of the longitudinal response\nfunction, while in the second one enforces the completeness of the states in\nthe space-like domain via the Foldy-Wouthuysen transformation. The\nenergy-weighted and the squared-energy-weighted sum rules for the reduced\nresponses are explored as well and the extension to momentum distributions that\nare more general than a step-function is also considered. The two methods yield\nreduced responses and Coulomb sum rules that saturate in the non-Pauli-blocked\nregion, which can hardly be distinguished for Fermi momenta appropriate to\natomic nuclei. Notably the sum rule obtained in the Foldy-Wouthuysen approach\ncoincides with the well known non-relativistic one. Only at quite large\nmomentum transfers (say 1 GeV/c) does a modest softening of the\nFoldy-Wouthuysen reduced response with respect to that obtained in the scaling\nframework show up. The two responses have the same half-width to second order\nin the Fermi momentum expansion. However, when distributions extending to\nmomenta larger than that at the Fermi surface are employed, then in both\nmethods the Coulomb sum rule saturates only if the normalizing factors are\nappropriately modified to account for the high momentum components of the\nnucleons.\n",
      "subjects": [
        "nucl-th"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevLett.71.2026",
      "title": "Spiral Defect Chaos in Large Aspect Ratio Rayleigh-Benard Convection",
      "abstract": "  We report experiments on convection patterns in a cylindrical cell with a\nlarge aspect ratio. The fluid had a Prandtl number of approximately 1. We\nobserved a chaotic pattern consisting of many rotating spirals and other\ndefects in the parameter range where theory predicts that steady straight rolls\nshould be stable. The correlation length of the pattern decreased rapidly with\nincreasing control parameter so that the size of a correlated area became much\nsmaller than the area of the cell. This suggests that the chaotic behavior is\nintrinsic to large aspect ratio geometries.\n",
      "subjects": [
        "patt-sol",
        "chao-dyn",
        "nlin.CD",
        "nlin.PS"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Analytic solution for a class of turbulence problems",
      "abstract": "  An exact analytical method for determining the Lagrangian velocity\ncorrelation and the diffusion coefficient for particles moving in a stochastic\nvelocity field is derived. It applies to divergence-free 2-dimensional Gaussian\nstochastic fields which are stationary, homogeneous and have factorized\nEulerian correlations.\n",
      "subjects": [
        "physics.plasm-ph",
        "physics.flu-dyn"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1088/0305-4470/34/49/103",
      "title": "Quantum Field Theory and Phylogenetic Branching",
      "abstract": "  A calculational framework is proposed for phylogenetics, using nonlocal\nquantum field theories in hypercubic geometry. Quadratic terms in the\nHamiltonian give the underlying Markov dynamics, while higher degree terms\nrepresent branching events. The spatial dimension L is the number of leaves of\nthe evolutionary tree under consideration. Momentum conservation modulo\n${\\mathbb Z}_{2}^{times L}$ in $L \\leftarrow 1$ scattering corresponds to tree\nedge labelling using binary L-vectors. The bilocal quadratic term allows for\nmomentum-dependent rate constants - only the tree(s) compatible with selected\nnonzero edge rates contribute to the branching probability distribution.\nApplications to models of evolutionary branching processes are discussed.\n",
      "subjects": [
        "physics.bio-ph",
        "physics.chem-ph",
        "q-bio"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Fundamental Research and Developing Countries",
      "abstract": "  In the first part of this report, I discuss the sociological role of\nfundamental research in Developing Countries (DC) and how to realize this\nprogram. In the second part, I give a brief and elementary introduction to the\nfield of high-energy physics (HEP), accessible to a large audience not\nnecessary physicists. The aim of this report is to make politicians and\nfinancial backers aware on the long-term usefulness of fundamental research in\nDC and on the possible globalisation of HEP and, in general, of science.\n",
      "subjects": [
        "physics.soc-ph",
        "hep-ph",
        "hep-th",
        "physics.ed-ph",
        "physics.pop-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1103/PhysRevA.67.060702",
      "title": "Correlation structure in nondipole photoionization",
      "abstract": "  The nondipole parameters that characterize the angular disribution of the\nphotoelectrons from the 3d subshell of Cs are found to be altered qualitatively\nby the inclusion of correlation in the form of interchannel coupling between\nthe $3d_{3/2}$ and $3d_{5/2}$ photoionization channels. A prominent\ncharacteristic maximum is predicted only in the parameters for $3d_{5/2}$\nphotoionization, while the effect for $3d_{3/2}$ is rather weak. The results\nare obtained within the framework of the Generalized Random Phase Approximation\nwith Exchange (GRPAE), which in addition to the RPAE effects takes into account\nthe rearrangement of all atomic electrons due to the creation of a 3d vacancy.\n",
      "subjects": [
        "physics.atom-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Structure of Unilamellar Dimyristoylphosphatidylcholine Vesicle.\n  Small-Angle Neutron Scattering Study",
      "abstract": "  On the basis of the separated form-factor model, a code for fitting the\nsmall-angle neutron scattering spectra of the polydispersed vesicle population\nhas been developed. Vesicle and membrane bilayer parameters are analyzed for\nvarious hierarchical models of the neutron scattering length density across the\nmembrane. It is shown that hydration of vesicle can be described by a linear\ndistribution function of water molecules. For the first time, the average\nradius and polydispersity of the vesicle population, thickness of the membrane\nbilayer, thickness of hydrophobic and hydrophilic parts of bilayer, and water\ndistribution function have been calculated from the SANS experiment, without\nadditional methods such as dynamic light scattering or freeze-fracture electron\nmicroscopy. The results, obtained at two different spectrometers, are\ndiscussed. The appropriate conditions of the SANS experiment on vesicles are\nformulated as a necessity to collect the SANS curve in the region of scattering\nvectors from qmin=0.0033 1/angstrom to qmax=0.56 1/angstrom.\n",
      "subjects": [
        "physics.chem-ph",
        "physics.bio-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.nima.2005.07.070",
      "title": "ATLAS Pixel Opto-Electronics",
      "abstract": "  We have developed two radiation-hard ASICs for optical data transmission in\nthe ATLAS pixel detector at the LHC at CERN: a driver chip for a Vertical\nCavity Surface Emitting Laser (VCSEL) diode for 80 Mbit/s data transmission\nfrom the detector, and a Bi-Phase Mark decoder chip to recover the control data\nand 40 MHz clock received optically by a PIN diode. We have successfully\nimplemented both ASICs in 0.25 micron CMOS technology using enclosed layout\ntransistors and guard rings for increased radiation hardness. We present\nresults of the performance of these chips, including irradiation with 24 GeV\nprotons up to 61 Mrad (2.3 x 10e15 p/cm^2).\n",
      "subjects": [
        "physics.ins-det",
        "hep-ex",
        "physics.acc-ph"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1016/j.asr.2005.05.019",
      "title": "Numerical Study of Structural Phase Transitions in a Vertically Confined\n  Plasma Crystal",
      "abstract": "  Dusty plasmas consists of an ionized gas containing small (usually negatively\ncharged) particles. Dusty plasmas are of interest in both astrophysics and\nspace physics as well as in research in plasma processing and nanofabrication.\nIn this work, the formation of plasma crystals confined in an external\none-dimensional parabolic potential well is simulated for a normal experimental\nenvironment employing a computer code called BOX_TREE. Such crystals are\nlayered systems, with each layer a two dimensional lattice composed of grain\nparticles. The number of layers is dependent upon the external potential\nparameter. For constant layer number, the intralayer structure transits from a\nsquare lattice to a hexagonal (triangular) lattice as the confining potential\ndecreases. For hexagonal lattices, both hcp and fcc characteristics were found\nbut hcp structures dominate. The relative thickness of the system was also\nexamined. The results were compared with previous experimental and theoretical\nresults and found to agree.\n",
      "subjects": [
        "physics.atm-clus"
      ]
    },
    {
      "source": "arXiv",
      "identifier": "10.1063/1.1428084",
      "title": "Stability of an oscillating tip in Non-Contact Atomic Force Microscopy:\n  theoretical and numerical investigations",
      "abstract": "  This paper is a theoretical and a numerical investigation of the stability of\na tip-cantilever system used in Non-Contact Atomic Force Microscopy (NC-AFM)\nwhen it oscillates close to a surface. No additional dissipative force is\nconsidered. The theoretical approach is based on a variationnal method\nexploiting a coarse grained operation that gives the temporal dependence of the\nnonlinear coupled equations of motion in amplitude and phase of the oscillator.\nStability criterions for the resonance peak are deduced and predict a stable\nbehavior of the oscillator in the vicinity of the resonance. The numerical\napproach is based on results obtained with a virtual NC-AFM developped in our\ngroup. The effect of the size of the stable domain in phase is investigated.\nThese results are in particularly good agreement with the theoretical\npredictions. Also they show the influence of the phase shifter in the feedback\nloop and the way it can affect the damping signal.\n",
      "subjects": [
        "physics.atm-clus"
      ]
    },
    {
      "source": "arXiv",
      "identifier": null,
      "title": "Alternative method of generation of Cerenkov radiation or shock wave",
      "abstract": "  An alternative method of generation of Cerenkev radiation is proposed over\nhere with the help of a rotating source and a reflector. The principle is that,\nif we focus a narrow beam of light on to source of light is rotated with\ncertain angular velocity then the light spot on the surface will move with very\nhigh velocity which may exceed the velocity of light. As a consequence of this\nwe shall observe an effect very similar to Cerknov radiation.\n",
      "subjects": [
        "physics.gen-ph"
      ]
    }
  ]
}